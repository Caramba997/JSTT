[{"url":"https://api.github.com/repos/evanw/esbuild/issues/2451","repository_url":"https://api.github.com/repos/evanw/esbuild","labels_url":"https://api.github.com/repos/evanw/esbuild/issues/2451/labels{/name}","comments_url":"https://api.github.com/repos/evanw/esbuild/issues/2451/comments","events_url":"https://api.github.com/repos/evanw/esbuild/issues/2451/events","html_url":"https://github.com/evanw/esbuild/pull/2451","id":1333976080,"node_id":"PR_kwDOA6ThAc487K9q","number":2451,"title":"Implement the Yarn Plug'n'Play module resolution algorithm","user":{"login":"evanw","id":406394,"node_id":"MDQ6VXNlcjQwNjM5NA==","avatar_url":"https://avatars.githubusercontent.com/u/406394?v=4","gravatar_id":"","url":"https://api.github.com/users/evanw","html_url":"https://github.com/evanw","followers_url":"https://api.github.com/users/evanw/followers","following_url":"https://api.github.com/users/evanw/following{/other_user}","gists_url":"https://api.github.com/users/evanw/gists{/gist_id}","starred_url":"https://api.github.com/users/evanw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/evanw/subscriptions","organizations_url":"https://api.github.com/users/evanw/orgs","repos_url":"https://api.github.com/users/evanw/repos","events_url":"https://api.github.com/users/evanw/events{/privacy}","received_events_url":"https://api.github.com/users/evanw/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-08-10T02:25:01Z","updated_at":"2022-08-10T11:15:50Z","closed_at":"2022-08-10T02:59:21Z","author_association":"OWNER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/evanw/esbuild/pulls/2451","html_url":"https://github.com/evanw/esbuild/pull/2451","diff_url":"https://github.com/evanw/esbuild/pull/2451.diff","patch_url":"https://github.com/evanw/esbuild/pull/2451.patch","merged_at":"2022-08-10T02:59:21Z"},"body":"[Node](https://nodejs.org/) comes with a package manager called [npm](https://www.npmjs.com/), which installs packages into a `node_modules` folder. Node and esbuild both come with built-in rules for resolving import paths to packages within `node_modules`, so packages installed via npm work automatically without any configuration. However, many people use an alternative package manager called [Yarn](https://yarnpkg.com/). While Yarn can install packages using `node_modules`, it also offers a different package installation strategy called [Plug'n'Play](https://yarnpkg.com/features/pnp/), which is often shortened to \"PnP\" (not to be confused with [pnpm](https://pnpm.io/), which is an entirely different unrelated package manager).\r\n\r\nPlug'n'Play installs packages as `.zip` files on your file system. The packages are never actually unzipped. Since Node doesn't know anything about Yarn's package installation strategy, this means you can no longer run your code with Node as it won't be able to find your packages. Instead, you need to run your code with Yarn, which applies patches to Node's file system APIs before running your code. These patches attempt to make zip files seem like normal directories. When running under Yarn, using Node's file system API to read `./some.zip/lib/file.js` actually automatically extracts `lib/file.js` from `./some.zip` at run-time as if it was a normal file. Other file system APIs behave similarly. However, these patches don't work with esbuild because esbuild is not written in JavaScript; it's a native binary executable that interacts with the file system directly through the operating system.\r\n\r\nPreviously the workaround for using esbuild with Plug'n'Play was to use the [`@yarnpkg/esbuild-plugin-pnp`](https://www.npmjs.com/package/@yarnpkg/esbuild-plugin-pnp) plugin with esbuild's JavaScript API. However, this wasn't great because the plugin needed to potentially intercept every single import path and file load to check whether it was a Plug'n'Play package, which has an unusually high performance cost. It also meant that certain subtleties of path resolution rules within a `.zip` file could differ slightly from the way esbuild normally works since path resolution inside `.zip` files was implemented by Yarn, not by esbuild (which is due to a limitation of esbuild's plugin API).\r\n\r\nWith this PR, esbuild now contains an independent implementation of Yarn's Plug'n'Play algorithm (which is used when esbuild finds a `.pnp.js`, `.pnp.cjs`, or `.pnp.data.json` file in the directory tree). Creating additional implementations of this algorithm recently became possible because Yarn's package manifest format was recently documented: https://yarnpkg.com/advanced/pnp-spec/. This should mean that you can now use esbuild to bundle Plug'n'Play projects without any additional configuration (so you shouldn't need `@yarnpkg/esbuild-plugin-pnp` anymore). Bundling these projects should now happen much faster as Yarn no longer even needs to be run at all. And path resolution rules within Yarn packages should now be consistent with how esbuild handles regular Node packages. For example, fields such as `module` and `browser` in `package.json` files within `.zip` files should now be respected.\r\n\r\nKeep in mind that this is brand new code and there may be some initial issues to work through before esbuild's implementation is solid. Yarn's Plug'n'Play specification is also brand new and may need some follow-up edits to guide new implementations to match Yarn's exact behavior. If you try this out, make sure to test it before committing to using it, and let me know if anything isn't working as expected. Should you need to debug esbuild's path resolution, you may find `--log-level=verbose` helpful.\r\n","reactions":{"url":"https://api.github.com/repos/evanw/esbuild/issues/2451/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/evanw/esbuild/issues/2451/timeline","performed_via_github_app":null,"state_reason":null,"score":1,"files":[{"sha":"6af330e1f5fa593bcc4887656e5f56f6aaf6d90c","filename":"CHANGELOG.md","status":"modified","additions":16,"deletions":0,"changes":16,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/CHANGELOG.md","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/CHANGELOG.md","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/CHANGELOG.md?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -1,5 +1,21 @@\n # Changelog\n \n+## Unreleased\n+\n+**This release contains backwards-incompatible changes.** Since esbuild is before version 1.0.0, these changes have been released as a new minor version to reflect this (as [recommended by npm](https://docs.npmjs.com/cli/v6/using-npm/semver/)). You should either be pinning the exact version of `esbuild` in your `package.json` file or be using a version range syntax that only accepts patch upgrades such as `~0.14.0`. See the documentation about [semver](https://docs.npmjs.com/cli/v6/using-npm/semver/) for more information.\n+\n+* Implement the Yarn Plug'n'Play module resolution algorithm ([#154](https://github.com/evanw/esbuild/issues/154), [#237](https://github.com/evanw/esbuild/issues/237), [#1263](https://github.com/evanw/esbuild/issues/1263), [#2451](https://github.com/evanw/esbuild/pull/2451))\n+\n+    [Node](https://nodejs.org/) comes with a package manager called [npm](https://www.npmjs.com/), which installs packages into a `node_modules` folder. Node and esbuild both come with built-in rules for resolving import paths to packages within `node_modules`, so packages installed via npm work automatically without any configuration. However, many people use an alternative package manager called [Yarn](https://yarnpkg.com/). While Yarn can install packages using `node_modules`, it also offers a different package installation strategy called [Plug'n'Play](https://yarnpkg.com/features/pnp/), which is often shortened to \"PnP\" (not to be confused with [pnpm](https://pnpm.io/), which is an entirely different unrelated package manager).\n+\n+    Plug'n'Play installs packages as `.zip` files on your file system. The packages are never actually unzipped. Since Node doesn't know anything about Yarn's package installation strategy, this means you can no longer run your code with Node as it won't be able to find your packages. Instead, you need to run your code with Yarn, which applies patches to Node's file system APIs before running your code. These patches attempt to make zip files seem like normal directories. When running under Yarn, using Node's file system API to read `./some.zip/lib/file.js` actually automatically extracts `lib/file.js` from `./some.zip` at run-time as if it was a normal file. Other file system APIs behave similarly. However, these patches don't work with esbuild because esbuild is not written in JavaScript; it's a native binary executable that interacts with the file system directly through the operating system.\n+\n+    Previously the workaround for using esbuild with Plug'n'Play was to use the [`@yarnpkg/esbuild-plugin-pnp`](https://www.npmjs.com/package/@yarnpkg/esbuild-plugin-pnp) plugin with esbuild's JavaScript API. However, this wasn't great because the plugin needed to potentially intercept every single import path and file load to check whether it was a Plug'n'Play package, which has an unusually high performance cost. It also meant that certain subtleties of path resolution rules within a `.zip` file could differ slightly from the way esbuild normally works since path resolution inside `.zip` files was implemented by Yarn, not by esbuild (which is due to a limitation of esbuild's plugin API).\n+\n+    With this release, esbuild now contains an independent implementation of Yarn's Plug'n'Play algorithm (which is used when esbuild finds a `.pnp.js`, `.pnp.cjs`, or `.pnp.data.json` file in the directory tree). Creating additional implementations of this algorithm recently became possible because Yarn's package manifest format was recently documented: https://yarnpkg.com/advanced/pnp-spec/. This should mean that you can now use esbuild to bundle Plug'n'Play projects without any additional configuration (so you shouldn't need `@yarnpkg/esbuild-plugin-pnp` anymore). Bundling these projects should now happen much faster as Yarn no longer even needs to be run at all. And path resolution rules within Yarn packages should now be consistent with how esbuild handles regular Node packages. For example, fields such as `module` and `browser` in `package.json` files within `.zip` files should now be respected.\n+\n+    Keep in mind that this is brand new code and there may be some initial issues to work through before esbuild's implementation is solid. Yarn's Plug'n'Play specification is also brand new and may need some follow-up edits to guide new implementations to match Yarn's exact behavior. If you try this out, make sure to test it before committing to using it, and let me know if anything isn't working as expected. Should you need to debug esbuild's path resolution, you may find `--log-level=verbose` helpful.\n+\n ## 0.14.54\n \n * Fix optimizations for calls containing spread arguments ([#2445](https://github.com/evanw/esbuild/issues/2445))"},{"sha":"11b5c604d6dbb3660584d262f1a381ea5f42b910","filename":"internal/js_ast/js_ast.go","status":"modified","additions":3,"deletions":0,"changes":3,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fjs_ast%2Fjs_ast.go","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fjs_ast%2Fjs_ast.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_ast%2Fjs_ast.go?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -1771,6 +1771,9 @@ type AST struct {\n \tModuleScope    *Scope\n \tCharFreq       *CharFreq\n \n+\t// This is internal-only data used for the implementation of Yarn PnP\n+\tManifestForYarnPnP Expr\n+\n \tHashbang  string\n \tDirective string\n \tURLForCSS string"},{"sha":"ecc82576643de81579f72a09caa45a6707e497cb","filename":"internal/js_parser/js_parser.go","status":"modified","additions":73,"deletions":0,"changes":73,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fjs_parser%2Fjs_parser.go","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fjs_parser%2Fjs_parser.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_parser%2Fjs_parser.go?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -149,6 +149,10 @@ type parser struct {\n \tloopBody         js_ast.S\n \tmoduleScope      *js_ast.Scope\n \n+\t// This is internal-only data used for the implementation of Yarn PnP\n+\tmanifestForYarnPnP     js_ast.Expr\n+\tstringLocalsForYarnPnP map[js_ast.Ref]stringLocalForYarnPnP\n+\n \t// This helps recognize the \"await import()\" pattern. When this is present,\n \t// warnings about non-string import paths will be omitted inside try blocks.\n \tawaitTarget js_ast.E\n@@ -341,6 +345,11 @@ type parser struct {\n \tisControlFlowDead        bool\n }\n \n+type stringLocalForYarnPnP struct {\n+\tvalue []uint16\n+\tloc   logger.Loc\n+}\n+\n type injectedSymbolSource struct {\n \tsource logger.Source\n \tloc    logger.Loc\n@@ -414,6 +423,17 @@ type optionsThatSupportStructuralEquality struct {\n \tmangleQuoted            bool\n \tunusedImportFlagsTS     config.UnusedImportFlagsTS\n \tuseDefineForClassFields config.MaybeBool\n+\n+\t// This is an internal-only option used for the implementation of Yarn PnP\n+\tdecodeHydrateRuntimeStateYarnPnP bool\n+}\n+\n+func OptionsForYarnPnP() Options {\n+\treturn Options{\n+\t\toptionsThatSupportStructuralEquality: optionsThatSupportStructuralEquality{\n+\t\t\tdecodeHydrateRuntimeStateYarnPnP: true,\n+\t\t},\n+\t}\n }\n \n func OptionsFromConfig(options *config.Options) Options {\n@@ -9463,6 +9483,18 @@ func (p *parser) visitAndAppendStmt(stmts []js_ast.Stmt, stmt js_ast.Stmt) []js_\n \t\t\t\t\t\t}\n \t\t\t\t\t}\n \t\t\t\t}\n+\n+\t\t\t\t// Yarn's PnP data may be stored in a variable: https://github.com/yarnpkg/berry/pull/4320\n+\t\t\t\tif p.options.decodeHydrateRuntimeStateYarnPnP {\n+\t\t\t\t\tif str, ok := d.ValueOrNil.Data.(*js_ast.EString); ok {\n+\t\t\t\t\t\tif id, ok := d.Binding.Data.(*js_ast.BIdentifier); ok {\n+\t\t\t\t\t\t\tif p.stringLocalsForYarnPnP == nil {\n+\t\t\t\t\t\t\t\tp.stringLocalsForYarnPnP = make(map[js_ast.Ref]stringLocalForYarnPnP)\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\tp.stringLocalsForYarnPnP[id.Ref] = stringLocalForYarnPnP{value: str.Value, loc: d.ValueOrNil.Loc}\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n \t\t\t}\n \n \t\t\t// Attempt to continue the const local prefix\n@@ -14039,6 +14071,46 @@ func (p *parser) visitExprInOut(expr js_ast.Expr, in exprIn) (js_ast.Expr, exprO\n \t\t\te.Args[i] = arg\n \t\t}\n \n+\t\t// Our hack for reading Yarn PnP files is implemented here:\n+\t\tif p.options.decodeHydrateRuntimeStateYarnPnP {\n+\t\t\tif id, ok := e.Target.Data.(*js_ast.EIdentifier); ok && p.symbols[id.Ref.InnerIndex].OriginalName == \"hydrateRuntimeState\" && len(e.Args) >= 1 {\n+\t\t\t\tswitch arg := e.Args[0].Data.(type) {\n+\t\t\t\tcase *js_ast.EObject:\n+\t\t\t\t\t// \"hydrateRuntimeState(<object literal>)\"\n+\t\t\t\t\tif arg := e.Args[0]; isValidJSON(arg) {\n+\t\t\t\t\t\tp.manifestForYarnPnP = arg\n+\t\t\t\t\t}\n+\n+\t\t\t\tcase *js_ast.ECall:\n+\t\t\t\t\t// \"hydrateRuntimeState(JSON.parse(<something>))\"\n+\t\t\t\t\tif len(arg.Args) == 1 {\n+\t\t\t\t\t\tif dot, ok := arg.Target.Data.(*js_ast.EDot); ok && dot.Name == \"parse\" {\n+\t\t\t\t\t\t\tif id, ok := dot.Target.Data.(*js_ast.EIdentifier); ok {\n+\t\t\t\t\t\t\t\tif symbol := &p.symbols[id.Ref.InnerIndex]; symbol.Kind == js_ast.SymbolUnbound && symbol.OriginalName == \"JSON\" {\n+\t\t\t\t\t\t\t\t\targ := arg.Args[0]\n+\t\t\t\t\t\t\t\t\tswitch a := arg.Data.(type) {\n+\t\t\t\t\t\t\t\t\tcase *js_ast.EString:\n+\t\t\t\t\t\t\t\t\t\t// \"hydrateRuntimeState(JSON.parse(<string literal>))\"\n+\t\t\t\t\t\t\t\t\t\tsource := logger.Source{KeyPath: p.source.KeyPath, Contents: helpers.UTF16ToString(a.Value)}\n+\t\t\t\t\t\t\t\t\t\tlog := logger.NewStringInJSLog(p.log, &p.tracker, arg.Loc, source.Contents)\n+\t\t\t\t\t\t\t\t\t\tp.manifestForYarnPnP, _ = ParseJSON(log, source, JSONOptions{})\n+\n+\t\t\t\t\t\t\t\t\tcase *js_ast.EIdentifier:\n+\t\t\t\t\t\t\t\t\t\t// \"hydrateRuntimeState(JSON.parse(<identifier>))\"\n+\t\t\t\t\t\t\t\t\t\tif data, ok := p.stringLocalsForYarnPnP[a.Ref]; ok {\n+\t\t\t\t\t\t\t\t\t\t\tsource := logger.Source{KeyPath: p.source.KeyPath, Contents: helpers.UTF16ToString(data.value)}\n+\t\t\t\t\t\t\t\t\t\t\tlog := logger.NewStringInJSLog(p.log, &p.tracker, data.loc, source.Contents)\n+\t\t\t\t\t\t\t\t\t\t\tp.manifestForYarnPnP, _ = ParseJSON(log, source, JSONOptions{})\n+\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n \t\t// Stop now if this call must be removed\n \t\tif out.methodCallMustBeReplacedWithUndefined {\n \t\t\tp.isControlFlowDead = oldIsControlFlowDead\n@@ -16486,6 +16558,7 @@ func (p *parser) toAST(before, parts, after []js_ast.Part, hashbang string, dire\n \t\tApproximateLineCount:            int32(p.lexer.ApproximateNewlineCount) + 1,\n \t\tMangledProps:                    p.mangledProps,\n \t\tReservedProps:                   p.reservedProps,\n+\t\tManifestForYarnPnP:              p.manifestForYarnPnP,\n \n \t\t// CommonJS features\n \t\tUsesExportsRef: usesExportsRef,"},{"sha":"8a77adc29a02ee5452889f383451a0b9d8ff9b95","filename":"internal/js_parser/json_parser.go","status":"modified","additions":31,"deletions":0,"changes":31,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fjs_parser%2Fjson_parser.go","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fjs_parser%2Fjson_parser.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_parser%2Fjson_parser.go?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -187,3 +187,34 @@ func ParseJSON(log logger.Log, source logger.Source, options JSONOptions) (resul\n \tp.lexer.Expect(js_lexer.TEndOfFile)\n \treturn\n }\n+\n+func isValidJSON(value js_ast.Expr) bool {\n+\tswitch e := value.Data.(type) {\n+\tcase *js_ast.ENull, *js_ast.EBoolean, *js_ast.EString, *js_ast.ENumber:\n+\t\treturn true\n+\n+\tcase *js_ast.EArray:\n+\t\tfor _, item := range e.Items {\n+\t\t\tif !isValidJSON(item) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t}\n+\t\treturn true\n+\n+\tcase *js_ast.EObject:\n+\t\tfor _, property := range e.Properties {\n+\t\t\tif property.Kind != js_ast.PropertyNormal || property.Flags&(js_ast.PropertyIsComputed|js_ast.PropertyIsMethod) != 0 {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\tif _, ok := property.Key.Data.(*js_ast.EString); !ok {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\tif !isValidJSON(property.ValueOrNil) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t}\n+\t\treturn true\n+\t}\n+\n+\treturn false\n+}"},{"sha":"323b86067e124c96f9c68f17c466661ef7670e35","filename":"internal/logger/logger.go","status":"modified","additions":162,"deletions":0,"changes":162,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Flogger%2Flogger.go","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Flogger%2Flogger.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Flogger%2Flogger.go?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -1686,3 +1686,165 @@ func allowOverride(overrides map[MsgID]LogLevel, id MsgID, kind MsgKind) (MsgKin\n \t}\n \treturn kind, true\n }\n+\n+// For Yarn PnP we sometimes parse JSON embedded in a JS string. This is a shim\n+// that remaps log message locations inside the embedded string literal into\n+// log messages in the actual JS file, which makes them easier to understand.\n+func NewStringInJSLog(log Log, outerTracker *LineColumnTracker, outerStringLiteralLoc Loc, innerContents string) Log {\n+\ttype entry struct {\n+\t\tline   int32\n+\t\tcolumn int32\n+\t\tloc    Loc\n+\t}\n+\n+\tvar table []entry\n+\toldAddMsg := log.AddMsg\n+\n+\tgenerateTable := func() {\n+\t\ti := 0\n+\t\tn := len(innerContents)\n+\t\tline := int32(1)\n+\t\tcolumn := int32(0)\n+\t\tloc := Loc{Start: outerStringLiteralLoc.Start + 1}\n+\t\touterContents := outerTracker.contents\n+\n+\t\tfor i < n {\n+\t\t\t// Ignore line continuations. A line continuation is not an escaped newline.\n+\t\t\tfor {\n+\t\t\t\tif c, _ := utf8.DecodeRuneInString(outerContents[loc.Start:]); c != '\\\\' {\n+\t\t\t\t\tbreak\n+\t\t\t\t}\n+\t\t\t\tc, width := utf8.DecodeRuneInString(outerContents[loc.Start+1:])\n+\t\t\t\tswitch c {\n+\t\t\t\tcase '\\n', '\\r', '\\u2028', '\\u2029':\n+\t\t\t\t\tloc.Start += 1 + int32(width)\n+\t\t\t\t\tif c == '\\r' && outerContents[loc.Start] == '\\n' {\n+\t\t\t\t\t\t// Make sure Windows CRLF counts as a single newline\n+\t\t\t\t\t\tloc.Start++\n+\t\t\t\t\t}\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\tbreak\n+\t\t\t}\n+\n+\t\t\tc, width := utf8.DecodeRuneInString(innerContents[i:])\n+\n+\t\t\t// Compress the table using run-length encoding\n+\t\t\ttable = append(table, entry{line: line, column: column, loc: loc})\n+\t\t\tif len(table) > 1 {\n+\t\t\t\tif last := table[len(table)-2]; line == last.line && loc.Start-column == last.loc.Start-last.column {\n+\t\t\t\t\ttable = table[:len(table)-1]\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\t// Advance the inner line/column\n+\t\t\tswitch c {\n+\t\t\tcase '\\n', '\\r', '\\u2028', '\\u2029':\n+\t\t\t\tline++\n+\t\t\t\tcolumn = 0\n+\n+\t\t\t\t// Handle newlines on Windows\n+\t\t\t\tif c == '\\r' && i+1 < n && innerContents[i+1] == '\\n' {\n+\t\t\t\t\ti++\n+\t\t\t\t}\n+\n+\t\t\tdefault:\n+\t\t\t\tcolumn += int32(width)\n+\t\t\t}\n+\t\t\ti += width\n+\n+\t\t\t// Advance the outer loc, assuming the string syntax is already valid\n+\t\t\tc, width = utf8.DecodeRuneInString(outerContents[loc.Start:])\n+\t\t\tif c == '\\r' && outerContents[loc.Start] == '\\n' {\n+\t\t\t\t// Handle newlines on Windows in template literal strings\n+\t\t\t\tloc.Start += 2\n+\t\t\t} else if c != '\\\\' {\n+\t\t\t\tloc.Start += int32(width)\n+\t\t\t} else {\n+\t\t\t\t// Handle an escape sequence\n+\t\t\t\tc, width = utf8.DecodeRuneInString(outerContents[loc.Start+1:])\n+\t\t\t\tswitch c {\n+\t\t\t\tcase 'x':\n+\t\t\t\t\t// 2-digit hexadecimal\n+\t\t\t\t\tloc.Start += 1 + 2\n+\n+\t\t\t\tcase 'u':\n+\t\t\t\t\tloc.Start++\n+\t\t\t\t\tif outerContents[loc.Start] == '{' {\n+\t\t\t\t\t\t// Variable-length\n+\t\t\t\t\t\tfor outerContents[loc.Start] != '}' {\n+\t\t\t\t\t\t\tloc.Start++\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\tloc.Start++\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\t// Fixed-length\n+\t\t\t\t\t\tloc.Start += 4\n+\t\t\t\t\t}\n+\n+\t\t\t\tcase '\\n', '\\r', '\\u2028', '\\u2029':\n+\t\t\t\t\t// This will be handled by the next iteration\n+\t\t\t\t\tbreak\n+\n+\t\t\t\tdefault:\n+\t\t\t\t\tloc.Start += int32(width)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tremapLineAndColumnToLoc := func(line int32, column int32) Loc {\n+\t\tcount := len(table)\n+\t\tindex := 0\n+\n+\t\t// Binary search to find the previous entry\n+\t\tfor count > 0 {\n+\t\t\tstep := count / 2\n+\t\t\ti := index + step\n+\t\t\tif i+1 < len(table) {\n+\t\t\t\tif entry := table[i+1]; entry.line < line || (entry.line == line && entry.column < column) {\n+\t\t\t\t\tindex = i + 1\n+\t\t\t\t\tcount -= step + 1\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tcount = step\n+\t\t}\n+\n+\t\tentry := table[index]\n+\t\tentry.loc.Start += column - entry.column // Undo run-length compression\n+\t\treturn entry.loc\n+\t}\n+\n+\tremapData := func(data MsgData) MsgData {\n+\t\tif data.Location == nil {\n+\t\t\treturn data\n+\t\t}\n+\n+\t\t// Generate and cache a lookup table to accelerate remappings\n+\t\tif table == nil {\n+\t\t\tgenerateTable()\n+\t\t}\n+\n+\t\t// Generate a range in the outer source using the line/column/length in the inner source\n+\t\tr := Range{Loc: remapLineAndColumnToLoc(int32(data.Location.Line), int32(data.Location.Column))}\n+\t\tif data.Location.Length != 0 {\n+\t\t\tr.Len = remapLineAndColumnToLoc(int32(data.Location.Line), int32(data.Location.Column+data.Location.Length)).Start - r.Loc.Start\n+\t\t}\n+\n+\t\t// Use that range to look up the line in the outer source\n+\t\tlocation := outerTracker.MsgData(r, data.Text).Location\n+\t\tlocation.Suggestion = data.Location.Suggestion\n+\t\tdata.Location = location\n+\t\treturn data\n+\t}\n+\n+\tlog.AddMsg = func(msg Msg) {\n+\t\tmsg.Data = remapData(msg.Data)\n+\t\tfor i, note := range msg.Notes {\n+\t\t\tmsg.Notes[i] = remapData(note)\n+\t\t}\n+\t\toldAddMsg(msg)\n+\t}\n+\n+\treturn log\n+}"},{"sha":"3feead3d9a9306345d0993b1ec6e5539bbac5d7b","filename":"internal/resolver/resolver.go","status":"modified","additions":31,"deletions":0,"changes":31,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fresolver%2Fresolver.go","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fresolver%2Fresolver.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fresolver%2Fresolver.go?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -691,6 +691,18 @@ func (r resolverQuery) finalizeResolve(result *ResolveResult) {\n }\n \n func (r resolverQuery) resolveWithoutSymlinks(sourceDir string, sourceDirInfo *dirInfo, importPath string) *ResolveResult {\n+\t// Find the parent directory with the Yarn PnP data\n+\tfor info := sourceDirInfo; info != nil; info = info.parent {\n+\t\tif info.pnpData != nil {\n+\t\t\tif result, ok := r.pnpResolve(importPath, sourceDirInfo.absPath, info.pnpData); ok {\n+\t\t\t\timportPath = result // Continue with the module resolution algorithm from node.js\n+\t\t\t} else {\n+\t\t\t\treturn nil // This is a module resolution error\n+\t\t\t}\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\n \t// This implements the module resolution algorithm from node.js, which is\n \t// described here: https://nodejs.org/api/modules.html#modules_all_together\n \tvar result ResolveResult\n@@ -848,6 +860,7 @@ type dirInfo struct {\n \t// All relevant information about this directory\n \tabsPath               string\n \tentries               fs.DirEntries\n+\tpnpData               *pnpData\n \tpackageJSON           *packageJSON  // Is there a \"package.json\" file in this directory?\n \tenclosingPackageJSON  *packageJSON  // Is there a \"package.json\" file in this directory or a parent directory?\n \tenclosingTSConfigJSON *TSConfigJSON // Is there a \"tsconfig.json\" file in this directory or a parent directory?\n@@ -1176,6 +1189,24 @@ func (r resolverQuery) dirInfoUncached(path string) *dirInfo {\n \t\t}\n \t}\n \n+\t// Record if this directory has a Yarn PnP data file\n+\tif pnp, _ := entries.Get(\".pnp.data.json\"); pnp != nil && pnp.Kind(r.fs) == fs.FileEntry {\n+\t\tabsPath := r.fs.Join(path, \".pnp.data.json\")\n+\t\tif json := r.extractYarnPnPDataFromJSON(absPath, &r.caches.JSONCache); json.Data != nil {\n+\t\t\tinfo.pnpData = compileYarnPnPData(absPath, path, json)\n+\t\t}\n+\t} else if pnp, _ := entries.Get(\".pnp.cjs\"); pnp != nil && pnp.Kind(r.fs) == fs.FileEntry {\n+\t\tabsPath := r.fs.Join(path, \".pnp.cjs\")\n+\t\tif json := r.tryToExtractYarnPnPDataFromJS(absPath, &r.caches.JSONCache); json.Data != nil {\n+\t\t\tinfo.pnpData = compileYarnPnPData(absPath, path, json)\n+\t\t}\n+\t} else if pnp, _ := entries.Get(\".pnp.js\"); pnp != nil && pnp.Kind(r.fs) == fs.FileEntry {\n+\t\tabsPath := r.fs.Join(path, \".pnp.js\")\n+\t\tif json := r.tryToExtractYarnPnPDataFromJS(absPath, &r.caches.JSONCache); json.Data != nil {\n+\t\t\tinfo.pnpData = compileYarnPnPData(absPath, path, json)\n+\t\t}\n+\t}\n+\n \treturn info\n }\n "},{"sha":"7a44b4339f16651bb87d9211f15c0a778e3d1a5c","filename":"internal/resolver/testExpectations.json","status":"added","additions":311,"deletions":0,"changes":311,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fresolver%2FtestExpectations.json","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fresolver%2FtestExpectations.json","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fresolver%2FtestExpectations.json?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -0,0 +1,311 @@\n+[{\n+  \"manifest\": {\n+    \"__info\": [],\n+    \"dependencyTreeRoots\": [{\n+      \"name\": \"root\",\n+      \"reference\": \"workspace:.\"\n+    }],\n+    \"ignorePatternData\": null,\n+    \"enableTopLevelFallback\": false,\n+    \"fallbackPool\": [],\n+    \"fallbackExclusionList\": [],\n+    \"packageRegistryData\": [\n+      [null, [\n+        [null, {\n+          \"packageLocation\": \"./\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"root\", [\n+        [\"workspace:.\", {\n+          \"packageLocation\": \"./\",\n+          \"packageDependencies\": [[\"test\", \"npm:1.0.0\"]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"workspace-alias-dependency\", [\n+        [\"workspace:workspace-alias-dependency\", {\n+          \"packageLocation\": \"./workspace-alias-dependency/\",\n+          \"packageDependencies\": [[\"alias\", [\"test\", \"npm:1.0.0\"]]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"workspace-self-dependency\", [\n+        [\"workspace:workspace-self-dependency\", {\n+          \"packageLocation\": \"./workspace-self-dependency/\",\n+          \"packageDependencies\": [[\"workspace-self-dependency\", \"workspace:workspace-self-dependency\"]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"workspace-unfulfilled-peer-dependency\", [\n+        [\"workspace:workspace-unfulfilled-peer-dependency\", {\n+          \"packageLocation\": \"./workspace-unfulfilled-peer-dependency/\",\n+          \"packageDependencies\": [[\"test\", null]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"longer\", [\n+        [\"workspace:longer\", {\n+          \"packageLocation\": \"./longer/\",\n+          \"packageDependencies\": [[\"test\", \"npm:2.0.0\"]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"long\", [\n+        [\"workspace:long\", {\n+          \"packageLocation\": \"./long/\",\n+          \"packageDependencies\": [[\"test\", \"npm:1.0.0\"]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"longerer\", [\n+        [\"workspace:longerer\", {\n+          \"packageLocation\": \"./longerer/\",\n+          \"packageDependencies\": [[\"test\", \"npm:3.0.0\"]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"test\", [\n+        [\"npm:1.0.0\", {\n+          \"packageLocation\": \"./test-1.0.0/\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"HARD\"\n+        }],\n+        [\"npm:2.0.0\", {\n+          \"packageLocation\": \"./test-2.0.0/\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"HARD\"\n+        }],\n+        [\"npm:3.0.0\", {\n+          \"packageLocation\": \"./test-3.0.0/\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"HARD\"\n+        }]\n+      ]]\n+    ]\n+  },\n+  \"tests\": [{\n+    \"it\": \"should allow a package to import one of its dependencies\",\n+    \"imported\": \"test\",\n+    \"importer\": \"/path/to/project/\",\n+    \"expected\": \"/path/to/project/test-1.0.0/\"\n+  }, {\n+    \"it\": \"should allow a package to import itself, if specified in its own dependencies\",\n+    \"imported\": \"workspace-self-dependency\",\n+    \"importer\": \"/path/to/project/workspace-self-dependency/\",\n+    \"expected\": \"/path/to/project/workspace-self-dependency/\"\n+  }, {\n+    \"it\": \"should allow a package to import an aliased dependency\",\n+    \"imported\": \"alias\",\n+    \"importer\": \"/path/to/project/workspace-alias-dependency/\",\n+    \"expected\": \"/path/to/project/test-1.0.0/\"\n+  }, {\n+    \"it\": \"shouldn't allow a package to import something that isn't one of its dependencies\",\n+    \"imported\": \"missing-dependency\",\n+    \"importer\": \"/path/to/project/\",\n+    \"expected\": \"error!\"\n+  }, {\n+    \"it\": \"shouldn't accidentally discard the trailing slash from the package locations\",\n+    \"imported\": \"test\",\n+    \"importer\": \"/path/to/project/long/\",\n+    \"expected\": \"/path/to/project/test-1.0.0/\"\n+  }, {\n+    \"it\": \"should throw an exception when trying to access an unfulfilled peer dependency\",\n+    \"imported\": \"test\",\n+    \"importer\": \"/path/to/project/workspace-unfulfilled-peer-dependency/\",\n+    \"expected\": \"error!\"\n+  }]\n+}, {\n+  \"manifest\": {\n+    \"__info\": [],\n+    \"dependencyTreeRoots\": [{\n+      \"name\": \"root\",\n+      \"reference\": \"workspace:.\"\n+    }],\n+    \"ignorePatternData\": null,\n+    \"enableTopLevelFallback\": true,\n+    \"fallbackPool\": [\n+      [\"test-2\", \"npm:1.0.0\"],\n+      [\"alias\", [\"test-1\", \"npm:1.0.0\"]]\n+    ],\n+    \"fallbackExclusionList\": [[\n+      \"workspace-no-fallbacks\",\n+      [\"workspace:workspace-no-fallbacks\"]\n+    ]],\n+    \"packageRegistryData\": [\n+      [null, [\n+        [null, {\n+          \"packageLocation\": \"./\",\n+          \"packageDependencies\": [[\"test-1\", \"npm:1.0.0\"]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"root\", [\n+        [\"workspace:.\", {\n+          \"packageLocation\": \"./\",\n+          \"packageDependencies\": [[\"test-1\", \"npm:1.0.0\"]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"workspace-no-fallbacks\", [\n+        [\"workspace:workspace-no-fallbacks\", {\n+          \"packageLocation\": \"./workspace-no-fallbacks/\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"workspace-with-fallbacks\", [\n+        [\"workspace:workspace-with-fallbacks\", {\n+          \"packageLocation\": \"./workspace-with-fallbacks/\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"workspace-unfulfilled-peer-dependency\", [\n+        [\"workspace:workspace-unfulfilled-peer-dependency\", {\n+          \"packageLocation\": \"./workspace-unfulfilled-peer-dependency/\",\n+          \"packageDependencies\": [\n+            [\"test-1\", null],\n+            [\"test-2\", null]\n+          ],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"test-1\", [\n+        [\"npm:1.0.0\", {\n+          \"packageLocation\": \"./test-1/\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"HARD\"\n+        }]\n+      ]],\n+      [\"test-2\", [\n+        [\"npm:1.0.0\", {\n+          \"packageLocation\": \"./test-2/\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"HARD\"\n+        }]\n+      ]]\n+    ]\n+  },\n+  \"tests\": [{\n+    \"it\": \"should allow resolution coming from the fallback pool if enableTopLevelFallback is set to true\",\n+    \"imported\": \"test-1\",\n+    \"importer\": \"/path/to/project/\",\n+    \"expected\": \"/path/to/project/test-1/\"\n+  }, {\n+    \"it\": \"should allow the fallback pool to contain aliases\",\n+    \"imported\": \"alias\",\n+    \"importer\": \"/path/to/project/\",\n+    \"expected\": \"/path/to/project/test-1/\"\n+  }, {\n+    \"it\": \"shouldn't use the fallback pool when the importer package is listed in fallbackExclusionList\",\n+    \"imported\": \"test-1\",\n+    \"importer\": \"/path/to/project/workspace-no-fallbacks/\",\n+    \"expected\": \"error!\"\n+  }, {\n+    \"it\": \"should implicitly use the top-level package dependencies as part of the fallback pool\",\n+    \"imported\": \"test-2\",\n+    \"importer\": \"/path/to/project/workspace-with-fallbacks/\",\n+    \"expected\": \"/path/to/project/test-2/\"\n+  }, {\n+    \"it\": \"should throw an error if a resolution isn't in in the package dependencies, nor inside the fallback pool\",\n+    \"imported\": \"test-3\",\n+    \"importer\": \"/path/to/project/workspace-with-fallbacks/\",\n+    \"expected\": \"error!\"\n+  }, {\n+    \"it\": \"should use the top-level fallback if a dependency is missing because of an unfulfilled peer dependency\",\n+    \"imported\": \"test-1\",\n+    \"importer\": \"/path/to/project/workspace-unfulfilled-peer-dependency/\",\n+    \"expected\": \"/path/to/project/test-1/\"\n+  }, {\n+    \"it\": \"should use the fallback pool if a dependency is missing because of an unfulfilled peer dependency\",\n+    \"imported\": \"test-2\",\n+    \"importer\": \"/path/to/project/workspace-unfulfilled-peer-dependency/\",\n+    \"expected\": \"/path/to/project/test-2/\"\n+  }]\n+}, {\n+  \"manifest\": {\n+    \"__info\": [],\n+    \"dependencyTreeRoots\": [{\n+      \"name\": \"root\",\n+      \"reference\": \"workspace:.\"\n+    }],\n+    \"ignorePatternData\": null,\n+    \"enableTopLevelFallback\": false,\n+    \"fallbackPool\": [\n+      [\"test\", \"npm:1.0.0\"]\n+    ],\n+    \"fallbackExclusionList\": [],\n+    \"packageRegistryData\": [\n+      [null, [\n+        [null, {\n+          \"packageLocation\": \"./\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"root\", [\n+        [\"workspace:.\", {\n+          \"packageLocation\": \"./\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"test\", [\n+        [\"npm:1.0.0\", {\n+          \"packageLocation\": \"./test-1/\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"HARD\"\n+        }]\n+      ]]\n+    ]\n+  },\n+  \"tests\": [{\n+    \"it\": \"should ignore the fallback pool if enableTopLevelFallback is set to false\",\n+    \"imported\": \"test\",\n+    \"importer\": \"/path/to/project/\",\n+    \"expected\": \"error!\"\n+  }]\n+}, {\n+  \"manifest\": {\n+    \"__info\": [],\n+    \"dependencyTreeRoots\": [{\n+      \"name\": \"root\",\n+      \"reference\": \"workspace:.\"\n+    }],\n+    \"ignorePatternData\": \"^not-a-workspace(/|$)\",\n+    \"enableTopLevelFallback\": false,\n+    \"fallbackPool\": [],\n+    \"fallbackExclusionList\": [],\n+    \"packageRegistryData\": [\n+      [null, [\n+        [null, {\n+          \"packageLocation\": \"./\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"root\", [\n+        [\"workspace:.\", {\n+          \"packageLocation\": \"./\",\n+          \"packageDependencies\": [[\"test\", \"npm:1.0.0\"]],\n+          \"linkType\": \"SOFT\"\n+        }]\n+      ]],\n+      [\"test\", [\n+        [\"npm:1.0.0\", {\n+          \"packageLocation\": \"./test/\",\n+          \"packageDependencies\": [],\n+          \"linkType\": \"HARD\"\n+        }]\n+      ]]\n+    ]\n+  },\n+  \"tests\": [{\n+    \"it\": \"shouldn't go through PnP when trying to resolve dependencies from packages covered by ignorePatternData\",\n+    \"imported\": \"test\",\n+    \"importer\": \"/path/to/project/not-a-workspace/\",\n+    \"expected\": \"error!\"\n+  }]\n+}]"},{"sha":"53b77419d03c3b7a7b2fc77e97e9a09b6358701e","filename":"internal/resolver/yarnpnp.go","status":"added","additions":631,"deletions":0,"changes":631,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fresolver%2Fyarnpnp.go","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fresolver%2Fyarnpnp.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fresolver%2Fyarnpnp.go?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -0,0 +1,631 @@\n+package resolver\n+\n+import (\n+\t\"fmt\"\n+\t\"regexp\"\n+\t\"strings\"\n+\n+\t\"github.com/evanw/esbuild/internal/cache\"\n+\t\"github.com/evanw/esbuild/internal/helpers\"\n+\t\"github.com/evanw/esbuild/internal/js_ast\"\n+\t\"github.com/evanw/esbuild/internal/js_parser\"\n+\t\"github.com/evanw/esbuild/internal/logger\"\n+)\n+\n+// This file implements the Yarn PnP specification: https://yarnpkg.com/advanced/pnp-spec/\n+\n+type pnpData struct {\n+\t// A list of package locators that are roots of the dependency tree. There\n+\t// will typically be one entry for each workspace in the project (always at\n+\t// least one, as the top-level package is a workspace by itself).\n+\tdependencyTreeRoots map[string]string\n+\n+\t// Keys are the package idents, values are sets of references. Combining the\n+\t// ident with each individual reference yields the set of affected locators.\n+\tfallbackExclusionList map[string]map[string]bool\n+\n+\t// A map of locators that all packages are allowed to access, regardless\n+\t// whether they list them in their dependencies or not.\n+\tfallbackPool map[string]pnpIdentAndReference\n+\n+\t// A nullable regexp. If set, all project-relative importer paths should be\n+\t// matched against it. If the match succeeds, the resolution should follow\n+\t// the classic Node.js resolution algorithm rather than the Plug'n'Play one.\n+\t// Note that unlike other paths in the manifest, the one checked against this\n+\t// regexp won't begin by `./`.\n+\tignorePatternData *regexp.Regexp\n+\n+\t// This is the main part of the PnP data file. This table contains the list\n+\t// of all packages, first keyed by package ident then by package reference.\n+\t// One entry will have `null` in both fields and represents the absolute\n+\t// top-level package.\n+\tpackageRegistryData map[string]map[string]pnpPackage\n+\n+\tpackageLocatorsByLocations map[string]pnpPackageLocatorByLocation\n+\n+\t// If true, should a dependency resolution fail for an importer that isn't\n+\t// explicitly listed in `fallbackExclusionList`, the runtime must first check\n+\t// whether the resolution would succeed for any of the packages in\n+\t// `fallbackPool`; if it would, transparently return this resolution. Note\n+\t// that all dependencies from the top-level package are implicitly part of\n+\t// the fallback pool, even if not listed here.\n+\tenableTopLevelFallback bool\n+\n+\tabsPath    string\n+\tabsDirPath string\n+}\n+\n+// This is called both a \"locator\" and a \"dependency target\" in the specification.\n+// When it's used as a dependency target, it can only be in one of three states:\n+//\n+//  1. A reference, to link with the dependency name\n+//     In this case ident is \"\".\n+//\n+//  2. An aliased package\n+//     In this case neither ident nor reference are \"\".\n+//\n+//  3. A missing peer dependency\n+//     In this case ident and reference are \"\".\n+type pnpIdentAndReference struct {\n+\tident     string // Empty if null\n+\treference string // Empty if null\n+}\n+\n+type pnpPackage struct {\n+\tpackageDependencies map[string]pnpIdentAndReference\n+\tpackageLocation     string\n+\tdiscardFromLookup   bool\n+}\n+\n+type pnpPackageLocatorByLocation struct {\n+\tlocator           pnpIdentAndReference\n+\tdiscardFromLookup bool\n+}\n+\n+// Note: If this returns successfully then the node module resolution algorithm\n+// (i.e. NM_RESOLVE in the Yarn PnP specification) is always run afterward\n+func (r resolverQuery) pnpResolve(specifier string, parentURL string, parentManifest *pnpData) (string, bool) {\n+\t// If specifier is a Node.js builtin, then\n+\tif BuiltInNodeModules[specifier] {\n+\t\t// Set resolved to specifier itself and return it\n+\t\treturn specifier, true\n+\t}\n+\n+\t// Otherwise, if specifier starts with \"/\", \"./\", or \"../\", then\n+\tif strings.HasPrefix(specifier, \"/\") || strings.HasPrefix(specifier, \"./\") || strings.HasPrefix(specifier, \"../\") {\n+\t\t// Set resolved to NM_RESOLVE(specifier, parentURL) and return it\n+\t\treturn specifier, true\n+\t}\n+\n+\t// Otherwise,\n+\t// Note: specifier is now a bare identifier\n+\t// Let unqualified be RESOLVE_TO_UNQUALIFIED(specifier, parentURL)\n+\t// Set resolved to NM_RESOLVE(unqualified, parentURL)\n+\treturn r.resolveToUnqualified(specifier, parentURL, parentManifest)\n+}\n+\n+func parseBareIdentifier(specifier string) (ident string, modulePath string, ok bool) {\n+\tslash := strings.IndexByte(specifier, '/')\n+\n+\t// If specifier starts with \"@\", then\n+\tif strings.HasPrefix(specifier, \"@\") {\n+\t\t// If specifier doesn't contain a \"/\" separator, then\n+\t\tif slash == -1 {\n+\t\t\t// Throw an error\n+\t\t\treturn\n+\t\t}\n+\n+\t\t// Otherwise,\n+\t\t// Set ident to the substring of specifier until the second \"/\" separator or the end of string, whatever happens first\n+\t\tif slash2 := strings.IndexByte(specifier[slash+1:], '/'); slash2 != -1 {\n+\t\t\tident = specifier[:slash+1+slash2]\n+\t\t} else {\n+\t\t\tident = specifier\n+\t\t}\n+\t} else {\n+\t\t// Otherwise,\n+\t\t// Set ident to the substring of specifier until the first \"/\" separator or the end of string, whatever happens first\n+\t\tif slash != -1 {\n+\t\t\tident = specifier[:slash]\n+\t\t} else {\n+\t\t\tident = specifier\n+\t\t}\n+\t}\n+\n+\t// Set modulePath to the substring of specifier starting from ident.length\n+\tmodulePath = specifier[len(ident):]\n+\n+\t// Return {ident, modulePath}\n+\tok = true\n+\treturn\n+}\n+\n+func (r resolverQuery) resolveToUnqualified(specifier string, parentURL string, manifest *pnpData) (string, bool) {\n+\t// Let resolved be undefined\n+\n+\t// Let ident and modulePath be the result of PARSE_BARE_IDENTIFIER(specifier)\n+\tident, modulePath, ok := parseBareIdentifier(specifier)\n+\tif !ok {\n+\t\treturn \"\", false\n+\t}\n+\n+\t// Let manifest be FIND_PNP_MANIFEST(parentURL)\n+\t// (this is already done by the time we get here)\n+\n+\t// If manifest is null, then\n+\t// Set resolved to NM_RESOLVE(specifier, parentURL) and return it\n+\tif manifest == nil {\n+\t\treturn specifier, true\n+\t}\n+\tif r.debugLogs != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"Using Yarn PnP manifest from %q to resolve %q\", manifest.absPath, ident))\n+\t}\n+\n+\t// Let parentLocator be FIND_LOCATOR(manifest, parentURL)\n+\tparentLocator, ok := r.findLocator(manifest, parentURL)\n+\n+\t// If parentLocator is null, then\n+\t// Set resolved to NM_RESOLVE(specifier, parentURL) and return it\n+\tif !ok {\n+\t\treturn specifier, true\n+\t}\n+\tif r.debugLogs != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"  Found parent locator: [%s, %s]\", quoteOrNullIfEmpty(parentLocator.ident), quoteOrNullIfEmpty(parentLocator.reference)))\n+\t}\n+\n+\t// Let parentPkg be GET_PACKAGE(manifest, parentLocator)\n+\tparentPkg, ok := r.getPackage(manifest, parentLocator.ident, parentLocator.reference)\n+\tif !ok {\n+\t\t// We aren't supposed to get here according to the Yarn PnP specification\n+\t\treturn \"\", false\n+\t}\n+\tif r.debugLogs != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"  Found parent package at %q\", parentPkg.packageLocation))\n+\t}\n+\n+\t// Let referenceOrAlias be the entry from parentPkg.packageDependencies referenced by ident\n+\treferenceOrAlias, ok := parentPkg.packageDependencies[ident]\n+\n+\t// If referenceOrAlias is null or undefined, then\n+\tif !ok || referenceOrAlias.reference == \"\" {\n+\t\tif r.debugLogs != nil {\n+\t\t\tr.debugLogs.addNote(fmt.Sprintf(\"  Failed to find %q in \\\"packageDependencies\\\" of parent package\", ident))\n+\t\t}\n+\n+\t\t// If manifest.enableTopLevelFallback is true, then\n+\t\tif manifest.enableTopLevelFallback {\n+\t\t\tif r.debugLogs != nil {\n+\t\t\t\tr.debugLogs.addNote(\"  Searching for a fallback because \\\"enableTopLevelFallback\\\" is true\")\n+\t\t\t}\n+\n+\t\t\t// If parentLocator isn't in manifest.fallbackExclusionList, then\n+\t\t\tif set, _ := manifest.fallbackExclusionList[parentLocator.ident]; !set[parentLocator.reference] {\n+\t\t\t\t// Let fallback be RESOLVE_VIA_FALLBACK(manifest, ident)\n+\t\t\t\tfallback, _ := r.resolveViaFallback(manifest, ident)\n+\n+\t\t\t\t// If fallback is neither null nor undefined\n+\t\t\t\tif fallback.reference != \"\" {\n+\t\t\t\t\t// Set referenceOrAlias to fallback\n+\t\t\t\t\treferenceOrAlias = fallback\n+\t\t\t\t\tok = true\n+\t\t\t\t}\n+\t\t\t} else if r.debugLogs != nil {\n+\t\t\t\tr.debugLogs.addNote(fmt.Sprintf(\"    Stopping because [%s, %s] is in \\\"fallbackExclusionList\\\"\",\n+\t\t\t\t\tquoteOrNullIfEmpty(parentLocator.ident), quoteOrNullIfEmpty(parentLocator.reference)))\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// If referenceOrAlias is still undefined, then\n+\tif !ok {\n+\t\t// Throw a resolution error\n+\t\treturn \"\", false\n+\t}\n+\n+\t// If referenceOrAlias is still null, then\n+\tif referenceOrAlias.reference == \"\" {\n+\t\t// Note: It means that parentPkg has an unfulfilled peer dependency on ident\n+\t\t// Throw a resolution error\n+\t\treturn \"\", false\n+\t}\n+\n+\tif r.debugLogs != nil {\n+\t\tvar referenceOrAliasStr string\n+\t\tif referenceOrAlias.ident != \"\" {\n+\t\t\treferenceOrAliasStr = fmt.Sprintf(\"[%q, %q]\", referenceOrAlias.ident, referenceOrAlias.reference)\n+\t\t} else {\n+\t\t\treferenceOrAliasStr = quoteOrNullIfEmpty(referenceOrAlias.reference)\n+\t\t}\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"  Found dependency locator: [%s, %s]\", quoteOrNullIfEmpty(ident), referenceOrAliasStr))\n+\t}\n+\n+\t// Otherwise, if referenceOrAlias is an array, then\n+\tvar dependencyPkg pnpPackage\n+\tif referenceOrAlias.ident != \"\" {\n+\t\t// Let alias be referenceOrAlias\n+\t\talias := referenceOrAlias\n+\n+\t\t// Let dependencyPkg be GET_PACKAGE(manifest, alias)\n+\t\tdependencyPkg, ok = r.getPackage(manifest, alias.ident, alias.reference)\n+\t\tif !ok {\n+\t\t\t// We aren't supposed to get here according to the Yarn PnP specification\n+\t\t\treturn \"\", false\n+\t\t}\n+\t} else {\n+\t\t// Otherwise,\n+\t\t// Let dependencyPkg be GET_PACKAGE(manifest, {ident, reference})\n+\t\tdependencyPkg, ok = r.getPackage(manifest, ident, referenceOrAlias.reference)\n+\t\tif !ok {\n+\t\t\t// We aren't supposed to get here according to the Yarn PnP specification\n+\t\t\treturn \"\", false\n+\t\t}\n+\t}\n+\tif r.debugLogs != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"  Found package %q at %q\", ident, dependencyPkg.packageLocation))\n+\t}\n+\n+\t// Return dependencyPkg.packageLocation concatenated with modulePath\n+\tresolved := dependencyPkg.packageLocation + modulePath\n+\tresult := r.fs.Join(manifest.absDirPath, resolved)\n+\tif strings.HasSuffix(resolved, \"/\") && !strings.HasSuffix(result, \"/\") {\n+\t\tresult += \"/\" // This is important for matching Yarn PnP's expectations in tests\n+\t}\n+\tif r.debugLogs != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"  Resolved %q via Yarn PnP to %q\", specifier, result))\n+\t}\n+\treturn result, true\n+}\n+\n+func (r resolverQuery) findLocator(manifest *pnpData, moduleUrl string) (pnpIdentAndReference, bool) {\n+\t// Let relativeUrl be the relative path between manifest and moduleUrl\n+\trelativeUrl, ok := r.fs.Rel(manifest.absDirPath, moduleUrl)\n+\tif !ok {\n+\t\treturn pnpIdentAndReference{}, false\n+\t}\n+\n+\t// The relative path must not start with ./; trim it if needed\n+\tif strings.HasPrefix(relativeUrl, \"./\") {\n+\t\trelativeUrl = relativeUrl[2:]\n+\t}\n+\n+\t// If relativeUrl matches manifest.ignorePatternData, then\n+\tif manifest.ignorePatternData != nil && manifest.ignorePatternData.MatchString(relativeUrl) {\n+\t\tif r.debugLogs != nil {\n+\t\t\tr.debugLogs.addNote(fmt.Sprintf(\"  Ignoring %q because it matches \\\"ignorePatternData\\\"\", relativeUrl))\n+\t\t}\n+\n+\t\t// Return null\n+\t\treturn pnpIdentAndReference{}, false\n+\t}\n+\n+\t// Note: Make sure relativeUrl always starts with a ./ or ../\n+\tif !strings.HasSuffix(relativeUrl, \"/\") {\n+\t\trelativeUrl += \"/\"\n+\t}\n+\tif !strings.HasPrefix(relativeUrl, \"./\") && !strings.HasPrefix(relativeUrl, \"../\") {\n+\t\trelativeUrl = \"./\" + relativeUrl\n+\t}\n+\n+\t// This is the inner loop from Yarn's PnP resolver implementation. This is\n+\t// different from the specification, which contains a hypothetical slow\n+\t// algorithm instead. The algorithm from the specification can sometimes\n+\t// produce different results from the one used by the implementation, so\n+\t// we follow the implementation.\n+\tfor {\n+\t\tentry, ok := manifest.packageLocatorsByLocations[relativeUrl]\n+\t\tif !ok || entry.discardFromLookup {\n+\t\t\t// Remove the last path component and try again\n+\t\t\trelativeUrl = relativeUrl[:strings.LastIndexByte(relativeUrl[:len(relativeUrl)-1], '/')+1]\n+\t\t\tif relativeUrl == \"\" {\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t\tcontinue\n+\t\t}\n+\t\treturn entry.locator, true\n+\t}\n+\n+\treturn pnpIdentAndReference{}, false\n+}\n+\n+func (r resolverQuery) resolveViaFallback(manifest *pnpData, ident string) (pnpIdentAndReference, bool) {\n+\t// Let topLevelPkg be GET_PACKAGE(manifest, {null, null})\n+\ttopLevelPkg, ok := r.getPackage(manifest, \"\", \"\")\n+\tif !ok {\n+\t\t// We aren't supposed to get here according to the Yarn PnP specification\n+\t\treturn pnpIdentAndReference{}, false\n+\t}\n+\n+\t// Let referenceOrAlias be the entry from topLevelPkg.packageDependencies referenced by ident\n+\treferenceOrAlias, ok := topLevelPkg.packageDependencies[ident]\n+\n+\t// If referenceOrAlias is defined, then\n+\tif ok {\n+\t\t// Return it immediately\n+\t\tif r.debugLogs != nil {\n+\t\t\tr.debugLogs.addNote(fmt.Sprintf(\"    Found fallback for %q in \\\"packageDependencies\\\" of top-level package: [%s, %s]\", ident,\n+\t\t\t\tquoteOrNullIfEmpty(referenceOrAlias.ident), quoteOrNullIfEmpty(referenceOrAlias.reference)))\n+\t\t}\n+\t\treturn referenceOrAlias, true\n+\t}\n+\n+\t// Otherwise,\n+\t// Let referenceOrAlias be the entry from manifest.fallbackPool referenced by ident\n+\treferenceOrAlias, ok = manifest.fallbackPool[ident]\n+\n+\t// Return it immediatly, whether it's defined or not\n+\tif r.debugLogs != nil {\n+\t\tif ok {\n+\t\t\tr.debugLogs.addNote(fmt.Sprintf(\"    Found fallback for %q in \\\"fallbackPool\\\": [%s, %s]\", ident,\n+\t\t\t\tquoteOrNullIfEmpty(referenceOrAlias.ident), quoteOrNullIfEmpty(referenceOrAlias.reference)))\n+\t\t} else {\n+\t\t\tr.debugLogs.addNote(fmt.Sprintf(\"    Failed to find fallback for %q in \\\"fallbackPool\\\"\", ident))\n+\t\t}\n+\t}\n+\treturn referenceOrAlias, ok\n+}\n+\n+func (r resolverQuery) getPackage(manifest *pnpData, ident string, reference string) (pnpPackage, bool) {\n+\tif inner, ok := manifest.packageRegistryData[ident]; ok {\n+\t\tif pkg, ok := inner[reference]; ok {\n+\t\t\treturn pkg, true\n+\t\t}\n+\t}\n+\n+\tif r.debugLogs != nil {\n+\t\t// We aren't supposed to get here according to the Yarn PnP specification:\n+\t\t// \"Note: pkg cannot be undefined here; all packages referenced in any of the\n+\t\t// Plug'n'Play data tables MUST have a corresponding entry inside packageRegistryData.\"\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"  Yarn PnP invariant violation: GET_PACKAGE failed to find a package: [%s, %s]\",\n+\t\t\tquoteOrNullIfEmpty(ident), quoteOrNullIfEmpty(reference)))\n+\t}\n+\treturn pnpPackage{}, false\n+}\n+\n+func quoteOrNullIfEmpty(str string) string {\n+\tif str != \"\" {\n+\t\treturn fmt.Sprintf(\"%q\", str)\n+\t}\n+\treturn \"null\"\n+}\n+\n+func compileYarnPnPData(absPath string, absDirPath string, json js_ast.Expr) *pnpData {\n+\tdata := pnpData{\n+\t\tabsPath:    absPath,\n+\t\tabsDirPath: absDirPath,\n+\t}\n+\n+\tif value, _, ok := getProperty(json, \"dependencyTreeRoots\"); ok {\n+\t\tif array, ok := value.Data.(*js_ast.EArray); ok {\n+\t\t\tdata.dependencyTreeRoots = make(map[string]string, len(array.Items))\n+\n+\t\t\tfor _, item := range array.Items {\n+\t\t\t\tif name, _, ok := getProperty(item, \"name\"); ok {\n+\t\t\t\t\tif reference, _, ok := getProperty(item, \"reference\"); ok {\n+\t\t\t\t\t\tif name, ok := getString(name); ok {\n+\t\t\t\t\t\t\tif reference, ok := getString(reference); ok {\n+\t\t\t\t\t\t\t\tdata.dependencyTreeRoots[name] = reference\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tif value, _, ok := getProperty(json, \"enableTopLevelFallback\"); ok {\n+\t\tif enableTopLevelFallback, ok := getBool(value); ok {\n+\t\t\tdata.enableTopLevelFallback = enableTopLevelFallback\n+\t\t}\n+\t}\n+\n+\tif value, _, ok := getProperty(json, \"fallbackExclusionList\"); ok {\n+\t\tif array, ok := value.Data.(*js_ast.EArray); ok {\n+\t\t\tdata.fallbackExclusionList = make(map[string]map[string]bool, len(array.Items))\n+\n+\t\t\tfor _, item := range array.Items {\n+\t\t\t\tif tuple, ok := item.Data.(*js_ast.EArray); ok && len(tuple.Items) == 2 {\n+\t\t\t\t\tif ident, ok := getStringOrNull(tuple.Items[0]); ok {\n+\t\t\t\t\t\tif array2, ok := tuple.Items[1].Data.(*js_ast.EArray); ok {\n+\t\t\t\t\t\t\treferences := make(map[string]bool, len(array2.Items))\n+\n+\t\t\t\t\t\t\tfor _, item2 := range array2.Items {\n+\t\t\t\t\t\t\t\tif reference, ok := getString(item2); ok {\n+\t\t\t\t\t\t\t\t\treferences[reference] = true\n+\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\tdata.fallbackExclusionList[ident] = references\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tif value, _, ok := getProperty(json, \"fallbackPool\"); ok {\n+\t\tif array, ok := value.Data.(*js_ast.EArray); ok {\n+\t\t\tdata.fallbackPool = make(map[string]pnpIdentAndReference, len(array.Items))\n+\n+\t\t\tfor _, item := range array.Items {\n+\t\t\t\tif array2, ok := item.Data.(*js_ast.EArray); ok && len(array2.Items) == 2 {\n+\t\t\t\t\tif ident, ok := getString(array2.Items[0]); ok {\n+\t\t\t\t\t\tif dependencyTarget, ok := getDependencyTarget(array2.Items[1]); ok {\n+\t\t\t\t\t\t\tdata.fallbackPool[ident] = dependencyTarget\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tif value, _, ok := getProperty(json, \"ignorePatternData\"); ok {\n+\t\tif ignorePatternData, ok := getString(value); ok {\n+\t\t\tdata.ignorePatternData, _ = regexp.Compile(ignorePatternData)\n+\t\t}\n+\t}\n+\n+\tif value, _, ok := getProperty(json, \"packageRegistryData\"); ok {\n+\t\tif array, ok := value.Data.(*js_ast.EArray); ok {\n+\t\t\tdata.packageRegistryData = make(map[string]map[string]pnpPackage, len(array.Items))\n+\t\t\tdata.packageLocatorsByLocations = make(map[string]pnpPackageLocatorByLocation)\n+\n+\t\t\tfor _, item := range array.Items {\n+\t\t\t\tif tuple, ok := item.Data.(*js_ast.EArray); ok && len(tuple.Items) == 2 {\n+\t\t\t\t\tif packageIdent, ok := getStringOrNull(tuple.Items[0]); ok {\n+\t\t\t\t\t\tif array2, ok := tuple.Items[1].Data.(*js_ast.EArray); ok {\n+\t\t\t\t\t\t\treferences := make(map[string]pnpPackage, len(array2.Items))\n+\t\t\t\t\t\t\tdata.packageRegistryData[packageIdent] = references\n+\n+\t\t\t\t\t\t\tfor _, item2 := range array2.Items {\n+\t\t\t\t\t\t\t\tif tuple2, ok := item2.Data.(*js_ast.EArray); ok && len(tuple2.Items) == 2 {\n+\t\t\t\t\t\t\t\t\tif packageReference, ok := getStringOrNull(tuple2.Items[0]); ok {\n+\t\t\t\t\t\t\t\t\t\tpkg := tuple2.Items[1]\n+\n+\t\t\t\t\t\t\t\t\t\tif packageLocation, _, ok := getProperty(pkg, \"packageLocation\"); ok {\n+\t\t\t\t\t\t\t\t\t\t\tif packageDependencies, _, ok := getProperty(pkg, \"packageDependencies\"); ok {\n+\t\t\t\t\t\t\t\t\t\t\t\tif packageLocation, ok := getString(packageLocation); ok {\n+\t\t\t\t\t\t\t\t\t\t\t\t\tif array3, ok := packageDependencies.Data.(*js_ast.EArray); ok {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\tdeps := make(map[string]pnpIdentAndReference, len(array3.Items))\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\tdiscardFromLookup := false\n+\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\tfor _, dep := range array3.Items {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif array4, ok := dep.Data.(*js_ast.EArray); ok && len(array4.Items) == 2 {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif ident, ok := getString(array4.Items[0]); ok {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif dependencyTarget, ok := getDependencyTarget(array4.Items[1]); ok {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdeps[ident] = dependencyTarget\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\tif value, _, ok := getProperty(pkg, \"discardFromLookup\"); ok {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif value, ok := getBool(value); ok {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdiscardFromLookup = value\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\treferences[packageReference] = pnpPackage{\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpackageLocation:     packageLocation,\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpackageDependencies: deps,\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdiscardFromLookup:   discardFromLookup,\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t// This is what Yarn's PnP implementation does (specifically in\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t// \"hydrateRuntimeState\"), so we replicate that behavior here:\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\tif entry, ok := data.packageLocatorsByLocations[packageLocation]; !ok {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdata.packageLocatorsByLocations[packageLocation] = pnpPackageLocatorByLocation{\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlocator:           pnpIdentAndReference{ident: packageIdent, reference: packageReference},\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdiscardFromLookup: discardFromLookup,\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tentry.discardFromLookup = entry.discardFromLookup && discardFromLookup\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif !discardFromLookup {\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tentry.locator = pnpIdentAndReference{ident: packageIdent, reference: packageReference}\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdata.packageLocatorsByLocations[packageLocation] = entry\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn &data\n+}\n+\n+func getStringOrNull(json js_ast.Expr) (string, bool) {\n+\tswitch value := json.Data.(type) {\n+\tcase *js_ast.EString:\n+\t\treturn helpers.UTF16ToString(value.Value), true\n+\n+\tcase *js_ast.ENull:\n+\t\treturn \"\", true\n+\t}\n+\n+\treturn \"\", false\n+}\n+\n+func getDependencyTarget(json js_ast.Expr) (pnpIdentAndReference, bool) {\n+\tswitch d := json.Data.(type) {\n+\tcase *js_ast.ENull:\n+\t\treturn pnpIdentAndReference{}, true\n+\n+\tcase *js_ast.EString:\n+\t\treturn pnpIdentAndReference{reference: helpers.UTF16ToString(d.Value)}, true\n+\n+\tcase *js_ast.EArray:\n+\t\tif len(d.Items) == 2 {\n+\t\t\tif name, ok := getString(d.Items[0]); ok {\n+\t\t\t\tif reference, ok := getString(d.Items[1]); ok {\n+\t\t\t\t\treturn pnpIdentAndReference{\n+\t\t\t\t\t\tident:     name,\n+\t\t\t\t\t\treference: reference,\n+\t\t\t\t\t}, true\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn pnpIdentAndReference{}, false\n+}\n+\n+func (r resolverQuery) extractYarnPnPDataFromJSON(pnpDataPath string, jsonCache *cache.JSONCache) (result js_ast.Expr) {\n+\tcontents, err, originalError := r.caches.FSCache.ReadFile(r.fs, pnpDataPath)\n+\tif r.debugLogs != nil && originalError != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"Failed to read file %q: %s\", pnpDataPath, originalError.Error()))\n+\t}\n+\tif err != nil {\n+\t\tr.log.AddError(nil, logger.Range{},\n+\t\t\tfmt.Sprintf(\"Cannot read file %q: %s\",\n+\t\t\t\tr.PrettyPath(logger.Path{Text: pnpDataPath, Namespace: \"file\"}), err.Error()))\n+\t\treturn\n+\t}\n+\tif r.debugLogs != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"The file %q exists\", pnpDataPath))\n+\t}\n+\tkeyPath := logger.Path{Text: pnpDataPath, Namespace: \"file\"}\n+\tsource := logger.Source{\n+\t\tKeyPath:    keyPath,\n+\t\tPrettyPath: r.PrettyPath(keyPath),\n+\t\tContents:   contents,\n+\t}\n+\tresult, _ = jsonCache.Parse(r.log, source, js_parser.JSONOptions{})\n+\treturn\n+}\n+\n+func (r resolverQuery) tryToExtractYarnPnPDataFromJS(pnpDataPath string, jsonCache *cache.JSONCache) (result js_ast.Expr) {\n+\tcontents, err, originalError := r.caches.FSCache.ReadFile(r.fs, pnpDataPath)\n+\tif r.debugLogs != nil && originalError != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"Failed to read file %q: %s\", pnpDataPath, originalError.Error()))\n+\t}\n+\tif err != nil {\n+\t\tr.log.AddError(nil, logger.Range{},\n+\t\t\tfmt.Sprintf(\"Cannot read file %q: %s\",\n+\t\t\t\tr.PrettyPath(logger.Path{Text: pnpDataPath, Namespace: \"file\"}), err.Error()))\n+\t\treturn\n+\t}\n+\tif r.debugLogs != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"The file %q exists\", pnpDataPath))\n+\t}\n+\n+\tkeyPath := logger.Path{Text: pnpDataPath, Namespace: \"file\"}\n+\tsource := logger.Source{\n+\t\tKeyPath:    keyPath,\n+\t\tPrettyPath: r.PrettyPath(keyPath),\n+\t\tContents:   contents,\n+\t}\n+\tast, _ := js_parser.Parse(r.log, source, js_parser.OptionsForYarnPnP())\n+\n+\tif r.debugLogs != nil && ast.ManifestForYarnPnP.Data != nil {\n+\t\tr.debugLogs.addNote(fmt.Sprintf(\"  Extracted JSON data from %q\", pnpDataPath))\n+\t}\n+\treturn ast.ManifestForYarnPnP\n+}"},{"sha":"df1c5c4b3122b9f1d2fe6af878bdc383b4b5010c","filename":"internal/resolver/yarnpnp_test.go","status":"added","additions":90,"deletions":0,"changes":90,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fresolver%2Fyarnpnp_test.go","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/internal%2Fresolver%2Fyarnpnp_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fresolver%2Fyarnpnp_test.go?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -0,0 +1,90 @@\n+package resolver\n+\n+import (\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\t\"io/ioutil\"\n+\t\"testing\"\n+\n+\t\"github.com/evanw/esbuild/internal/config\"\n+\t\"github.com/evanw/esbuild/internal/fs\"\n+\t\"github.com/evanw/esbuild/internal/js_parser\"\n+\t\"github.com/evanw/esbuild/internal/logger\"\n+\t\"github.com/evanw/esbuild/internal/test\"\n+)\n+\n+type pnpTestExpectation struct {\n+\tManifest interface{}\n+\tTests    []pnpTest\n+}\n+\n+type pnpTest struct {\n+\tIt       string\n+\tImported string\n+\tImporter string\n+\tExpected string\n+}\n+\n+func TestYarnPnP(t *testing.T) {\n+\tt.Helper()\n+\tcontents, err := ioutil.ReadFile(\"testExpectations.json\")\n+\tif err != nil {\n+\t\tt.Fatalf(\"Failed to read testExpectations.json: %s\", err.Error())\n+\t}\n+\n+\tvar expectations []pnpTestExpectation\n+\terr = json.Unmarshal(contents, &expectations)\n+\tif err != nil {\n+\t\tt.Fatalf(\"Failed to parse testExpectations.json: %s\", err.Error())\n+\t}\n+\n+\tfor i, expectation := range expectations {\n+\t\tpath := fmt.Sprintf(\"testExpectations[%d].manifest\", i)\n+\t\tcontents, err := json.Marshal(expectation.Manifest)\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"Failed to generate JSON: %s\", err.Error())\n+\t\t}\n+\n+\t\tsource := logger.Source{\n+\t\t\tKeyPath:    logger.Path{Text: path},\n+\t\t\tPrettyPath: path,\n+\t\t\tContents:   string(contents),\n+\t\t}\n+\t\ttempLog := logger.NewDeferLog(logger.DeferLogAll, nil)\n+\t\texpr, ok := js_parser.ParseJSON(tempLog, source, js_parser.JSONOptions{})\n+\t\tif !ok {\n+\t\t\tt.Fatalf(\"Failed to re-parse JSON: %s\", path)\n+\t\t}\n+\n+\t\tmsgs := tempLog.Done()\n+\t\tif len(msgs) != 0 {\n+\t\t\tt.Fatalf(\"Log not empty after re-parsing JSON: %s\", path)\n+\t\t}\n+\n+\t\tmanifest := compileYarnPnPData(path, \"/path/to/project/\", expr)\n+\n+\t\tfor _, current := range expectation.Tests {\n+\t\t\tfunc(current pnpTest) {\n+\t\t\t\tt.Run(current.It, func(t *testing.T) {\n+\t\t\t\t\trr := NewResolver(fs.MockFS(nil), logger.NewDeferLog(logger.DeferLogNoVerboseOrDebug, nil), nil, config.Options{})\n+\t\t\t\t\tr := resolverQuery{resolver: rr.(*resolver)}\n+\t\t\t\t\tresult, ok := r.pnpResolve(current.Imported, current.Importer, manifest)\n+\t\t\t\t\tif !ok {\n+\t\t\t\t\t\tresult = \"error!\"\n+\t\t\t\t\t}\n+\t\t\t\t\texpected := current.Expected\n+\n+\t\t\t\t\t// If a we aren't going through PnP, then we should just run the\n+\t\t\t\t\t// normal node module resolution rules instead of throwing an error.\n+\t\t\t\t\t// However, this test requires us to throw an error, which seems\n+\t\t\t\t\t// incorrect. So we change the expected value of the test instead.\n+\t\t\t\t\tif current.It == `shouldn't go through PnP when trying to resolve dependencies from packages covered by ignorePatternData` {\n+\t\t\t\t\t\texpected = current.Imported\n+\t\t\t\t\t}\n+\n+\t\t\t\t\ttest.AssertEqualWithDiff(t, result, expected)\n+\t\t\t\t})\n+\t\t\t}(current)\n+\t\t}\n+\t}\n+}"},{"sha":"b9eed43e217152c35df19284e6f8cac3d0e6a026","filename":"scripts/js-api-tests.js","status":"modified","additions":254,"deletions":0,"changes":254,"blob_url":"https://github.com/evanw/esbuild/blob/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/scripts%2Fjs-api-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/3d0b0b4e428cff9a4d03e4a76be46da9b183390e/scripts%2Fjs-api-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fjs-api-tests.js?ref=3d0b0b4e428cff9a4d03e4a76be46da9b183390e","patch":"@@ -2711,6 +2711,260 @@ require(\"/assets/file.png\");\n     virtual3: foo_default4\n   });\n })();\n+`)\n+  },\n+\n+  async yarnPnP_pnp_data_json({ esbuild, testDir }) {\n+    const entry = path.join(testDir, 'entry.js')\n+    const manifest = path.join(testDir, '.pnp.data.json')\n+    const leftPad = path.join(testDir, '.yarn', 'cache', 'left-pad', 'index.js')\n+\n+    await writeFileAsync(entry, `\n+      import leftPad from 'left-pad'\n+      console.log(leftPad())\n+    `)\n+\n+    await writeFileAsync(manifest, `{\n+      \"packageRegistryData\": [\n+        [null, [\n+          [null, {\n+            \"packageLocation\": \"./\",\n+            \"packageDependencies\": [\n+              [\"left-pad\", \"npm:1.3.0\"]\n+            ],\n+            \"linkType\": \"SOFT\"\n+          }]\n+        ]],\n+        [\"left-pad\", [\n+          [\"npm:1.3.0\", {\n+            \"packageLocation\": \"./.yarn/cache/left-pad/\",\n+            \"packageDependencies\": [\n+              [\"left-pad\", \"npm:1.3.0\"]\n+            ],\n+            \"linkType\": \"HARD\"\n+          }]\n+        ]]\n+      ]\n+    }`)\n+\n+    await mkdirAsync(path.dirname(leftPad), { recursive: true })\n+    await writeFileAsync(leftPad, `export default function() {}`)\n+\n+    const value = await esbuild.build({\n+      entryPoints: [entry],\n+      bundle: true,\n+      write: false,\n+    })\n+\n+    assert.strictEqual(value.outputFiles.length, 1)\n+    assert.strictEqual(value.outputFiles[0].text, `(() => {\n+  // scripts/.js-api-tests/yarnPnP_pnp_data_json/.yarn/cache/left-pad/index.js\n+  function left_pad_default() {\n+  }\n+\n+  // scripts/.js-api-tests/yarnPnP_pnp_data_json/entry.js\n+  console.log(left_pad_default());\n+})();\n+`)\n+  },\n+\n+  async yarnPnP_pnp_js_object_literal({ esbuild, testDir }) {\n+    const entry = path.join(testDir, 'entry.js')\n+    const manifest = path.join(testDir, '.pnp.js')\n+    const leftPad = path.join(testDir, '.yarn', 'cache', 'left-pad', 'index.js')\n+\n+    await writeFileAsync(entry, `\n+      import leftPad from 'left-pad'\n+      console.log(leftPad())\n+    `)\n+\n+    await writeFileAsync(manifest, `#!/usr/bin/env node\n+      /* eslint-disable */\n+\n+      try {\n+        Object.freeze({}).detectStrictMode = true;\n+      } catch (error) {\n+        throw new Error();\n+      }\n+\n+      function $$SETUP_STATE(hydrateRuntimeState, basePath) {\n+        return hydrateRuntimeState({\n+          \"packageRegistryData\": [\n+            [null, [\n+              [null, {\n+                \"packageLocation\": \"./\",\n+                \"packageDependencies\": [\n+                  [\"left-pad\", \"npm:1.3.0\"]\n+                ],\n+                \"linkType\": \"SOFT\"\n+              }]\n+            ]],\n+            [\"left-pad\", [\n+              [\"npm:1.3.0\", {\n+                \"packageLocation\": \"./.yarn/cache/left-pad/\",\n+                \"packageDependencies\": [\n+                  [\"left-pad\", \"npm:1.3.0\"]\n+                ],\n+                \"linkType\": \"HARD\"\n+              }]\n+            ]]\n+          ]\n+        })\n+      }\n+    `)\n+\n+    await mkdirAsync(path.dirname(leftPad), { recursive: true })\n+    await writeFileAsync(leftPad, `export default function() {}`)\n+\n+    const value = await esbuild.build({\n+      entryPoints: [entry],\n+      bundle: true,\n+      write: false,\n+    })\n+\n+    assert.strictEqual(value.outputFiles.length, 1)\n+    assert.strictEqual(value.outputFiles[0].text, `(() => {\n+  // scripts/.js-api-tests/yarnPnP_pnp_js_object_literal/.yarn/cache/left-pad/index.js\n+  function left_pad_default() {\n+  }\n+\n+  // scripts/.js-api-tests/yarnPnP_pnp_js_object_literal/entry.js\n+  console.log(left_pad_default());\n+})();\n+`)\n+  },\n+\n+  async yarnPnP_pnp_cjs_JSON_parse_string_literal({ esbuild, testDir }) {\n+    const entry = path.join(testDir, 'entry.js')\n+    const manifest = path.join(testDir, '.pnp.cjs')\n+    const leftPad = path.join(testDir, '.yarn', 'cache', 'left-pad', 'index.js')\n+\n+    await writeFileAsync(entry, `\n+      import leftPad from 'left-pad'\n+      console.log(leftPad())\n+    `)\n+\n+    await writeFileAsync(manifest, `#!/usr/bin/env node\n+      /* eslint-disable */\n+\n+      try {\n+        Object.freeze({}).detectStrictMode = true;\n+      } catch (error) {\n+        throw new Error();\n+      }\n+\n+      function $$SETUP_STATE(hydrateRuntimeState, basePath) {\n+        return hydrateRuntimeState(JSON.parse('{\\\\\n+          \"packageRegistryData\": [\\\\\n+            [null, [\\\\\n+              [null, {\\\\\n+                \"packageLocation\": \"./\",\\\\\n+                \"packageDependencies\": [\\\\\n+                  [\"left-pad\", \"npm:1.3.0\"]\\\\\n+                ],\\\\\n+                \"linkType\": \"SOFT\"\\\\\n+              }]\\\\\n+            ]],\\\\\n+            [\"left-pad\", [\\\\\n+              [\"npm:1.3.0\", {\\\\\n+                \"packageLocation\": \"./.yarn/cache/left-pad/\",\\\\\n+                \"packageDependencies\": [\\\\\n+                  [\"left-pad\", \"npm:1.3.0\"]\\\\\n+                ],\\\\\n+                \"linkType\": \"HARD\"\\\\\n+              }]\\\\\n+            ]]\\\\\n+          ]\\\\\n+        }'))\n+      }\n+    `)\n+\n+    await mkdirAsync(path.dirname(leftPad), { recursive: true })\n+    await writeFileAsync(leftPad, `export default function() {}`)\n+\n+    const value = await esbuild.build({\n+      entryPoints: [entry],\n+      bundle: true,\n+      write: false,\n+    })\n+\n+    assert.strictEqual(value.outputFiles.length, 1)\n+    assert.strictEqual(value.outputFiles[0].text, `(() => {\n+  // scripts/.js-api-tests/yarnPnP_pnp_cjs_JSON_parse_string_literal/.yarn/cache/left-pad/index.js\n+  function left_pad_default() {\n+  }\n+\n+  // scripts/.js-api-tests/yarnPnP_pnp_cjs_JSON_parse_string_literal/entry.js\n+  console.log(left_pad_default());\n+})();\n+`)\n+  },\n+\n+  async yarnPnP_pnp_cjs_JSON_parse_identifier({ esbuild, testDir }) {\n+    const entry = path.join(testDir, 'entry.js')\n+    const manifest = path.join(testDir, '.pnp.cjs')\n+    const leftPad = path.join(testDir, '.yarn', 'cache', 'left-pad', 'index.js')\n+\n+    await writeFileAsync(entry, `\n+      import leftPad from 'left-pad'\n+      console.log(leftPad())\n+    `)\n+\n+    await writeFileAsync(manifest, `#!/usr/bin/env node\n+      /* eslint-disable */\n+\n+      try {\n+        Object.freeze({}).detectStrictMode = true;\n+      } catch (error) {\n+        throw new Error();\n+      }\n+\n+      const RAW_RUNTIME_STATE = '{\\\\\n+        \"packageRegistryData\": [\\\\\n+          [null, [\\\\\n+            [null, {\\\\\n+              \"packageLocation\": \"./\",\\\\\n+              \"packageDependencies\": [\\\\\n+                [\"left-pad\", \"npm:1.3.0\"]\\\\\n+              ],\\\\\n+              \"linkType\": \"SOFT\"\\\\\n+            }]\\\\\n+          ]],\\\\\n+          [\"left-pad\", [\\\\\n+            [\"npm:1.3.0\", {\\\\\n+              \"packageLocation\": \"./.yarn/cache/left-pad/\",\\\\\n+              \"packageDependencies\": [\\\\\n+                [\"left-pad\", \"npm:1.3.0\"]\\\\\n+              ],\\\\\n+              \"linkType\": \"HARD\"\\\\\n+            }]\\\\\n+          ]]\\\\\n+        ]\\\\\n+      }'\n+\n+      function $$SETUP_STATE(hydrateRuntimeState, basePath) {\n+        return hydrateRuntimeState(JSON.parse(RAW_RUNTIME_STATE))\n+      }\n+    `)\n+\n+    await mkdirAsync(path.dirname(leftPad), { recursive: true })\n+    await writeFileAsync(leftPad, `export default function() {}`)\n+\n+    const value = await esbuild.build({\n+      entryPoints: [entry],\n+      bundle: true,\n+      write: false,\n+    })\n+\n+    assert.strictEqual(value.outputFiles.length, 1)\n+    assert.strictEqual(value.outputFiles[0].text, `(() => {\n+  // scripts/.js-api-tests/yarnPnP_pnp_cjs_JSON_parse_identifier/.yarn/cache/left-pad/index.js\n+  function left_pad_default() {\n+  }\n+\n+  // scripts/.js-api-tests/yarnPnP_pnp_cjs_JSON_parse_identifier/entry.js\n+  console.log(left_pad_default());\n+})();\n `)\n   },\n }"}]},{"url":"https://api.github.com/repos/evanw/esbuild/issues/2349","repository_url":"https://api.github.com/repos/evanw/esbuild","labels_url":"https://api.github.com/repos/evanw/esbuild/issues/2349/labels{/name}","comments_url":"https://api.github.com/repos/evanw/esbuild/issues/2349/comments","events_url":"https://api.github.com/repos/evanw/esbuild/issues/2349/events","html_url":"https://github.com/evanw/esbuild/pull/2349","id":1284709441,"node_id":"PR_kwDOA6ThAc46XGvn","number":2349,"title":"fix #334: support automatic JSX runtime","user":{"login":"jgoz","id":132233,"node_id":"MDQ6VXNlcjEzMjIzMw==","avatar_url":"https://avatars.githubusercontent.com/u/132233?v=4","gravatar_id":"","url":"https://api.github.com/users/jgoz","html_url":"https://github.com/jgoz","followers_url":"https://api.github.com/users/jgoz/followers","following_url":"https://api.github.com/users/jgoz/following{/other_user}","gists_url":"https://api.github.com/users/jgoz/gists{/gist_id}","starred_url":"https://api.github.com/users/jgoz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jgoz/subscriptions","organizations_url":"https://api.github.com/users/jgoz/orgs","repos_url":"https://api.github.com/users/jgoz/repos","events_url":"https://api.github.com/users/jgoz/events{/privacy}","received_events_url":"https://api.github.com/users/jgoz/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":10,"created_at":"2022-06-25T20:41:38Z","updated_at":"2022-07-28T18:19:52Z","closed_at":"2022-07-28T15:20:18Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/evanw/esbuild/pulls/2349","html_url":"https://github.com/evanw/esbuild/pull/2349","diff_url":"https://github.com/evanw/esbuild/pull/2349.diff","patch_url":"https://github.com/evanw/esbuild/pull/2349.patch","merged_at":"2022-07-28T15:20:17Z"},"body":"fixes #334\r\nfixes #718 \r\nfixes #1172\r\nfixes #2318\r\n\r\nThis adds support for the [new (automatic) JSX runtime](https://reactjs.org/blog/2020/09/22/introducing-the-new-jsx-transform.html) to esbuild for both the build and transform APIs.\r\n\r\n**New CLI flags and API options**:\r\n- `--jsx-runtime`, `jsxRuntime` &mdash; `\"automatic\"` or `\"classic\"` (default)\r\n- `--jsx-development`, `jsxDevelopment` &mdash; toggles development mode for the automatic runtime\r\n- `--jsx-import-source`, `jsxImportSource` &mdash; Overrides the root import for runtime functions (default `\"react\"`)\r\n\r\n**New JSX pragmas**:\r\n- `@jsx` &mdash; sets the runtime (`\"automatic\"` or `\"classic\"`)\r\n- `@jsxImportSource` &mdash; sets the import source (only valid with automatic runtime)\r\n\r\n`@jsxFragment` and `@jsxFactory` are only valid with classic runtime.\r\n\r\n**Implementation details**:\r\nMost of the work to support the automatic runtime happens in the second parsing pass. Here is a high level overview of the logic when `automatic` runtime is enabled:\r\n\r\n- Determine whether `Fragment` needs to be imported (from the appropriate runtime import)\r\n- Look for `key` prop and extract it from the props argument, since it's now passed directly to a jsx function\r\n- Inspect children and determine whether they are considered static (generally, more than 1 child) or not\r\n- Build up arguments list to pass to the appropriate jsx function\r\n  - In development mode, this includes \"source\" and \"self\" args and \"isStaticChildren\" is an argument\r\n- Determine which jsx function to use:\r\n  - `jsxDEV` &mdash; development mode (from `{importSource}/jsx-dev-runtime`)\r\n  - `jsxs` &mdash; production mode, static children (from `{importSource}/jsx-runtime`)\r\n  - `jsx` &mdash; production mode, non-static children (from `{importSource}/jsx-runtime`)\r\n  - `createElement` &mdash; fallback mode* (from `{importSource}`)\r\n- Record an import of the appropriate function from the appropriate source\r\n- Insert a function call with the assembled arguments\r\n\r\nAt the end of parsing, if any JSX symbols had recorded usage, the appropriate import statement is generated for only those symbols that were actually used within the file. These are generated as external imports, unlike esbuild's runtime.\r\n\r\n\\* Fallback mode &mdash; If a component includes spread props followed by a `key` prop, `{...props} key={1}`, [Babel triggers a fallback mode](https://github.com/babel/babel/blob/4c3365f6bd67385ddbaf44c86e975025e2f8ff2a/packages/babel-plugin-transform-react-jsx/src/create-plugin.ts#L347-L351) to `createElement`. Apparently this is a temporary special case that will be removed once spreading \"key\" from props is no longer supported. It looks like the TypeScript compiler also implements this special case, so it seemed prudent to be compatible here.\r\n\r\n**Development mode**:\r\nAside from importing a different function from a different source (`{ jsxDEV } from 'react/jsx-dev-runtime'`), development mode also passes more arguments, one of which is the \"source\" argument. This contains the current filename, line number, and column number mapping to the original source location of the element.\r\n\r\nI used the LineColumnTracker to extract those details from the element's location, which will probably incur a minor performance cost that should be documented for the `jsxDevelopment` option. The alternative was to simply omit those details, but that would defeat the purpose of supporting development mode.\r\n\r\n**TSConfig resolving**:\r\nAlong with accepting the new options directly via CLI or API, I implemented option inference from tsconfig compiler options.\r\n\r\n- `\"jsx\": \"preserve\"` or `\"jsx\": \"react-native\"` &rarr; preserve\r\n- `\"jsx\": \"react\"` &rarr; classic runtime\r\n- `\"jsx\": \"react-jsx\"` &rarr; automatic runtime\r\n- `\"jsx\": \"react-jsxdev\"` &rarr; automatic runtime and development mode enabled\r\n\r\nIt also reads the value of `\"jsxImportSource\"` from tsconfig if specified.\r\n\r\nFor `react-jsx` it's important to note that it doesn't implicitly set `jsxDevelopment` to false. This is to support the case where a user sets `react-jsx` in their tsconfig but then toggles development mode directly in esbuild, e.g., by environment variable or some other means.\r\n\r\n**esbuild vs Babel vs TS vs...**\r\n\r\nThere are a few differences between the various technologies that implement automatic JSX runtimes. Though esbuild generally follows TypeScript's behavior when there is a disagreement, I chose to follow Babel in cases where it might help the user catch invalid or undesirable behavior.\r\n\r\nHere are the notable differences:\r\n- Element has `__source` or `__self` props:\r\n  - Babel: print an error about a deprecated transform plugin\r\n  - TypeScript: allow the props\r\n  - swc: Hard crash\r\n  - **esbuild**: print an error &mdash; I chose to follow Babel for this one because this might help people catch configuration issues where JSX files are being parsed by multiple tools\r\n\r\n- Element has an \"implicit true\" key prop, e.g. `<a key />`:\r\n  - Babel: print an error indicating that \"key\" props require an explicit value\r\n  - TypeScript: silently omit the \"key\" prop\r\n  - swc: Hard crash\r\n  - **esbuild**: print an error like Babel &mdash; this might help catch legitimate programming mistakes\r\n\r\n- Element has spread children, e.g. `<a>{...children}</a>`\r\n  - Babel: print an error stating that React doesn't support spread children\r\n  - TypeScript: use static jsx function and pass children as-is, including spread operator\r\n  - swc: same as Babel\r\n  - **esbuild**: same as TypeScript\r\n","reactions":{"url":"https://api.github.com/repos/evanw/esbuild/issues/2349/reactions","total_count":100,"+1":44,"-1":0,"laugh":0,"hooray":13,"confused":0,"heart":33,"rocket":10,"eyes":0},"timeline_url":"https://api.github.com/repos/evanw/esbuild/issues/2349/timeline","performed_via_github_app":null,"state_reason":null,"score":1,"files":[{"sha":"ea475536c162c5d470a028df172f0d75d9d732e4","filename":"CHANGELOG.md","status":"modified","additions":55,"deletions":0,"changes":55,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/CHANGELOG.md","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/CHANGELOG.md","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/CHANGELOG.md?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -1,5 +1,60 @@\n # Changelog\n \n+## Unreleased\n+\n+* Add support for React 17's `automatic` JSX transform ([#334](https://github.com/evanw/esbuild/issues/334), [#718](https://github.com/evanw/esbuild/issues/718), [#1172](https://github.com/evanw/esbuild/issues/1172), [#2318](https://github.com/evanw/esbuild/issues/2318), [#334](https://github.com/evanw/esbuild/pull/2349))\n+\n+    This adds support for the [new \"automatic\" JSX runtime from React 17+](https://reactjs.org/blog/2020/09/22/introducing-the-new-jsx-transform.html) to esbuild for both the build and transform APIs.\n+\n+    **New CLI flags and API options:**\n+    - `--jsx`, `jsx` &mdash; Set this to `\"automatic\"` to opt in to this new transform\n+    - `--jsx-dev`, `jsxDev` &mdash; Toggles development mode for the automatic runtime\n+    - `--jsx-import-source`, `jsxImportSource` &mdash; Overrides the root import for runtime functions (default `\"react\"`)\n+\n+    **New JSX pragma comments:**\n+    - `@jsxRuntime` &mdash; Sets the runtime (`automatic` or `classic`)\n+    - `@jsxImportSource` &mdash; Sets the import source (only valid with automatic runtime)\n+\n+    The existing `@jsxFragment` and `@jsxFactory` pragma comments are only valid with \"classic\" runtime.\n+\n+    **TSConfig resolving:**\n+    Along with accepting the new options directly via CLI or API, option inference from `tsconfig.json` compiler options was also implemented:\n+\n+    - `\"jsx\": \"preserve\"` or `\"jsx\": \"react-native\"` &rarr; Same as `--jsx=preserve` in esbuild\n+    - `\"jsx\": \"react\"` &rarr; Same as `--jsx=transform` in esbuild (which is the default behavior)\n+    - `\"jsx\": \"react-jsx\"` &rarr; Same as `--jsx=automatic` in esbuild\n+    - `\"jsx\": \"react-jsxdev\"` &rarr; Same as `--jsx=automatic --jsx-dev` in esbuild\n+\n+    It also reads the value of `\"jsxImportSource\"` from `tsconfig.json` if specified.\n+\n+    For `react-jsx` it's important to note that it doesn't implicitly disable `--jsx-dev`. This is to support the case where a user sets `\"react-jsx\"` in their `tsconfig.json` but then toggles development mode directly in esbuild.\n+\n+    **esbuild vs Babel vs TS vs...**\n+\n+    There are a few differences between the various technologies that implement automatic JSX runtimes. The JSX transform in esbuild follows a mix of Babel's and TypeScript's behavior:\n+\n+    - When an element has `__source` or `__self` props:\n+        - Babel: Print an error about a deprecated transform plugin\n+        - TypeScript: Allow the props\n+        - swc: Hard crash\n+        - **esbuild**: Print an error &mdash; Following Babel was chosen for this one because this might help people catch configuration issues where JSX files are being parsed by multiple tools\n+\n+    - Element has an \"implicit true\" key prop, e.g. `<a key />`:\n+        - Babel: Print an error indicating that \"key\" props require an explicit value\n+        - TypeScript: Silently omit the \"key\" prop\n+        - swc: Hard crash\n+        - **esbuild**: Print an error like Babel &mdash; This might help catch legitimate programming mistakes\n+\n+    - Element has spread children, e.g. `<a>{...children}</a>`\n+        - Babel: Print an error stating that React doesn't support spread children\n+        - TypeScript: Use static jsx function and pass children as-is, including spread operator\n+        - swc: same as Babel\n+        - **esbuild**: Same as TypeScript\n+\n+    Also note that TypeScript has some bugs regarding JSX development mode and the generation of `lineNumber` and `columnNumber` values. Babel's values are accurate though, so esbuild's line and column numbers match Babel. Both numbers are 1-based and columns are counted in terms of UTF-16 code units.\n+\n+    This feature was contributed by [@jgoz](https://github.com/jgoz).\n+\n ## 0.14.50\n \n * Emit `names` in source maps ([#1296](https://github.com/evanw/esbuild/issues/1296))"},{"sha":"6f9dc823a9a64c3fc0bdcc32f7587b2f947fe012","filename":"cmd/esbuild/main.go","status":"modified","additions":5,"deletions":1,"changes":6,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/cmd%2Fesbuild%2Fmain.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/cmd%2Fesbuild%2Fmain.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/cmd%2Fesbuild%2Fmain.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -77,9 +77,13 @@ var helpText = func(colors logger.Colors) string {\n                             incorrect tree-shaking annotations\n   --inject:F                Import the file F into all input files and\n                             automatically replace matching globals with imports\n+  --jsx-dev                 Use React's automatic runtime in development mode\n   --jsx-factory=...         What to use for JSX instead of React.createElement\n   --jsx-fragment=...        What to use for JSX instead of React.Fragment\n-  --jsx=...                 Set to \"preserve\" to disable transforming JSX to JS\n+  --jsx-import-source=...   Override the package name for the automatic runtime\n+                            (default \"react\")\n+  --jsx=...                 Set to \"automatic\" to use React's automatic runtime\n+                            or to \"preserve\" to disable transforming JSX to JS\n   --keep-names              Preserve \"name\" on functions and classes\n   --legal-comments=...      Where to place legal comments (none | inline |\n                             eof | linked | external, default eof when bundling"},{"sha":"4c3c2c61c0a853cbf6b9f5d747009c09ce641ea1","filename":"internal/bundler/bundler.go","status":"modified","additions":6,"deletions":0,"changes":6,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fbundler.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fbundler.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -1194,6 +1194,12 @@ func (s *scanner) maybeParseFile(\n \tif len(resolveResult.JSXFragment) > 0 {\n \t\toptionsClone.JSX.Fragment = config.DefineExpr{Parts: resolveResult.JSXFragment}\n \t}\n+\tif resolveResult.JSX != config.TSJSXNone {\n+\t\toptionsClone.JSX.SetOptionsFromTSJSX(resolveResult.JSX)\n+\t}\n+\tif resolveResult.JSXImportSource != \"\" {\n+\t\toptionsClone.JSX.ImportSource = resolveResult.JSXImportSource\n+\t}\n \tif resolveResult.UseDefineForClassFieldsTS != config.Unspecified {\n \t\toptionsClone.UseDefineForClassFields = resolveResult.UseDefineForClassFieldsTS\n \t}"},{"sha":"465695864ae5642cf73e608babbc7d282012cfd2","filename":"internal/bundler/bundler_default_test.go","status":"modified","additions":82,"deletions":0,"changes":82,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fbundler_default_test.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fbundler_default_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler_default_test.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -539,6 +539,88 @@ func TestJSXConstantFragments(t *testing.T) {\n \t})\n }\n \n+func TestJSXAutomaticImportsCommonJS(t *testing.T) {\n+\tdefault_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/entry.jsx\": `\n+\t\t\t\timport {jsx, Fragment} from './custom-react'\n+\t\t\t\tconsole.log(<div jsx={jsx}/>, <><Fragment/></>)\n+\t\t\t`,\n+\t\t\t\"/custom-react.js\": `\n+\t\t\t\tmodule.exports = {}\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/entry.jsx\"},\n+\t\toptions: config.Options{\n+\t\t\tMode: config.ModeBundle,\n+\t\t\tJSX: config.JSXOptions{\n+\t\t\t\tAutomaticRuntime: true,\n+\t\t\t},\n+\t\t\tExternalSettings: config.ExternalSettings{\n+\t\t\t\tPreResolve: config.ExternalMatchers{Exact: map[string]bool{\n+\t\t\t\t\t\"react/jsx-runtime\": true,\n+\t\t\t\t}},\n+\t\t\t},\n+\t\t\tAbsOutputFile: \"/out.js\",\n+\t\t},\n+\t})\n+}\n+\n+func TestJSXAutomaticImportsES6(t *testing.T) {\n+\tdefault_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/entry.jsx\": `\n+\t\t\t\timport {jsx, Fragment} from './custom-react'\n+\t\t\t\tconsole.log(<div jsx={jsx}/>, <><Fragment/></>)\n+\t\t\t`,\n+\t\t\t\"/custom-react.js\": `\n+\t\t\t\texport function jsx() {}\n+\t\t\t\texport function Fragment() {}\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/entry.jsx\"},\n+\t\toptions: config.Options{\n+\t\t\tMode: config.ModeBundle,\n+\t\t\tJSX: config.JSXOptions{\n+\t\t\t\tAutomaticRuntime: true,\n+\t\t\t},\n+\t\t\tExternalSettings: config.ExternalSettings{\n+\t\t\t\tPreResolve: config.ExternalMatchers{Exact: map[string]bool{\n+\t\t\t\t\t\"react/jsx-runtime\": true,\n+\t\t\t\t}},\n+\t\t\t},\n+\t\t\tAbsOutputFile: \"/out.js\",\n+\t\t},\n+\t})\n+}\n+\n+func TestJSXAutomaticSyntaxInJS(t *testing.T) {\n+\tdefault_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/entry.js\": `\n+\t\t\t\tconsole.log(<div/>)\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode: config.ModeBundle,\n+\t\t\tJSX: config.JSXOptions{\n+\t\t\t\tAutomaticRuntime: true,\n+\t\t\t},\n+\t\t\tExternalSettings: config.ExternalSettings{\n+\t\t\t\tPreResolve: config.ExternalMatchers{Exact: map[string]bool{\n+\t\t\t\t\t\"react/jsx-runtime\": true,\n+\t\t\t\t}},\n+\t\t\t},\n+\t\t\tAbsOutputFile: \"/out.js\",\n+\t\t},\n+\t\texpectedScanLog: `entry.js: ERROR: The JSX syntax extension is not currently enabled\n+NOTE: The esbuild loader for this file is currently set to \"js\" but it must be set to \"jsx\" to be able to parse JSX syntax. ` +\n+\t\t\t`You can use 'Loader: map[string]api.Loader{\".js\": api.LoaderJSX}' to do that.\n+`,\n+\t})\n+}\n+\n func TestNodeModules(t *testing.T) {\n \tdefault_suite.expectBundled(t, bundled{\n \t\tfiles: map[string]string{"},{"sha":"5fd33baa7aa38aa9eaf535e9c4537afec23c2b72","filename":"internal/bundler/bundler_tsconfig_test.go","status":"modified","additions":85,"deletions":0,"changes":85,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fbundler_tsconfig_test.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fbundler_tsconfig_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler_tsconfig_test.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -601,6 +601,91 @@ func TestTsConfigNestedJSX(t *testing.T) {\n \t})\n }\n \n+func TestTsConfigReactJSX(t *testing.T) {\n+\ttsconfig_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/entry.tsx\": `\n+\t\t\t\tconsole.log(<><div/><div/></>)\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/tsconfig.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"compilerOptions\": {\n+\t\t\t\t\t\t\"jsx\": \"react-jsx\",\n+\t\t\t\t\t\t\"jsxImportSource\": \"notreact\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/entry.tsx\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t\tExternalSettings: config.ExternalSettings{\n+\t\t\t\tPreResolve: config.ExternalMatchers{Exact: map[string]bool{\n+\t\t\t\t\t\"notreact/jsx-runtime\": true,\n+\t\t\t\t}},\n+\t\t\t},\n+\t\t},\n+\t})\n+}\n+\n+func TestTsConfigReactJSXDev(t *testing.T) {\n+\ttsconfig_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/entry.tsx\": `\n+\t\t\t\tconsole.log(<><div/><div/></>)\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/tsconfig.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"compilerOptions\": {\n+\t\t\t\t\t\t\"jsx\": \"react-jsxdev\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/entry.tsx\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t\tExternalSettings: config.ExternalSettings{\n+\t\t\t\tPreResolve: config.ExternalMatchers{Exact: map[string]bool{\n+\t\t\t\t\t\"react/jsx-dev-runtime\": true,\n+\t\t\t\t}},\n+\t\t\t},\n+\t\t},\n+\t})\n+}\n+\n+func TestTsConfigReactJSXWithDevInMainConfig(t *testing.T) {\n+\ttsconfig_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/entry.tsx\": `\n+\t\t\t\tconsole.log(<><div/><div/></>)\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/tsconfig.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"compilerOptions\": {\n+\t\t\t\t\t\t\"jsx\": \"react-jsx\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/entry.tsx\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t\tJSX: config.JSXOptions{\n+\t\t\t\tDevelopment: true,\n+\t\t\t},\n+\t\t\tExternalSettings: config.ExternalSettings{\n+\t\t\t\tPreResolve: config.ExternalMatchers{Exact: map[string]bool{\n+\t\t\t\t\t\"react/jsx-dev-runtime\": true,\n+\t\t\t\t}},\n+\t\t\t},\n+\t\t},\n+\t})\n+}\n+\n func TestTsconfigJsonBaseUrl(t *testing.T) {\n \ttsconfig_suite.expectBundled(t, bundled{\n \t\tfiles: map[string]string{"},{"sha":"4816fecf9c7636754df98338799e13f63ddfabb8","filename":"internal/bundler/snapshots/snapshots_default.txt","status":"modified","additions":36,"deletions":0,"changes":36,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fsnapshots%2Fsnapshots_default.txt","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fsnapshots%2Fsnapshots_default.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_default.txt?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -1415,6 +1415,42 @@ console.log(replace.test);\n console.log(collide);\n console.log(re_export);\n \n+================================================================================\n+TestJSXAutomaticImportsCommonJS\n+---------- /out.js ----------\n+// custom-react.js\n+var require_custom_react = __commonJS({\n+  \"custom-react.js\"(exports, module) {\n+    module.exports = {};\n+  }\n+});\n+\n+// entry.jsx\n+var import_custom_react = __toESM(require_custom_react());\n+import { Fragment as Fragment2, jsx as jsx2 } from \"react/jsx-runtime\";\n+console.log(/* @__PURE__ */ jsx2(\"div\", {\n+  jsx: import_custom_react.jsx\n+}), /* @__PURE__ */ jsx2(Fragment2, {\n+  children: /* @__PURE__ */ jsx2(import_custom_react.Fragment, {})\n+}));\n+\n+================================================================================\n+TestJSXAutomaticImportsES6\n+---------- /out.js ----------\n+// custom-react.js\n+function jsx() {\n+}\n+function Fragment() {\n+}\n+\n+// entry.jsx\n+import { Fragment as Fragment2, jsx as jsx2 } from \"react/jsx-runtime\";\n+console.log(/* @__PURE__ */ jsx2(\"div\", {\n+  jsx\n+}), /* @__PURE__ */ jsx2(Fragment2, {\n+  children: /* @__PURE__ */ jsx2(Fragment, {})\n+}));\n+\n ================================================================================\n TestJSXConstantFragments\n ---------- /out.js ----------"},{"sha":"63831a5ca0152adff8874ae9f1999bf54bf05d56","filename":"internal/bundler/snapshots/snapshots_tsconfig.txt","status":"modified","additions":60,"deletions":0,"changes":60,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fsnapshots%2Fsnapshots_tsconfig.txt","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fbundler%2Fsnapshots%2Fsnapshots_tsconfig.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_tsconfig.txt?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -314,6 +314,66 @@ function fib(input) {\n // Users/user/project/entry.ts\n console.log(fib(10));\n \n+================================================================================\n+TestTsConfigReactJSX\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/entry.tsx\n+import { Fragment, jsx, jsxs } from \"notreact/jsx-runtime\";\n+console.log(/* @__PURE__ */ jsxs(Fragment, {\n+  children: [\n+    /* @__PURE__ */ jsx(\"div\", {}),\n+    /* @__PURE__ */ jsx(\"div\", {})\n+  ]\n+}));\n+\n+================================================================================\n+TestTsConfigReactJSXDev\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/entry.tsx\n+import { Fragment, jsxDEV } from \"react/jsx-dev-runtime\";\n+console.log(/* @__PURE__ */ jsxDEV(Fragment, {\n+  children: [\n+    /* @__PURE__ */ jsxDEV(\"div\", {}, void 0, false, {\n+      fileName: \"Users/user/project/entry.tsx\",\n+      lineNumber: 2,\n+      columnNumber: 19\n+    }, this),\n+    /* @__PURE__ */ jsxDEV(\"div\", {}, void 0, false, {\n+      fileName: \"Users/user/project/entry.tsx\",\n+      lineNumber: 2,\n+      columnNumber: 25\n+    }, this)\n+  ]\n+}, void 0, true, {\n+  fileName: \"Users/user/project/entry.tsx\",\n+  lineNumber: 2,\n+  columnNumber: 17\n+}, this));\n+\n+================================================================================\n+TestTsConfigReactJSXWithDevInMainConfig\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/entry.tsx\n+import { Fragment, jsxDEV } from \"react/jsx-dev-runtime\";\n+console.log(/* @__PURE__ */ jsxDEV(Fragment, {\n+  children: [\n+    /* @__PURE__ */ jsxDEV(\"div\", {}, void 0, false, {\n+      fileName: \"Users/user/project/entry.tsx\",\n+      lineNumber: 2,\n+      columnNumber: 19\n+    }, this),\n+    /* @__PURE__ */ jsxDEV(\"div\", {}, void 0, false, {\n+      fileName: \"Users/user/project/entry.tsx\",\n+      lineNumber: 2,\n+      columnNumber: 25\n+    }, this)\n+  ]\n+}, void 0, true, {\n+  fileName: \"Users/user/project/entry.tsx\",\n+  lineNumber: 2,\n+  columnNumber: 17\n+}, this));\n+\n ================================================================================\n TestTsConfigWithStatementAlwaysStrictFalse\n ---------- /Users/user/project/out.js ----------"},{"sha":"043313fd97068e748dac12caf1e43fe28fc5c0e1","filename":"internal/config/config.go","status":"modified","additions":34,"deletions":4,"changes":38,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fconfig%2Fconfig.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fconfig%2Fconfig.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fconfig%2Fconfig.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -13,10 +13,39 @@ import (\n )\n \n type JSXOptions struct {\n-\tFactory  DefineExpr\n-\tFragment DefineExpr\n-\tParse    bool\n-\tPreserve bool\n+\tFactory          DefineExpr\n+\tFragment         DefineExpr\n+\tParse            bool\n+\tPreserve         bool\n+\tAutomaticRuntime bool\n+\tImportSource     string\n+\tDevelopment      bool\n+}\n+\n+type TSJSX uint8\n+\n+const (\n+\tTSJSXNone TSJSX = iota\n+\tTSJSXPreserve\n+\tTSJSXReact\n+\tTSJSXReactJSX\n+\tTSJSXReactJSXDev\n+)\n+\n+func (jsxOptions *JSXOptions) SetOptionsFromTSJSX(tsx TSJSX) {\n+\tswitch tsx {\n+\tcase TSJSXPreserve:\n+\t\tjsxOptions.Preserve = true\n+\tcase TSJSXReact:\n+\t\tjsxOptions.AutomaticRuntime = false\n+\t\tjsxOptions.Development = false\n+\tcase TSJSXReactJSX:\n+\t\tjsxOptions.AutomaticRuntime = true\n+\t\t// Don't set Development = false implicitly\n+\tcase TSJSXReactJSXDev:\n+\t\tjsxOptions.AutomaticRuntime = true\n+\t\tjsxOptions.Development = true\n+\t}\n }\n \n type TSOptions struct {\n@@ -276,6 +305,7 @@ type Options struct {\n \tWriteToStdout bool\n \n \tOmitRuntimeForTests     bool\n+\tOmitJSXRuntimeForTests  bool\n \tUnusedImportFlagsTS     UnusedImportFlagsTS\n \tUseDefineForClassFields MaybeBool\n \tASCIIOnly               bool"},{"sha":"55fc0c233f505d711ae197379ca9d0c18219949c","filename":"internal/js_ast/js_ast.go","status":"modified","additions":1,"deletions":0,"changes":1,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_ast%2Fjs_ast.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_ast%2Fjs_ast.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_ast%2Fjs_ast.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -1525,6 +1525,7 @@ const (\n \tImplicitStrictModeClass\n \tImplicitStrictModeESM\n \tImplicitStrictModeTSAlwaysStrict\n+\tImplicitStrictModeJSXAutomaticRuntime\n )\n \n func (s *Scope) RecursiveSetStrictMode(kind StrictModeKind) {"},{"sha":"b25189b3b9a4f068af2279921beb2b1d809133b2","filename":"internal/js_lexer/js_lexer.go","status":"modified","additions":19,"deletions":9,"changes":28,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_lexer%2Fjs_lexer.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_lexer%2Fjs_lexer.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_lexer%2Fjs_lexer.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -245,15 +245,17 @@ type MaybeSubstring struct {\n }\n \n type Lexer struct {\n-\tCommentsToPreserveBefore []js_ast.Comment\n-\tAllOriginalComments      []js_ast.Comment\n-\tIdentifier               MaybeSubstring\n-\tlog                      logger.Log\n-\tsource                   logger.Source\n-\tJSXFactoryPragmaComment  logger.Span\n-\tJSXFragmentPragmaComment logger.Span\n-\tSourceMappingURL         logger.Span\n-\tBadArrowInTSXSuggestion  string\n+\tCommentsToPreserveBefore     []js_ast.Comment\n+\tAllOriginalComments          []js_ast.Comment\n+\tIdentifier                   MaybeSubstring\n+\tlog                          logger.Log\n+\tsource                       logger.Source\n+\tJSXFactoryPragmaComment      logger.Span\n+\tJSXFragmentPragmaComment     logger.Span\n+\tJSXRuntimePragmaComment      logger.Span\n+\tJSXImportSourcePragmaComment logger.Span\n+\tSourceMappingURL             logger.Span\n+\tBadArrowInTSXSuggestion      string\n \n \t// Escape sequences in string literals are decoded lazily because they are\n \t// not interpreted inside tagged templates, and tagged templates can contain\n@@ -2786,6 +2788,14 @@ func (lexer *Lexer) scanCommentText() {\n \t\t\t\tif arg, ok := scanForPragmaArg(pragmaSkipSpaceFirst, lexer.start+i+1, \"jsxFrag\", rest); ok {\n \t\t\t\t\tlexer.JSXFragmentPragmaComment = arg\n \t\t\t\t}\n+\t\t\t} else if hasPrefixWithWordBoundary(rest, \"jsxRuntime\") {\n+\t\t\t\tif arg, ok := scanForPragmaArg(pragmaSkipSpaceFirst, lexer.start+i+1, \"jsxRuntime\", rest); ok {\n+\t\t\t\t\tlexer.JSXRuntimePragmaComment = arg\n+\t\t\t\t}\n+\t\t\t} else if hasPrefixWithWordBoundary(rest, \"jsxImportSource\") {\n+\t\t\t\tif arg, ok := scanForPragmaArg(pragmaSkipSpaceFirst, lexer.start+i+1, \"jsxImportSource\", rest); ok {\n+\t\t\t\t\tlexer.JSXImportSourcePragmaComment = arg\n+\t\t\t\t}\n \t\t\t} else if i == 2 && strings.HasPrefix(rest, \" sourceMappingURL=\") {\n \t\t\t\tif arg, ok := scanForPragmaArg(pragmaNoSpaceFirst, lexer.start+i+1, \" sourceMappingURL=\", rest); ok {\n \t\t\t\t\tlexer.SourceMappingURL = arg"},{"sha":"90b64074f0342603f1b19feecda4dfe6a154cf93","filename":"internal/js_parser/js_parser.go","status":"modified","additions":391,"deletions":49,"changes":440,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_parser%2Fjs_parser.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_parser%2Fjs_parser.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_parser%2Fjs_parser.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -194,6 +194,11 @@ type parser struct {\n \ttempRefCount         int\n \ttopLevelTempRefCount int\n \n+\t// We need to scan over the source contents to recover the line and column offsets\n+\tjsxSourceLoc    int\n+\tjsxSourceLine   int\n+\tjsxSourceColumn int\n+\n \texportsRef               js_ast.Ref\n \trequireRef               js_ast.Ref\n \tmoduleRef                js_ast.Ref\n@@ -204,6 +209,11 @@ type parser struct {\n \tsuperCtorRef             js_ast.Ref\n \tjsxDevRef                js_ast.Ref\n \n+\t// Imports from \"react/jsx-runtime\" and \"react\", respectively.\n+\t// (Or whatever was specified in the \"importSource\" option)\n+\tjsxRuntimeImports map[string]js_ast.Ref\n+\tjsxLegacyImports  map[string]js_ast.Ref\n+\n \t// For lowering private methods\n \tweakMapRef js_ast.Ref\n \tweakSetRef js_ast.Ref\n@@ -216,6 +226,7 @@ type parser struct {\n \n \tlatestArrowArgLoc      logger.Loc\n \tforbidSuffixAfterAsLoc logger.Loc\n+\tfirstJSXElementLoc     logger.Loc\n \n \tfnOrArrowDataVisit fnOrArrowDataVisit\n \n@@ -396,6 +407,7 @@ type optionsThatSupportStructuralEquality struct {\n \tminifySyntax            bool\n \tminifyIdentifiers       bool\n \tomitRuntimeForTests     bool\n+\tomitJSXRuntimeForTests  bool\n \tignoreDCEAnnotations    bool\n \ttreeShaking             bool\n \tdropDebugger            bool\n@@ -430,6 +442,7 @@ func OptionsFromConfig(options *config.Options) Options {\n \t\t\tminifySyntax:                      options.MinifySyntax,\n \t\t\tminifyIdentifiers:                 options.MinifyIdentifiers,\n \t\t\tomitRuntimeForTests:               options.OmitRuntimeForTests,\n+\t\t\tomitJSXRuntimeForTests:            options.OmitJSXRuntimeForTests,\n \t\t\tignoreDCEAnnotations:              options.IgnoreDCEAnnotations,\n \t\t\ttreeShaking:                       options.TreeShaking,\n \t\t\tdropDebugger:                      options.DropDebugger,\n@@ -1515,6 +1528,55 @@ func (p *parser) callRuntime(loc logger.Loc, name string, args []js_ast.Expr) js\n \t}}\n }\n \n+type JSXImport uint8\n+\n+const (\n+\tJSXImportJSX JSXImport = iota\n+\tJSXImportJSXS\n+\tJSXImportFragment\n+\tJSXImportCreateElement\n+)\n+\n+func (p *parser) importJSXSymbol(loc logger.Loc, jsx JSXImport) js_ast.Expr {\n+\tvar symbols map[string]js_ast.Ref\n+\tvar name string\n+\n+\tswitch jsx {\n+\tcase JSXImportJSX:\n+\t\tsymbols = p.jsxRuntimeImports\n+\t\tif p.options.jsx.Development {\n+\t\t\tname = \"jsxDEV\"\n+\t\t} else {\n+\t\t\tname = \"jsx\"\n+\t\t}\n+\tcase JSXImportJSXS:\n+\t\tsymbols = p.jsxRuntimeImports\n+\t\tif p.options.jsx.Development {\n+\t\t\tname = \"jsxDEV\"\n+\t\t} else {\n+\t\t\tname = \"jsxs\"\n+\t\t}\n+\tcase JSXImportFragment:\n+\t\tsymbols = p.jsxRuntimeImports\n+\t\tname = \"Fragment\"\n+\tcase JSXImportCreateElement:\n+\t\tsymbols = p.jsxLegacyImports\n+\t\tname = \"createElement\"\n+\t}\n+\n+\tref, ok := symbols[name]\n+\tif !ok {\n+\t\tref = p.newSymbol(js_ast.SymbolOther, name)\n+\t\tp.moduleScope.Generated = append(p.moduleScope.Generated, ref)\n+\t\tp.isImportItem[ref] = true\n+\t\tsymbols[name] = ref\n+\t}\n+\tp.recordUsage(ref)\n+\treturn p.handleIdentifier(loc, &js_ast.EIdentifier{Ref: ref}, identifierOpts{\n+\t\twasOriginallyIdentifier: true,\n+\t})\n+}\n+\n func (p *parser) valueToSubstituteForRequire(loc logger.Loc) js_ast.Expr {\n \tif p.source.Index != runtime.SourceIndex &&\n \t\tconfig.ShouldCallRuntimeRequire(p.options.mode, p.options.outputFormat) {\n@@ -4455,6 +4517,11 @@ func (p *parser) parseJSXTag() (logger.Range, string, js_ast.Expr) {\n }\n \n func (p *parser) parseJSXElement(loc logger.Loc) js_ast.Expr {\n+\t// Keep track of the location of the first JSX element for error messages\n+\tif p.firstJSXElementLoc.Start == -1 {\n+\t\tp.firstJSXElementLoc = loc\n+\t}\n+\n \t// Parse the tag\n \tstartRange, startText, startTagOrNil := p.parseJSXTag()\n \n@@ -12058,6 +12125,38 @@ func (p *parser) visitExprInOut(expr js_ast.Expr, in exprIn) (js_ast.Expr, exprO\n \n \tcase *js_ast.EJSXElement:\n \t\tpropsLoc := expr.Loc\n+\n+\t\t// Resolving the location index to a specific line and column in\n+\t\t// development mode is not too expensive because we seek from the\n+\t\t// previous JSX element. It amounts to at most a single additional\n+\t\t// scan over the source code. Note that this has to happen before\n+\t\t// we visit anything about this JSX element to make sure that we\n+\t\t// only ever need to scan forward, not backward.\n+\t\tvar jsxSourceLine int\n+\t\tvar jsxSourceColumn int\n+\t\tif p.options.jsx.Development && p.options.jsx.AutomaticRuntime {\n+\t\t\tfor p.jsxSourceLoc < int(propsLoc.Start) {\n+\t\t\t\tr, size := utf8.DecodeRuneInString(p.source.Contents[p.jsxSourceLoc:])\n+\t\t\t\tp.jsxSourceLoc += size\n+\t\t\t\tif r == '\\n' || r == '\\r' || r == '\\u2028' || r == '\\u2029' {\n+\t\t\t\t\tif r == '\\r' && p.jsxSourceLoc < len(p.source.Contents) && p.source.Contents[p.jsxSourceLoc] == '\\n' {\n+\t\t\t\t\t\tp.jsxSourceLoc++ // Handle Windows-style CRLF newlines\n+\t\t\t\t\t}\n+\t\t\t\t\tp.jsxSourceLine++\n+\t\t\t\t\tp.jsxSourceColumn = 0\n+\t\t\t\t} else {\n+\t\t\t\t\t// Babel and TypeScript count columns in UTF-16 code units\n+\t\t\t\t\tif r < 0xFFFF {\n+\t\t\t\t\t\tp.jsxSourceColumn++\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tp.jsxSourceColumn += 2\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tjsxSourceLine = p.jsxSourceLine\n+\t\t\tjsxSourceColumn = p.jsxSourceColumn\n+\t\t}\n+\n \t\tif e.TagOrNil.Data != nil {\n \t\t\tpropsLoc = e.TagOrNil.Loc\n \t\t\te.TagOrNil = p.visitExpr(e.TagOrNil)\n@@ -12101,39 +12200,195 @@ func (p *parser) visitExprInOut(expr js_ast.Expr, in exprIn) (js_ast.Expr, exprO\n \t\t} else {\n \t\t\t// A missing tag is a fragment\n \t\t\tif e.TagOrNil.Data == nil {\n-\t\t\t\te.TagOrNil = p.instantiateDefineExpr(expr.Loc, p.options.jsx.Fragment, identifierOpts{\n-\t\t\t\t\twasOriginallyIdentifier: true,\n-\t\t\t\t\tmatchAgainstDefines:     true, // Allow defines to rewrite the JSX fragment factory\n-\t\t\t\t})\n+\t\t\t\tif p.options.jsx.AutomaticRuntime {\n+\t\t\t\t\te.TagOrNil = p.importJSXSymbol(expr.Loc, JSXImportFragment)\n+\t\t\t\t} else {\n+\t\t\t\t\te.TagOrNil = p.instantiateDefineExpr(expr.Loc, p.options.jsx.Fragment, identifierOpts{\n+\t\t\t\t\t\twasOriginallyIdentifier: true,\n+\t\t\t\t\t\tmatchAgainstDefines:     true, // Allow defines to rewrite the JSX fragment factory\n+\t\t\t\t\t})\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tshouldUseCreateElement := !p.options.jsx.AutomaticRuntime\n+\t\t\tif !shouldUseCreateElement {\n+\t\t\t\t// Even for runtime=\"automatic\", <div {...props} key={key} /> is special cased to createElement\n+\t\t\t\t// See https://github.com/babel/babel/blob/e482c763466ba3f44cb9e3467583b78b7f030b4a/packages/babel-plugin-transform-react-jsx/src/create-plugin.ts#L352\n+\t\t\t\tseenPropsSpread := false\n+\t\t\t\tfor _, property := range e.Properties {\n+\t\t\t\t\tif seenPropsSpread && property.Kind == js_ast.PropertyNormal {\n+\t\t\t\t\t\tif str, ok := property.Key.Data.(*js_ast.EString); ok && helpers.UTF16EqualsString(str.Value, \"key\") {\n+\t\t\t\t\t\t\tshouldUseCreateElement = true\n+\t\t\t\t\t\t\tbreak\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else if property.Kind == js_ast.PropertySpread {\n+\t\t\t\t\t\tseenPropsSpread = true\n+\t\t\t\t\t}\n+\t\t\t\t}\n \t\t\t}\n \n-\t\t\t// Arguments to createElement()\n-\t\t\targs := []js_ast.Expr{e.TagOrNil}\n-\t\t\tif len(e.Properties) > 0 {\n+\t\t\tif shouldUseCreateElement {\n+\t\t\t\t// Arguments to createElement()\n+\t\t\t\targs := []js_ast.Expr{e.TagOrNil}\n+\t\t\t\tif len(e.Properties) > 0 {\n+\t\t\t\t\targs = append(args, p.lowerObjectSpread(propsLoc, &js_ast.EObject{\n+\t\t\t\t\t\tProperties: e.Properties,\n+\t\t\t\t\t}))\n+\t\t\t\t} else {\n+\t\t\t\t\targs = append(args, js_ast.Expr{Loc: propsLoc, Data: js_ast.ENullShared})\n+\t\t\t\t}\n+\t\t\t\tif len(e.Children) > 0 {\n+\t\t\t\t\targs = append(args, e.Children...)\n+\t\t\t\t}\n+\n+\t\t\t\t// Call createElement()\n+\t\t\t\tvar target js_ast.Expr\n+\t\t\t\tif p.options.jsx.AutomaticRuntime {\n+\t\t\t\t\ttarget = p.importJSXSymbol(expr.Loc, JSXImportCreateElement)\n+\t\t\t\t} else {\n+\t\t\t\t\ttarget = p.instantiateDefineExpr(expr.Loc, p.options.jsx.Factory, identifierOpts{\n+\t\t\t\t\t\twasOriginallyIdentifier: true,\n+\t\t\t\t\t\tmatchAgainstDefines:     true, // Allow defines to rewrite the JSX factory\n+\t\t\t\t\t})\n+\t\t\t\t\tp.warnAboutImportNamespaceCall(target, exprKindCall)\n+\t\t\t\t}\n+\t\t\t\treturn js_ast.Expr{Loc: expr.Loc, Data: &js_ast.ECall{\n+\t\t\t\t\tTarget:        target,\n+\t\t\t\t\tArgs:          args,\n+\t\t\t\t\tCloseParenLoc: e.CloseLoc,\n+\n+\t\t\t\t\t// Enable tree shaking\n+\t\t\t\t\tCanBeUnwrappedIfUnused: !p.options.ignoreDCEAnnotations,\n+\t\t\t\t}}, exprOut{}\n+\t\t\t} else {\n+\t\t\t\t// Arguments to jsx()\n+\t\t\t\targs := []js_ast.Expr{e.TagOrNil}\n+\n+\t\t\t\t// Props argument\n+\t\t\t\tproperties := make([]js_ast.Property, 0, len(e.Properties)+1)\n+\n+\t\t\t\t// For jsx(), \"key\" is passed in as a separate argument, so filter it out\n+\t\t\t\t// from the props here. Also, check for __source and __self, which might have\n+\t\t\t\t// been added by some upstream plugin. Their presence here would represent a\n+\t\t\t\t// configuration error.\n+\t\t\t\thasKey := false\n+\t\t\t\tkeyProperty := js_ast.Expr{Loc: expr.Loc, Data: js_ast.EUndefinedShared}\n+\t\t\t\tfor _, property := range e.Properties {\n+\t\t\t\t\tif str, ok := property.Key.Data.(*js_ast.EString); ok {\n+\t\t\t\t\t\tpropName := helpers.UTF16ToString(str.Value)\n+\t\t\t\t\t\tswitch propName {\n+\t\t\t\t\t\tcase \"key\":\n+\t\t\t\t\t\t\tif property.Flags.Has(js_ast.PropertyWasShorthand) {\n+\t\t\t\t\t\t\t\tr := js_lexer.RangeOfIdentifier(p.source, property.Loc)\n+\t\t\t\t\t\t\t\tmsg := logger.Msg{\n+\t\t\t\t\t\t\t\t\tKind:  logger.Error,\n+\t\t\t\t\t\t\t\t\tData:  p.tracker.MsgData(r, \"Please provide an explicit value for \\\"key\\\":\"),\n+\t\t\t\t\t\t\t\t\tNotes: []logger.MsgData{{Text: \"Using \\\"key\\\" as a shorthand for \\\"key={true}\\\" is not allowed when using React's \\\"automatic\\\" JSX transform.\"}},\n+\t\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\t\tmsg.Data.Location.Suggestion = \"key={true}\"\n+\t\t\t\t\t\t\t\tp.log.AddMsg(msg)\n+\t\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t\tkeyProperty = property.ValueOrNil\n+\t\t\t\t\t\t\t\thasKey = true\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\tcontinue\n+\n+\t\t\t\t\t\tcase \"__source\", \"__self\":\n+\t\t\t\t\t\t\tr := js_lexer.RangeOfIdentifier(p.source, property.Loc)\n+\t\t\t\t\t\t\tp.log.AddErrorWithNotes(&p.tracker, r,\n+\t\t\t\t\t\t\t\tfmt.Sprintf(\"Duplicate \\\"%s\\\" prop found:\", propName),\n+\t\t\t\t\t\t\t\t[]logger.MsgData{{Text: \"Both \\\"__source\\\" and \\\"__self\\\" are set automatically by esbuild when using React's \\\"automatic\\\" JSX transform. \" +\n+\t\t\t\t\t\t\t\t\t\"This duplicate prop may have come from a plugin.\"}})\n+\t\t\t\t\t\t\tcontinue\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tproperties = append(properties, property)\n+\t\t\t\t}\n+\n+\t\t\t\tisStaticChildren := len(e.Children) > 1\n+\n+\t\t\t\t// Children are passed in as an explicit prop\n+\t\t\t\tif len(e.Children) > 0 {\n+\t\t\t\t\tchildrenValue := e.Children[0]\n+\n+\t\t\t\t\tif len(e.Children) > 1 {\n+\t\t\t\t\t\tchildrenValue.Data = &js_ast.EArray{Items: e.Children}\n+\t\t\t\t\t} else if _, ok := childrenValue.Data.(*js_ast.ESpread); ok {\n+\t\t\t\t\t\t// TypeScript considers spread children to be static, but Babel considers\n+\t\t\t\t\t\t// it to be an error (\"Spread children are not supported in React.\").\n+\t\t\t\t\t\t// We'll follow TypeScript's behavior here because spread children may be\n+\t\t\t\t\t\t// valid with non-React source runtimes.\n+\t\t\t\t\t\tchildrenValue.Data = &js_ast.EArray{Items: []js_ast.Expr{childrenValue}}\n+\t\t\t\t\t\tisStaticChildren = true\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tproperties = append(properties, js_ast.Property{\n+\t\t\t\t\t\tKey: js_ast.Expr{\n+\t\t\t\t\t\t\tData: &js_ast.EString{Value: helpers.StringToUTF16(\"children\")},\n+\t\t\t\t\t\t\tLoc:  childrenValue.Loc,\n+\t\t\t\t\t\t},\n+\t\t\t\t\t\tValueOrNil: childrenValue,\n+\t\t\t\t\t\tKind:       js_ast.PropertyNormal,\n+\t\t\t\t\t\tLoc:        childrenValue.Loc,\n+\t\t\t\t\t})\n+\t\t\t\t}\n+\n \t\t\t\targs = append(args, p.lowerObjectSpread(propsLoc, &js_ast.EObject{\n-\t\t\t\t\tProperties: e.Properties,\n+\t\t\t\t\tProperties: properties,\n \t\t\t\t}))\n-\t\t\t} else {\n-\t\t\t\targs = append(args, js_ast.Expr{Loc: propsLoc, Data: js_ast.ENullShared})\n-\t\t\t}\n-\t\t\tif len(e.Children) > 0 {\n-\t\t\t\targs = append(args, e.Children...)\n-\t\t\t}\n \n-\t\t\t// Call createElement()\n-\t\t\ttarget := p.instantiateDefineExpr(expr.Loc, p.options.jsx.Factory, identifierOpts{\n-\t\t\t\twasOriginallyIdentifier: true,\n-\t\t\t\tmatchAgainstDefines:     true, // Allow defines to rewrite the JSX factory\n-\t\t\t})\n-\t\t\tp.warnAboutImportNamespaceCall(target, exprKindCall)\n-\t\t\treturn js_ast.Expr{Loc: expr.Loc, Data: &js_ast.ECall{\n-\t\t\t\tTarget:        target,\n-\t\t\t\tArgs:          args,\n-\t\t\t\tCloseParenLoc: e.CloseLoc,\n+\t\t\t\t// \"key\"\n+\t\t\t\tif hasKey || p.options.jsx.Development {\n+\t\t\t\t\targs = append(args, keyProperty)\n+\t\t\t\t}\n+\n+\t\t\t\tif p.options.jsx.Development {\n+\t\t\t\t\t// \"isStaticChildren\"\n+\t\t\t\t\targs = append(args, js_ast.Expr{Loc: expr.Loc, Data: &js_ast.EBoolean{Value: isStaticChildren}})\n+\n+\t\t\t\t\t// \"__source\"\n+\t\t\t\t\targs = append(args, js_ast.Expr{Loc: expr.Loc, Data: &js_ast.EObject{\n+\t\t\t\t\t\tProperties: []js_ast.Property{\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tKind:       js_ast.PropertyNormal,\n+\t\t\t\t\t\t\t\tKey:        js_ast.Expr{Loc: expr.Loc, Data: &js_ast.EString{Value: helpers.StringToUTF16(\"fileName\")}},\n+\t\t\t\t\t\t\t\tValueOrNil: js_ast.Expr{Loc: expr.Loc, Data: &js_ast.EString{Value: helpers.StringToUTF16(p.source.PrettyPath)}},\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tKind:       js_ast.PropertyNormal,\n+\t\t\t\t\t\t\t\tKey:        js_ast.Expr{Loc: expr.Loc, Data: &js_ast.EString{Value: helpers.StringToUTF16(\"lineNumber\")}},\n+\t\t\t\t\t\t\t\tValueOrNil: js_ast.Expr{Loc: expr.Loc, Data: &js_ast.ENumber{Value: float64(jsxSourceLine + 1)}}, // 1-based lines\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tKind:       js_ast.PropertyNormal,\n+\t\t\t\t\t\t\t\tKey:        js_ast.Expr{Loc: expr.Loc, Data: &js_ast.EString{Value: helpers.StringToUTF16(\"columnNumber\")}},\n+\t\t\t\t\t\t\t\tValueOrNil: js_ast.Expr{Loc: expr.Loc, Data: &js_ast.ENumber{Value: float64(jsxSourceColumn + 1)}}, // 1-based columns\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t},\n+\t\t\t\t\t}})\n+\n+\t\t\t\t\t// \"__self\"\n+\t\t\t\t\tif p.fnOrArrowDataParse.isThisDisallowed {\n+\t\t\t\t\t\targs = append(args, js_ast.Expr{Loc: expr.Loc, Data: js_ast.EUndefinedShared})\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\targs = append(args, js_ast.Expr{Loc: expr.Loc, Data: js_ast.EThisShared})\n+\t\t\t\t\t}\n+\t\t\t\t}\n \n-\t\t\t\t// Enable tree shaking\n-\t\t\t\tCanBeUnwrappedIfUnused: !p.options.ignoreDCEAnnotations,\n-\t\t\t}}, exprOut{}\n+\t\t\t\tjsx := JSXImportJSX\n+\t\t\t\tif isStaticChildren {\n+\t\t\t\t\tjsx = JSXImportJSXS\n+\t\t\t\t}\n+\n+\t\t\t\treturn js_ast.Expr{Loc: expr.Loc, Data: &js_ast.ECall{\n+\t\t\t\t\tTarget:        p.importJSXSymbol(expr.Loc, jsx),\n+\t\t\t\t\tArgs:          args,\n+\t\t\t\t\tCloseParenLoc: e.CloseLoc,\n+\n+\t\t\t\t\t// Enable tree shaking\n+\t\t\t\t\tCanBeUnwrappedIfUnused: !p.options.ignoreDCEAnnotations,\n+\t\t\t\t}}, exprOut{}\n+\t\t\t}\n \t\t}\n \n \tcase *js_ast.ETemplate:\n@@ -15360,6 +15615,7 @@ func newParser(log logger.Log, source logger.Source, lexer js_lexer.Lexer, optio\n \t\tpromiseRef:               js_ast.InvalidRef,\n \t\tregExpRef:                js_ast.InvalidRef,\n \t\tafterArrowBodyLoc:        logger.Loc{Start: -1},\n+\t\tfirstJSXElementLoc:       logger.Loc{Start: -1},\n \t\timportMetaRef:            js_ast.InvalidRef,\n \t\truntimePublicFieldImport: js_ast.InvalidRef,\n \t\tsuperCtorRef:             js_ast.InvalidRef,\n@@ -15383,6 +15639,10 @@ func newParser(log logger.Log, source logger.Source, lexer js_lexer.Lexer, optio\n \t\tnamedImports:            make(map[js_ast.Ref]js_ast.NamedImport),\n \t\tnamedExports:            make(map[string]js_ast.NamedExport),\n \n+\t\t// For JSX runtime imports\n+\t\tjsxRuntimeImports: make(map[string]js_ast.Ref),\n+\t\tjsxLegacyImports:  make(map[string]js_ast.Ref),\n+\n \t\tsuppressWarningsAboutWeirdCode: helpers.IsInsideNodeModules(source.KeyPath.Text),\n \t}\n \n@@ -15398,6 +15658,8 @@ func newParser(log logger.Log, source logger.Source, lexer js_lexer.Lexer, optio\n var defaultJSXFactory = []string{\"React\", \"createElement\"}\n var defaultJSXFragment = []string{\"React\", \"Fragment\"}\n \n+const defaultJSXImportSource = \"react\"\n+\n func Parse(log logger.Log, source logger.Source, options Options) (result js_ast.AST, ok bool) {\n \tok = true\n \tdefer func() {\n@@ -15416,6 +15678,9 @@ func Parse(log logger.Log, source logger.Source, options Options) (result js_ast\n \tif len(options.jsx.Fragment.Parts) == 0 && options.jsx.Fragment.Constant == nil {\n \t\toptions.jsx.Fragment = config.DefineExpr{Parts: defaultJSXFragment}\n \t}\n+\tif len(options.jsx.ImportSource) == 0 {\n+\t\toptions.jsx.ImportSource = defaultJSXImportSource\n+\t}\n \n \tif !options.ts.Parse {\n \t\t// Non-TypeScript files always get the real JavaScript class field behavior\n@@ -15531,7 +15796,7 @@ func Parse(log logger.Log, source logger.Source, options Options) (result js_ast\n \t\t\t\t}\n \t\t\t}\n \t\t}\n-\t\tbefore = p.generateImportStmt(file.Source.KeyPath.Text, exportsNoConflict, file.Source.Index, before, symbols)\n+\t\tbefore = p.generateImportStmt(file.Source.KeyPath.Text, exportsNoConflict, &file.Source.Index, before, symbols)\n \t}\n \n \t// Bind symbols in a second pass over the AST. I started off doing this in a\n@@ -15606,8 +15871,7 @@ func Parse(log logger.Log, source logger.Source, options Options) (result js_ast\n \t// Pop the module scope to apply the \"ContainsDirectEval\" rules\n \tp.popScope()\n \n-\tparts = append(append(before, parts...), after...)\n-\tresult = p.toAST(parts, hashbang, directive)\n+\tresult = p.toAST(before, parts, after, hashbang, directive)\n \tresult.SourceMapComment = p.lexer.SourceMappingURL\n \treturn\n }\n@@ -15638,18 +15902,11 @@ func LazyExportAST(log logger.Log, source logger.Source, options Options, expr j\n \t}\n \tp.symbolUses = nil\n \n-\tast := p.toAST([]js_ast.Part{nsExportPart, part}, \"\", \"\")\n+\tast := p.toAST(nil, []js_ast.Part{nsExportPart, part}, nil, \"\", \"\")\n \tast.HasLazyExport = true\n \treturn ast\n }\n \n-type JSXExprKind uint8\n-\n-const (\n-\tJSXFactory JSXExprKind = iota\n-\tJSXFragment\n-)\n-\n func ParseDefineExprOrJSON(text string) (config.DefineExpr, js_ast.E) {\n \tif text == \"\" {\n \t\treturn config.DefineExpr{}, nil\n@@ -15785,22 +16042,60 @@ func (p *parser) prepareForVisitPass() {\n \n \t// Handle \"@jsx\" and \"@jsxFrag\" pragmas now that lexing is done\n \tif p.options.jsx.Parse {\n+\t\tif jsxRuntime := p.lexer.JSXRuntimePragmaComment; jsxRuntime.Text != \"\" {\n+\t\t\tif jsxRuntime.Text == \"automatic\" {\n+\t\t\t\tp.options.jsx.AutomaticRuntime = true\n+\t\t\t} else if jsxRuntime.Text == \"classic\" {\n+\t\t\t\tp.options.jsx.AutomaticRuntime = false\n+\t\t\t} else {\n+\t\t\t\tp.log.AddIDWithNotes(logger.MsgID_JS_UnsupportedJSXComment, logger.Warning, &p.tracker, jsxRuntime.Range,\n+\t\t\t\t\tfmt.Sprintf(\"Invalid JSX runtime: %q\", jsxRuntime.Text),\n+\t\t\t\t\t[]logger.MsgData{{Text: \"The JSX runtime can only be set to either \\\"classic\\\" or \\\"automatic\\\".\"}})\n+\t\t\t}\n+\t\t}\n+\n \t\tif jsxFactory := p.lexer.JSXFactoryPragmaComment; jsxFactory.Text != \"\" {\n-\t\t\tif expr, _ := ParseDefineExprOrJSON(jsxFactory.Text); len(expr.Parts) > 0 {\n+\t\t\tif p.options.jsx.AutomaticRuntime {\n+\t\t\t\tp.log.AddID(logger.MsgID_JS_UnsupportedJSXComment, logger.Warning, &p.tracker, jsxFactory.Range,\n+\t\t\t\t\t\"The JSX factory cannot be set when using React's \\\"automatic\\\" JSX transform\")\n+\t\t\t} else if expr, _ := ParseDefineExprOrJSON(jsxFactory.Text); len(expr.Parts) > 0 {\n \t\t\t\tp.options.jsx.Factory = expr\n \t\t\t} else {\n \t\t\t\tp.log.AddID(logger.MsgID_JS_UnsupportedJSXComment, logger.Warning, &p.tracker, jsxFactory.Range,\n \t\t\t\t\tfmt.Sprintf(\"Invalid JSX factory: %s\", jsxFactory.Text))\n \t\t\t}\n \t\t}\n+\n \t\tif jsxFragment := p.lexer.JSXFragmentPragmaComment; jsxFragment.Text != \"\" {\n-\t\t\tif expr, _ := ParseDefineExprOrJSON(jsxFragment.Text); len(expr.Parts) > 0 || expr.Constant != nil {\n+\t\t\tif p.options.jsx.AutomaticRuntime {\n+\t\t\t\tp.log.AddID(logger.MsgID_JS_UnsupportedJSXComment, logger.Warning, &p.tracker, jsxFragment.Range,\n+\t\t\t\t\t\"The JSX fragment cannot be set when using React's \\\"automatic\\\" JSX transform\")\n+\t\t\t} else if expr, _ := ParseDefineExprOrJSON(jsxFragment.Text); len(expr.Parts) > 0 || expr.Constant != nil {\n \t\t\t\tp.options.jsx.Fragment = expr\n \t\t\t} else {\n \t\t\t\tp.log.AddID(logger.MsgID_JS_UnsupportedJSXComment, logger.Warning, &p.tracker, jsxFragment.Range,\n \t\t\t\t\tfmt.Sprintf(\"Invalid JSX fragment: %s\", jsxFragment.Text))\n \t\t\t}\n \t\t}\n+\n+\t\tif jsxImportSource := p.lexer.JSXImportSourcePragmaComment; jsxImportSource.Text != \"\" {\n+\t\t\tif !p.options.jsx.AutomaticRuntime {\n+\t\t\t\tp.log.AddIDWithNotes(logger.MsgID_JS_UnsupportedJSXComment, logger.Warning, &p.tracker, jsxImportSource.Range,\n+\t\t\t\t\tfmt.Sprintf(\"The JSX import source cannot be set without also enabling React's \\\"automatic\\\" JSX transform\"),\n+\t\t\t\t\t[]logger.MsgData{{Text: \"You can enable React's \\\"automatic\\\" JSX transform for this file by using a \\\"@jsxRuntime automatic\\\" comment.\"}})\n+\t\t\t} else {\n+\t\t\t\tp.options.jsx.ImportSource = jsxImportSource.Text\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Force-enable strict mode if the JSX \"automatic\" runtime is enabled and\n+\t// there is at least one JSX element. This is because the automatically-\n+\t// generated import statement turns the file into an ES module. This behavior\n+\t// matches TypeScript which also does this. See this PR for more information:\n+\t// https://github.com/microsoft/TypeScript/pull/39199\n+\tif p.currentScope.StrictMode == js_ast.SloppyMode && p.options.jsx.AutomaticRuntime && p.firstJSXElementLoc.Start != -1 {\n+\t\tp.currentScope.StrictMode = js_ast.ImplicitStrictModeJSXAutomaticRuntime\n \t}\n }\n \n@@ -15907,7 +16202,7 @@ func (p *parser) computeCharacterFrequency() *js_ast.CharFreq {\n func (p *parser) generateImportStmt(\n \tpath string,\n \timports []string,\n-\tsourceIndex uint32,\n+\tsourceIndex *uint32,\n \tparts []js_ast.Part,\n \tsymbols map[string]js_ast.Ref,\n ) []js_ast.Part {\n@@ -15916,7 +16211,9 @@ func (p *parser) generateImportStmt(\n \tdeclaredSymbols := make([]js_ast.DeclaredSymbol, len(imports))\n \tclauseItems := make([]js_ast.ClauseItem, len(imports))\n \timportRecordIndex := p.addImportRecord(ast.ImportStmt, logger.Loc{}, path, nil)\n-\tp.importRecords[importRecordIndex].SourceIndex = ast.MakeIndex32(sourceIndex)\n+\tif sourceIndex != nil {\n+\t\tp.importRecords[importRecordIndex].SourceIndex = ast.MakeIndex32(*sourceIndex)\n+\t}\n \n \t// Create per-import information\n \tfor i, alias := range imports {\n@@ -15940,21 +16237,66 @@ func (p *parser) generateImportStmt(\n \t\t\tNamespaceRef:      namespaceRef,\n \t\t\tItems:             &clauseItems,\n \t\t\tImportRecordIndex: importRecordIndex,\n+\t\t\tIsSingleLine:      true,\n \t\t}}},\n \t})\n }\n \n-func (p *parser) toAST(parts []js_ast.Part, hashbang string, directive string) js_ast.AST {\n+// Sort the keys for determinism\n+func sortedKeysOfMapStringRef(in map[string]js_ast.Ref) []string {\n+\tkeys := make([]string, 0, len(in))\n+\tfor key := range in {\n+\t\tkeys = append(keys, key)\n+\t}\n+\tsort.Strings(keys)\n+\treturn keys\n+}\n+\n+func (p *parser) toAST(before, parts, after []js_ast.Part, hashbang string, directive string) js_ast.AST {\n \t// Insert an import statement for any runtime imports we generated\n \tif len(p.runtimeImports) > 0 && !p.options.omitRuntimeForTests {\n-\t\t// Sort the imports for determinism\n-\t\tkeys := make([]string, 0, len(p.runtimeImports))\n-\t\tfor key := range p.runtimeImports {\n-\t\t\tkeys = append(keys, key)\n+\t\tkeys := sortedKeysOfMapStringRef(p.runtimeImports)\n+\t\tsourceIndex := runtime.SourceIndex\n+\t\tbefore = p.generateImportStmt(\"<runtime>\", keys, &sourceIndex, before, p.runtimeImports)\n+\t}\n+\n+\t// Insert an import statement for any jsx runtime imports we generated\n+\tif len(p.jsxRuntimeImports) > 0 && !p.options.omitJSXRuntimeForTests {\n+\t\tkeys := sortedKeysOfMapStringRef(p.jsxRuntimeImports)\n+\n+\t\t// Determine the runtime source and whether it's prod or dev\n+\t\tpath := p.options.jsx.ImportSource\n+\t\tif p.options.jsx.Development {\n+\t\t\tpath = path + \"/jsx-dev-runtime\"\n+\t\t} else {\n+\t\t\tpath = path + \"/jsx-runtime\"\n \t\t}\n-\t\tsort.Strings(keys)\n-\t\tparts = p.generateImportStmt(\"<runtime>\", keys, runtime.SourceIndex, parts, p.runtimeImports)\n+\n+\t\tbefore = p.generateImportStmt(path, keys, nil, before, p.jsxRuntimeImports)\n+\t}\n+\n+\t// Insert an import statement for any legacy jsx imports we generated (i.e., createElement)\n+\tif len(p.jsxLegacyImports) > 0 && !p.options.omitJSXRuntimeForTests {\n+\t\tkeys := sortedKeysOfMapStringRef(p.jsxLegacyImports)\n+\t\tpath := p.options.jsx.ImportSource\n+\t\tbefore = p.generateImportStmt(path, keys, nil, before, p.jsxLegacyImports)\n+\t}\n+\n+\t// Generated imports are inserted before other code instead of appending them\n+\t// to the end of the file. Appending them should work fine because JavaScript\n+\t// import statements are \"hoisted\" to run before the importing file. However,\n+\t// some buggy JavaScript toolchains such as the TypeScript compiler convert\n+\t// ESM into CommonJS by replacing \"import\" statements inline without doing\n+\t// any hoisting, which is incorrect. See the following issue for more info:\n+\t// https://github.com/microsoft/TypeScript/issues/16166. Since JSX-related\n+\t// imports are present in the generated code when bundling is disabled, and\n+\t// could therefore be processed by these buggy tools, it's more robust to put\n+\t// them at the top even though it means potentially reallocating almost the\n+\t// entire array of parts.\n+\tif len(before) > 0 {\n+\t\tparts = append(before, parts...)\n \t}\n+\tparts = append(parts, after...)\n \n \t// Handle import paths after the whole file has been visited because we need\n \t// symbol usage counts to be able to remove unused type-only imports in"},{"sha":"50daf17d34d510dfc13230ce676e7d742e90f92e","filename":"internal/js_parser/js_parser_lower.go","status":"modified","additions":7,"deletions":0,"changes":7,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_parser%2Fjs_parser_lower.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_parser%2Fjs_parser_lower.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_parser%2Fjs_parser_lower.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -220,6 +220,13 @@ func (p *parser) markStrictModeFeature(feature strictModeFeature, r logger.Range\n \t\t\tnotes = []logger.MsgData{t.MsgData(tsAlwaysStrict.Range, fmt.Sprintf(\n \t\t\t\t\"TypeScript's %q setting was enabled here:\", tsAlwaysStrict.Name))}\n \n+\t\tcase js_ast.ImplicitStrictModeJSXAutomaticRuntime:\n+\t\t\tnotes = []logger.MsgData{p.tracker.MsgData(logger.Range{Loc: p.firstJSXElementLoc, Len: 1},\n+\t\t\t\t\"This file is implicitly in strict mode due to the JSX element here:\"),\n+\t\t\t\t{Text: \"When React's \\\"automatic\\\" JSX transform is enabled, using a JSX element automatically inserts \" +\n+\t\t\t\t\t\"an \\\"import\\\" statement at the top of the file for the corresponding the JSX helper function. \" +\n+\t\t\t\t\t\"This means the file is considered an ECMAScript module, and all ECMAScript modules use strict mode.\"}}\n+\n \t\tcase js_ast.ExplicitStrictMode:\n \t\t\tnotes = []logger.MsgData{p.tracker.MsgData(p.source.RangeOfString(p.currentScope.UseStrictLoc),\n \t\t\t\t\"Strict mode is triggered by the \\\"use strict\\\" directive here:\")}"},{"sha":"507b903b63969746e963f3c5ee0a5c500a7f0545","filename":"internal/js_parser/js_parser_test.go","status":"modified","additions":172,"deletions":10,"changes":182,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_parser%2Fjs_parser_test.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_parser%2Fjs_parser_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_parser%2Fjs_parser_test.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -149,26 +149,34 @@ func expectPrintedJSX(t *testing.T, contents string, expected string) {\n \t})\n }\n \n-func expectParseErrorTargetJSX(t *testing.T, esVersion int, contents string, expected string) {\n+type JSXAutomaticTestOptions struct {\n+\tDevelopment            bool\n+\tImportSource           string\n+\tOmitJSXRuntimeForTests bool\n+}\n+\n+func expectParseErrorJSXAutomatic(t *testing.T, options JSXAutomaticTestOptions, contents string, expected string) {\n \tt.Helper()\n \texpectParseErrorCommon(t, contents, expected, config.Options{\n-\t\tUnsupportedJSFeatures: compat.UnsupportedJSFeatures(map[compat.Engine][]int{\n-\t\t\tcompat.ES: {esVersion},\n-\t\t}),\n+\t\tOmitJSXRuntimeForTests: options.OmitJSXRuntimeForTests,\n \t\tJSX: config.JSXOptions{\n-\t\t\tParse: true,\n+\t\t\tAutomaticRuntime: true,\n+\t\t\tParse:            true,\n+\t\t\tDevelopment:      options.Development,\n+\t\t\tImportSource:     options.ImportSource,\n \t\t},\n \t})\n }\n \n-func expectPrintedTargetJSX(t *testing.T, esVersion int, contents string, expected string) {\n+func expectPrintedJSXAutomatic(t *testing.T, options JSXAutomaticTestOptions, contents string, expected string) {\n \tt.Helper()\n \texpectPrintedCommon(t, contents, expected, config.Options{\n-\t\tUnsupportedJSFeatures: compat.UnsupportedJSFeatures(map[compat.Engine][]int{\n-\t\t\tcompat.ES: {esVersion},\n-\t\t}),\n+\t\tOmitJSXRuntimeForTests: options.OmitJSXRuntimeForTests,\n \t\tJSX: config.JSXOptions{\n-\t\t\tParse: true,\n+\t\t\tAutomaticRuntime: true,\n+\t\t\tParse:            true,\n+\t\t\tDevelopment:      options.Development,\n+\t\t\tImportSource:     options.ImportSource,\n \t\t},\n \t})\n }\n@@ -4718,6 +4726,160 @@ func TestJSXPragmas(t *testing.T) {\n \texpectPrintedJSX(t, \"/* @jsxFrag a.b.c */\\n<></>\", \"/* @__PURE__ */ React.createElement(a.b.c, null);\\n\")\n }\n \n+func TestJSXAutomatic(t *testing.T) {\n+\t// Prod, without runtime imports\n+\tp := JSXAutomaticTestOptions{Development: false, OmitJSXRuntimeForTests: true}\n+\texpectPrintedJSXAutomatic(t, p, \"<div>></div>\", \"/* @__PURE__ */ jsx(\\\"div\\\", {\\n  children: \\\">\\\"\\n});\\n\")\n+\texpectPrintedJSXAutomatic(t, p, \"<div>{1}}</div>\", \"/* @__PURE__ */ jsxs(\\\"div\\\", {\\n  children: [\\n    1,\\n    \\\"}\\\"\\n  ]\\n});\\n\")\n+\texpectPrintedJSXAutomatic(t, p, \"<div key={true} />\", \"/* @__PURE__ */ jsx(\\\"div\\\", {}, true);\\n\")\n+\texpectPrintedJSXAutomatic(t, p, \"<div key=\\\"key\\\" />\", \"/* @__PURE__ */ jsx(\\\"div\\\", {}, \\\"key\\\");\\n\")\n+\texpectPrintedJSXAutomatic(t, p, \"<div key=\\\"key\\\" {...props} />\", \"/* @__PURE__ */ jsx(\\\"div\\\", {\\n  ...props\\n}, \\\"key\\\");\\n\")\n+\texpectPrintedJSXAutomatic(t, p, \"<div {...props} key=\\\"key\\\" />\", \"/* @__PURE__ */ createElement(\\\"div\\\", {\\n  ...props,\\n  key: \\\"key\\\"\\n});\\n\") // Falls back to createElement\n+\texpectPrintedJSXAutomatic(t, p, \"<div>{...children}</div>\", \"/* @__PURE__ */ jsxs(\\\"div\\\", {\\n  children: [\\n    ...children\\n  ]\\n});\\n\")\n+\texpectPrintedJSXAutomatic(t, p, \"<div>{...children}<a/></div>\", \"/* @__PURE__ */ jsxs(\\\"div\\\", {\\n  children: [\\n    ...children,\\n    /* @__PURE__ */ jsx(\\\"a\\\", {})\\n  ]\\n});\\n\")\n+\texpectPrintedJSXAutomatic(t, p, \"<>></>\", \"/* @__PURE__ */ jsx(Fragment, {\\n  children: \\\">\\\"\\n});\\n\")\n+\n+\texpectParseErrorJSXAutomatic(t, p, \"<a key/>\",\n+\t\t`<stdin>: ERROR: Please provide an explicit value for \"key\":\n+NOTE: Using \"key\" as a shorthand for \"key={true}\" is not allowed when using React's \"automatic\" JSX transform.\n+`)\n+\texpectParseErrorJSXAutomatic(t, p, \"<div __self={self} />\",\n+\t\t`<stdin>: ERROR: Duplicate \"__self\" prop found:\n+NOTE: Both \"__source\" and \"__self\" are set automatically by esbuild when using React's \"automatic\" JSX transform. This duplicate prop may have come from a plugin.\n+`)\n+\texpectParseErrorJSXAutomatic(t, p, \"<div __source=\\\"/path/to/source.jsx\\\" />\",\n+\t\t`<stdin>: ERROR: Duplicate \"__source\" prop found:\n+NOTE: Both \"__source\" and \"__self\" are set automatically by esbuild when using React's \"automatic\" JSX transform. This duplicate prop may have come from a plugin.\n+`)\n+\n+\t// Prod, with runtime imports\n+\tpr := JSXAutomaticTestOptions{Development: false}\n+\texpectPrintedJSXAutomatic(t, pr, \"<div/>\", \"import { jsx } from \\\"react/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"div\\\", {});\\n\")\n+\texpectPrintedJSXAutomatic(t, pr, \"<><a/><b/></>\", \"import { Fragment, jsx, jsxs } from \\\"react/jsx-runtime\\\";\\n/* @__PURE__ */ jsxs(Fragment, {\\n  children: [\\n    /* @__PURE__ */ jsx(\\\"a\\\", {}),\\n    /* @__PURE__ */ jsx(\\\"b\\\", {})\\n  ]\\n});\\n\")\n+\texpectPrintedJSXAutomatic(t, pr, \"<div {...props} key=\\\"key\\\" />\", \"import { createElement } from \\\"react\\\";\\n/* @__PURE__ */ createElement(\\\"div\\\", {\\n  ...props,\\n  key: \\\"key\\\"\\n});\\n\")\n+\texpectPrintedJSXAutomatic(t, pr, \"<><div {...props} key=\\\"key\\\" /></>\", \"import { Fragment, jsx } from \\\"react/jsx-runtime\\\";\\nimport { createElement } from \\\"react\\\";\\n/* @__PURE__ */ jsx(Fragment, {\\n  children: /* @__PURE__ */ createElement(\\\"div\\\", {\\n    ...props,\\n    key: \\\"key\\\"\\n  })\\n});\\n\")\n+\n+\tpri := JSXAutomaticTestOptions{Development: false, ImportSource: \"my-jsx-lib\"}\n+\texpectPrintedJSXAutomatic(t, pri, \"<div/>\", \"import { jsx } from \\\"my-jsx-lib/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"div\\\", {});\\n\")\n+\texpectPrintedJSXAutomatic(t, pri, \"<div {...props} key=\\\"key\\\" />\", \"import { createElement } from \\\"my-jsx-lib\\\";\\n/* @__PURE__ */ createElement(\\\"div\\\", {\\n  ...props,\\n  key: \\\"key\\\"\\n});\\n\")\n+\n+\t// Dev, without runtime imports\n+\td := JSXAutomaticTestOptions{Development: true, OmitJSXRuntimeForTests: true}\n+\texpectPrintedJSXAutomatic(t, d, \"<div>></div>\", \"/* @__PURE__ */ jsxDEV(\\\"div\\\", {\\n  children: \\\">\\\"\\n}, void 0, false, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, d, \"<div>{1}}</div>\", \"/* @__PURE__ */ jsxDEV(\\\"div\\\", {\\n  children: [\\n    1,\\n    \\\"}\\\"\\n  ]\\n}, void 0, true, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, d, \"<div key={true} />\", \"/* @__PURE__ */ jsxDEV(\\\"div\\\", {}, true, false, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, d, \"<div key=\\\"key\\\" />\", \"/* @__PURE__ */ jsxDEV(\\\"div\\\", {}, \\\"key\\\", false, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, d, \"<div key=\\\"key\\\" {...props} />\", \"/* @__PURE__ */ jsxDEV(\\\"div\\\", {\\n  ...props\\n}, \\\"key\\\", false, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, d, \"<div {...props} key=\\\"key\\\" />\", \"/* @__PURE__ */ createElement(\\\"div\\\", {\\n  ...props,\\n  key: \\\"key\\\"\\n});\\n\") // Falls back to createElement\n+\texpectPrintedJSXAutomatic(t, d, \"<div>{...children}</div>\", \"/* @__PURE__ */ jsxDEV(\\\"div\\\", {\\n  children: [\\n    ...children\\n  ]\\n}, void 0, true, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, d, \"<div>\\n  {...children}\\n  <a/></div>\", \"/* @__PURE__ */ jsxDEV(\\\"div\\\", {\\n  children: [\\n    ...children,\\n    /* @__PURE__ */ jsxDEV(\\\"a\\\", {}, void 0, false, {\\n      fileName: \\\"<stdin>\\\",\\n      lineNumber: 3,\\n      columnNumber: 3\\n    }, this)\\n  ]\\n}, void 0, true, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, d, \"<>></>\", \"/* @__PURE__ */ jsxDEV(Fragment, {\\n  children: \\\">\\\"\\n}, void 0, false, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\n+\texpectParseErrorJSXAutomatic(t, d, \"<a key/>\",\n+\t\t`<stdin>: ERROR: Please provide an explicit value for \"key\":\n+NOTE: Using \"key\" as a shorthand for \"key={true}\" is not allowed when using React's \"automatic\" JSX transform.\n+`)\n+\texpectParseErrorJSXAutomatic(t, d, \"<div __self={self} />\",\n+\t\t`<stdin>: ERROR: Duplicate \"__self\" prop found:\n+NOTE: Both \"__source\" and \"__self\" are set automatically by esbuild when using React's \"automatic\" JSX transform. This duplicate prop may have come from a plugin.\n+`)\n+\texpectParseErrorJSXAutomatic(t, d, \"<div __source=\\\"/path/to/source.jsx\\\" />\",\n+\t\t`<stdin>: ERROR: Duplicate \"__source\" prop found:\n+NOTE: Both \"__source\" and \"__self\" are set automatically by esbuild when using React's \"automatic\" JSX transform. This duplicate prop may have come from a plugin.\n+`)\n+\n+\t// Line/column offset tests. Unlike Babel, TypeScript sometimes points to a\n+\t// location other than the start of the element. I'm not sure if that's a bug\n+\t// or not, but it seems weird. So I decided to match Babel instead.\n+\texpectPrintedJSXAutomatic(t, d, \"\\r\\n<x/>\", \"/* @__PURE__ */ jsxDEV(\\\"x\\\", {}, void 0, false, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 2,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, d, \"\\n\\r<x/>\", \"/* @__PURE__ */ jsxDEV(\\\"x\\\", {}, void 0, false, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 3,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, d, \"let 𐀀 = <x>🍕🍕🍕<y/></x>\", \"let 𐀀 = /* @__PURE__ */ jsxDEV(\\\"x\\\", {\\n  children: [\\n    \\\"🍕🍕🍕\\\",\\n    /* @__PURE__ */ jsxDEV(\\\"y\\\", {}, void 0, false, {\\n      fileName: \\\"<stdin>\\\",\\n      lineNumber: 1,\\n      columnNumber: 19\\n    }, this)\\n  ]\\n}, void 0, true, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 10\\n}, this);\\n\")\n+\n+\t// Dev, with runtime imports\n+\tdr := JSXAutomaticTestOptions{Development: true}\n+\texpectPrintedJSXAutomatic(t, dr, \"<div/>\", \"import { jsxDEV } from \\\"react/jsx-dev-runtime\\\";\\n/* @__PURE__ */ jsxDEV(\\\"div\\\", {}, void 0, false, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, dr, \"<>\\n  <a/>\\n  <b/>\\n</>\", \"import { Fragment, jsxDEV } from \\\"react/jsx-dev-runtime\\\";\\n/* @__PURE__ */ jsxDEV(Fragment, {\\n  children: [\\n    /* @__PURE__ */ jsxDEV(\\\"a\\\", {}, void 0, false, {\\n      fileName: \\\"<stdin>\\\",\\n      lineNumber: 2,\\n      columnNumber: 3\\n    }, this),\\n    /* @__PURE__ */ jsxDEV(\\\"b\\\", {}, void 0, false, {\\n      fileName: \\\"<stdin>\\\",\\n      lineNumber: 3,\\n      columnNumber: 3\\n    }, this)\\n  ]\\n}, void 0, true, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\n+\tdri := JSXAutomaticTestOptions{Development: true, ImportSource: \"preact\"}\n+\texpectPrintedJSXAutomatic(t, dri, \"<div/>\", \"import { jsxDEV } from \\\"preact/jsx-dev-runtime\\\";\\n/* @__PURE__ */ jsxDEV(\\\"div\\\", {}, void 0, false, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\texpectPrintedJSXAutomatic(t, dri, \"<>\\n  <a/>\\n  <b/>\\n</>\", \"import { Fragment, jsxDEV } from \\\"preact/jsx-dev-runtime\\\";\\n/* @__PURE__ */ jsxDEV(Fragment, {\\n  children: [\\n    /* @__PURE__ */ jsxDEV(\\\"a\\\", {}, void 0, false, {\\n      fileName: \\\"<stdin>\\\",\\n      lineNumber: 2,\\n      columnNumber: 3\\n    }, this),\\n    /* @__PURE__ */ jsxDEV(\\\"b\\\", {}, void 0, false, {\\n      fileName: \\\"<stdin>\\\",\\n      lineNumber: 3,\\n      columnNumber: 3\\n    }, this)\\n  ]\\n}, void 0, true, {\\n  fileName: \\\"<stdin>\\\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n\")\n+\n+\t// JSX namespaced names\n+\tfor _, colon := range []string{\":\", \" :\", \": \", \" : \"} {\n+\t\texpectPrintedJSXAutomatic(t, p, \"<a\"+colon+\"b/>\", \"/* @__PURE__ */ jsx(\\\"a:b\\\", {});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<a-b\"+colon+\"c-d/>\", \"/* @__PURE__ */ jsx(\\\"a-b:c-d\\\", {});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<a-\"+colon+\"b-/>\", \"/* @__PURE__ */ jsx(\\\"a-:b-\\\", {});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<Te\"+colon+\"st/>\", \"/* @__PURE__ */ jsx(\\\"Te:st\\\", {});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<x a\"+colon+\"b/>\", \"/* @__PURE__ */ jsx(\\\"x\\\", {\\n  \\\"a:b\\\": true\\n});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<x a-b\"+colon+\"c-d/>\", \"/* @__PURE__ */ jsx(\\\"x\\\", {\\n  \\\"a-b:c-d\\\": true\\n});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<x a-\"+colon+\"b-/>\", \"/* @__PURE__ */ jsx(\\\"x\\\", {\\n  \\\"a-:b-\\\": true\\n});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<x Te\"+colon+\"st/>\", \"/* @__PURE__ */ jsx(\\\"x\\\", {\\n  \\\"Te:st\\\": true\\n});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<x a\"+colon+\"b={0}/>\", \"/* @__PURE__ */ jsx(\\\"x\\\", {\\n  \\\"a:b\\\": 0\\n});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<x a-b\"+colon+\"c-d={0}/>\", \"/* @__PURE__ */ jsx(\\\"x\\\", {\\n  \\\"a-b:c-d\\\": 0\\n});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<x a-\"+colon+\"b-={0}/>\", \"/* @__PURE__ */ jsx(\\\"x\\\", {\\n  \\\"a-:b-\\\": 0\\n});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<x Te\"+colon+\"st={0}/>\", \"/* @__PURE__ */ jsx(\\\"x\\\", {\\n  \\\"Te:st\\\": 0\\n});\\n\")\n+\t\texpectPrintedJSXAutomatic(t, p, \"<a-b a-b={a-b}/>\", \"/* @__PURE__ */ jsx(\\\"a-b\\\", {\\n  \\\"a-b\\\": a - b\\n});\\n\")\n+\t\texpectParseErrorJSXAutomatic(t, p, \"<x\"+colon+\"/>\", \"<stdin>: ERROR: Expected identifier after \\\"x:\\\" in namespaced JSX name\\n\")\n+\t\texpectParseErrorJSXAutomatic(t, p, \"<x\"+colon+\"y\"+colon+\"/>\", \"<stdin>: ERROR: Expected \\\">\\\" but found \\\":\\\"\\n\")\n+\t\texpectParseErrorJSXAutomatic(t, p, \"<x\"+colon+\"0y/>\", \"<stdin>: ERROR: Expected identifier after \\\"x:\\\" in namespaced JSX name\\n\")\n+\t}\n+\n+\t// Enabling the \"automatic\" runtime means that any JSX element will cause the\n+\t// file to be implicitly in strict mode due to the automatically-generated\n+\t// import statement. This is the same behavior as the TypeScript compiler.\n+\tstrictModeError := \"<stdin>: ERROR: With statements cannot be used in strict mode\\n\" +\n+\t\t\"<stdin>: NOTE: This file is implicitly in strict mode due to the JSX element here:\\n\" +\n+\t\t\"NOTE: When React's \\\"automatic\\\" JSX transform is enabled, using a JSX element automatically inserts an \\\"import\\\" statement at the top of the file \" +\n+\t\t\"for the corresponding the JSX helper function. This means the file is considered an ECMAScript module, and all ECMAScript modules use strict mode.\\n\"\n+\texpectPrintedJSX(t, \"with (x) y(<z/>)\", \"with (x)\\n  y(/* @__PURE__ */ React.createElement(\\\"z\\\", null));\\n\")\n+\texpectPrintedJSXAutomatic(t, p, \"with (x) y\", \"with (x)\\n  y;\\n\")\n+\texpectParseErrorJSX(t, \"with (x) y(<z/>) // @jsxRuntime automatic\", strictModeError)\n+\texpectParseErrorJSXAutomatic(t, p, \"with (x) y(<z/>)\", strictModeError)\n+}\n+\n+func TestJSXAutomaticPragmas(t *testing.T) {\n+\texpectPrintedJSX(t, \"// @jsxRuntime automatic\\n<a/>\", \"import { jsx } from \\\"react/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"/*@jsxRuntime automatic*/\\n<a/>\", \"import { jsx } from \\\"react/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"/* @jsxRuntime automatic */\\n<a/>\", \"import { jsx } from \\\"react/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"<a/>\\n/*@jsxRuntime automatic*/\", \"import { jsx } from \\\"react/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"<a/>\\n/* @jsxRuntime automatic */\", \"import { jsx } from \\\"react/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\n+\texpectPrintedJSX(t, \"// @jsxRuntime classic\\n<a/>\", \"/* @__PURE__ */ React.createElement(\\\"a\\\", null);\\n\")\n+\texpectPrintedJSX(t, \"/*@jsxRuntime classic*/\\n<a/>\", \"/* @__PURE__ */ React.createElement(\\\"a\\\", null);\\n\")\n+\texpectPrintedJSX(t, \"/* @jsxRuntime classic */\\n<a/>\", \"/* @__PURE__ */ React.createElement(\\\"a\\\", null);\\n\")\n+\texpectPrintedJSX(t, \"<a/>\\n/*@jsxRuntime classic*/\\n\", \"/* @__PURE__ */ React.createElement(\\\"a\\\", null);\\n\")\n+\texpectPrintedJSX(t, \"<a/>\\n/* @jsxRuntime classic */\\n\", \"/* @__PURE__ */ React.createElement(\\\"a\\\", null);\\n\")\n+\n+\texpectParseErrorJSX(t, \"// @jsxRuntime foo\\n<a/>\",\n+\t\t`<stdin>: WARNING: Invalid JSX runtime: \"foo\"\n+NOTE: The JSX runtime can only be set to either \"classic\" or \"automatic\".\n+`)\n+\n+\texpectPrintedJSX(t, \"// @jsxRuntime automatic @jsxImportSource src\\n<a/>\", \"import { jsx } from \\\"src/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"/*@jsxRuntime automatic @jsxImportSource src*/\\n<a/>\", \"import { jsx } from \\\"src/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"/*@jsxRuntime automatic*//*@jsxImportSource src*/\\n<a/>\", \"import { jsx } from \\\"src/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"/* @jsxRuntime automatic */\\n/* @jsxImportSource src */\\n<a/>\", \"import { jsx } from \\\"src/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"<a/>\\n/*@jsxRuntime automatic @jsxImportSource src*/\", \"import { jsx } from \\\"src/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"<a/>\\n/*@jsxRuntime automatic*/\\n/*@jsxImportSource src*/\", \"import { jsx } from \\\"src/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectPrintedJSX(t, \"<a/>\\n/* @jsxRuntime automatic */\\n/* @jsxImportSource src */\", \"import { jsx } from \\\"src/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\n+\texpectPrintedJSX(t, \"// @jsxRuntime classic @jsxImportSource src\\n<a/>\", \"/* @__PURE__ */ React.createElement(\\\"a\\\", null);\\n\")\n+\texpectParseErrorJSX(t, \"// @jsxRuntime classic @jsxImportSource src\\n<a/>\",\n+\t\t`<stdin>: WARNING: The JSX import source cannot be set without also enabling React's \"automatic\" JSX transform\n+NOTE: You can enable React's \"automatic\" JSX transform for this file by using a \"@jsxRuntime automatic\" comment.\n+`)\n+\texpectParseErrorJSX(t, \"// @jsxImportSource src\\n<a/>\",\n+\t\t`<stdin>: WARNING: The JSX import source cannot be set without also enabling React's \"automatic\" JSX transform\n+NOTE: You can enable React's \"automatic\" JSX transform for this file by using a \"@jsxRuntime automatic\" comment.\n+`)\n+\n+\texpectPrintedJSX(t, \"// @jsxRuntime automatic @jsx h\\n<a/>\", \"import { jsx } from \\\"react/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(\\\"a\\\", {});\\n\")\n+\texpectParseErrorJSX(t, \"// @jsxRuntime automatic @jsx h\\n<a/>\", \"<stdin>: WARNING: The JSX factory cannot be set when using React's \\\"automatic\\\" JSX transform\\n\")\n+\n+\texpectPrintedJSX(t, \"// @jsxRuntime automatic @jsxFrag f\\n<></>\", \"import { Fragment, jsx } from \\\"react/jsx-runtime\\\";\\n/* @__PURE__ */ jsx(Fragment, {});\\n\")\n+\texpectParseErrorJSX(t, \"// @jsxRuntime automatic @jsxFrag f\\n<></>\", \"<stdin>: WARNING: The JSX fragment cannot be set when using React's \\\"automatic\\\" JSX transform\\n\")\n+}\n+\n func TestPreserveOptionalChainParentheses(t *testing.T) {\n \texpectPrinted(t, \"a?.b.c\", \"a?.b.c;\\n\")\n \texpectPrinted(t, \"(a?.b).c\", \"(a?.b).c;\\n\")"},{"sha":"66acda27a890067b67947415190bad015d258fbd","filename":"internal/js_printer/js_printer_test.go","status":"modified","additions":5,"deletions":5,"changes":10,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_printer%2Fjs_printer_test.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fjs_printer%2Fjs_printer_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_printer%2Fjs_printer_test.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -953,15 +953,15 @@ func TestAvoidSlashScript(t *testing.T) {\n \texpectPrinted(t, \"/*! </SCRIPT \\n </SCRIPT */\", \"/*! <\\\\/SCRIPT \\n <\\\\/SCRIPT */\\n\")\n \texpectPrinted(t, \"/*! </ScRiPt \\n </ScRiPt */\", \"/*! <\\\\/ScRiPt \\n <\\\\/ScRiPt */\\n\")\n \texpectPrinted(t, \"String.raw`</script`\",\n-\t\t\"var _a;\\nString.raw(_a || (_a = __template([\\\"<\\\\/script\\\"])));\\nimport {\\n  __template\\n} from \\\"<runtime>\\\";\\n\")\n+\t\t\"import { __template } from \\\"<runtime>\\\";\\nvar _a;\\nString.raw(_a || (_a = __template([\\\"<\\\\/script\\\"])));\\n\")\n \texpectPrinted(t, \"String.raw`</script${a}`\",\n-\t\t\"var _a;\\nString.raw(_a || (_a = __template([\\\"<\\\\/script\\\", \\\"\\\"])), a);\\nimport {\\n  __template\\n} from \\\"<runtime>\\\";\\n\")\n+\t\t\"import { __template } from \\\"<runtime>\\\";\\nvar _a;\\nString.raw(_a || (_a = __template([\\\"<\\\\/script\\\", \\\"\\\"])), a);\\n\")\n \texpectPrinted(t, \"String.raw`${a}</script`\",\n-\t\t\"var _a;\\nString.raw(_a || (_a = __template([\\\"\\\", \\\"<\\\\/script\\\"])), a);\\nimport {\\n  __template\\n} from \\\"<runtime>\\\";\\n\")\n+\t\t\"import { __template } from \\\"<runtime>\\\";\\nvar _a;\\nString.raw(_a || (_a = __template([\\\"\\\", \\\"<\\\\/script\\\"])), a);\\n\")\n \texpectPrinted(t, \"String.raw`</SCRIPT`\",\n-\t\t\"var _a;\\nString.raw(_a || (_a = __template([\\\"<\\\\/SCRIPT\\\"])));\\nimport {\\n  __template\\n} from \\\"<runtime>\\\";\\n\")\n+\t\t\"import { __template } from \\\"<runtime>\\\";\\nvar _a;\\nString.raw(_a || (_a = __template([\\\"<\\\\/SCRIPT\\\"])));\\n\")\n \texpectPrinted(t, \"String.raw`</ScRiPt`\",\n-\t\t\"var _a;\\nString.raw(_a || (_a = __template([\\\"<\\\\/ScRiPt\\\"])));\\nimport {\\n  __template\\n} from \\\"<runtime>\\\";\\n\")\n+\t\t\"import { __template } from \\\"<runtime>\\\";\\nvar _a;\\nString.raw(_a || (_a = __template([\\\"<\\\\/ScRiPt\\\"])));\\n\")\n \n \t// Negative cases\n \texpectPrinted(t, \"x = '</'\", \"x = \\\"</\\\";\\n\")"},{"sha":"551c0f8c06561eee2f4837f9b3d86fbf6b341db2","filename":"internal/resolver/resolver.go","status":"modified","additions":6,"deletions":2,"changes":8,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fresolver%2Fresolver.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fresolver%2Fresolver.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fresolver%2Fresolver.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -101,8 +101,10 @@ type ResolveResult struct {\n \tPluginData interface{}\n \n \t// If not empty, these should override the default values\n-\tJSXFactory  []string // Default if empty: \"React.createElement\"\n-\tJSXFragment []string // Default if empty: \"React.Fragment\"\n+\tJSXFactory      []string // Default if empty: \"React.createElement\"\n+\tJSXFragment     []string // Default if empty: \"React.Fragment\"\n+\tJSXImportSource string   // Default if empty: \"react\"\n+\tJSX             config.TSJSX\n \n \tDifferentCase *fs.DifferentCase\n \n@@ -626,6 +628,8 @@ func (r resolverQuery) finalizeResolve(result *ResolveResult) {\n \t\t\t\t\t} else {\n \t\t\t\t\t\tresult.JSXFactory = dirInfo.enclosingTSConfigJSON.JSXFactory\n \t\t\t\t\t\tresult.JSXFragment = dirInfo.enclosingTSConfigJSON.JSXFragmentFactory\n+\t\t\t\t\t\tresult.JSX = dirInfo.enclosingTSConfigJSON.JSX\n+\t\t\t\t\t\tresult.JSXImportSource = dirInfo.enclosingTSConfigJSON.JSXImportSource\n \t\t\t\t\t\tresult.UseDefineForClassFieldsTS = dirInfo.enclosingTSConfigJSON.UseDefineForClassFields\n \t\t\t\t\t\tresult.UnusedImportFlagsTS = config.UnusedImportFlagsFromTsconfigValues(\n \t\t\t\t\t\t\tdirInfo.enclosingTSConfigJSON.PreserveImportsNotUsedAsValues,"},{"sha":"a47eadb1eb75b91f47fffb0c8d68cf0427832ff8","filename":"internal/resolver/tsconfig_json.go","status":"modified","additions":27,"deletions":0,"changes":27,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fresolver%2Ftsconfig_json.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/internal%2Fresolver%2Ftsconfig_json.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fresolver%2Ftsconfig_json.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -38,8 +38,10 @@ type TSConfigJSON struct {\n \tTSTarget                       *config.TSTarget\n \tTSStrict                       *config.TSAlwaysStrict\n \tTSAlwaysStrict                 *config.TSAlwaysStrict\n+\tJSX                            config.TSJSX\n \tJSXFactory                     []string\n \tJSXFragmentFactory             []string\n+\tJSXImportSource                string\n \tModuleSuffixes                 []string\n \tUseDefineForClassFields        config.MaybeBool\n \tPreserveImportsNotUsedAsValues bool\n@@ -105,6 +107,24 @@ func ParseTSConfigJSON(\n \t\t\t}\n \t\t}\n \n+\t\t// Parse \"jsx\"\n+\t\tif valueJSON, _, ok := getProperty(compilerOptionsJSON, \"jsx\"); ok {\n+\t\t\tif value, ok := getString(valueJSON); ok {\n+\t\t\t\tswitch strings.ToLower(value) {\n+\t\t\t\tcase \"none\":\n+\t\t\t\t\tresult.JSX = config.TSJSXNone\n+\t\t\t\tcase \"preserve\", \"react-native\":\n+\t\t\t\t\tresult.JSX = config.TSJSXPreserve\n+\t\t\t\tcase \"react\":\n+\t\t\t\t\tresult.JSX = config.TSJSXReact\n+\t\t\t\tcase \"react-jsx\":\n+\t\t\t\t\tresult.JSX = config.TSJSXReactJSX\n+\t\t\t\tcase \"react-jsxdev\":\n+\t\t\t\t\tresult.JSX = config.TSJSXReactJSXDev\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n \t\t// Parse \"jsxFactory\"\n \t\tif valueJSON, _, ok := getProperty(compilerOptionsJSON, \"jsxFactory\"); ok {\n \t\t\tif value, ok := getString(valueJSON); ok {\n@@ -119,6 +139,13 @@ func ParseTSConfigJSON(\n \t\t\t}\n \t\t}\n \n+\t\t// Parse \"jsxImportSource\"\n+\t\tif valueJSON, _, ok := getProperty(compilerOptionsJSON, \"jsxImportSource\"); ok {\n+\t\t\tif value, ok := getString(valueJSON); ok {\n+\t\t\t\tresult.JSXImportSource = value\n+\t\t\t}\n+\t\t}\n+\n \t\t// Parse \"moduleSuffixes\"\n \t\tif valueJSON, _, ok := getProperty(compilerOptionsJSON, \"moduleSuffixes\"); ok {\n \t\t\tif value, ok := valueJSON.Data.(*js_ast.EArray); ok {"},{"sha":"662f43107de315a22c20c78c770de7e009a6370a","filename":"lib/shared/common.ts","status":"modified","additions":4,"deletions":0,"changes":4,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/lib%2Fshared%2Fcommon.ts","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/lib%2Fshared%2Fcommon.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Fshared%2Fcommon.ts?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -140,6 +140,8 @@ function pushCommonFlags(flags: string[], options: CommonOptions, keys: OptionKe\n   let jsx = getFlag(options, keys, 'jsx', mustBeString);\n   let jsxFactory = getFlag(options, keys, 'jsxFactory', mustBeString);\n   let jsxFragment = getFlag(options, keys, 'jsxFragment', mustBeString);\n+  let jsxImportSource = getFlag(options, keys, 'jsxImportSource', mustBeString);\n+  let jsxDev = getFlag(options, keys, 'jsxDev', mustBeBoolean);\n   let define = getFlag(options, keys, 'define', mustBeObject);\n   let logOverride = getFlag(options, keys, 'logOverride', mustBeObject);\n   let supported = getFlag(options, keys, 'supported', mustBeObject);\n@@ -173,6 +175,8 @@ function pushCommonFlags(flags: string[], options: CommonOptions, keys: OptionKe\n   if (jsx) flags.push(`--jsx=${jsx}`);\n   if (jsxFactory) flags.push(`--jsx-factory=${jsxFactory}`);\n   if (jsxFragment) flags.push(`--jsx-fragment=${jsxFragment}`);\n+  if (jsxImportSource) flags.push(`--jsx-import-source=${jsxImportSource}`);\n+  if (jsxDev) flags.push(`--jsx-dev`);\n \n   if (define) {\n     for (let key in define) {"},{"sha":"31a5d0ba60a871c058ce474ae36302d83f23b321","filename":"lib/shared/types.ts","status":"modified","additions":5,"deletions":1,"changes":6,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/lib%2Fshared%2Ftypes.ts","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/lib%2Fshared%2Ftypes.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Fshared%2Ftypes.ts?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -52,11 +52,15 @@ interface CommonOptions {\n   ignoreAnnotations?: boolean;\n \n   /** Documentation: https://esbuild.github.io/api/#jsx */\n-  jsx?: 'transform' | 'preserve';\n+  jsx?: 'transform' | 'preserve' | 'automatic';\n   /** Documentation: https://esbuild.github.io/api/#jsx-factory */\n   jsxFactory?: string;\n   /** Documentation: https://esbuild.github.io/api/#jsx-fragment */\n   jsxFragment?: string;\n+  /** Documentation: https://esbuild.github.io/api/#jsx-import-source */\n+  jsxImportSource?: string;\n+  /** Documentation: https://esbuild.github.io/api/#jsx-development */\n+  jsxDev?: boolean;\n \n   /** Documentation: https://esbuild.github.io/api/#define */\n   define?: { [key: string]: string };"},{"sha":"8d5745e44f5d15613c5d7c1c4db5974d74d33874","filename":"pkg/api/api.go","status":"modified","additions":11,"deletions":6,"changes":17,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/pkg%2Fapi%2Fapi.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/pkg%2Fapi%2Fapi.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fapi%2Fapi.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -110,6 +110,7 @@ type JSXMode uint8\n const (\n \tJSXModeTransform JSXMode = iota\n \tJSXModePreserve\n+\tJSXModeAutomatic\n )\n \n type Target uint8\n@@ -276,9 +277,11 @@ type BuildOptions struct {\n \tIgnoreAnnotations bool                   // Documentation: https://esbuild.github.io/api/#ignore-annotations\n \tLegalComments     LegalComments          // Documentation: https://esbuild.github.io/api/#legal-comments\n \n-\tJSXMode     JSXMode // Documentation: https://esbuild.github.io/api/#jsx-mode\n-\tJSXFactory  string  // Documentation: https://esbuild.github.io/api/#jsx-factory\n-\tJSXFragment string  // Documentation: https://esbuild.github.io/api/#jsx-fragment\n+\tJSXMode         JSXMode // Documentation: https://esbuild.github.io/api/#jsx-mode\n+\tJSXFactory      string  // Documentation: https://esbuild.github.io/api/#jsx-factory\n+\tJSXFragment     string  // Documentation: https://esbuild.github.io/api/#jsx-fragment\n+\tJSXImportSource string  // Documentation: https://esbuild.github.io/api/#jsx-import-source\n+\tJSXDev          bool    // Documentation: https://esbuild.github.io/api/#jsx-dev\n \n \tDefine    map[string]string // Documentation: https://esbuild.github.io/api/#define\n \tPure      []string          // Documentation: https://esbuild.github.io/api/#pure\n@@ -396,9 +399,11 @@ type TransformOptions struct {\n \tIgnoreAnnotations bool                   // Documentation: https://esbuild.github.io/api/#ignore-annotations\n \tLegalComments     LegalComments          // Documentation: https://esbuild.github.io/api/#legal-comments\n \n-\tJSXMode     JSXMode // Documentation: https://esbuild.github.io/api/#jsx\n-\tJSXFactory  string  // Documentation: https://esbuild.github.io/api/#jsx-factory\n-\tJSXFragment string  // Documentation: https://esbuild.github.io/api/#jsx-fragment\n+\tJSXMode         JSXMode // Documentation: https://esbuild.github.io/api/#jsx\n+\tJSXFactory      string  // Documentation: https://esbuild.github.io/api/#jsx-factory\n+\tJSXFragment     string  // Documentation: https://esbuild.github.io/api/#jsx-fragment\n+\tJSXImportSource string  // Documentation: https://esbuild.github.io/api/#jsx-import-source\n+\tJSXDev          bool    // Documentation: https://esbuild.github.io/api/#jsx-dev\n \n \tTsconfigRaw string // Documentation: https://esbuild.github.io/api/#tsconfig-raw\n \tBanner      string // Documentation: https://esbuild.github.io/api/#banner"},{"sha":"12fdc23c313324b276e14ccec73eee34b57f02ea","filename":"pkg/api/api_impl.go","status":"modified","additions":18,"deletions":6,"changes":24,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/pkg%2Fapi%2Fapi_impl.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/pkg%2Fapi%2Fapi_impl.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fapi%2Fapi_impl.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -897,9 +897,12 @@ func rebuildImpl(\n \t\tUnsupportedCSSFeatureOverridesMask: cssMask,\n \t\tOriginalTargetEnv:                  targetEnv,\n \t\tJSX: config.JSXOptions{\n-\t\t\tPreserve: buildOpts.JSXMode == JSXModePreserve,\n-\t\t\tFactory:  validateJSXExpr(log, buildOpts.JSXFactory, \"factory\"),\n-\t\t\tFragment: validateJSXExpr(log, buildOpts.JSXFragment, \"fragment\"),\n+\t\t\tPreserve:         buildOpts.JSXMode == JSXModePreserve,\n+\t\t\tAutomaticRuntime: buildOpts.JSXMode == JSXModeAutomatic,\n+\t\t\tFactory:          validateJSXExpr(log, buildOpts.JSXFactory, \"factory\"),\n+\t\t\tFragment:         validateJSXExpr(log, buildOpts.JSXFragment, \"fragment\"),\n+\t\t\tDevelopment:      buildOpts.JSXDev,\n+\t\t\tImportSource:     buildOpts.JSXImportSource,\n \t\t},\n \t\tDefines:               defines,\n \t\tInjectedDefines:       injectedDefines,\n@@ -1356,9 +1359,12 @@ func transformImpl(input string, transformOpts TransformOptions) TransformResult\n \tvar unusedImportFlagsTS config.UnusedImportFlagsTS\n \tuseDefineForClassFieldsTS := config.Unspecified\n \tjsx := config.JSXOptions{\n-\t\tPreserve: transformOpts.JSXMode == JSXModePreserve,\n-\t\tFactory:  validateJSXExpr(log, transformOpts.JSXFactory, \"factory\"),\n-\t\tFragment: validateJSXExpr(log, transformOpts.JSXFragment, \"fragment\"),\n+\t\tPreserve:         transformOpts.JSXMode == JSXModePreserve,\n+\t\tAutomaticRuntime: transformOpts.JSXMode == JSXModeAutomatic,\n+\t\tFactory:          validateJSXExpr(log, transformOpts.JSXFactory, \"factory\"),\n+\t\tFragment:         validateJSXExpr(log, transformOpts.JSXFragment, \"fragment\"),\n+\t\tDevelopment:      transformOpts.JSXDev,\n+\t\tImportSource:     transformOpts.JSXImportSource,\n \t}\n \n \t// Settings from \"tsconfig.json\" override those\n@@ -1372,12 +1378,18 @@ func transformImpl(input string, transformOpts TransformOptions) TransformResult\n \t\t\tContents:   transformOpts.TsconfigRaw,\n \t\t}\n \t\tif result := resolver.ParseTSConfigJSON(log, source, &caches.JSONCache, nil); result != nil {\n+\t\t\tif result.JSX != config.TSJSXNone {\n+\t\t\t\tjsx.SetOptionsFromTSJSX(result.JSX)\n+\t\t\t}\n \t\t\tif len(result.JSXFactory) > 0 {\n \t\t\t\tjsx.Factory = config.DefineExpr{Parts: result.JSXFactory}\n \t\t\t}\n \t\t\tif len(result.JSXFragmentFactory) > 0 {\n \t\t\t\tjsx.Fragment = config.DefineExpr{Parts: result.JSXFragmentFactory}\n \t\t\t}\n+\t\t\tif len(result.JSXImportSource) > 0 {\n+\t\t\t\tjsx.ImportSource = result.JSXImportSource\n+\t\t\t}\n \t\t\tif result.UseDefineForClassFields != config.Unspecified {\n \t\t\t\tuseDefineForClassFieldsTS = result.UseDefineForClassFields\n \t\t\t}"},{"sha":"08064021362e85d73fb7ce17518621387f4504fd","filename":"pkg/cli/cli_impl.go","status":"modified","additions":22,"deletions":1,"changes":23,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/pkg%2Fcli%2Fcli_impl.go","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/pkg%2Fcli%2Fcli_impl.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fcli%2Fcli_impl.go?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -610,10 +610,12 @@ func parseOptionsImpl(\n \t\t\t\tmode = api.JSXModeTransform\n \t\t\tcase \"preserve\":\n \t\t\t\tmode = api.JSXModePreserve\n+\t\t\tcase \"automatic\":\n+\t\t\t\tmode = api.JSXModeAutomatic\n \t\t\tdefault:\n \t\t\t\treturn parseOptionsExtras{}, cli_helpers.MakeErrorWithNote(\n \t\t\t\t\tfmt.Sprintf(\"Invalid value %q in %q\", value, arg),\n-\t\t\t\t\t\"Valid values are \\\"transform\\\" or \\\"preserve\\\".\",\n+\t\t\t\t\t\"Valid values are \\\"transform\\\", \\\"automatic\\\", or \\\"preserve\\\".\",\n \t\t\t\t)\n \t\t\t}\n \t\t\tif buildOpts != nil {\n@@ -638,6 +640,23 @@ func parseOptionsImpl(\n \t\t\t\ttransformOpts.JSXFragment = value\n \t\t\t}\n \n+\t\tcase strings.HasPrefix(arg, \"--jsx-import-source=\"):\n+\t\t\tvalue := arg[len(\"--jsx-import-source=\"):]\n+\t\t\tif buildOpts != nil {\n+\t\t\t\tbuildOpts.JSXImportSource = value\n+\t\t\t} else {\n+\t\t\t\ttransformOpts.JSXImportSource = value\n+\t\t\t}\n+\n+\t\tcase isBoolFlag(arg, \"--jsx-dev\"):\n+\t\t\tif value, err := parseBoolFlag(arg, true); err != nil {\n+\t\t\t\treturn parseOptionsExtras{}, err\n+\t\t\t} else if buildOpts != nil {\n+\t\t\t\tbuildOpts.JSXDev = value\n+\t\t\t} else {\n+\t\t\t\ttransformOpts.JSXDev = value\n+\t\t\t}\n+\n \t\tcase strings.HasPrefix(arg, \"--banner=\") && transformOpts != nil:\n \t\t\ttransformOpts.Banner = arg[len(\"--banner=\"):]\n \n@@ -734,6 +753,7 @@ func parseOptionsImpl(\n \t\t\t\t\"allow-overwrite\":    true,\n \t\t\t\t\"bundle\":             true,\n \t\t\t\t\"ignore-annotations\": true,\n+\t\t\t\t\"jsx-dev\":            true,\n \t\t\t\t\"keep-names\":         true,\n \t\t\t\t\"minify-identifiers\": true,\n \t\t\t\t\"minify-syntax\":      true,\n@@ -761,6 +781,7 @@ func parseOptionsImpl(\n \t\t\t\t\"ignore-annotations\": true,\n \t\t\t\t\"jsx-factory\":        true,\n \t\t\t\t\"jsx-fragment\":       true,\n+\t\t\t\t\"jsx-import-source\":  true,\n \t\t\t\t\"jsx\":                true,\n \t\t\t\t\"keep-names\":         true,\n \t\t\t\t\"legal-comments\":     true,"},{"sha":"f6eac4ff2dcd819879321ffe0d4a18000c89b5d6","filename":"scripts/js-api-tests.js","status":"modified","additions":46,"deletions":0,"changes":46,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/scripts%2Fjs-api-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/scripts%2Fjs-api-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fjs-api-tests.js?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -3526,6 +3526,37 @@ let transformTests = {\n       loader: 'jsx',\n     })\n     assert.strictEqual(code2, `/* @__PURE__ */ factory(fragment, null, /* @__PURE__ */ factory(\"div\", null));\\n`)\n+\n+    const { code: code3 } = await esbuild.transform(`<><div/></>`, {\n+      tsconfigRaw: {\n+        compilerOptions: {\n+          jsx: 'react-jsx'\n+        },\n+      },\n+      loader: 'jsx',\n+    })\n+    assert.strictEqual(code3, `import { Fragment, jsx } from \"react/jsx-runtime\";\\n/* @__PURE__ */ jsx(Fragment, {\\n  children: /* @__PURE__ */ jsx(\"div\", {})\\n});\\n`)\n+\n+    const { code: code4 } = await esbuild.transform(`<><div/></>`, {\n+      tsconfigRaw: {\n+        compilerOptions: {\n+          jsx: 'react-jsx',\n+          jsxImportSource: 'notreact'\n+        },\n+      },\n+      loader: 'jsx',\n+    })\n+    assert.strictEqual(code4, `import { Fragment, jsx } from \"notreact/jsx-runtime\";\\n/* @__PURE__ */ jsx(Fragment, {\\n  children: /* @__PURE__ */ jsx(\"div\", {})\\n});\\n`)\n+\n+    const { code: code5 } = await esbuild.transform(`<><div/></>`, {\n+      tsconfigRaw: {\n+        compilerOptions: {\n+          jsx: 'react-jsxdev'\n+        },\n+      },\n+      loader: 'jsx',\n+    })\n+    assert.strictEqual(code5, `import { Fragment, jsxDEV } from \"react/jsx-dev-runtime\";\\n/* @__PURE__ */ jsxDEV(Fragment, {\\n  children: /* @__PURE__ */ jsxDEV(\"div\", {}, void 0, false, {\\n    fileName: \"<stdin>\",\\n    lineNumber: 1,\\n    columnNumber: 3\\n  }, this)\\n}, void 0, false, {\\n  fileName: \"<stdin>\",\\n  lineNumber: 1,\\n  columnNumber: 1\\n}, this);\\n`)\n   },\n \n   // Note: tree shaking is disabled when the output format isn't IIFE\n@@ -3883,6 +3914,21 @@ let transformTests = {\n     assert.strictEqual(code, `console.log(<div />);\\n`)\n   },\n \n+  async jsxRuntimeAutomatic({ esbuild }) {\n+    const { code } = await esbuild.transform(`console.log(<div/>)`, { loader: 'jsx', jsx: 'automatic' })\n+    assert.strictEqual(code, `import { jsx } from \"react/jsx-runtime\";\\nconsole.log(/* @__PURE__ */ jsx(\"div\", {}));\\n`)\n+  },\n+\n+  async jsxDev({ esbuild }) {\n+    const { code } = await esbuild.transform(`console.log(<div/>)`, { loader: 'jsx', jsx: 'automatic', jsxDev: true })\n+    assert.strictEqual(code, `import { jsxDEV } from \"react/jsx-dev-runtime\";\\nconsole.log(/* @__PURE__ */ jsxDEV(\"div\", {}, void 0, false, {\\n  fileName: \"<stdin>\",\\n  lineNumber: 1,\\n  columnNumber: 13\\n}, this));\\n`)\n+  },\n+\n+  async jsxImportSource({ esbuild }) {\n+    const { code } = await esbuild.transform(`console.log(<div/>)`, { loader: 'jsx', jsx: 'automatic', jsxImportSource: 'notreact' })\n+    assert.strictEqual(code, `import { jsx } from \"notreact/jsx-runtime\";\\nconsole.log(/* @__PURE__ */ jsx(\"div\", {}));\\n`)\n+  },\n+\n   async ts({ esbuild }) {\n     const { code } = await esbuild.transform(`enum Foo { FOO }`, { loader: 'ts' })\n     assert.strictEqual(code, `var Foo = /* @__PURE__ */ ((Foo2) => {\\n  Foo2[Foo2[\"FOO\"] = 0] = \"FOO\";\\n  return Foo2;\\n})(Foo || {});\\n`)"},{"sha":"c1c138f93390c6b1ff7c604e302fb6a31afb33fa","filename":"scripts/verify-source-map.js","status":"modified","additions":39,"deletions":0,"changes":39,"blob_url":"https://github.com/evanw/esbuild/blob/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/scripts%2Fverify-source-map.js","raw_url":"https://github.com/evanw/esbuild/raw/c20f3c252e5a290c6c95b508fb07b4b4bb7e669e/scripts%2Fverify-source-map.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fverify-source-map.js?ref=c20f3c252e5a290c6c95b508fb07b4b4bb7e669e","patch":"@@ -320,6 +320,33 @@ const testCaseBundleCSS = {\n   `,\n }\n \n+const testCaseJSXRuntime = {\n+  'entry.jsx': `\n+    import { A0, A1, A2 } from './a.jsx';\n+    console.log(<A0><A1/><A2/></A0>)\n+  `,\n+  'a.jsx': `\n+    import {jsx} from './b-dir/b'\n+    import {Fragment} from './b-dir/c-dir/c'\n+    export function A0() { return <Fragment id=\"A0\"><>a0</></Fragment> }\n+    export function A1() { return <div {...jsx} data-testid=\"A1\">a1</div> }\n+    export function A2() { return <A1 id=\"A2\"><a/><b/></A1> }\n+  `,\n+  'b-dir/b.js': `\n+    export const jsx = {id: 'jsx'}\n+  `,\n+  'b-dir/c-dir/c.jsx': `\n+    exports.Fragment = function() { return <></> }\n+  `,\n+}\n+\n+const toSearchJSXRuntime = {\n+  A0: 'a.jsx',\n+  A1: 'a.jsx',\n+  A2: 'a.jsx',\n+  jsx: 'b-dir/b.js',\n+}\n+\n const testCaseNames = {\n   'entry.js': `\n     import \"./nested1\"\n@@ -759,6 +786,18 @@ async function main() {\n           entryPoints: ['entry.css'],\n           crlf,\n         }),\n+        check('jsx-runtime' + suffix, testCaseJSXRuntime, toSearchJSXRuntime, {\n+          ext: 'js',\n+          flags: flags.concat('--outfile=out.js', '--bundle', '--jsx=automatic', '--external:react/jsx-runtime'),\n+          entryPoints: ['entry.jsx'],\n+          crlf,\n+        }),\n+        check('jsx-dev-runtime' + suffix, testCaseJSXRuntime, toSearchJSXRuntime, {\n+          ext: 'js',\n+          flags: flags.concat('--outfile=out.js', '--bundle', '--jsx=automatic', '--jsx-dev', '--external:react/jsx-dev-runtime'),\n+          entryPoints: ['entry.jsx'],\n+          crlf,\n+        }),\n \n         // Checks for the \"names\" field\n         checkNames('names' + suffix, testCaseNames, {"}]},{"url":"https://api.github.com/repos/evanw/esbuild/issues/1244","repository_url":"https://api.github.com/repos/evanw/esbuild","labels_url":"https://api.github.com/repos/evanw/esbuild/issues/1244/labels{/name}","comments_url":"https://api.github.com/repos/evanw/esbuild/issues/1244/comments","events_url":"https://api.github.com/repos/evanw/esbuild/issues/1244/events","html_url":"https://github.com/evanw/esbuild/pull/1244","id":874964196,"node_id":"MDExOlB1bGxSZXF1ZXN0NjI5NDA5OTU0","number":1244,"title":"Annotate module wrapper functions in debug builds","user":{"login":"evanw","id":406394,"node_id":"MDQ6VXNlcjQwNjM5NA==","avatar_url":"https://avatars.githubusercontent.com/u/406394?v=4","gravatar_id":"","url":"https://api.github.com/users/evanw","html_url":"https://github.com/evanw","followers_url":"https://api.github.com/users/evanw/followers","following_url":"https://api.github.com/users/evanw/following{/other_user}","gists_url":"https://api.github.com/users/evanw/gists{/gist_id}","starred_url":"https://api.github.com/users/evanw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/evanw/subscriptions","organizations_url":"https://api.github.com/users/evanw/orgs","repos_url":"https://api.github.com/users/evanw/repos","events_url":"https://api.github.com/users/evanw/events{/privacy}","received_events_url":"https://api.github.com/users/evanw/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-05-03T22:44:04Z","updated_at":"2021-05-03T23:20:32Z","closed_at":"2021-05-03T22:59:08Z","author_association":"OWNER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/evanw/esbuild/pulls/1244","html_url":"https://github.com/evanw/esbuild/pull/1244","diff_url":"https://github.com/evanw/esbuild/pull/1244.diff","patch_url":"https://github.com/evanw/esbuild/pull/1244.patch","merged_at":"2021-05-03T22:59:07Z"},"body":"Sometimes esbuild needs to wrap certain modules in a function when bundling. This is done both for lazy evaluation and for CommonJS modules that use a top-level `return` statement. Previously these functions were all anonymous, so stack traces for errors thrown during initialization looked like this:\r\n\r\n```\r\nError: Electron failed to install correctly, please delete node_modules/electron and try installing again\r\n    at getElectronPath (out.js:16:13)\r\n    at out.js:19:21\r\n    at out.js:1:45\r\n    at out.js:24:3\r\n    at out.js:1:45\r\n    at out.js:29:3\r\n    at out.js:1:45\r\n    at Object.<anonymous> (out.js:33:1)\r\n```\r\n\r\nThis release adds names to these anonymous functions when minification is disabled. The above stack trace now looks like this:\r\n\r\n```\r\nError: Electron failed to install correctly, please delete node_modules/electron and try installing again\r\n    at getElectronPath (out.js:19:15)\r\n    at node_modules/electron/index.js (out.js:22:23)\r\n    at __require (out.js:2:44)\r\n    at src/base/window.js (out.js:29:5)\r\n    at __require (out.js:2:44)\r\n    at src/base/kiosk.js (out.js:36:5)\r\n    at __require (out.js:2:44)\r\n    at Object.<anonymous> (out.js:41:1)\r\n```\r\n\r\nThis is similar to Webpack's development-mode behavior:\r\n\r\n```\r\nError: Electron failed to install correctly, please delete node_modules/electron and try installing again\r\n    at getElectronPath (out.js:23:11)\r\n    at Object../node_modules/electron/index.js (out.js:27:18)\r\n    at __webpack_require__ (out.js:96:41)\r\n    at Object../src/base/window.js (out.js:49:1)\r\n    at __webpack_require__ (out.js:96:41)\r\n    at Object../src/base/kiosk.js (out.js:38:1)\r\n    at __webpack_require__ (out.js:96:41)\r\n    at out.js:109:1\r\n    at out.js:111:3\r\n    at Object.<anonymous> (out.js:113:12)\r\n```\r\n\r\nThese descriptive function names will additionally be available when using a profiler such as the one included in the \"Performance\" tab in Chrome Developer Tools. Previously all functions were named `(anonymous)` which made it difficult to investigate performance issues during bundle initialization.\r\n\r\nCloses #1236\r\n","reactions":{"url":"https://api.github.com/repos/evanw/esbuild/issues/1244/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/evanw/esbuild/issues/1244/timeline","performed_via_github_app":null,"state_reason":null,"score":1,"files":[{"sha":"57dcda7c268b8f9d0baac35f22e6c4afe78ea476","filename":"CHANGELOG.md","status":"modified","additions":48,"deletions":0,"changes":48,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/CHANGELOG.md","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/CHANGELOG.md","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/CHANGELOG.md?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -6,6 +6,54 @@\n \n     This fixes a bug with TypeScript code that uses `declare` on a class field and your `tsconfig.json` file has `\"useDefineForClassFields\": true`. Fields marked as `declare` should not be defined in the generated code, but they were incorrectly being declared as `undefined`. These fields are now correctly omitted from the generated code.\n \n+* Annotate module wrapper functions in debug builds ([#1236](https://github.com/evanw/esbuild/pull/1236))\n+\n+    Sometimes esbuild needs to wrap certain modules in a function when bundling. This is done both for lazy evaluation and for CommonJS modules that use a top-level `return` statement. Previously these functions were all anonymous, so stack traces for errors thrown during initialization looked like this:\n+\n+    ```\n+    Error: Electron failed to install correctly, please delete node_modules/electron and try installing again\n+        at getElectronPath (out.js:16:13)\n+        at out.js:19:21\n+        at out.js:1:45\n+        at out.js:24:3\n+        at out.js:1:45\n+        at out.js:29:3\n+        at out.js:1:45\n+        at Object.<anonymous> (out.js:33:1)\n+    ```\n+\n+    This release adds names to these anonymous functions when minification is disabled. The above stack trace now looks like this:\n+\n+    ```\n+    Error: Electron failed to install correctly, please delete node_modules/electron and try installing again\n+        at getElectronPath (out.js:19:15)\n+        at node_modules/electron/index.js (out.js:22:23)\n+        at __require (out.js:2:44)\n+        at src/base/window.js (out.js:29:5)\n+        at __require (out.js:2:44)\n+        at src/base/kiosk.js (out.js:36:5)\n+        at __require (out.js:2:44)\n+        at Object.<anonymous> (out.js:41:1)\n+    ```\n+\n+    This is similar to Webpack's development-mode behavior:\n+\n+    ```\n+    Error: Electron failed to install correctly, please delete node_modules/electron and try installing again\n+        at getElectronPath (out.js:23:11)\n+        at Object../node_modules/electron/index.js (out.js:27:18)\n+        at __webpack_require__ (out.js:96:41)\n+        at Object../src/base/window.js (out.js:49:1)\n+        at __webpack_require__ (out.js:96:41)\n+        at Object../src/base/kiosk.js (out.js:38:1)\n+        at __webpack_require__ (out.js:96:41)\n+        at out.js:109:1\n+        at out.js:111:3\n+        at Object.<anonymous> (out.js:113:12)\n+    ```\n+\n+    These descriptive function names will additionally be available when using a profiler such as the one included in the \"Performance\" tab in Chrome Developer Tools. Previously all functions were named `(anonymous)` which made it difficult to investigate performance issues during bundle initialization.\n+\n ## 0.11.18\n \n * Add support for OpenBSD on x86-64 ([#1235](https://github.com/evanw/esbuild/issues/1235))"},{"sha":"16698f5441b1d01d2bb48a108c91bd88be0a0154","filename":"internal/bundler/bundler.go","status":"modified","additions":11,"deletions":2,"changes":13,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fbundler.go","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fbundler.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler.go?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -1855,6 +1855,8 @@ func applyOptionDefaults(options *config.Options) {\n \t\t\t{Data: \"-\", Placeholder: config.HashPlaceholder},\n \t\t}\n \t}\n+\n+\toptions.ProfilerNames = !options.MinifyIdentifiers\n }\n \n func (b *Bundle) Compile(log logger.Log, options config.Options, timer *helpers.Timer) ([]graph.OutputFile, string) {\n@@ -2142,6 +2144,7 @@ func (b *Bundle) generateMetadataJSON(results []graph.OutputFile, allReachableFi\n type runtimeCacheKey struct {\n \tMangleSyntax      bool\n \tMinifyIdentifiers bool\n+\tProfilerNames     bool\n \tES6               bool\n \tPlatform          config.Platform\n }\n@@ -2161,6 +2164,7 @@ func (cache *runtimeCache) parseRuntime(options *config.Options) (source logger.\n \t\t// All configuration options that the runtime code depends on must go here\n \t\tMangleSyntax:      options.MangleSyntax,\n \t\tMinifyIdentifiers: options.MinifyIdentifiers,\n+\t\tProfilerNames:     options.ProfilerNames,\n \t\tPlatform:          options.Platform,\n \t\tES6:               runtime.CanUseES6(options.UnsupportedJSFeatures),\n \t}\n@@ -2197,7 +2201,7 @@ func (cache *runtimeCache) parseRuntime(options *config.Options) (source logger.\n \t\tMangleSyntax:      key.MangleSyntax,\n \t\tMinifyIdentifiers: key.MinifyIdentifiers,\n \t\tPlatform:          key.Platform,\n-\t\tDefines:           cache.processedDefines(key.Platform),\n+\t\tDefines:           cache.processedDefines(key.Platform, key.ProfilerNames),\n \t\tUnsupportedJSFeatures: compat.UnsupportedJSFeatures(\n \t\t\tmap[compat.Engine][]int{compat.ES: {constraint}}),\n \n@@ -2225,7 +2229,7 @@ func (cache *runtimeCache) parseRuntime(options *config.Options) (source logger.\n \treturn\n }\n \n-func (cache *runtimeCache) processedDefines(key config.Platform) (defines *config.ProcessedDefines) {\n+func (cache *runtimeCache) processedDefines(key config.Platform, profilerNames bool) (defines *config.ProcessedDefines) {\n \tok := false\n \n \t// Cache hit?\n@@ -2256,6 +2260,11 @@ func (cache *runtimeCache) processedDefines(key config.Platform) (defines *confi\n \t\t\t\treturn &js_ast.EString{Value: js_lexer.StringToUTF16(platform)}\n \t\t\t},\n \t\t},\n+\t\t\"__profiler\": {\n+\t\t\tDefineFunc: func(da config.DefineArgs) js_ast.E {\n+\t\t\t\treturn &js_ast.EBoolean{Value: profilerNames}\n+\t\t\t},\n+\t\t},\n \t})\n \tdefines = &result\n "},{"sha":"b9ce8753fc3f77e430252d812711b4f3da411953","filename":"internal/bundler/linker.go","status":"modified","additions":36,"deletions":24,"changes":60,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Flinker.go","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Flinker.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Flinker.go?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -3371,21 +3371,27 @@ func (c *linkerContext) generateCodeForFileInChunkJS(\n \t\t\t\t}\n \t\t\t}\n \n-\t\t\t// \"__commonJS((exports, module) => { ... })\"\n-\t\t\tvar value js_ast.Expr\n-\t\t\tif c.options.UnsupportedJSFeatures.Has(compat.Arrow) {\n-\t\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n-\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: commonJSRef}},\n-\t\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EFunction{Fn: js_ast.Fn{Args: args, Body: js_ast.FnBody{Stmts: stmts}}}}},\n-\t\t\t\t}}\n+\t\t\tvar cjsArgs []js_ast.Expr\n+\t\t\tif c.options.ProfilerNames {\n+\t\t\t\t// \"__commonJS({ 'file.js'(exports, module) { ... } })\"\n+\t\t\t\tcjsArgs = []js_ast.Expr{{Data: &js_ast.EObject{Properties: []js_ast.Property{{\n+\t\t\t\t\tIsMethod: !c.options.UnsupportedJSFeatures.Has(compat.ObjectExtensions),\n+\t\t\t\t\tKey:      js_ast.Expr{Data: &js_ast.EString{Value: js_lexer.StringToUTF16(file.InputFile.Source.PrettyPath)}},\n+\t\t\t\t\tValue:    &js_ast.Expr{Data: &js_ast.EFunction{Fn: js_ast.Fn{Args: args, Body: js_ast.FnBody{Stmts: stmts}}}},\n+\t\t\t\t}}}}}\n+\t\t\t} else if c.options.UnsupportedJSFeatures.Has(compat.Arrow) {\n+\t\t\t\t// \"__commonJS(function (exports, module) { ... })\"\n+\t\t\t\tcjsArgs = []js_ast.Expr{{Data: &js_ast.EFunction{Fn: js_ast.Fn{Args: args, Body: js_ast.FnBody{Stmts: stmts}}}}}\n \t\t\t} else {\n-\t\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n-\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: commonJSRef}},\n-\t\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EArrow{Args: args, Body: js_ast.FnBody{Stmts: stmts}}}},\n-\t\t\t\t}}\n+\t\t\t\t// \"__commonJS((exports, module) => { ... })\"\n+\t\t\t\tcjsArgs = []js_ast.Expr{{Data: &js_ast.EArrow{Args: args, Body: js_ast.FnBody{Stmts: stmts}}}}\n \t\t\t}\n+\t\t\tvalue := js_ast.Expr{Data: &js_ast.ECall{\n+\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: commonJSRef}},\n+\t\t\t\tArgs:   cjsArgs,\n+\t\t\t}}\n \n-\t\t\t// \"var require_foo = __commonJS((exports, module) => { ... });\"\n+\t\t\t// \"var require_foo = __commonJS(...);\"\n \t\t\tstmts = append(stmtList.outsideWrapperPrefix, js_ast.Stmt{Data: &js_ast.SLocal{\n \t\t\t\tDecls: []js_ast.Decl{{\n \t\t\t\t\tBinding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.AST.WrapperRef}},\n@@ -3433,19 +3439,25 @@ func (c *linkerContext) generateCodeForFileInChunkJS(\n \t\t\t}\n \t\t\tstmts = stmts[:end]\n \n-\t\t\t// \"__esm(() => { ... })\"\n-\t\t\tvar value js_ast.Expr\n-\t\t\tif c.options.UnsupportedJSFeatures.Has(compat.Arrow) {\n-\t\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n-\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: esmRef}},\n-\t\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EFunction{Fn: js_ast.Fn{Body: js_ast.FnBody{Stmts: stmts}, IsAsync: isAsync}}}},\n-\t\t\t\t}}\n+\t\t\tvar esmArgs []js_ast.Expr\n+\t\t\tif c.options.ProfilerNames {\n+\t\t\t\t// \"__esm({ 'file.js'() { ... } })\"\n+\t\t\t\tesmArgs = []js_ast.Expr{{Data: &js_ast.EObject{Properties: []js_ast.Property{{\n+\t\t\t\t\tIsMethod: !c.options.UnsupportedJSFeatures.Has(compat.ObjectExtensions),\n+\t\t\t\t\tKey:      js_ast.Expr{Data: &js_ast.EString{Value: js_lexer.StringToUTF16(file.InputFile.Source.PrettyPath)}},\n+\t\t\t\t\tValue:    &js_ast.Expr{Data: &js_ast.EFunction{Fn: js_ast.Fn{Body: js_ast.FnBody{Stmts: stmts}, IsAsync: isAsync}}},\n+\t\t\t\t}}}}}\n+\t\t\t} else if c.options.UnsupportedJSFeatures.Has(compat.Arrow) {\n+\t\t\t\t// \"__esm(function () { ... })\"\n+\t\t\t\tesmArgs = []js_ast.Expr{{Data: &js_ast.EFunction{Fn: js_ast.Fn{Body: js_ast.FnBody{Stmts: stmts}, IsAsync: isAsync}}}}\n \t\t\t} else {\n-\t\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n-\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: esmRef}},\n-\t\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EArrow{Body: js_ast.FnBody{Stmts: stmts}, IsAsync: isAsync}}},\n-\t\t\t\t}}\n+\t\t\t\t// \"__esm(() => { ... })\"\n+\t\t\t\tesmArgs = []js_ast.Expr{{Data: &js_ast.EArrow{Body: js_ast.FnBody{Stmts: stmts}, IsAsync: isAsync}}}\n \t\t\t}\n+\t\t\tvalue := js_ast.Expr{Data: &js_ast.ECall{\n+\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: esmRef}},\n+\t\t\t\tArgs:   esmArgs,\n+\t\t\t}}\n \n \t\t\t// \"var foo, bar;\"\n \t\t\tif !c.options.MangleSyntax && len(decls) > 0 {\n@@ -3455,7 +3467,7 @@ func (c *linkerContext) generateCodeForFileInChunkJS(\n \t\t\t\tdecls = nil\n \t\t\t}\n \n-\t\t\t// \"var init_foo = __esm(() => { ... });\"\n+\t\t\t// \"var init_foo = __esm(...);\"\n \t\t\tstmts = append(stmtList.outsideWrapperPrefix, js_ast.Stmt{Data: &js_ast.SLocal{\n \t\t\t\tDecls: append(decls, js_ast.Decl{\n \t\t\t\t\tBinding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.AST.WrapperRef}},"},{"sha":"8c844e2522ab27d414f11437bc1123359324e2d5","filename":"internal/bundler/snapshots/snapshots_dce.txt","status":"modified","additions":77,"deletions":43,"changes":120,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_dce.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_dce.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_dce.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -107,8 +107,10 @@ console.log(\"unused import\");\n TestImportReExportOfNamespaceImport\n ---------- /out.js ----------\n // Users/user/project/node_modules/pkg/foo.js\n-var require_foo = __commonJS((exports, module) => {\n-  module.exports = 123;\n+var require_foo = __commonJS({\n+  \"Users/user/project/node_modules/pkg/foo.js\"(exports, module) {\n+    module.exports = 123;\n+  }\n });\n \n // Users/user/project/node_modules/pkg/index.js\n@@ -147,9 +149,11 @@ __export(index_main_exports, {\n   foo: () => foo\n });\n var foo;\n-var init_index_main = __esm(() => {\n-  foo = 123;\n-  console.log(\"this should be kept\");\n+var init_index_main = __esm({\n+  \"Users/user/project/node_modules/demo-pkg/index-main.js\"() {\n+    foo = 123;\n+    console.log(\"this should be kept\");\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -191,9 +195,11 @@ __export(index_main_exports, {\n   foo: () => foo\n });\n var foo;\n-var init_index_main = __esm(() => {\n-  foo = 123;\n-  console.log(\"this should be kept\");\n+var init_index_main = __esm({\n+  \"Users/user/project/node_modules/demo-pkg/index-main.js\"() {\n+    foo = 123;\n+    console.log(\"this should be kept\");\n+  }\n });\n \n // Users/user/project/src/require-demo-pkg.js\n@@ -237,22 +243,28 @@ TestPackageJsonSideEffectsFalseAllFork\n ---------- /out.js ----------\n // Users/user/project/node_modules/c/index.js\n var foo;\n-var init_c = __esm(() => {\n-  foo = \"foo\";\n+var init_c = __esm({\n+  \"Users/user/project/node_modules/c/index.js\"() {\n+    foo = \"foo\";\n+  }\n });\n \n // Users/user/project/node_modules/b/index.js\n-var init_b = __esm(() => {\n-  init_c();\n+var init_b = __esm({\n+  \"Users/user/project/node_modules/b/index.js\"() {\n+    init_c();\n+  }\n });\n \n // Users/user/project/node_modules/a/index.js\n var a_exports = {};\n __export(a_exports, {\n   foo: () => foo\n });\n-var init_a = __esm(() => {\n-  init_b();\n+var init_a = __esm({\n+  \"Users/user/project/node_modules/a/index.js\"() {\n+    init_b();\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -317,9 +329,11 @@ console.log(foo);\n TestPackageJsonSideEffectsFalseKeepBareImportAndRequireCommonJS\n ---------- /out.js ----------\n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports) => {\n-  exports.foo = 123;\n-  console.log(\"hello\");\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports) {\n+    exports.foo = 123;\n+    console.log(\"hello\");\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -335,9 +349,11 @@ __export(demo_pkg_exports, {\n   foo: () => foo\n });\n var foo;\n-var init_demo_pkg = __esm(() => {\n-  foo = 123;\n-  console.log(\"hello\");\n+var init_demo_pkg = __esm({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"() {\n+    foo = 123;\n+    console.log(\"hello\");\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -348,9 +364,11 @@ console.log(\"unused import\");\n TestPackageJsonSideEffectsFalseKeepNamedImportCommonJS\n ---------- /out.js ----------\n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports) => {\n-  exports.foo = 123;\n-  console.log(\"hello\");\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports) {\n+    exports.foo = 123;\n+    console.log(\"hello\");\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -371,9 +389,11 @@ console.log(foo);\n TestPackageJsonSideEffectsFalseKeepStarImportCommonJS\n ---------- /out.js ----------\n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports) => {\n-  exports.foo = 123;\n-  console.log(\"hello\");\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports) {\n+    exports.foo = 123;\n+    console.log(\"hello\");\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -408,27 +428,35 @@ TestPackageJsonSideEffectsFalseOneFork\n ---------- /out.js ----------\n // Users/user/project/node_modules/c/index.js\n var foo;\n-var init_c = __esm(() => {\n-  foo = \"foo\";\n+var init_c = __esm({\n+  \"Users/user/project/node_modules/c/index.js\"() {\n+    foo = \"foo\";\n+  }\n });\n \n // Users/user/project/node_modules/d/index.js\n-var init_d = __esm(() => {\n+var init_d = __esm({\n+  \"Users/user/project/node_modules/d/index.js\"() {\n+  }\n });\n \n // Users/user/project/node_modules/b/index.js\n-var init_b = __esm(() => {\n-  init_c();\n-  init_d();\n+var init_b = __esm({\n+  \"Users/user/project/node_modules/b/index.js\"() {\n+    init_c();\n+    init_d();\n+  }\n });\n \n // Users/user/project/node_modules/a/index.js\n var a_exports = {};\n __export(a_exports, {\n   foo: () => foo\n });\n-var init_a = __esm(() => {\n-  init_b();\n+var init_a = __esm({\n+  \"Users/user/project/node_modules/a/index.js\"() {\n+    init_b();\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -489,9 +517,11 @@ console.log(\"unused import\");\n TestPackageJsonSideEffectsTrueKeepCommonJS\n ---------- /out.js ----------\n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports) => {\n-  exports.foo = 123;\n-  console.log(\"hello\");\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports) {\n+    exports.foo = 123;\n+    console.log(\"hello\");\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -639,9 +669,11 @@ TestTreeShakingInESMWrapper\n ---------- /out.js ----------\n // lib.js\n var keep1, keep2;\n-var init_lib = __esm(() => {\n-  keep1 = () => \"keep1\";\n-  keep2 = () => \"keep2\";\n+var init_lib = __esm({\n+  \"lib.js\"() {\n+    keep1 = () => \"keep1\";\n+    keep2 = () => \"keep2\";\n+  }\n });\n \n // cjs.js\n@@ -650,9 +682,11 @@ __export(cjs_exports, {\n   default: () => cjs_default\n });\n var cjs_default;\n-var init_cjs = __esm(() => {\n-  init_lib();\n-  cjs_default = keep2();\n+var init_cjs = __esm({\n+  \"cjs.js\"() {\n+    init_lib();\n+    cjs_default = keep2();\n+  }\n });\n \n // entry.js"},{"sha":"a179cc83e8354a730a345a60330b7691b6024e9d","filename":"internal/bundler/snapshots/snapshots_default.txt","status":"modified","additions":385,"deletions":249,"changes":634,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_default.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_default.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_default.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -230,7 +230,9 @@ __export(foo_exports, {\n function foo() {\n   return \"foo\";\n }\n-var init_foo = __esm(() => {\n+var init_foo = __esm({\n+  \"foo.js\"() {\n+  }\n });\n \n // bar.js\n@@ -241,7 +243,9 @@ __export(bar_exports, {\n function bar() {\n   return \"bar\";\n }\n-var init_bar = __esm(() => {\n+var init_bar = __esm({\n+  \"bar.js\"() {\n+  }\n });\n \n // entry.js\n@@ -253,17 +257,21 @@ var {bar: bar2} = (init_bar(), bar_exports);\n TestConditionalImport\n ---------- /out/a.js ----------\n // import.js\n-var require_import = __commonJS((exports) => {\n-  exports.foo = 213;\n+var require_import = __commonJS({\n+  \"import.js\"(exports) {\n+    exports.foo = 213;\n+  }\n });\n \n // a.js\n x ? import(\"a\") : y ? Promise.resolve().then(() => __toModule(require_import())) : import(\"c\");\n \n ---------- /out/b.js ----------\n // import.js\n-var require_import = __commonJS((exports) => {\n-  exports.foo = 213;\n+var require_import = __commonJS({\n+  \"import.js\"(exports) {\n+    exports.foo = 213;\n+  }\n });\n \n // b.js\n@@ -273,8 +281,10 @@ x ? y ? import(\"a\") : Promise.resolve().then(() => __toModule(require_import()))\n TestConditionalRequire\n ---------- /out.js ----------\n // b.js\n-var require_b = __commonJS((exports) => {\n-  exports.foo = 213;\n+var require_b = __commonJS({\n+  \"b.js\"(exports) {\n+    exports.foo = 213;\n+  }\n });\n \n // a.js\n@@ -384,8 +394,10 @@ function test5() {\n TestDotImport\n ---------- /out.js ----------\n // index.js\n-var require_index = __commonJS((exports) => {\n-  exports.x = 123;\n+var require_index = __commonJS({\n+  \"index.js\"(exports) {\n+    exports.x = 123;\n+  }\n });\n \n // entry.js\n@@ -409,8 +421,10 @@ TestDynamicImportWithTemplateIIFE\n ---------- /out.js ----------\n (() => {\n   // b.js\n-  var require_b = __commonJS((exports) => {\n-    exports.x = 123;\n+  var require_b = __commonJS({\n+    \"b.js\"(exports) {\n+      exports.x = 123;\n+    }\n   });\n \n   // a.js\n@@ -422,17 +436,21 @@ TestDynamicImportWithTemplateIIFE\n TestES6FromCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = function() {\n-    return \"foo\";\n-  };\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.foo = function() {\n+      return \"foo\";\n+    };\n+  }\n });\n \n // bar.js\n-var require_bar = __commonJS((exports) => {\n-  exports.bar = function() {\n-    return \"bar\";\n-  };\n+var require_bar = __commonJS({\n+  \"bar.js\"(exports) {\n+    exports.bar = function() {\n+      return \"bar\";\n+    };\n+  }\n });\n \n // entry.js\n@@ -445,7 +463,9 @@ TestEmptyExportClauseBundleAsCommonJSIssue910\n ---------- /out.js ----------\n // types.mjs\n var types_exports = {};\n-var init_types = __esm(() => {\n+var init_types = __esm({\n+  \"types.mjs\"() {\n+  }\n });\n \n // entry.js\n@@ -477,10 +497,12 @@ TestExportFSNodeInCommonJSModule\n // entry.js\n import * as fs from \"fs\";\n import {readFileSync} from \"fs\";\n-var require_entry = __commonJS((exports) => {\n-  exports.fs = fs;\n-  exports.readFileSync = readFileSync;\n-  exports.foo = 123;\n+var require_entry = __commonJS({\n+  \"entry.js\"(exports) {\n+    exports.fs = fs;\n+    exports.readFileSync = readFileSync;\n+    exports.foo = 123;\n+  }\n });\n export default require_entry();\n \n@@ -489,8 +511,10 @@ TestExportFormsCommonJS\n ---------- /out.js ----------\n // a.js\n var abc;\n-var init_a = __esm(() => {\n-  abc = void 0;\n+var init_a = __esm({\n+  \"a.js\"() {\n+    abc = void 0;\n+  }\n });\n \n // b.js\n@@ -499,8 +523,10 @@ __export(b_exports, {\n   xyz: () => xyz\n });\n var xyz;\n-var init_b = __esm(() => {\n-  xyz = null;\n+var init_b = __esm({\n+  \"b.js\"() {\n+    xyz = null;\n+  }\n });\n \n // commonjs.js\n@@ -519,15 +545,17 @@ __export(commonjs_exports, {\n function Fn() {\n }\n var commonjs_default, v, l, c, Class;\n-var init_commonjs = __esm(() => {\n-  init_a();\n-  init_b();\n-  commonjs_default = 123;\n-  v = 234;\n-  l = 234;\n-  c = 234;\n-  Class = class {\n-  };\n+var init_commonjs = __esm({\n+  \"commonjs.js\"() {\n+    init_a();\n+    init_b();\n+    commonjs_default = 123;\n+    v = 234;\n+    l = 234;\n+    c = 234;\n+    Class = class {\n+    };\n+  }\n });\n \n // c.js\n@@ -536,10 +564,12 @@ __export(c_exports, {\n   default: () => c_default2\n });\n var c_default, c_default2;\n-var init_c = __esm(() => {\n-  c_default = class {\n-  };\n-  c_default2 = c_default;\n+var init_c = __esm({\n+  \"c.js\"() {\n+    c_default = class {\n+    };\n+    c_default2 = c_default;\n+  }\n });\n \n // d.js\n@@ -548,11 +578,13 @@ __export(d_exports, {\n   default: () => d_default\n });\n var Foo, d_default;\n-var init_d = __esm(() => {\n-  Foo = class {\n-  };\n-  d_default = Foo;\n-  Foo.prop = 123;\n+var init_d = __esm({\n+  \"d.js\"() {\n+    Foo = class {\n+    };\n+    d_default = Foo;\n+    Foo.prop = 123;\n+  }\n });\n \n // e.js\n@@ -562,7 +594,9 @@ __export(e_exports, {\n });\n function e_default() {\n }\n-var init_e = __esm(() => {\n+var init_e = __esm({\n+  \"e.js\"() {\n+  }\n });\n \n // f.js\n@@ -572,8 +606,10 @@ __export(f_exports, {\n });\n function foo() {\n }\n-var init_f = __esm(() => {\n-  foo.prop = 123;\n+var init_f = __esm({\n+  \"f.js\"() {\n+    foo.prop = 123;\n+  }\n });\n \n // g.js\n@@ -583,7 +619,9 @@ __export(g_exports, {\n });\n async function g_default() {\n }\n-var init_g = __esm(() => {\n+var init_g = __esm({\n+  \"g.js\"() {\n+  }\n });\n \n // h.js\n@@ -593,8 +631,10 @@ __export(h_exports, {\n });\n async function foo2() {\n }\n-var init_h = __esm(() => {\n-  foo2.prop = 123;\n+var init_h = __esm({\n+  \"h.js\"() {\n+    foo2.prop = 123;\n+  }\n });\n \n // entry.js\n@@ -757,7 +797,9 @@ __export(a_exports, {\n   ns: () => ns\n });\n import * as ns from \"x\";\n-var init_a = __esm(() => {\n+var init_a = __esm({\n+  \"a.js\"() {\n+  }\n });\n \n // b.js\n@@ -766,7 +808,9 @@ __export(b_exports, {\n   ns: () => ns2\n });\n import * as ns2 from \"x\";\n-var init_b = __esm(() => {\n+var init_b = __esm({\n+  \"b.js\"() {\n+  }\n });\n \n // c.js\n@@ -775,7 +819,9 @@ __export(c_exports, {\n   ns: () => ns3\n });\n import * as ns3 from \"x\";\n-var init_c = __esm(() => {\n+var init_c = __esm({\n+  \"c.js\"() {\n+  }\n });\n \n // d.js\n@@ -784,14 +830,18 @@ __export(d_exports, {\n   ns: () => ns4\n });\n import {ns as ns4} from \"x\";\n-var init_d = __esm(() => {\n+var init_d = __esm({\n+  \"d.js\"() {\n+  }\n });\n \n // e.js\n var e_exports = {};\n import * as x_star from \"x\";\n-var init_e = __esm(() => {\n-  __reExport(e_exports, x_star);\n+var init_e = __esm({\n+  \"e.js\"() {\n+    __reExport(e_exports, x_star);\n+  }\n });\n \n // entry.js\n@@ -963,8 +1013,10 @@ console.log(import.meta.url, import.meta.path);\n TestImportMissingCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.x = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.x = 123;\n+  }\n });\n \n // entry.js\n@@ -975,8 +1027,10 @@ console.log((0, import_foo.default)(import_foo.x, import_foo.y));\n TestImportMissingNeitherES6NorCommonJS\n ---------- /out/named.js ----------\n // foo.js\n-var require_foo = __commonJS(() => {\n-  console.log(\"no exports here\");\n+var require_foo = __commonJS({\n+  \"foo.js\"() {\n+    console.log(\"no exports here\");\n+  }\n });\n \n // named.js\n@@ -985,8 +1039,10 @@ console.log((0, import_foo.default)(void 0, void 0));\n \n ---------- /out/star.js ----------\n // foo.js\n-var require_foo = __commonJS(() => {\n-  console.log(\"no exports here\");\n+var require_foo = __commonJS({\n+  \"foo.js\"() {\n+    console.log(\"no exports here\");\n+  }\n });\n \n // star.js\n@@ -995,8 +1051,10 @@ console.log(ns.default(void 0, void 0));\n \n ---------- /out/star-capture.js ----------\n // foo.js\n-var require_foo = __commonJS(() => {\n-  console.log(\"no exports here\");\n+var require_foo = __commonJS({\n+  \"foo.js\"() {\n+    console.log(\"no exports here\");\n+  }\n });\n \n // star-capture.js\n@@ -1009,17 +1067,21 @@ console.log(\"no exports here\");\n \n ---------- /out/require.js ----------\n // foo.js\n-var require_foo = __commonJS(() => {\n-  console.log(\"no exports here\");\n+var require_foo = __commonJS({\n+  \"foo.js\"() {\n+    console.log(\"no exports here\");\n+  }\n });\n \n // require.js\n console.log(require_foo());\n \n ---------- /out/import.js ----------\n // foo.js\n-var require_foo = __commonJS(() => {\n-  console.log(\"no exports here\");\n+var require_foo = __commonJS({\n+  \"foo.js\"() {\n+    console.log(\"no exports here\");\n+  }\n });\n \n // import.js\n@@ -1211,8 +1273,10 @@ console.log(/* @__PURE__ */ React.createElement(\"]\", null));\n TestJSXImportsCommonJS\n ---------- /out.js ----------\n // custom-react.js\n-var require_custom_react = __commonJS((exports, module) => {\n-  module.exports = {};\n+var require_custom_react = __commonJS({\n+  \"custom-react.js\"(exports, module) {\n+    module.exports = {};\n+  }\n });\n \n // entry.jsx\n@@ -1697,7 +1761,7 @@ console.log(shared_default);\n ================================================================================\n TestMinifiedBundleCommonJS\n ---------- /out.js ----------\n-var n=e(r=>{r.foo=function(){return 123}});var u=e((j,t)=>{t.exports={test:!0}});var{foo:c}=n();console.log(c(),u());\n+var t=r(n=>{n.foo=function(){return 123}});var s=r((l,u)=>{u.exports={test:!0}});var{foo:c}=t();console.log(c(),s());\n \n ================================================================================\n TestMinifiedBundleES6\n@@ -1853,10 +1917,12 @@ console.log(foo);\n TestNestedCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // entry.js\n@@ -1870,10 +1936,12 @@ nestedScope();\n TestNestedES6FromCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.fn = function() {\n-    return 123;\n-  };\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.fn = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // entry.js\n@@ -1910,10 +1978,12 @@ TestNestedScopeBug\n TestNewExpressionCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports, module) => {\n-  var Foo = class {\n-  };\n-  module.exports = {Foo};\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports, module) {\n+    var Foo = class {\n+    };\n+    module.exports = {Foo};\n+  }\n });\n \n // entry.js\n@@ -1923,10 +1993,12 @@ new (require_foo()).Foo();\n TestNodeModules\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -1959,8 +2031,10 @@ console.log(\"test\");\n TestReExportCommonJSAsES6\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.bar = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.bar = 123;\n+  }\n });\n \n // entry.js\n@@ -2142,8 +2216,10 @@ try {\n TestRequireChildDirCommonJS\n ---------- /out.js ----------\n // Users/user/project/src/dir/index.js\n-var require_dir = __commonJS((exports, module) => {\n-  module.exports = 123;\n+var require_dir = __commonJS({\n+  \"Users/user/project/src/dir/index.js\"(exports, module) {\n+    module.exports = 123;\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -2173,12 +2249,14 @@ return require(\"fs\");\n TestRequireJson\n ---------- /out.js ----------\n // test.json\n-var require_test = __commonJS((exports, module) => {\n-  module.exports = {\n-    a: true,\n-    b: 123,\n-    c: [null]\n-  };\n+var require_test = __commonJS({\n+  \"test.json\"(exports, module) {\n+    module.exports = {\n+      a: true,\n+      b: 123,\n+      c: [null]\n+    };\n+  }\n });\n \n // entry.js\n@@ -2188,8 +2266,10 @@ console.log(require_test());\n TestRequireMainCacheCommonJS\n ---------- /out.js ----------\n // is-main.js\n-var require_is_main = __commonJS((exports2, module2) => {\n-  module2.exports = require.main === module2;\n+var require_is_main = __commonJS({\n+  \"is-main.js\"(exports2, module2) {\n+    module2.exports = require.main === module2;\n+  }\n });\n \n // entry.js\n@@ -2201,8 +2281,10 @@ console.log(\"cache:\", require.cache);\n TestRequireParentDirCommonJS\n ---------- /out.js ----------\n // Users/user/project/src/index.js\n-var require_src = __commonJS((exports, module) => {\n-  module.exports = 123;\n+var require_src = __commonJS({\n+  \"Users/user/project/src/index.js\"(exports, module) {\n+    module.exports = 123;\n+  }\n });\n \n // Users/user/project/src/dir/entry.js\n@@ -2258,8 +2340,10 @@ console.log(true);\n TestRequireTxt\n ---------- /out.js ----------\n // test.txt\n-var require_test = __commonJS((exports, module) => {\n-  module.exports = \"This is a test.\";\n+var require_test = __commonJS({\n+  \"test.txt\"(exports, module) {\n+    module.exports = \"This is a test.\";\n+  }\n });\n \n // entry.js\n@@ -2269,13 +2353,15 @@ console.log(require_test());\n TestRequireWithCallInsideTry\n ---------- /out.js ----------\n // entry.js\n-var require_entry = __commonJS((exports) => {\n-  try {\n-    const supportsColor = require(\"supports-color\");\n-    if (supportsColor && (supportsColor.stderr || supportsColor).level >= 2) {\n-      exports.colors = [];\n+var require_entry = __commonJS({\n+  \"entry.js\"(exports) {\n+    try {\n+      const supportsColor = require(\"supports-color\");\n+      if (supportsColor && (supportsColor.stderr || supportsColor).level >= 2) {\n+        exports.colors = [];\n+      }\n+    } catch (error) {\n     }\n-  } catch (error) {\n   }\n });\n export default require_entry();\n@@ -2284,8 +2370,10 @@ export default require_entry();\n TestRequireWithTemplate\n ---------- /out.js ----------\n // b.js\n-var require_b = __commonJS((exports) => {\n-  exports.x = 123;\n+var require_b = __commonJS({\n+  \"b.js\"(exports) {\n+    exports.x = 123;\n+  }\n });\n \n // a.js\n@@ -2337,10 +2425,12 @@ export {\n TestSimpleCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // entry.js\n@@ -2634,45 +2724,47 @@ var bar2;\n TestThisOutsideFunction\n ---------- /out.js ----------\n // entry.js\n-var require_entry = __commonJS((exports) => {\n-  if (shouldBeExportsNotThis) {\n-    console.log(exports);\n-    console.log((x = exports) => exports);\n-    console.log({x: exports});\n-    console.log(class extends exports.foo {\n-    });\n-    console.log(class {\n-      [exports.foo];\n-    });\n-    console.log(class {\n-      [exports.foo]() {\n-      }\n-    });\n-    console.log(class {\n-      static [exports.foo];\n-    });\n-    console.log(class {\n-      static [exports.foo]() {\n-      }\n-    });\n-  }\n-  if (shouldBeThisNotExports) {\n-    console.log(class {\n-      foo = this;\n-    });\n-    console.log(class {\n-      foo() {\n-        this;\n-      }\n-    });\n-    console.log(class {\n-      static foo = this;\n-    });\n-    console.log(class {\n-      static foo() {\n-        this;\n-      }\n-    });\n+var require_entry = __commonJS({\n+  \"entry.js\"(exports) {\n+    if (shouldBeExportsNotThis) {\n+      console.log(exports);\n+      console.log((x = exports) => exports);\n+      console.log({x: exports});\n+      console.log(class extends exports.foo {\n+      });\n+      console.log(class {\n+        [exports.foo];\n+      });\n+      console.log(class {\n+        [exports.foo]() {\n+        }\n+      });\n+      console.log(class {\n+        static [exports.foo];\n+      });\n+      console.log(class {\n+        static [exports.foo]() {\n+        }\n+      });\n+    }\n+    if (shouldBeThisNotExports) {\n+      console.log(class {\n+        foo = this;\n+      });\n+      console.log(class {\n+        foo() {\n+          this;\n+        }\n+      });\n+      console.log(class {\n+        static foo = this;\n+      });\n+      console.log(class {\n+        static foo() {\n+          this;\n+        }\n+      });\n+    }\n   }\n });\n export default require_entry();\n@@ -2693,8 +2785,10 @@ console.log(file1_default, file2_default);\n TestThisWithES6Syntax\n ---------- /out.js ----------\n // cjs.js\n-var require_cjs = __commonJS((exports) => {\n-  console.log(exports);\n+var require_cjs = __commonJS({\n+  \"cjs.js\"(exports) {\n+    console.log(exports);\n+  }\n });\n \n // dummy.js\n@@ -2703,117 +2797,145 @@ __export(dummy_exports, {\n   dummy: () => dummy\n });\n var dummy;\n-var init_dummy = __esm(() => {\n-  dummy = 123;\n+var init_dummy = __esm({\n+  \"dummy.js\"() {\n+    dummy = 123;\n+  }\n });\n \n // es6-import-assign.ts\n-var require_es6_import_assign = __commonJS((exports) => {\n-  var x2 = (init_dummy(), dummy_exports);\n-  console.log(exports);\n+var require_es6_import_assign = __commonJS({\n+  \"es6-import-assign.ts\"(exports) {\n+    var x2 = (init_dummy(), dummy_exports);\n+    console.log(exports);\n+  }\n });\n \n // es6-import-dynamic.js\n-var require_es6_import_dynamic = __commonJS((exports) => {\n-  Promise.resolve().then(() => init_dummy());\n-  console.log(exports);\n+var require_es6_import_dynamic = __commonJS({\n+  \"es6-import-dynamic.js\"(exports) {\n+    Promise.resolve().then(() => init_dummy());\n+    console.log(exports);\n+  }\n });\n \n // es6-expr-import-dynamic.js\n-var require_es6_expr_import_dynamic = __commonJS((exports) => {\n-  Promise.resolve().then(() => init_dummy());\n-  console.log(exports);\n+var require_es6_expr_import_dynamic = __commonJS({\n+  \"es6-expr-import-dynamic.js\"(exports) {\n+    Promise.resolve().then(() => init_dummy());\n+    console.log(exports);\n+  }\n });\n \n // es6-export-assign.ts\n-var require_es6_export_assign = __commonJS((exports, module) => {\n-  console.log(exports);\n-  module.exports = 123;\n+var require_es6_export_assign = __commonJS({\n+  \"es6-export-assign.ts\"(exports, module) {\n+    console.log(exports);\n+    module.exports = 123;\n+  }\n });\n \n // es6-ns-export-variable.ts\n-var require_es6_ns_export_variable = __commonJS((exports) => {\n-  var ns;\n-  (function(ns2) {\n-    ns2.foo = 123;\n-  })(ns || (ns = {}));\n-  console.log(exports);\n+var require_es6_ns_export_variable = __commonJS({\n+  \"es6-ns-export-variable.ts\"(exports) {\n+    var ns;\n+    (function(ns2) {\n+      ns2.foo = 123;\n+    })(ns || (ns = {}));\n+    console.log(exports);\n+  }\n });\n \n // es6-ns-export-function.ts\n-var require_es6_ns_export_function = __commonJS((exports) => {\n-  var ns;\n-  (function(ns2) {\n-    function foo() {\n-    }\n-    ns2.foo = foo;\n-  })(ns || (ns = {}));\n-  console.log(exports);\n+var require_es6_ns_export_function = __commonJS({\n+  \"es6-ns-export-function.ts\"(exports) {\n+    var ns;\n+    (function(ns2) {\n+      function foo() {\n+      }\n+      ns2.foo = foo;\n+    })(ns || (ns = {}));\n+    console.log(exports);\n+  }\n });\n \n // es6-ns-export-async-function.ts\n-var require_es6_ns_export_async_function = __commonJS((exports) => {\n-  var ns;\n-  (function(ns2) {\n-    async function foo() {\n-    }\n-    ns2.foo = foo;\n-  })(ns || (ns = {}));\n-  console.log(exports);\n+var require_es6_ns_export_async_function = __commonJS({\n+  \"es6-ns-export-async-function.ts\"(exports) {\n+    var ns;\n+    (function(ns2) {\n+      async function foo() {\n+      }\n+      ns2.foo = foo;\n+    })(ns || (ns = {}));\n+    console.log(exports);\n+  }\n });\n \n // es6-ns-export-enum.ts\n-var require_es6_ns_export_enum = __commonJS((exports) => {\n-  var ns;\n-  (function(ns2) {\n-    let Foo3;\n-    (function(Foo4) {\n-    })(Foo3 = ns2.Foo || (ns2.Foo = {}));\n-  })(ns || (ns = {}));\n-  console.log(exports);\n+var require_es6_ns_export_enum = __commonJS({\n+  \"es6-ns-export-enum.ts\"(exports) {\n+    var ns;\n+    (function(ns2) {\n+      let Foo3;\n+      (function(Foo4) {\n+      })(Foo3 = ns2.Foo || (ns2.Foo = {}));\n+    })(ns || (ns = {}));\n+    console.log(exports);\n+  }\n });\n \n // es6-ns-export-const-enum.ts\n-var require_es6_ns_export_const_enum = __commonJS((exports) => {\n-  var ns;\n-  (function(ns2) {\n-    let Foo3;\n-    (function(Foo4) {\n-    })(Foo3 = ns2.Foo || (ns2.Foo = {}));\n-  })(ns || (ns = {}));\n-  console.log(exports);\n+var require_es6_ns_export_const_enum = __commonJS({\n+  \"es6-ns-export-const-enum.ts\"(exports) {\n+    var ns;\n+    (function(ns2) {\n+      let Foo3;\n+      (function(Foo4) {\n+      })(Foo3 = ns2.Foo || (ns2.Foo = {}));\n+    })(ns || (ns = {}));\n+    console.log(exports);\n+  }\n });\n \n // es6-ns-export-module.ts\n-var require_es6_ns_export_module = __commonJS((exports) => {\n-  console.log(exports);\n+var require_es6_ns_export_module = __commonJS({\n+  \"es6-ns-export-module.ts\"(exports) {\n+    console.log(exports);\n+  }\n });\n \n // es6-ns-export-namespace.ts\n-var require_es6_ns_export_namespace = __commonJS((exports) => {\n-  console.log(exports);\n+var require_es6_ns_export_namespace = __commonJS({\n+  \"es6-ns-export-namespace.ts\"(exports) {\n+    console.log(exports);\n+  }\n });\n \n // es6-ns-export-class.ts\n-var require_es6_ns_export_class = __commonJS((exports) => {\n-  var ns;\n-  (function(ns2) {\n-    class Foo3 {\n-    }\n-    ns2.Foo = Foo3;\n-  })(ns || (ns = {}));\n-  console.log(exports);\n+var require_es6_ns_export_class = __commonJS({\n+  \"es6-ns-export-class.ts\"(exports) {\n+    var ns;\n+    (function(ns2) {\n+      class Foo3 {\n+      }\n+      ns2.Foo = Foo3;\n+    })(ns || (ns = {}));\n+    console.log(exports);\n+  }\n });\n \n // es6-ns-export-abstract-class.ts\n-var require_es6_ns_export_abstract_class = __commonJS((exports) => {\n-  var ns;\n-  (function(ns2) {\n-    class Foo3 {\n-    }\n-    ns2.Foo = Foo3;\n-  })(ns || (ns = {}));\n-  console.log(exports);\n+var require_es6_ns_export_abstract_class = __commonJS({\n+  \"es6-ns-export-abstract-class.ts\"(exports) {\n+    var ns;\n+    (function(ns2) {\n+      class Foo3 {\n+      }\n+      ns2.Foo = Foo3;\n+    })(ns || (ns = {}));\n+    console.log(exports);\n+  }\n });\n \n // entry.js\n@@ -2937,30 +3059,38 @@ TestTopLevelAwaitAllowedImportWithoutSplitting\n ---------- /out.js ----------\n // c.js\n var c_exports = {};\n-var init_c = __esm(async () => {\n-  await 0;\n+var init_c = __esm({\n+  async \"c.js\"() {\n+    await 0;\n+  }\n });\n \n // b.js\n var b_exports = {};\n-var init_b = __esm(async () => {\n-  await init_c();\n+var init_b = __esm({\n+  async \"b.js\"() {\n+    await init_c();\n+  }\n });\n \n // a.js\n var a_exports = {};\n-var init_a = __esm(async () => {\n-  await init_b();\n+var init_a = __esm({\n+  async \"a.js\"() {\n+    await init_b();\n+  }\n });\n \n // entry.js\n var entry_exports = {};\n-var init_entry = __esm(async () => {\n-  init_a();\n-  init_b();\n-  init_c();\n-  init_entry();\n-  await 0;\n+var init_entry = __esm({\n+  async \"entry.js\"() {\n+    init_a();\n+    init_b();\n+    init_c();\n+    init_entry();\n+    await 0;\n+  }\n });\n await init_entry();\n \n@@ -3001,18 +3131,24 @@ TestUseStrictDirectiveMinifyNoBundle\n TestWarningsInsideNodeModules\n ---------- /out.js ----------\n // return-asi.js\n-var require_return_asi = __commonJS(() => {\n-  return;\n+var require_return_asi = __commonJS({\n+  \"return-asi.js\"() {\n+    return;\n+  }\n });\n \n // node_modules/return-asi.js\n-var require_return_asi2 = __commonJS(() => {\n-  return;\n+var require_return_asi2 = __commonJS({\n+  \"node_modules/return-asi.js\"() {\n+    return;\n+  }\n });\n \n // plugin-dir/node_modules/return-asi.js\n-var require_return_asi3 = __commonJS(() => {\n-  return;\n+var require_return_asi3 = __commonJS({\n+  \"plugin-dir/node_modules/return-asi.js\"() {\n+    return;\n+  }\n });\n \n // dup-case.js"},{"sha":"b7293c03aeac830dc08acfed3c3de308ca90a0d8","filename":"internal/bundler/snapshots/snapshots_importstar.txt","status":"modified","additions":55,"deletions":31,"changes":86,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -1,8 +1,10 @@\n TestExportOtherAsNamespaceCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n // entry.js\n@@ -16,8 +18,10 @@ var ns = __toModule(require_foo());\n TestExportOtherCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n // entry.js\n@@ -31,8 +35,10 @@ var import_foo = __toModule(require_foo());\n TestExportOtherNestedCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n // entry.js\n@@ -64,9 +70,11 @@ __export(exports, {\n   foo: () => foo\n });\n var foo;\n-var init_entry = __esm(() => {\n-  foo = 123;\n-  console.log((init_entry(), exports));\n+var init_entry = __esm({\n+  \"entry.js\"() {\n+    foo = 123;\n+    console.log((init_entry(), exports));\n+  }\n });\n init_entry();\n \n@@ -110,11 +118,11 @@ var foo = 123;\n TestExportSelfCommonJSMinified\n ---------- /out.js ----------\n // entry.js\n-var r = n((t, e) => {\n-  e.exports = {foo: 123};\n-  console.log(r());\n+var l = n((c, r) => {\n+  r.exports = {foo: 123};\n+  console.log(l());\n });\n-module.exports = r();\n+module.exports = l();\n \n ================================================================================\n TestExportSelfES6\n@@ -252,8 +260,10 @@ console.log(internal_default, void 0);\n TestImportExportOtherAsNamespaceCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n // entry.js\n@@ -322,10 +332,12 @@ console.log(value);\n TestImportSelfCommonJS\n ---------- /out.js ----------\n // entry.js\n-var require_entry = __commonJS((exports) => {\n-  var import_entry = __toModule(require_entry());\n-  exports.foo = 123;\n-  console.log(import_entry.foo);\n+var require_entry = __commonJS({\n+  \"entry.js\"(exports) {\n+    var import_entry = __toModule(require_entry());\n+    exports.foo = 123;\n+    console.log(import_entry.foo);\n+  }\n });\n module.exports = require_entry();\n \n@@ -338,8 +350,10 @@ __export(foo_exports, {\n   foo: () => foo\n });\n var foo;\n-var init_foo = __esm(() => {\n-  foo = 123;\n+var init_foo = __esm({\n+  \"foo.js\"() {\n+    foo = 123;\n+  }\n });\n \n // entry.js\n@@ -365,8 +379,10 @@ console.log(foo_exports, foo, foo2);\n TestImportStarCommonJSCapture\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n // entry.js\n@@ -378,8 +394,10 @@ console.log(ns, ns.foo, foo);\n TestImportStarCommonJSNoCapture\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n // entry.js\n@@ -391,8 +409,10 @@ console.log(ns.foo, ns.foo, foo2);\n TestImportStarCommonJSUnused\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n // entry.js\n@@ -619,8 +639,10 @@ console.log(JSON.stringify(folders_exports));\n TestNamespaceImportMissingCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.x = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.x = 123;\n+  }\n });\n \n // entry.js\n@@ -665,8 +687,10 @@ console.log(void 0);\n TestNamespaceImportUnusedMissingCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.x = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.x = 123;\n+  }\n });\n \n // entry.js"},{"sha":"0ff0a4304e0ff42f53133c4c9a1d91043becbea6","filename":"internal/bundler/snapshots/snapshots_importstar_ts.txt","status":"modified","additions":12,"deletions":6,"changes":18,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar_ts.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar_ts.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar_ts.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -6,8 +6,10 @@ __export(foo_exports, {\n   foo: () => foo\n });\n var foo;\n-var init_foo = __esm(() => {\n-  foo = 123;\n+var init_foo = __esm({\n+  \"foo.ts\"() {\n+    foo = 123;\n+  }\n });\n \n // entry.js\n@@ -33,8 +35,10 @@ console.log(foo_exports, foo, foo2);\n TestTSImportStarCommonJSCapture\n ---------- /out.js ----------\n // foo.ts\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_foo = __commonJS({\n+  \"foo.ts\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n // entry.ts\n@@ -46,8 +50,10 @@ console.log(ns, ns.foo, foo);\n TestTSImportStarCommonJSNoCapture\n ---------- /out.js ----------\n // foo.ts\n-var require_foo = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_foo = __commonJS({\n+  \"foo.ts\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n // entry.ts"},{"sha":"8f3d9317756c8ab549203785bf074bce63b00c23","filename":"internal/bundler/snapshots/snapshots_loader.txt","status":"modified","additions":60,"deletions":30,"changes":90,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_loader.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_loader.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_loader.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -1,8 +1,10 @@\n TestAutoDetectMimeTypeFromExtension\n ---------- /out.js ----------\n // test.svg\n-var require_test = __commonJS((exports, module) => {\n-  module.exports = \"data:image/svg+xml;base64,YQBigGP/ZA==\";\n+var require_test = __commonJS({\n+  \"test.svg\"(exports, module) {\n+    module.exports = \"data:image/svg+xml;base64,YQBigGP/ZA==\";\n+  }\n });\n \n // entry.js\n@@ -18,8 +20,10 @@ console.log(/* @__PURE__ */ React.createElement(\"div\", null));\n TestLoaderBase64CommonJSAndES6\n ---------- /out.js ----------\n // x.b64\n-var require_x = __commonJS((exports, module) => {\n-  module.exports = \"eA==\";\n+var require_x = __commonJS({\n+  \"x.b64\"(exports, module) {\n+    module.exports = \"eA==\";\n+  }\n });\n \n // y.b64\n@@ -33,8 +37,10 @@ console.log(x_b64, y_default);\n TestLoaderDataURLCommonJSAndES6\n ---------- /out.js ----------\n // x.txt\n-var require_x = __commonJS((exports, module) => {\n-  module.exports = \"data:text/plain;charset=utf-8;base64,eA==\";\n+var require_x = __commonJS({\n+  \"x.txt\"(exports, module) {\n+    module.exports = \"data:text/plain;charset=utf-8;base64,eA==\";\n+  }\n });\n \n // y.txt\n@@ -50,8 +56,10 @@ TestLoaderFile\n <svg></svg>\n ---------- /out/entry.js ----------\n // test.svg\n-var require_test = __commonJS((exports, module) => {\n-  module.exports = \"./test-IPILGNO5.svg\";\n+var require_test = __commonJS({\n+  \"test.svg\"(exports, module) {\n+    module.exports = \"./test-IPILGNO5.svg\";\n+  }\n });\n \n // entry.js\n@@ -65,8 +73,10 @@ y\n x\n ---------- /out.js ----------\n // x.txt\n-var require_x = __commonJS((exports, module) => {\n-  module.exports = \"./x-LSAMBFUD.txt\";\n+var require_x = __commonJS({\n+  \"x.txt\"(exports, module) {\n+    module.exports = \"./x-LSAMBFUD.txt\";\n+  }\n });\n \n // y.txt\n@@ -82,13 +92,17 @@ TestLoaderFileMultipleNoCollision\n test\n ---------- /dist/out.js ----------\n // a/test.txt\n-var require_test = __commonJS((exports, module) => {\n-  module.exports = \"./test-J7OMUXO3.txt\";\n+var require_test = __commonJS({\n+  \"a/test.txt\"(exports, module) {\n+    module.exports = \"./test-J7OMUXO3.txt\";\n+  }\n });\n \n // b/test.txt\n-var require_test2 = __commonJS((exports, module) => {\n-  module.exports = \"./test-J7OMUXO3.txt\";\n+var require_test2 = __commonJS({\n+  \"b/test.txt\"(exports, module) {\n+    module.exports = \"./test-J7OMUXO3.txt\";\n+  }\n });\n \n // entry.js\n@@ -98,8 +112,10 @@ console.log(require_test(), require_test2());\n TestLoaderJSONCommonJSAndES6\n ---------- /out.js ----------\n // x.json\n-var require_x = __commonJS((exports, module) => {\n-  module.exports = {x: true};\n+var require_x = __commonJS({\n+  \"x.json\"(exports, module) {\n+    module.exports = {x: true};\n+  }\n });\n \n // y.json\n@@ -169,8 +185,10 @@ export {\n TestLoaderJSONNoBundleIIFE\n ---------- /out.js ----------\n (() => {\n-  var require_test = __commonJS((exports, module) => {\n-    module.exports = {test: 123, \"invalid-identifier\": true};\n+  var require_test = __commonJS({\n+    \"test.json\"(exports, module) {\n+      module.exports = {test: 123, \"invalid-identifier\": true};\n+    }\n   });\n   require_test();\n })();\n@@ -197,8 +215,10 @@ console.log(\"b:\", data_default);\n TestLoaderTextCommonJSAndES6\n ---------- /out.js ----------\n // x.txt\n-var require_x = __commonJS((exports, module) => {\n-  module.exports = \"x\";\n+var require_x = __commonJS({\n+  \"x.txt\"(exports, module) {\n+    module.exports = \"x\";\n+  }\n });\n \n // y.txt\n@@ -212,8 +232,10 @@ console.log(x_txt, y_default);\n TestRequireCustomExtensionBase64\n ---------- /out.js ----------\n // test.custom\n-var require_test = __commonJS((exports, module) => {\n-  module.exports = \"YQBigGP/ZA==\";\n+var require_test = __commonJS({\n+  \"test.custom\"(exports, module) {\n+    module.exports = \"YQBigGP/ZA==\";\n+  }\n });\n \n // entry.js\n@@ -223,8 +245,10 @@ console.log(require_test());\n TestRequireCustomExtensionDataURL\n ---------- /out.js ----------\n // test.custom\n-var require_test = __commonJS((exports, module) => {\n-  module.exports = \"data:application/octet-stream;base64,YQBigGP/ZA==\";\n+var require_test = __commonJS({\n+  \"test.custom\"(exports, module) {\n+    module.exports = \"data:application/octet-stream;base64,YQBigGP/ZA==\";\n+  }\n });\n \n // entry.js\n@@ -234,13 +258,17 @@ console.log(require_test());\n TestRequireCustomExtensionPreferLongest\n ---------- /out.js ----------\n // test.txt\n-var require_test = __commonJS((exports, module) => {\n-  module.exports = \"test.txt\";\n+var require_test = __commonJS({\n+  \"test.txt\"(exports, module) {\n+    module.exports = \"test.txt\";\n+  }\n });\n \n // test.base64.txt\n-var require_test_base64 = __commonJS((exports, module) => {\n-  module.exports = \"dGVzdC5iYXNlNjQudHh0\";\n+var require_test_base64 = __commonJS({\n+  \"test.base64.txt\"(exports, module) {\n+    module.exports = \"dGVzdC5iYXNlNjQudHh0\";\n+  }\n });\n \n // entry.js\n@@ -250,8 +278,10 @@ console.log(require_test(), require_test_base64());\n TestRequireCustomExtensionString\n ---------- /out.js ----------\n // test.custom\n-var require_test = __commonJS((exports, module) => {\n-  module.exports = \"#include <stdio.h>\";\n+var require_test = __commonJS({\n+  \"test.custom\"(exports, module) {\n+    module.exports = \"#include <stdio.h>\";\n+  }\n });\n \n // entry.js"},{"sha":"b49d8e7b4e026b89d06a9137514b6efd016880f5","filename":"internal/bundler/snapshots/snapshots_lower.txt","status":"modified","additions":6,"deletions":4,"changes":10,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_lower.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_lower.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_lower.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -119,10 +119,12 @@ class Derived extends Base {\n TestLowerAsyncThis2016CommonJS\n ---------- /out.js ----------\n // entry.js\n-var require_entry = __commonJS((exports) => {\n-  exports.foo = () => __async(exports, null, function* () {\n-    return exports;\n-  });\n+var require_entry = __commonJS({\n+  \"entry.js\"(exports) {\n+    exports.foo = () => __async(exports, null, function* () {\n+      return exports;\n+    });\n+  }\n });\n export default require_entry();\n "},{"sha":"97a9c190b8c1587ab559853004a36ade24d1a8e3","filename":"internal/bundler/snapshots/snapshots_packagejson.txt","status":"modified","additions":162,"deletions":100,"changes":262,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_packagejson.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_packagejson.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_packagejson.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -1,10 +1,12 @@\n TestPackageJsonBadMain\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -33,10 +35,12 @@ console.log(browser2);\n TestPackageJsonBrowserMapAvoidMissing\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/component-indexof/index.js\n-var require_component_indexof = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 234;\n-  };\n+var require_component_indexof = __commonJS({\n+  \"Users/user/project/node_modules/component-indexof/index.js\"(exports, module) {\n+    module.exports = function() {\n+      return 234;\n+    };\n+  }\n });\n \n // Users/user/project/node_modules/component-classes/index.js\n@@ -51,15 +55,19 @@ var index;\n TestPackageJsonBrowserMapModuleDisabled\n ---------- /Users/user/project/out.js ----------\n // (disabled):Users/user/project/node_modules/node-pkg/index.js\n-var require_node_pkg = __commonJS(() => {\n+var require_node_pkg = __commonJS({\n+  \"(disabled):Users/user/project/node_modules/node-pkg/index.js\"() {\n+  }\n });\n \n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports, module) => {\n-  var fn2 = require_node_pkg();\n-  module.exports = function() {\n-    return fn2();\n-  };\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports, module) {\n+    var fn2 = require_node_pkg();\n+    module.exports = function() {\n+      return fn2();\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -70,18 +78,22 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonBrowserMapModuleToModule\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/node-pkg-browser/index.js\n-var require_node_pkg_browser = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_node_pkg_browser = __commonJS({\n+  \"Users/user/project/node_modules/node-pkg-browser/index.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports, module) => {\n-  var fn2 = require_node_pkg_browser();\n-  module.exports = function() {\n-    return fn2();\n-  };\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports, module) {\n+    var fn2 = require_node_pkg_browser();\n+    module.exports = function() {\n+      return fn2();\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -92,18 +104,22 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonBrowserMapModuleToRelative\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/node-pkg-browser.js\n-var require_node_pkg_browser = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_node_pkg_browser = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/node-pkg-browser.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports, module) => {\n-  var fn2 = require_node_pkg_browser();\n-  module.exports = function() {\n-    return fn2();\n-  };\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports, module) {\n+    var fn2 = require_node_pkg_browser();\n+    module.exports = function() {\n+      return fn2();\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -114,15 +130,19 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonBrowserMapNativeModuleDisabled\n ---------- /Users/user/project/out.js ----------\n // (disabled):fs\n-var require_fs = __commonJS(() => {\n+var require_fs = __commonJS({\n+  \"(disabled):fs\"() {\n+  }\n });\n \n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports, module) => {\n-  var fs = require_fs();\n-  module.exports = function() {\n-    return fs.readFile();\n-  };\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports, module) {\n+    var fs = require_fs();\n+    module.exports = function() {\n+      return fs.readFile();\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -133,15 +153,19 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonBrowserMapRelativeDisabled\n ---------- /Users/user/project/out.js ----------\n // (disabled):Users/user/project/node_modules/demo-pkg/util-node\n-var require_util_node = __commonJS(() => {\n+var require_util_node = __commonJS({\n+  \"(disabled):Users/user/project/node_modules/demo-pkg/util-node\"() {\n+  }\n });\n \n // Users/user/project/node_modules/demo-pkg/main.js\n-var require_main = __commonJS((exports, module) => {\n-  var util = require_util_node();\n-  module.exports = function(obj) {\n-    return util.inspect(obj);\n-  };\n+var require_main = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.js\"(exports, module) {\n+    var util = require_util_node();\n+    module.exports = function(obj) {\n+      return util.inspect(obj);\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -152,16 +176,20 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonBrowserMapRelativeToModule\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/util-browser/index.js\n-var require_util_browser = __commonJS((exports, module) => {\n-  module.exports = \"util-browser\";\n+var require_util_browser = __commonJS({\n+  \"Users/user/project/node_modules/util-browser/index.js\"(exports, module) {\n+    module.exports = \"util-browser\";\n+  }\n });\n \n // Users/user/project/node_modules/demo-pkg/main.js\n-var require_main = __commonJS((exports, module) => {\n-  var util = require_util_browser();\n-  module.exports = function() {\n-    return [\"main\", util];\n-  };\n+var require_main = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.js\"(exports, module) {\n+    var util = require_util_browser();\n+    module.exports = function() {\n+      return [\"main\", util];\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -172,16 +200,20 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonBrowserMapRelativeToRelative\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/lib/util-browser.js\n-var require_util_browser = __commonJS((exports, module) => {\n-  module.exports = \"util-browser\";\n+var require_util_browser = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/lib/util-browser.js\"(exports, module) {\n+    module.exports = \"util-browser\";\n+  }\n });\n \n // Users/user/project/node_modules/demo-pkg/main-browser.js\n-var require_main_browser = __commonJS((exports, module) => {\n-  var util = require_util_browser();\n-  module.exports = function() {\n-    return [\"main-browser\", util];\n-  };\n+var require_main_browser = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main-browser.js\"(exports, module) {\n+    var util = require_util_browser();\n+    module.exports = function() {\n+      return [\"main-browser\", util];\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -246,10 +278,12 @@ console.log(browser2);\n TestPackageJsonBrowserOverMainNode\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/main.js\n-var require_main = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_main = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -260,10 +294,12 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonBrowserOverModuleBrowser\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/main.browser.js\n-var require_main_browser = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_main_browser = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.browser.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -274,10 +310,12 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonBrowserString\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/browser.js\n-var require_browser = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_browser = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/browser.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -288,10 +326,12 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonBrowserWithMainNode\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/main.js\n-var require_main = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_main = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -313,8 +353,10 @@ console.log(main_browser_esm_default());\n TestPackageJsonDualPackageHazardImportAndRequireBrowser\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/main.browser.js\n-var require_main_browser = __commonJS((exports, module) => {\n-  module.exports = \"browser main\";\n+var require_main_browser = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.browser.js\"(exports, module) {\n+    module.exports = \"browser main\";\n+  }\n });\n \n // Users/user/project/src/test-main.js\n@@ -333,8 +375,10 @@ __export(module_exports, {\n   default: () => module_default\n });\n var module_default;\n-var init_module = __esm(() => {\n-  module_default = \"module\";\n+var init_module = __esm({\n+  \"Users/user/project/node_modules/demo-pkg/module.js\"() {\n+    module_default = \"module\";\n+  }\n });\n \n // Users/user/project/src/test-main.js\n@@ -348,8 +392,10 @@ console.log(module_default);\n TestPackageJsonDualPackageHazardImportAndRequireImplicitMain\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports, module) => {\n-  module.exports = \"index\";\n+var require_demo_pkg = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/index.js\"(exports, module) {\n+    module.exports = \"index\";\n+  }\n });\n \n // Users/user/project/src/test-index.js\n@@ -368,8 +414,10 @@ __export(module_exports, {\n   default: () => module_default\n });\n var module_default;\n-var init_module = __esm(() => {\n-  module_default = \"module\";\n+var init_module = __esm({\n+  \"Users/user/project/node_modules/demo-pkg/module.js\"() {\n+    module_default = \"module\";\n+  }\n });\n \n // Users/user/project/src/test-index.js\n@@ -383,8 +431,10 @@ console.log(module_default);\n TestPackageJsonDualPackageHazardImportAndRequireSameFile\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/main.js\n-var require_main = __commonJS((exports, module) => {\n-  module.exports = \"main\";\n+var require_main = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.js\"(exports, module) {\n+    module.exports = \"main\";\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -395,8 +445,10 @@ console.log(import_demo_pkg.default, require_main());\n TestPackageJsonDualPackageHazardImportAndRequireSeparateFiles\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/main.js\n-var require_main = __commonJS((exports, module) => {\n-  module.exports = \"main\";\n+var require_main = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.js\"(exports, module) {\n+    module.exports = \"main\";\n+  }\n });\n \n // Users/user/project/src/test-main.js\n@@ -419,8 +471,10 @@ console.log(module_default);\n TestPackageJsonDualPackageHazardRequireOnly\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/main.js\n-var require_main = __commonJS((exports, module) => {\n-  module.exports = \"main\";\n+var require_main = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.js\"(exports, module) {\n+    module.exports = \"main\";\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -481,8 +535,10 @@ console.log(\"SUCCESS\");\n TestPackageJsonExportsRequireOverImport\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/pkg/require.js\n-var require_require = __commonJS(() => {\n-  console.log(\"SUCCESS\");\n+var require_require = __commonJS({\n+  \"Users/user/project/node_modules/pkg/require.js\"() {\n+    console.log(\"SUCCESS\");\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -492,10 +548,12 @@ require_require();\n TestPackageJsonMain\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/custom-main.js\n-var require_custom_main = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_custom_main = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/custom-main.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -506,8 +564,10 @@ console.log((0, import_demo_pkg.default)());\n TestPackageJsonMainFieldsA\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/a.js\n-var require_a = __commonJS((exports, module) => {\n-  module.exports = \"a\";\n+var require_a = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/a.js\"(exports, module) {\n+    module.exports = \"a\";\n+  }\n });\n \n // Users/user/project/src/entry.js\n@@ -538,10 +598,12 @@ console.log(main_esm_default());\n TestPackageJsonNeutralExplicitMainFields\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/main.js\n-var require_main = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_main = __commonJS({\n+  \"Users/user/project/node_modules/demo-pkg/main.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/entry.js"},{"sha":"a88f26ff5563ec631c76f6c866685bfe8f603c85","filename":"internal/bundler/snapshots/snapshots_splitting.txt","status":"modified","additions":28,"deletions":20,"changes":48,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_splitting.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_splitting.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_splitting.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -205,22 +205,24 @@ TestSplittingDynamicAndNotDynamicCommonJSIntoES6\n import {\n   __toModule,\n   require_foo\n-} from \"./chunk-DOF77JFX.js\";\n+} from \"./chunk-NCSI7JR5.js\";\n \n // entry.js\n var import_foo = __toModule(require_foo());\n-import(\"./foo-RHEBPILD.js\").then(({default: {bar: b}}) => console.log(import_foo.bar, b));\n+import(\"./foo-UF4SFHDB.js\").then(({default: {bar: b}}) => console.log(import_foo.bar, b));\n \n----------- /out/foo-RHEBPILD.js ----------\n+---------- /out/foo-UF4SFHDB.js ----------\n import {\n   require_foo\n-} from \"./chunk-DOF77JFX.js\";\n+} from \"./chunk-NCSI7JR5.js\";\n export default require_foo();\n \n----------- /out/chunk-DOF77JFX.js ----------\n+---------- /out/chunk-NCSI7JR5.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.bar = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.bar = 123;\n+  }\n });\n \n export {\n@@ -258,12 +260,14 @@ export {\n TestSplittingDynamicCommonJSIntoES6\n ---------- /out/entry.js ----------\n // entry.js\n-import(\"./foo-BQWGKGO4.js\").then(({default: {bar}}) => console.log(bar));\n+import(\"./foo-B5AKBR53.js\").then(({default: {bar}}) => console.log(bar));\n \n----------- /out/foo-BQWGKGO4.js ----------\n+---------- /out/foo-B5AKBR53.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  exports.bar = 123;\n+var require_foo = __commonJS({\n+  \"foo.js\"(exports) {\n+    exports.bar = 123;\n+  }\n });\n export default require_foo();\n \n@@ -313,7 +317,7 @@ TestSplittingHybridESMAndCJSIssue617\n import {\n   foo,\n   init_a\n-} from \"./chunk-XSW6IF3B.js\";\n+} from \"./chunk-LGBOX6O3.js\";\n init_a();\n export {\n   foo\n@@ -323,22 +327,24 @@ export {\n import {\n   a_exports,\n   init_a\n-} from \"./chunk-XSW6IF3B.js\";\n+} from \"./chunk-LGBOX6O3.js\";\n \n // b.js\n var bar = (init_a(), a_exports);\n export {\n   bar\n };\n \n----------- /out/chunk-XSW6IF3B.js ----------\n+---------- /out/chunk-LGBOX6O3.js ----------\n // a.js\n var a_exports = {};\n __export(a_exports, {\n   foo: () => foo\n });\n var foo;\n-var init_a = __esm(() => {\n+var init_a = __esm({\n+  \"a.js\"() {\n+  }\n });\n \n export {\n@@ -479,7 +485,7 @@ TestSplittingSharedCommonJSIntoES6\n ---------- /out/a.js ----------\n import {\n   require_shared\n-} from \"./chunk-JWGRGYBR.js\";\n+} from \"./chunk-WD5UYFOD.js\";\n \n // a.js\n var {foo} = require_shared();\n@@ -488,16 +494,18 @@ console.log(foo);\n ---------- /out/b.js ----------\n import {\n   require_shared\n-} from \"./chunk-JWGRGYBR.js\";\n+} from \"./chunk-WD5UYFOD.js\";\n \n // b.js\n var {foo} = require_shared();\n console.log(foo);\n \n----------- /out/chunk-JWGRGYBR.js ----------\n+---------- /out/chunk-WD5UYFOD.js ----------\n // shared.js\n-var require_shared = __commonJS((exports) => {\n-  exports.foo = 123;\n+var require_shared = __commonJS({\n+  \"shared.js\"(exports) {\n+    exports.foo = 123;\n+  }\n });\n \n export {"},{"sha":"389915a21ec30bb12815404a2f531a2f21568f26","filename":"internal/bundler/snapshots/snapshots_ts.txt","status":"modified","additions":6,"deletions":4,"changes":10,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_ts.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_ts.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_ts.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -195,10 +195,12 @@ export {\n TestTSExportEquals\n ---------- /out.js ----------\n // b.ts\n-var require_b = __commonJS((exports, module) => {\n-  function foo() {\n+var require_b = __commonJS({\n+  \"b.ts\"(exports, module) {\n+    function foo() {\n+    }\n+    module.exports = [123, foo];\n   }\n-  module.exports = [123, foo];\n });\n \n // a.ts\n@@ -301,7 +303,7 @@ console.log(a, b, c, d, e, real);\n ================================================================================\n TestTSMinifiedBundleCommonJS\n ---------- /out.js ----------\n-var n=e(r=>{r.foo=function(){return 123}});var u=e((j,t)=>{t.exports={test:!0}});var{foo:c}=n();console.log(c(),u());\n+var t=r(n=>{n.foo=function(){return 123}});var s=r((l,u)=>{u.exports={test:!0}});var{foo:c}=t();console.log(c(),s());\n \n ================================================================================\n TestTSMinifiedBundleES6"},{"sha":"ea1ada0b7ba6df1cc86b0c4c2c2b6d44e01385bb","filename":"internal/bundler/snapshots/snapshots_tsconfig.txt","status":"modified","additions":30,"deletions":20,"changes":50,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_tsconfig.txt","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fbundler%2Fsnapshots%2Fsnapshots_tsconfig.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_tsconfig.txt?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -1,10 +1,12 @@\n TestJsconfigJsonBaseUrl\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/src/lib/util.js\n-var require_util = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_util = __commonJS({\n+  \"Users/user/project/src/lib/util.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/app/entry.js\n@@ -200,10 +202,12 @@ console.log(test_default);\n TestTsconfigJsonAbsoluteBaseUrl\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/src/lib/util.js\n-var require_util = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_util = __commonJS({\n+  \"Users/user/project/src/lib/util.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/app/entry.js\n@@ -214,10 +218,12 @@ console.log((0, import_util.default)());\n TestTsconfigJsonBaseUrl\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/src/lib/util.js\n-var require_util = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_util = __commonJS({\n+  \"Users/user/project/src/lib/util.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/app/entry.js\n@@ -228,10 +234,12 @@ console.log((0, import_util.default)());\n TestTsconfigJsonCommentAllowed\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/src/lib/util.js\n-var require_util = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_util = __commonJS({\n+  \"Users/user/project/src/lib/util.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/app/entry.js\n@@ -293,10 +301,12 @@ console.log(\"good\");\n TestTsconfigJsonTrailingCommaAllowed\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/src/lib/util.js\n-var require_util = __commonJS((exports, module) => {\n-  module.exports = function() {\n-    return 123;\n-  };\n+var require_util = __commonJS({\n+  \"Users/user/project/src/lib/util.js\"(exports, module) {\n+    module.exports = function() {\n+      return 123;\n+    };\n+  }\n });\n \n // Users/user/project/src/app/entry.js"},{"sha":"29f20a81b76a19a274f1679e04b431cbd8f6c373","filename":"internal/config/config.go","status":"modified","additions":1,"deletions":0,"changes":1,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fconfig%2Fconfig.go","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fconfig%2Fconfig.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fconfig%2Fconfig.go?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -202,6 +202,7 @@ type Options struct {\n \tRemoveWhitespace  bool\n \tMinifyIdentifiers bool\n \tMangleSyntax      bool\n+\tProfilerNames     bool\n \tCodeSplitting     bool\n \tWatchMode         bool\n \tAllowOverwrite    bool"},{"sha":"8c0cabc07964e2ee6318b6b962ee92881866f896","filename":"internal/runtime/runtime.go","status":"modified","additions":16,"deletions":4,"changes":20,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fruntime%2Fruntime.go","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/internal%2Fruntime%2Fruntime.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fruntime%2Fruntime.go?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -141,11 +141,23 @@ func code(isES6 bool) string {\n \t\t\treturn target\n \t\t}\n \n-\t\t// This is for lazily-initialized ESM code\n-\t\texport var __esm = (fn, res) => () => (fn && (res = fn(fn = 0)), res)\n+\t\t// This is for lazily-initialized ESM code. This has two implementations, a\n+\t\t// compact one for minified code and a verbose one that generates friendly\n+\t\t// names in V8's profiler and in stack traces.\n+\t\texport var __esm = __profiler\n+\t\t\t&& ((fn, res) => function __init() {\n+\t\t\t\treturn fn && (res = (0, fn[Object.keys(fn)[0]])(fn = 0)), res\n+\t\t\t})\n+\t\t\t|| ((fn, res) => () => (fn && (res = fn(fn = 0)), res))\n \n-\t\t// Wraps a CommonJS closure and returns a require() function\n-\t\texport var __commonJS = (cb, mod) => () => (mod || cb((mod = {exports: {}}).exports, mod), mod.exports)\n+\t\t// Wraps a CommonJS closure and returns a require() function. This has two\n+\t\t// implementations, a compact one for minified code and a verbose one that\n+\t\t// generates friendly names in V8's profiler and in stack traces.\n+\t\texport var __commonJS = __profiler\n+\t\t\t&& ((cb, mod) => function __require() {\n+\t\t\t\treturn mod || (0, cb[Object.keys(cb)[0]])((mod = {exports: {}}).exports, mod), mod.exports\n+\t\t\t})\n+\t\t\t|| ((cb, mod) => () => (mod || cb((mod = {exports: {}}).exports, mod), mod.exports))\n \n \t\t// Used to implement ES6 exports to CommonJS\n \t\texport var __export = (target, all) => {"},{"sha":"1517065082dfeba40aa7080717eace2be0301d42","filename":"scripts/end-to-end-tests.js","status":"modified","additions":53,"deletions":0,"changes":53,"blob_url":"https://github.com/evanw/esbuild/blob/e0484fdcce24c0206d8ff7073a3dca160d99241a/scripts%2Fend-to-end-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/e0484fdcce24c0206d8ff7073a3dca160d99241a/scripts%2Fend-to-end-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fend-to-end-tests.js?ref=e0484fdcce24c0206d8ff7073a3dca160d99241a","patch":"@@ -1597,6 +1597,59 @@\n     }),\n   )\n \n+  // Check for file names of wrapped modules in non-minified stack traces (for profiling)\n+  // Context: https://github.com/evanw/esbuild/pull/1236\n+  tests.push(\n+    test(['entry.js', '--outfile=node.js', '--bundle'], {\n+      'entry.js': `\n+        try {\n+          require('./src/a')\n+        } catch (e) {\n+          if (!e.stack.includes('at __require') || !e.stack.includes('at src/a.ts') || !e.stack.includes('at src/b.ts'))\n+            throw new Error(e.stack)\n+        }\n+      `,\n+      'src/a.ts': `require('./b')`,\n+      'src/b.ts': `throw new Error('fail')`,\n+    }),\n+    test(['entry.js', '--outfile=node.js', '--bundle', '--minify-identifiers'], {\n+      'entry.js': `\n+        try {\n+          require('./src/a')\n+        } catch (e) {\n+          if (e.stack.includes('at __require') || e.stack.includes('at src/a.ts') || e.stack.includes('at src/b.ts'))\n+            throw new Error(e.stack)\n+        }\n+      `,\n+      'src/a.ts': `require('./b')`,\n+      'src/b.ts': `throw new Error('fail')`,\n+    }),\n+    test(['entry.js', '--outfile=node.js', '--bundle'], {\n+      'entry.js': `\n+        try {\n+          require('./src/a')\n+        } catch (e) {\n+          if (!e.stack.includes('at __init') || !e.stack.includes('at src/a.ts') || !e.stack.includes('at src/b.ts'))\n+            throw new Error(e.stack)\n+        }\n+      `,\n+      'src/a.ts': `export let esm = true; require('./b')`,\n+      'src/b.ts': `export let esm = true; throw new Error('fail')`,\n+    }),\n+    test(['entry.js', '--outfile=node.js', '--bundle', '--minify-identifiers'], {\n+      'entry.js': `\n+        try {\n+          require('./src/a')\n+        } catch (e) {\n+          if (e.stack.includes('at __init') || e.stack.includes('at src/a.ts') || e.stack.includes('at src/b.ts'))\n+            throw new Error(e.stack)\n+        }\n+      `,\n+      'src/a.ts': `export let esm = true; require('./b')`,\n+      'src/b.ts': `export let esm = true; throw new Error('fail')`,\n+    }),\n+  )\n+\n   // This shouldn't crash\n   // https://github.com/evanw/esbuild/issues/1080\n   tests.push("}]},{"url":"https://api.github.com/repos/evanw/esbuild/issues/1078","repository_url":"https://api.github.com/repos/evanw/esbuild","labels_url":"https://api.github.com/repos/evanw/esbuild/issues/1078/labels{/name}","comments_url":"https://api.github.com/repos/evanw/esbuild/issues/1078/comments","events_url":"https://api.github.com/repos/evanw/esbuild/issues/1078/events","html_url":"https://github.com/evanw/esbuild/pull/1078","id":842854575,"node_id":"MDExOlB1bGxSZXF1ZXN0NjAyMzI3Mzc0","number":1078,"title":"PR for version 0.11.0","user":{"login":"evanw","id":406394,"node_id":"MDQ6VXNlcjQwNjM5NA==","avatar_url":"https://avatars.githubusercontent.com/u/406394?v=4","gravatar_id":"","url":"https://api.github.com/users/evanw","html_url":"https://github.com/evanw","followers_url":"https://api.github.com/users/evanw/followers","following_url":"https://api.github.com/users/evanw/following{/other_user}","gists_url":"https://api.github.com/users/evanw/gists{/gist_id}","starred_url":"https://api.github.com/users/evanw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/evanw/subscriptions","organizations_url":"https://api.github.com/users/evanw/orgs","repos_url":"https://api.github.com/users/evanw/repos","events_url":"https://api.github.com/users/evanw/events{/privacy}","received_events_url":"https://api.github.com/users/evanw/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-03-28T23:12:40Z","updated_at":"2021-03-29T04:25:29Z","closed_at":"2021-03-29T02:34:50Z","author_association":"OWNER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/evanw/esbuild/pulls/1078","html_url":"https://github.com/evanw/esbuild/pull/1078","diff_url":"https://github.com/evanw/esbuild/pull/1078.diff","patch_url":"https://github.com/evanw/esbuild/pull/1078.patch","merged_at":"2021-03-29T02:34:49Z"},"body":"This is a PR for version 0.11.0, which is a release that contains the following breaking changes:\r\n\r\n* Change how `require()` and `import()` of ESM works (fixes #667, fixes #706)\r\n\r\n    Previously if you call `require()` on an ESM file, or call `import()` on an ESM file with code splitting disabled, esbuild would convert the ESM file to CommonJS. For example, if you had the following input files:\r\n\r\n    ```js\r\n    // cjs-file.js\r\n    console.log(require('./esm-file.js').foo)\r\n    // esm-file.js\r\n    export let foo = bar()\r\n    ```\r\n\r\n    The previous bundling behavior would generate something like this:\r\n\r\n    ```js\r\n    var require_esm_file = __commonJS((exports) => {\r\n      __markAsModule(exports);\r\n      __export(exports, {\r\n        foo: () => foo\r\n      });\r\n      var foo = bar();\r\n    });\r\n    console.log(require_esm_file().foo);\r\n    ```\r\n\r\n    This behavior has been changed and esbuild now generates something like this instead:\r\n\r\n    ```js\r\n    var esm_file_exports = {};\r\n    __export(esm_file_exports, {\r\n      foo: () => foo\r\n    });\r\n    var foo;\r\n    var init_esm_file = __esm(() => {\r\n      foo = bar();\r\n    });\r\n    console.log((init_esm_file(), esm_file_exports).foo);\r\n    ```\r\n\r\n    The variables have been pulled out of the lazily-initialized closure and are accessible to the rest of the module's scope. Some benefits of this approach:\r\n\r\n    * If another file does `import {foo} from \"./esm-file.js\"`, it will just reference `foo` directly and will not pay the performance penalty or code size overhead of the dynamic property accesses that come with CommonJS-style exports. So this improves performance and reduces code size in some cases.\r\n\r\n    * This fixes a long-standing bug (#706) where entry point exports could be broken if the entry point is a target of a `require()` call and the output format was ESM. This happened because previously calling `require()` on an entry point converted it to CommonJS, which then meant it only had a single `default` export, and the exported variables were inside the CommonJS closure and inaccessible to an ESM-style `export {}` clause. Now calling `require()` on an entry point only causes it to be lazily-initialized but all exports are still in the module scope and can still be exported using a normal `export {}` clause.\r\n\r\n    * Now that this has been changed, `import()` of a module with top-level await (#253) is now allowed when code splitting is disabled. Previously this didn't work because `import()` with code splitting disabled was implemented by converting the module to CommonJS and using `Promise.resolve().then(() => require())`, but converting a module with top-level await to CommonJS is impossible because the CommonJS call signature must be synchronous. Now that this implemented using lazy initialization instead of CommonJS conversion, the closure wrapping the ESM file can now be `async` and the `import()` expression can be replaced by a call to the lazy initializer.\r\n\r\n    * Adding the ability for ESM files to be lazily-initialized is an important step toward additional future code splitting improvements including: manual chunk names (#207), correct import evaluation order (#399), and correct top-level await evaluation order (#253). These features all need to make use of deferred evaluation of ESM code.\r\n\r\n    In addition, calling `require()` on an ESM file now recursively wraps all transitive dependencies of that file instead of just wrapping that ESM file itself. This is an increase in the size of the generated code, but it is important for correctness (#667). Calling `require()` on a module means its evaluation order is determined at run-time, which means the evaluation order of all dependencies must also be determined at run-time. If you don't want the increase in code size, you should use an `import` statement instead of a `require()` call.\r\n\r\n* Dynamic imports now use chunk names instead of entry names (fixes #1056)\r\n\r\n    Previously the output paths of dynamic imports (files imported using the `import()` syntax) were determined by the `--entry-names=` setting. However, this can cause problems if you configure the `--entry-names=` setting to omit both `[dir]` and `[hash]` because then two dynamic imports with the same name will cause an output file name collision.\r\n\r\n    Now dynamic imports use the `--chunk-names=` setting instead, which is used for automatically-generated chunks. This setting is effectively required to include `[hash]` so dynamic import name collisions should now be avoided.\r\n\r\n    In addition, dynamic imports no longer affect the automatically-computed default value of `outbase`. By default `outbase` is computed to be the [lowest common ancestor](https://en.wikipedia.org/wiki/Lowest_common_ancestor) directory of all entry points. Previously dynamic imports were considered entry points in this calculation so adding a dynamic entry point could unexpectedly affect entry point output file paths. This issue has now been fixed.\r\n\r\n* Allow custom output paths for individual entry points\r\n\r\n    By default, esbuild will automatically generate an output path for each entry point by computing the relative path from the `outbase` directory to the entry point path, and then joining that relative path to the `outdir` directory. The output path can be customized using `outpath`, but that only works for a single file. Sometimes you may need custom output paths while using multiple entry points. You can now do this by passing the entry points as a map instead of an array:\r\n\r\n    * CLI\r\n        ```\r\n        esbuild out1=in1.js out2=in2.js --outdir=out\r\n        ```\r\n\r\n    * JS\r\n        ```js\r\n        esbuild.build({\r\n          entryPoints: {\r\n            out1: 'in1.js',\r\n            out2: 'in2.js',\r\n          },\r\n          outdir: 'out',\r\n        })\r\n        ```\r\n\r\n    * Go\r\n\r\n        ```go\r\n        api.Build(api.BuildOptions{\r\n          EntryPointsAdvanced: []api.EntryPoint{{\r\n            OutputPath: \"out1\",\r\n            InputPath: \"in1.js\",\r\n          }, {\r\n            OutputPath: \"out2\",\r\n            InputPath: \"in2.js\",\r\n          }},\r\n          Outdir: \"out\",\r\n        })\r\n        ```\r\n\r\n    This will cause esbuild to generate the files `out/out1.js` and `out/out2.js` inside the output directory. These custom output paths are used as input for the `--entry-names=` path template setting, so you can use something like `--entry-names=[dir]/[name]-[hash]` to add an automatically-computed hash to each entry point while still using the custom output path.\r\n\r\n* Derive entry point output paths from the original input (fixes #945)\r\n\r\n    Previously esbuild would determine the output path for an entry point by looking at the post-resolved path. For example, running `esbuild --bundle react --outdir=out` would generate the output path `out/index.js` because the input path `react` was resolved to `node_modules/react/index.js`. With this release, the output path is now determined by looking at the pre-resolved path. For example, running `esbuild --bundle react --outdir=out` now generates the output path `out/react.js`. If you need to keep using the output path that esbuild previously generated with the old behavior, you can use the custom output path feature (described above).\r\n\r\n* Use the `file` namespace for file entry points (fixes #791)\r\n\r\n    Plugins that contain an `onResolve` callback with the `file` filter don't apply to entry point paths because it's not clear that entry point paths are files. For example, you could potentially bundle an entry point of `https://www.example.com/file.js` with a HTTP plugin that automatically downloads data from the server at that URL. But this behavior can be unexpected for people writing plugins.\r\n\r\n    With this release, esbuild will do a quick check first to see if the entry point path exists on the file system before running plugins. If it exists as a file, the namespace will now be `file` for that entry point path. This only checks the exact entry point name and doesn't attempt to search for the file, so for example it won't handle cases where you pass a package path as an entry point or where you pass an entry point without an extension. Hopefully this should help improve this situation in the common case where the entry point is an exact path.\r\n","reactions":{"url":"https://api.github.com/repos/evanw/esbuild/issues/1078/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":1,"eyes":0},"timeline_url":"https://api.github.com/repos/evanw/esbuild/issues/1078/timeline","performed_via_github_app":null,"state_reason":null,"score":1,"files":[{"sha":"8a7710e73d0bc71ee6d0e60d36a41ed370e1a66b","filename":"CHANGELOG.md","status":"modified","additions":108,"deletions":0,"changes":108,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/CHANGELOG.md","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/CHANGELOG.md","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/CHANGELOG.md?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -1,5 +1,113 @@\n # Changelog\n \n+## Breaking Changes\n+\n+* Change how `require()` and `import()` of ESM works ([#667](https://github.com/evanw/esbuild/issues/667), [#706](https://github.com/evanw/esbuild/issues/706))\n+\n+    Previously if you call `require()` on an ESM file, or call `import()` on an ESM file with code splitting disabled, esbuild would convert the ESM file to CommonJS. For example, if you had the following input files:\n+\n+    ```js\n+    // cjs-file.js\n+    console.log(require('./esm-file.js').foo)\n+\n+    // esm-file.js\n+    export let foo = bar()\n+    ```\n+\n+    The previous bundling behavior would generate something like this:\n+\n+    ```js\n+    var require_esm_file = __commonJS((exports) => {\n+      __markAsModule(exports);\n+      __export(exports, {\n+        foo: () => foo\n+      });\n+      var foo = bar();\n+    });\n+    console.log(require_esm_file().foo);\n+    ```\n+\n+    This behavior has been changed and esbuild now generates something like this instead:\n+\n+    ```js\n+    var esm_file_exports = {};\n+    __export(esm_file_exports, {\n+      foo: () => foo\n+    });\n+    var foo;\n+    var init_esm_file = __esm(() => {\n+      foo = bar();\n+    });\n+    console.log((init_esm_file(), esm_file_exports).foo);\n+    ```\n+\n+    The variables have been pulled out of the lazily-initialized closure and are accessible to the rest of the module's scope. Some benefits of this approach:\n+\n+    * If another file does `import {foo} from \"./esm-file.js\"`, it will just reference `foo` directly and will not pay the performance penalty or code size overhead of the dynamic property accesses that come with CommonJS-style exports. So this improves performance and reduces code size in some cases.\n+\n+    * This fixes a long-standing bug ([#706](https://github.com/evanw/esbuild/issues/706)) where entry point exports could be broken if the entry point is a target of a `require()` call and the output format was ESM. This happened because previously calling `require()` on an entry point converted it to CommonJS, which then meant it only had a single `default` export, and the exported variables were inside the CommonJS closure and inaccessible to an ESM-style `export {}` clause. Now calling `require()` on an entry point only causes it to be lazily-initialized but all exports are still in the module scope and can still be exported using a normal `export {}` clause.\n+\n+    * Now that this has been changed, `import()` of a module with top-level await ([#253](https://github.com/evanw/esbuild/issues/253)) is now allowed when code splitting is disabled. Previously this didn't work because `import()` with code splitting disabled was implemented by converting the module to CommonJS and using `Promise.resolve().then(() => require())`, but converting a module with top-level await to CommonJS is impossible because the CommonJS call signature must be synchronous. Now that this implemented using lazy initialization instead of CommonJS conversion, the closure wrapping the ESM file can now be `async` and the `import()` expression can be replaced by a call to the lazy initializer.\n+\n+    * Adding the ability for ESM files to be lazily-initialized is an important step toward additional future code splitting improvements including: manual chunk names ([#207](https://github.com/evanw/esbuild/issues/207)), correct import evaluation order ([#399](https://github.com/evanw/esbuild/issues/399)), and correct top-level await evaluation order ([#253](https://github.com/evanw/esbuild/issues/253)). These features all need to make use of deferred evaluation of ESM code.\n+\n+    In addition, calling `require()` on an ESM file now recursively wraps all transitive dependencies of that file instead of just wrapping that ESM file itself. This is an increase in the size of the generated code, but it is important for correctness ([#667](https://github.com/evanw/esbuild/issues/667)). Calling `require()` on a module means its evaluation order is determined at run-time, which means the evaluation order of all dependencies must also be determined at run-time. If you don't want the increase in code size, you should use an `import` statement instead of a `require()` call.\n+\n+* Dynamic imports now use chunk names instead of entry names ([#1056](https://github.com/evanw/esbuild/issues/1056))\n+\n+    Previously the output paths of dynamic imports (files imported using the `import()` syntax) were determined by the `--entry-names=` setting. However, this can cause problems if you configure the `--entry-names=` setting to omit both `[dir]` and `[hash]` because then two dynamic imports with the same name will cause an output file name collision.\n+\n+    Now dynamic imports use the `--chunk-names=` setting instead, which is used for automatically-generated chunks. This setting is effectively required to include `[hash]` so dynamic import name collisions should now be avoided.\n+\n+    In addition, dynamic imports no longer affect the automatically-computed default value of `outbase`. By default `outbase` is computed to be the [lowest common ancestor](https://en.wikipedia.org/wiki/Lowest_common_ancestor) directory of all entry points. Previously dynamic imports were considered entry points in this calculation so adding a dynamic entry point could unexpectedly affect entry point output file paths. This issue has now been fixed.\n+\n+* Allow custom output paths for individual entry points\n+\n+    By default, esbuild will automatically generate an output path for each entry point by computing the relative path from the `outbase` directory to the entry point path, and then joining that relative path to the `outdir` directory. The output path can be customized using `outpath`, but that only works for a single file. Sometimes you may need custom output paths while using multiple entry points. You can now do this by passing the entry points as a map instead of an array:\n+\n+    * CLI\n+        ```\n+        esbuild out1=in1.js out2=in2.js --outdir=out\n+        ```\n+\n+    * JS\n+        ```js\n+        esbuild.build({\n+          entryPoints: {\n+            out1: 'in1.js',\n+            out2: 'in2.js',\n+          },\n+          outdir: 'out',\n+        })\n+        ```\n+\n+    * Go\n+\n+        ```go\n+        api.Build(api.BuildOptions{\n+          EntryPointsAdvanced: []api.EntryPoint{{\n+            OutputPath: \"out1\",\n+            InputPath: \"in1.js\",\n+          }, {\n+            OutputPath: \"out2\",\n+            InputPath: \"in2.js\",\n+          }},\n+          Outdir: \"out\",\n+        })\n+        ```\n+\n+    This will cause esbuild to generate the files `out/out1.js` and `out/out2.js` inside the output directory. These custom output paths are used as input for the `--entry-names=` path template setting, so you can use something like `--entry-names=[dir]/[name]-[hash]` to add an automatically-computed hash to each entry point while still using the custom output path.\n+\n+* Derive entry point output paths from the original input ([#945](https://github.com/evanw/esbuild/issues/945))\n+\n+    Previously esbuild would determine the output path for an entry point by looking at the post-resolved path. For example, running `esbuild --bundle react --outdir=out` would generate the output path `out/index.js` because the input path `react` was resolved to `node_modules/react/index.js`. With this release, the output path is now determined by looking at the pre-resolved path. For example, For example, running `esbuild --bundle react --outdir=out` now generates the output path `out/react.js`. If you need to keep using the output path that esbuild previously generated with the old behavior, you can use the custom output path feature (described above).\n+\n+* Use the `file` namespace for file entry points ([#791](https://github.com/evanw/esbuild/issues/791))\n+\n+    Plugins that contain an `onResolve` callback with the `file` filter don't apply to entry point paths because it's not clear that entry point paths are files. For example, you could potentially bundle an entry point of `https://www.example.com/file.js` with a HTTP plugin that automatically downloads data from the server at that URL. But this behavior can be unexpected for people writing plugins.\n+\n+    With this release, esbuild will do a quick check first to see if the entry point path exists on the file system before running plugins. If it exists as a file, the namespace will now be `file` for that entry point path. This only checks the exact entry point name and doesn't attempt to search for the file, so for example it won't handle cases where you pass a package path as an entry point or where you pass an entry point without an extension. Hopefully this should help improve this situation in the common case where the entry point is an exact path.\n+\n ## Unreleased\n \n * Warn about mutation of private methods ([#1067](https://github.com/evanw/esbuild/pull/1067))"},{"sha":"99c68cbb243ce929922ae499edc1f15642be4409","filename":"cmd/esbuild/service.go","status":"modified","additions":11,"deletions":0,"changes":11,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/cmd%2Fesbuild%2Fservice.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/cmd%2Fesbuild%2Fservice.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/cmd%2Fesbuild%2Fservice.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -352,12 +352,23 @@ func (service *serviceType) handleBuildRequest(id uint32, request map[string]int\n \tincremental := request[\"incremental\"].(bool)\n \thasOnRebuild := request[\"hasOnRebuild\"].(bool)\n \tserveObj, isServe := request[\"serve\"].(interface{})\n+\tentries := request[\"entries\"].([]interface{})\n \tflags := decodeStringArray(request[\"flags\"].([]interface{}))\n \n \toptions, err := cli.ParseBuildOptions(flags)\n \toptions.AbsWorkingDir = request[\"absWorkingDir\"].(string)\n \toptions.NodePaths = decodeStringArray(request[\"nodePaths\"].([]interface{}))\n \n+\tfor _, entry := range entries {\n+\t\tentry := entry.([]interface{})\n+\t\tkey := entry[0].(string)\n+\t\tvalue := entry[1].(string)\n+\t\toptions.EntryPointsAdvanced = append(options.EntryPointsAdvanced, api.EntryPoint{\n+\t\t\tOutputPath: key,\n+\t\t\tInputPath:  value,\n+\t\t})\n+\t}\n+\n \t// Normally when \"write\" is true and there is no output file/directory then\n \t// the output is written to stdout instead. However, we're currently using\n \t// stdout as a communication channel and writing the build output to stdout"},{"sha":"44e5a4f869355dc390ce50f564e7804810c98977","filename":"internal/bundler/bundler.go","status":"modified","additions":291,"deletions":147,"changes":438,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fbundler.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fbundler.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -32,6 +32,14 @@ import (\n \t\"github.com/evanw/esbuild/internal/sourcemap\"\n )\n \n+type entryPointKind uint8\n+\n+const (\n+\tentryPointNone entryPointKind = iota\n+\tentryPointUserSpecified\n+\tentryPointDynamicImport\n+)\n+\n type file struct {\n \tsource     logger.Source\n \trepr       fileRepr\n@@ -52,16 +60,20 @@ type file struct {\n \t// fully assembled later.\n \tjsonMetadataChunk string\n \n-\t// If \"isEntryPoint\" is true, this is the index of the corresponding entry\n-\t// point chunk.\n+\t// If \"entryPointKind\" is not \"entryPointNone\", this is the index of the\n+\t// corresponding entry point chunk.\n \tentryPointChunkIndex uint32\n \n \t// If this file ends up being used in the bundle, these are additional files\n \t// that must be written to the output directory. It's used by the \"file\"\n \t// loader.\n \tadditionalFiles []OutputFile\n \n-\tisEntryPoint bool\n+\t// This file is an entry point if and only if this is not \"entryPointNone\".\n+\t// Note that dynamically-imported files are allowed to also be specified by\n+\t// the user as top-level entry points, so some dynamically-imported files\n+\t// may be \"entryPointUserSpecified\" instead of \"entryPointDynamicImport\".\n+\tentryPointKind entryPointKind\n \n \t// If true, this file was listed as not having side effects by a package.json\n \t// file in one of our containing directories with a \"sideEffects\" field, or\n@@ -79,6 +91,10 @@ type file struct {\n \twarnIfUnusedData *resolver.IgnoreIfUnusedData\n }\n \n+func (f *file) isEntryPoint() bool {\n+\treturn f.entryPointKind != entryPointNone\n+}\n+\n type fileRepr interface {\n \timportRecords() *[]ast.ImportRecord\n }\n@@ -91,6 +107,8 @@ type reprJS struct {\n \t// A JavaScript stub is automatically generated for a CSS file when it's\n \t// imported from a JavaScript file.\n \tcssSourceIndex ast.Index32\n+\n+\tdidWrapDependencies bool\n }\n \n func (repr *reprJS) importRecords() *[]ast.ImportRecord {\n@@ -129,7 +147,7 @@ type Bundle struct {\n \tfs          fs.FS\n \tres         resolver.Resolver\n \tfiles       []file\n-\tentryPoints []uint32\n+\tentryPoints []entryMeta\n }\n \n type parseArgs struct {\n@@ -445,6 +463,7 @@ func parseFile(args parseArgs) {\n \t\t\t\t\t&args.caches.FSCache,\n \t\t\t\t\t&source,\n \t\t\t\t\trecord.Range,\n+\t\t\t\t\tsource.KeyPath.Namespace,\n \t\t\t\t\trecord.Path.Text,\n \t\t\t\t\trecord.Kind,\n \t\t\t\t\tabsResolveDir,\n@@ -680,6 +699,7 @@ func runOnResolvePlugins(\n \tfsCache *cache.FSCache,\n \timportSource *logger.Source,\n \timportPathRange logger.Range,\n+\timportNamespace string,\n \tpath string,\n \tkind ast.ImportKind,\n \tabsResolveDir string,\n@@ -691,10 +711,14 @@ func runOnResolvePlugins(\n \t\tKind:       kind,\n \t\tPluginData: pluginData,\n \t}\n-\tapplyPath := logger.Path{Text: path}\n+\tapplyPath := logger.Path{\n+\t\tText:      path,\n+\t\tNamespace: importNamespace,\n+\t}\n \tif importSource != nil {\n \t\tresolverArgs.Importer = importSource.KeyPath\n-\t\tapplyPath.Namespace = importSource.KeyPath.Namespace\n+\t} else {\n+\t\tresolverArgs.Importer.Namespace = importNamespace\n \t}\n \n \t// Apply resolver plugins in order until one succeeds\n@@ -954,7 +978,20 @@ type scanner struct {\n \tremaining     int\n }\n \n-func ScanBundle(log logger.Log, fs fs.FS, res resolver.Resolver, caches *cache.CacheSet, entryPoints []string, options config.Options) Bundle {\n+type EntryPoint struct {\n+\tInputPath  string\n+\tOutputPath string\n+\tIsFile     bool\n+}\n+\n+func ScanBundle(\n+\tlog logger.Log,\n+\tfs fs.FS,\n+\tres resolver.Resolver,\n+\tcaches *cache.CacheSet,\n+\tentryPoints []EntryPoint,\n+\toptions config.Options,\n+) Bundle {\n \tapplyOptionDefaults(&options)\n \n \ts := scanner{\n@@ -977,15 +1014,15 @@ func ScanBundle(log logger.Log, fs fs.FS, res resolver.Resolver, caches *cache.C\n \t}()\n \n \ts.preprocessInjectedFiles()\n-\tentryPointIndices := s.addEntryPoints(entryPoints)\n+\tentryPointMeta := s.addEntryPoints(entryPoints)\n \ts.scanAllDependencies()\n \tfiles := s.processScannedFiles()\n \n \treturn Bundle{\n \t\tfs:          fs,\n \t\tres:         res,\n \t\tfiles:       files,\n-\t\tentryPoints: entryPointIndices,\n+\t\tentryPoints: entryPointMeta,\n \t}\n }\n \n@@ -1203,9 +1240,15 @@ func (s *scanner) preprocessInjectedFiles() {\n \ts.options.InjectedFiles = injectedFiles\n }\n \n-func (s *scanner) addEntryPoints(entryPoints []string) []uint32 {\n+type entryMeta struct {\n+\toutputPath                 string\n+\tsourceIndex                uint32\n+\toutputPathWasAutoGenerated bool\n+}\n+\n+func (s *scanner) addEntryPoints(entryPoints []EntryPoint) []entryMeta {\n \t// Reserve a slot for each entry point\n-\tentryPointIndices := make([]uint32, 0, len(entryPoints)+1)\n+\tentryMetas := make([]entryMeta, 0, len(entryPoints)+1)\n \n \t// Treat stdin as an extra entry point\n \tif stdin := s.options.Stdin; stdin != nil {\n@@ -1221,30 +1264,40 @@ func (s *scanner) addEntryPoints(entryPoints []string) []uint32 {\n \t\t}\n \t\tresolveResult := resolver.ResolveResult{PathPair: resolver.PathPair{Primary: stdinPath}}\n \t\tsourceIndex := s.maybeParseFile(resolveResult, s.res.PrettyPath(stdinPath), nil, logger.Range{}, nil, inputKindStdin, nil)\n-\t\tentryPointIndices = append(entryPointIndices, sourceIndex)\n-\t}\n-\n-\t// Entry point paths without a leading \"./\" are interpreted as package\n-\t// paths. This happens because they go through general path resolution\n-\t// like all other import paths so that plugins can run on them. Requiring\n-\t// a leading \"./\" for a relative path simplifies writing plugins because\n-\t// entry points aren't a special case.\n-\t//\n-\t// However, requiring a leading \"./\" also breaks backward compatibility\n-\t// and makes working with the CLI more difficult. So attempt to insert\n-\t// \"./\" automatically when needed. We don't want to unconditionally insert\n-\t// a leading \"./\" because the path may not be a file system path. For\n-\t// example, it may be a URL. So only insert a leading \"./\" when the path\n-\t// is an exact match for an existing file.\n+\t\tentryMetas = append(entryMetas, entryMeta{\n+\t\t\toutputPath:  \"stdin\",\n+\t\t\tsourceIndex: sourceIndex,\n+\t\t})\n+\t}\n+\n+\t// Check each entry point ahead of time to see if it's a real file\n \tentryPointAbsResolveDir := s.fs.Cwd()\n-\tfor i, path := range entryPoints {\n-\t\tif !s.fs.IsAbs(path) && resolver.IsPackagePath(path) {\n-\t\t\tabsPath := s.fs.Join(entryPointAbsResolveDir, path)\n-\t\t\tdir := s.fs.Dir(absPath)\n-\t\t\tbase := s.fs.Base(absPath)\n-\t\t\tif entries, err := s.fs.ReadDirectory(dir); err == nil {\n-\t\t\t\tif entry, _ := entries.Get(base); entry != nil && entry.Kind(s.fs) == fs.FileEntry {\n-\t\t\t\t\tentryPoints[i] = \"./\" + path\n+\tfor i := range entryPoints {\n+\t\tentryPoint := &entryPoints[i]\n+\t\tabsPath := entryPoint.InputPath\n+\t\tif !s.fs.IsAbs(absPath) {\n+\t\t\tabsPath = s.fs.Join(entryPointAbsResolveDir, absPath)\n+\t\t}\n+\t\tdir := s.fs.Dir(absPath)\n+\t\tbase := s.fs.Base(absPath)\n+\t\tif entries, err := s.fs.ReadDirectory(dir); err == nil {\n+\t\t\tif entry, _ := entries.Get(base); entry != nil && entry.Kind(s.fs) == fs.FileEntry {\n+\t\t\t\tentryPoint.IsFile = true\n+\n+\t\t\t\t// Entry point paths without a leading \"./\" are interpreted as package\n+\t\t\t\t// paths. This happens because they go through general path resolution\n+\t\t\t\t// like all other import paths so that plugins can run on them. Requiring\n+\t\t\t\t// a leading \"./\" for a relative path simplifies writing plugins because\n+\t\t\t\t// entry points aren't a special case.\n+\t\t\t\t//\n+\t\t\t\t// However, requiring a leading \"./\" also breaks backward compatibility\n+\t\t\t\t// and makes working with the CLI more difficult. So attempt to insert\n+\t\t\t\t// \"./\" automatically when needed. We don't want to unconditionally insert\n+\t\t\t\t// a leading \"./\" because the path may not be a file system path. For\n+\t\t\t\t// example, it may be a URL. So only insert a leading \"./\" when the path\n+\t\t\t\t// is an exact match for an existing file.\n+\t\t\t\tif !s.fs.IsAbs(entryPoint.InputPath) && resolver.IsPackagePath(entryPoint.InputPath) {\n+\t\t\t\t\tentryPoint.InputPath = \"./\" + entryPoint.InputPath\n \t\t\t\t}\n \t\t\t}\n \t\t}\n@@ -1256,8 +1309,13 @@ func (s *scanner) addEntryPoints(entryPoints []string) []uint32 {\n \tentryPointResolveResults := make([]*resolver.ResolveResult, len(entryPoints))\n \tentryPointWaitGroup := sync.WaitGroup{}\n \tentryPointWaitGroup.Add(len(entryPoints))\n-\tfor i, path := range entryPoints {\n-\t\tgo func(i int, path string) {\n+\tfor i, entryPoint := range entryPoints {\n+\t\tgo func(i int, entryPoint EntryPoint) {\n+\t\t\tnamespace := \"\"\n+\t\t\tif entryPoint.IsFile {\n+\t\t\t\tnamespace = \"file\"\n+\t\t\t}\n+\n \t\t\t// Run the resolver and log an error if the path couldn't be resolved\n \t\t\tresolveResult, didLogError, debug := runOnResolvePlugins(\n \t\t\t\ts.options.Plugins,\n@@ -1267,49 +1325,173 @@ func (s *scanner) addEntryPoints(entryPoints []string) []uint32 {\n \t\t\t\t&s.caches.FSCache,\n \t\t\t\tnil,\n \t\t\t\tlogger.Range{},\n-\t\t\t\tpath,\n+\t\t\t\tnamespace,\n+\t\t\t\tentryPoint.InputPath,\n \t\t\t\tast.ImportEntryPoint,\n \t\t\t\tentryPointAbsResolveDir,\n \t\t\t\tnil,\n \t\t\t)\n \t\t\tif resolveResult != nil {\n \t\t\t\tif resolveResult.IsExternal {\n-\t\t\t\t\ts.log.AddError(nil, logger.Loc{}, fmt.Sprintf(\"The entry point %q cannot be marked as external\", path))\n+\t\t\t\t\ts.log.AddError(nil, logger.Loc{}, fmt.Sprintf(\"The entry point %q cannot be marked as external\", entryPoint.InputPath))\n \t\t\t\t} else {\n \t\t\t\t\tentryPointResolveResults[i] = resolveResult\n \t\t\t\t}\n \t\t\t} else if !didLogError {\n \t\t\t\thint := \"\"\n-\t\t\t\tif !s.fs.IsAbs(path) {\n-\t\t\t\t\tif strings.ContainsRune(path, '*') {\n+\t\t\t\tif !s.fs.IsAbs(entryPoint.InputPath) {\n+\t\t\t\t\tif strings.ContainsRune(entryPoint.InputPath, '*') {\n \t\t\t\t\t\thint = \" (glob syntax must be expanded first before passing the paths to esbuild)\"\n-\t\t\t\t\t} else if query := s.res.ProbeResolvePackageAsRelative(entryPointAbsResolveDir, path, ast.ImportEntryPoint); query != nil {\n-\t\t\t\t\t\thint = fmt.Sprintf(\" (use %q to reference the file %q)\", \"./\"+path, s.res.PrettyPath(query.PathPair.Primary))\n+\t\t\t\t\t} else if query := s.res.ProbeResolvePackageAsRelative(entryPointAbsResolveDir, entryPoint.InputPath, ast.ImportEntryPoint); query != nil {\n+\t\t\t\t\t\thint = fmt.Sprintf(\" (use %q to reference the file %q)\", \"./\"+entryPoint.InputPath, s.res.PrettyPath(query.PathPair.Primary))\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t\ts.log.AddErrorWithNotes(nil, logger.Loc{}, fmt.Sprintf(\"Could not resolve %q%s\", path, hint), debug.Notes(nil, logger.Range{}))\n+\t\t\t\ts.log.AddErrorWithNotes(nil, logger.Loc{}, fmt.Sprintf(\"Could not resolve %q%s\", entryPoint.InputPath, hint), debug.Notes(nil, logger.Range{}))\n \t\t\t}\n \t\t\tentryPointWaitGroup.Done()\n-\t\t}(i, path)\n+\t\t}(i, entryPoint)\n \t}\n \tentryPointWaitGroup.Wait()\n \n \t// Parse all entry points that were resolved successfully\n-\tduplicateEntryPoints := make(map[uint32]bool)\n-\tfor _, resolveResult := range entryPointResolveResults {\n+\tfor i, resolveResult := range entryPointResolveResults {\n \t\tif resolveResult != nil {\n \t\t\tprettyPath := s.res.PrettyPath(resolveResult.PathPair.Primary)\n \t\t\tsourceIndex := s.maybeParseFile(*resolveResult, prettyPath, nil, logger.Range{}, resolveResult.PluginData, inputKindEntryPoint, nil)\n-\t\t\tif duplicateEntryPoints[sourceIndex] {\n-\t\t\t\ts.log.AddError(nil, logger.Loc{}, fmt.Sprintf(\"Duplicate entry point %q\", prettyPath))\n-\t\t\t\tcontinue\n+\t\t\toutputPath := entryPoints[i].OutputPath\n+\t\t\toutputPathWasAutoGenerated := false\n+\n+\t\t\t// If the output path is missing, automatically generate one from the input path\n+\t\t\tif outputPath == \"\" {\n+\t\t\t\toutputPath = entryPoints[i].InputPath\n+\t\t\t\twindowsVolumeLabel := \"\"\n+\n+\t\t\t\t// The \":\" character is invalid in file paths on Windows except when\n+\t\t\t\t// it's used as a volume separator. Special-case that here so volume\n+\t\t\t\t// labels don't break on Windows.\n+\t\t\t\tif s.fs.IsAbs(outputPath) && len(outputPath) >= 3 && outputPath[1] == ':' {\n+\t\t\t\t\tif c := outputPath[0]; (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') {\n+\t\t\t\t\t\tif c := outputPath[2]; c == '/' || c == '\\\\' {\n+\t\t\t\t\t\t\twindowsVolumeLabel = outputPath[:3]\n+\t\t\t\t\t\t\toutputPath = outputPath[3:]\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// For cross-platform robustness, do not allow characters in the output\n+\t\t\t\t// path that are invalid on Windows. This is especially relevant when\n+\t\t\t\t// the input path is something other than a file path, such as a URL.\n+\t\t\t\toutputPath = sanitizeFilePathForVirtualModulePath(outputPath)\n+\t\t\t\tif windowsVolumeLabel != \"\" {\n+\t\t\t\t\toutputPath = windowsVolumeLabel + outputPath\n+\t\t\t\t}\n+\t\t\t\toutputPathWasAutoGenerated = true\n+\n+\t\t\t\t// Strip the file extension from the output path if there is one so the\n+\t\t\t\t// \"out extension\" setting is used instead\n+\t\t\t\tif last := strings.LastIndexAny(outputPath, \"/.\\\\\"); last != -1 && outputPath[last] == '.' {\n+\t\t\t\t\toutputPath = outputPath[:last]\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tentryMetas = append(entryMetas, entryMeta{\n+\t\t\t\toutputPath:                 outputPath,\n+\t\t\t\tsourceIndex:                sourceIndex,\n+\t\t\t\toutputPathWasAutoGenerated: outputPathWasAutoGenerated,\n+\t\t\t})\n+\t\t}\n+\t}\n+\n+\t// Turn all automatically-generated output paths into absolute paths\n+\tfor i := range entryMetas {\n+\t\tentryPoint := &entryMetas[i]\n+\t\tif entryPoint.outputPathWasAutoGenerated && !s.fs.IsAbs(entryPoint.outputPath) {\n+\t\t\tentryPoint.outputPath = s.fs.Join(entryPointAbsResolveDir, entryPoint.outputPath)\n+\t\t}\n+\t}\n+\n+\t// Automatically compute \"outbase\" if it wasn't provided\n+\tif s.options.AbsOutputBase == \"\" {\n+\t\ts.options.AbsOutputBase = lowestCommonAncestorDirectory(s.fs, entryMetas)\n+\t\tif s.options.AbsOutputBase == \"\" {\n+\t\t\ts.options.AbsOutputBase = entryPointAbsResolveDir\n+\t\t}\n+\t}\n+\n+\t// Turn all output paths back into relative paths, but this time relative to\n+\t// the \"outbase\" value we computed above\n+\tfor i := range entryMetas {\n+\t\tentryPoint := &entryMetas[i]\n+\t\tif s.fs.IsAbs(entryPoint.outputPath) {\n+\t\t\tif !entryPoint.outputPathWasAutoGenerated {\n+\t\t\t\t// If an explicit absolute output path was specified, use the path\n+\t\t\t\t// relative to the \"outdir\" directory\n+\t\t\t\tif relPath, ok := s.fs.Rel(s.options.AbsOutputDir, entryPoint.outputPath); ok {\n+\t\t\t\t\tentryPoint.outputPath = relPath\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\t// Otherwise if the absolute output path was derived from the input\n+\t\t\t\t// path, use the path relative to the \"outbase\" directory\n+\t\t\t\tif relPath, ok := s.fs.Rel(s.options.AbsOutputBase, entryPoint.outputPath); ok {\n+\t\t\t\t\tentryPoint.outputPath = relPath\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn entryMetas\n+}\n+\n+func lowestCommonAncestorDirectory(fs fs.FS, entryPoints []entryMeta) string {\n+\t// Ignore any explicitly-specified output paths\n+\tabsPaths := make([]string, 0, len(entryPoints))\n+\tfor _, entryPoint := range entryPoints {\n+\t\tif entryPoint.outputPathWasAutoGenerated {\n+\t\t\tabsPaths = append(absPaths, entryPoint.outputPath)\n+\t\t}\n+\t}\n+\n+\tif len(absPaths) == 0 {\n+\t\treturn \"\"\n+\t}\n+\n+\tlowestAbsDir := fs.Dir(absPaths[0])\n+\n+\tfor _, absPath := range absPaths[1:] {\n+\t\tabsDir := fs.Dir(absPath)\n+\t\tlastSlash := 0\n+\t\ta := 0\n+\t\tb := 0\n+\n+\t\tfor {\n+\t\t\truneA, widthA := utf8.DecodeRuneInString(absDir[a:])\n+\t\t\truneB, widthB := utf8.DecodeRuneInString(lowestAbsDir[b:])\n+\t\t\tboundaryA := widthA == 0 || runeA == '/' || runeA == '\\\\'\n+\t\t\tboundaryB := widthB == 0 || runeB == '/' || runeB == '\\\\'\n+\n+\t\t\tif boundaryA && boundaryB {\n+\t\t\t\tif widthA == 0 || widthB == 0 {\n+\t\t\t\t\t// Truncate to the smaller path if one path is a prefix of the other\n+\t\t\t\t\tlowestAbsDir = absDir[:a]\n+\t\t\t\t\tbreak\n+\t\t\t\t} else {\n+\t\t\t\t\t// Track the longest common directory so far\n+\t\t\t\t\tlastSlash = a\n+\t\t\t\t}\n+\t\t\t} else if boundaryA != boundaryB || unicode.ToLower(runeA) != unicode.ToLower(runeB) {\n+\t\t\t\t// If both paths are different at this point, stop and set the lowest so\n+\t\t\t\t// far to the common parent directory. Compare using a case-insensitive\n+\t\t\t\t// comparison to handle paths on Windows.\n+\t\t\t\tlowestAbsDir = absDir[:lastSlash]\n+\t\t\t\tbreak\n \t\t\t}\n-\t\t\tduplicateEntryPoints[sourceIndex] = true\n-\t\t\tentryPointIndices = append(entryPointIndices, sourceIndex)\n+\n+\t\t\ta += widthA\n+\t\t\tb += widthB\n \t\t}\n \t}\n \n-\treturn entryPointIndices\n+\treturn lowestAbsDir\n }\n \n func (s *scanner) scanAllDependencies() {\n@@ -1535,8 +1717,8 @@ func (s *scanner) processScannedFiles() []file {\n \t// can't be constructed earlier because we generate new parse results for\n \t// JavaScript stub files for CSS imports above.\n \tfiles := make([]file, len(s.results))\n-\tfor sourceIndex, result := range s.results {\n-\t\tif result.ok {\n+\tfor sourceIndex := range s.results {\n+\t\tif result := &s.results[sourceIndex]; result.ok {\n \t\t\ts.validateTLA(uint32(sourceIndex))\n \t\t\tfiles[sourceIndex] = result.file\n \t\t}\n@@ -1555,9 +1737,7 @@ func (s *scanner) validateTLA(sourceIndex uint32) tlaCheck {\n \t\t\t}\n \n \t\t\tfor importRecordIndex, record := range repr.ast.ImportRecords {\n-\t\t\t\tif record.SourceIndex.IsValid() &&\n-\t\t\t\t\t(record.Kind == ast.ImportRequire || record.Kind == ast.ImportStmt ||\n-\t\t\t\t\t\t(record.Kind == ast.ImportDynamic && !s.options.CodeSplitting)) {\n+\t\t\t\tif record.SourceIndex.IsValid() && (record.Kind == ast.ImportRequire || record.Kind == ast.ImportStmt) {\n \t\t\t\t\tparent := s.validateTLA(record.SourceIndex.GetIndex())\n \t\t\t\t\tif !parent.parent.IsValid() {\n \t\t\t\t\t\tcontinue\n@@ -1571,9 +1751,8 @@ func (s *scanner) validateTLA(sourceIndex uint32) tlaCheck {\n \t\t\t\t\t\tcontinue\n \t\t\t\t\t}\n \n-\t\t\t\t\t// Require of a top-level await chain is forbidden. Dynamic import of\n-\t\t\t\t\t// a top-level await chain is also forbidden if code splitting is off.\n-\t\t\t\t\tif record.Kind == ast.ImportRequire || (record.Kind == ast.ImportDynamic && !s.options.CodeSplitting) {\n+\t\t\t\t\t// Require of a top-level await chain is forbidden\n+\t\t\t\t\tif record.Kind == ast.ImportRequire {\n \t\t\t\t\t\tvar notes []logger.MsgData\n \t\t\t\t\t\tvar tlaPrettyPath string\n \t\t\t\t\t\totherSourceIndex := record.SourceIndex.GetIndex()\n@@ -1604,27 +1783,27 @@ func (s *scanner) validateTLA(sourceIndex uint32) tlaCheck {\n \t\t\t\t\t\t}\n \n \t\t\t\t\t\tvar text string\n-\t\t\t\t\t\twhat := \"require call\"\n-\t\t\t\t\t\twhy := \"\"\n \t\t\t\t\t\timportedPrettyPath := s.results[record.SourceIndex.GetIndex()].file.source.PrettyPath\n \n-\t\t\t\t\t\tif record.Kind == ast.ImportDynamic {\n-\t\t\t\t\t\t\twhat = \"dynamic import\"\n-\t\t\t\t\t\t\twhy = \" (enable code splitting to allow this)\"\n-\t\t\t\t\t\t}\n-\n \t\t\t\t\t\tif importedPrettyPath == tlaPrettyPath {\n-\t\t\t\t\t\t\ttext = fmt.Sprintf(\"This %s is not allowed because the imported file %q contains a top-level await%s\",\n-\t\t\t\t\t\t\t\twhat, importedPrettyPath, why)\n+\t\t\t\t\t\t\ttext = fmt.Sprintf(\"This require call is not allowed because the imported file %q contains a top-level await\",\n+\t\t\t\t\t\t\t\timportedPrettyPath)\n \t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\ttext = fmt.Sprintf(\"This %s is not allowed because the transitive dependency %q contains a top-level await%s\",\n-\t\t\t\t\t\t\t\twhat, tlaPrettyPath, why)\n+\t\t\t\t\t\t\ttext = fmt.Sprintf(\"This require call is not allowed because the transitive dependency %q contains a top-level await\",\n+\t\t\t\t\t\t\t\ttlaPrettyPath)\n \t\t\t\t\t\t}\n \n \t\t\t\t\t\ts.log.AddRangeErrorWithNotes(&result.file.source, record.Range, text, notes)\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n+\n+\t\t\t// Make sure that if we wrap this module in a closure, the closure is also\n+\t\t\t// async. This happens when you call \"import()\" on this module and code\n+\t\t\t// splitting is off.\n+\t\t\tif result.tlaCheck.parent.IsValid() {\n+\t\t\t\trepr.meta.isAsyncOrHasAsyncDependency = true\n+\t\t\t}\n \t\t}\n \t}\n \n@@ -1699,9 +1878,6 @@ func (b *Bundle) Compile(log logger.Log, options config.Options) ([]OutputFile,\n \n \t// Get the base path from the options or choose the lowest common ancestor of all entry points\n \tallReachableFiles := findReachableFiles(b.files, b.entryPoints)\n-\tif options.AbsOutputBase == \"\" {\n-\t\toptions.AbsOutputBase = b.lowestCommonAncestorDirectory(options.CodeSplitting, allReachableFiles)\n-\t}\n \n \t// Compute source map data in parallel with linking\n \tdataForSourceMaps := b.computeDataForSourceMapsInParallel(&options, allReachableFiles)\n@@ -1717,8 +1893,8 @@ func (b *Bundle) Compile(log logger.Log, options config.Options) ([]OutputFile,\n \t\tresultGroups = make([][]OutputFile, len(b.entryPoints))\n \t\tfor i, entryPoint := range b.entryPoints {\n \t\t\twaitGroup.Add(1)\n-\t\t\tgo func(i int, entryPoint uint32) {\n-\t\t\t\tentryPoints := []uint32{entryPoint}\n+\t\t\tgo func(i int, entryPoint entryMeta) {\n+\t\t\t\tentryPoints := []entryMeta{entryPoint}\n \t\t\t\treachableFiles := findReachableFiles(b.files, entryPoints)\n \t\t\t\tc := newLinkerContext(&options, log, b.fs, b.res, b.files, entryPoints, reachableFiles, dataForSourceMaps)\n \t\t\t\tresultGroups[i] = c.link()\n@@ -1795,6 +1971,45 @@ func (b *Bundle) Compile(log logger.Log, options config.Options) ([]OutputFile,\n \treturn outputFiles, metafileJSON\n }\n \n+// Find all files reachable from all entry points. This order should be\n+// deterministic given that the entry point order is deterministic, since the\n+// returned order is the postorder of the graph traversal and import record\n+// order within a given file is deterministic.\n+func findReachableFiles(files []file, entryPoints []entryMeta) []uint32 {\n+\tvisited := make(map[uint32]bool)\n+\tvar order []uint32\n+\tvar visit func(uint32)\n+\n+\t// Include this file and all files it imports\n+\tvisit = func(sourceIndex uint32) {\n+\t\tif !visited[sourceIndex] {\n+\t\t\tvisited[sourceIndex] = true\n+\t\t\tfile := &files[sourceIndex]\n+\t\t\tif repr, ok := file.repr.(*reprJS); ok && repr.cssSourceIndex.IsValid() {\n+\t\t\t\tvisit(repr.cssSourceIndex.GetIndex())\n+\t\t\t}\n+\t\t\tfor _, record := range *file.repr.importRecords() {\n+\t\t\t\tif record.SourceIndex.IsValid() {\n+\t\t\t\t\tvisit(record.SourceIndex.GetIndex())\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\t// Each file must come after its dependencies\n+\t\t\torder = append(order, sourceIndex)\n+\t\t}\n+\t}\n+\n+\t// The runtime is always included in case it's needed\n+\tvisit(runtime.SourceIndex)\n+\n+\t// Include all files reachable from any entry point\n+\tfor _, entryPoint := range entryPoints {\n+\t\tvisit(entryPoint.sourceIndex)\n+\t}\n+\n+\treturn order\n+}\n+\n // This is done in parallel with linking because linking is a mostly serial\n // phase and there are extra resources for parallelism. This could also be done\n // during parsing but that would slow down parsing and delay the start of the\n@@ -1861,77 +2076,6 @@ func (b *Bundle) computeDataForSourceMapsInParallel(options *config.Options, rea\n \t}\n }\n \n-func (b *Bundle) lowestCommonAncestorDirectory(codeSplitting bool, allReachableFiles []uint32) string {\n-\tisEntryPoint := make(map[uint32]bool)\n-\tfor _, entryPoint := range b.entryPoints {\n-\t\tisEntryPoint[entryPoint] = true\n-\t}\n-\n-\t// If code splitting is enabled, also treat dynamic imports as entry points\n-\tif codeSplitting {\n-\t\tfor _, sourceIndex := range allReachableFiles {\n-\t\t\tif repr, ok := b.files[sourceIndex].repr.(*reprJS); ok {\n-\t\t\t\tfor importRecordIndex := range repr.ast.ImportRecords {\n-\t\t\t\t\tif record := &repr.ast.ImportRecords[importRecordIndex]; record.SourceIndex.IsValid() && record.Kind == ast.ImportDynamic {\n-\t\t\t\t\t\tisEntryPoint[record.SourceIndex.GetIndex()] = true\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\t// Ignore any paths for virtual modules (that don't exist on the file system)\n-\tabsPaths := make([]string, 0, len(isEntryPoint))\n-\tfor entryPoint := range isEntryPoint {\n-\t\tkeyPath := b.files[entryPoint].source.KeyPath\n-\t\tif keyPath.Namespace == \"file\" {\n-\t\t\tabsPaths = append(absPaths, keyPath.Text)\n-\t\t}\n-\t}\n-\n-\tif len(absPaths) == 0 {\n-\t\treturn \"\"\n-\t}\n-\n-\tlowestAbsDir := b.fs.Dir(absPaths[0])\n-\n-\tfor _, absPath := range absPaths[1:] {\n-\t\tabsDir := b.fs.Dir(absPath)\n-\t\tlastSlash := 0\n-\t\ta := 0\n-\t\tb := 0\n-\n-\t\tfor {\n-\t\t\truneA, widthA := utf8.DecodeRuneInString(absDir[a:])\n-\t\t\truneB, widthB := utf8.DecodeRuneInString(lowestAbsDir[b:])\n-\t\t\tboundaryA := widthA == 0 || runeA == '/' || runeA == '\\\\'\n-\t\t\tboundaryB := widthB == 0 || runeB == '/' || runeB == '\\\\'\n-\n-\t\t\tif boundaryA && boundaryB {\n-\t\t\t\tif widthA == 0 || widthB == 0 {\n-\t\t\t\t\t// Truncate to the smaller path if one path is a prefix of the other\n-\t\t\t\t\tlowestAbsDir = absDir[:a]\n-\t\t\t\t\tbreak\n-\t\t\t\t} else {\n-\t\t\t\t\t// Track the longest common directory so far\n-\t\t\t\t\tlastSlash = a\n-\t\t\t\t}\n-\t\t\t} else if boundaryA != boundaryB || unicode.ToLower(runeA) != unicode.ToLower(runeB) {\n-\t\t\t\t// If both paths are different at this point, stop and set the lowest so\n-\t\t\t\t// far to the common parent directory. Compare using a case-insensitive\n-\t\t\t\t// comparison to handle paths on Windows.\n-\t\t\t\tlowestAbsDir = absDir[:lastSlash]\n-\t\t\t\tbreak\n-\t\t\t}\n-\n-\t\t\ta += widthA\n-\t\t\tb += widthB\n-\t\t}\n-\t}\n-\n-\treturn lowestAbsDir\n-}\n-\n func (b *Bundle) generateMetadataJSON(results []OutputFile, allReachableFiles []uint32, asciiOnly bool) string {\n \tsb := strings.Builder{}\n \tsb.WriteString(\"{\\n  \\\"inputs\\\": {\")"},{"sha":"ec2778563e6a645f6fdf7f0095ee33bf2d35b677","filename":"internal/bundler/bundler_dce_test.go","status":"modified","additions":26,"deletions":0,"changes":26,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fbundler_dce_test.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fbundler_dce_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler_dce_test.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -1395,3 +1395,29 @@ func TestTreeShakingNoBundleIIFE(t *testing.T) {\n \t\t},\n \t})\n }\n+\n+func TestTreeShakingInESMWrapper(t *testing.T) {\n+\tdce_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/entry.js\": `\n+\t\t\t\timport {keep1} from './lib'\n+\t\t\t\tconsole.log(keep1(), require('./cjs'))\n+\t\t\t`,\n+\t\t\t\"/cjs.js\": `\n+\t\t\t\timport {keep2} from './lib'\n+\t\t\t\texport default keep2()\n+\t\t\t`,\n+\t\t\t\"/lib.js\": `\n+\t\t\t\texport let keep1 = () => 'keep1'\n+\t\t\t\texport let keep2 = () => 'keep2'\n+\t\t\t\texport let REMOVE = () => 'REMOVE'\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tOutputFormat:  config.FormatESModule,\n+\t\t\tAbsOutputFile: \"/out.js\",\n+\t\t},\n+\t})\n+}"},{"sha":"f224f33ecace95bae8c98013909a7fc2f298cb2b","filename":"internal/bundler/bundler_default_test.go","status":"modified","additions":3,"deletions":17,"changes":20,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fbundler_default_test.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fbundler_default_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler_default_test.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -1868,7 +1868,7 @@ func TestThisWithES6Syntax(t *testing.T) {\n \t\t\t\timport './es6-ns-export-namespace'\n \t\t\t\timport './es6-ns-export-class'\n \t\t\t\timport './es6-ns-export-abstract-class'\n-\t\t\t\t`,\n+\t\t\t`,\n \t\t\t\"/dummy.js\": `export const dummy = 123`,\n \t\t\t\"/cjs.js\":   `console.log(this)`,\n \n@@ -2779,7 +2779,7 @@ func TestNoOverwriteInputFileError(t *testing.T) {\n \t})\n }\n \n-func TestDuplicateEntryPointError(t *testing.T) {\n+func TestDuplicateEntryPoint(t *testing.T) {\n \tdefault_suite.expectBundled(t, bundled{\n \t\tfiles: map[string]string{\n \t\t\t\"/entry.js\": `\n@@ -2791,8 +2791,6 @@ func TestDuplicateEntryPointError(t *testing.T) {\n \t\t\tMode:         config.ModeBundle,\n \t\t\tAbsOutputDir: \"/out.js\",\n \t\t},\n-\t\texpectedScanLog: `error: Duplicate entry point \"entry.js\"\n-`,\n \t})\n }\n \n@@ -3256,7 +3254,7 @@ entry.js: note: The top-level await in \"entry.js\" is here\n \t})\n }\n \n-func TestTopLevelAwaitForbiddenImportWithoutSplitting(t *testing.T) {\n+func TestTopLevelAwaitAllowedImportWithoutSplitting(t *testing.T) {\n \tdefault_suite.expectBundled(t, bundled{\n \t\tfiles: map[string]string{\n \t\t\t\"/entry.js\": `\n@@ -3282,18 +3280,6 @@ func TestTopLevelAwaitForbiddenImportWithoutSplitting(t *testing.T) {\n \t\t\tOutputFormat:  config.FormatESModule,\n \t\t\tAbsOutputFile: \"/out.js\",\n \t\t},\n-\t\texpectedScanLog: `entry.js: error: This dynamic import is not allowed because the transitive dependency \"c.js\" contains a top-level await (enable code splitting to allow this)\n-a.js: note: The file \"a.js\" imports the file \"b.js\" here\n-b.js: note: The file \"b.js\" imports the file \"c.js\" here\n-c.js: note: The top-level await in \"c.js\" is here\n-entry.js: error: This dynamic import is not allowed because the transitive dependency \"c.js\" contains a top-level await (enable code splitting to allow this)\n-b.js: note: The file \"b.js\" imports the file \"c.js\" here\n-c.js: note: The top-level await in \"c.js\" is here\n-entry.js: error: This dynamic import is not allowed because the imported file \"c.js\" contains a top-level await (enable code splitting to allow this)\n-c.js: note: The top-level await in \"c.js\" is here\n-entry.js: error: This dynamic import is not allowed because the imported file \"entry.js\" contains a top-level await (enable code splitting to allow this)\n-entry.js: note: The top-level await in \"entry.js\" is here\n-`,\n \t})\n }\n "},{"sha":"50d3a2a646174a1e6726f410dc67f2f3bd9a8ed9","filename":"internal/bundler/bundler_test.go","status":"modified","additions":5,"deletions":1,"changes":6,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fbundler_test.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fbundler_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler_test.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -94,7 +94,11 @@ func (s *suite) expectBundled(t *testing.T, args bundled) {\n \t\tlog := logger.NewDeferLog()\n \t\tcaches := cache.MakeCacheSet()\n \t\tresolver := resolver.NewResolver(fs, log, caches, args.options)\n-\t\tbundle := ScanBundle(log, fs, resolver, caches, args.entryPaths, args.options)\n+\t\tentryPoints := make([]EntryPoint, 0, len(args.entryPaths))\n+\t\tfor _, path := range args.entryPaths {\n+\t\t\tentryPoints = append(entryPoints, EntryPoint{InputPath: path})\n+\t\t}\n+\t\tbundle := ScanBundle(log, fs, resolver, caches, entryPoints, args.options)\n \t\tmsgs := log.Done()\n \t\tassertLog(t, msgs, args.expectedScanLog)\n "},{"sha":"364ad5b6ca69899a1dcffbaecc5200ca8ab8d63d","filename":"internal/bundler/linker.go","status":"modified","additions":699,"deletions":430,"changes":1129,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Flinker.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Flinker.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Flinker.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -8,7 +8,6 @@ import (\n \t\"fmt\"\n \t\"hash\"\n \t\"math/rand\"\n-\t\"path\"\n \t\"sort\"\n \t\"strings\"\n \t\"sync\"\n@@ -67,7 +66,7 @@ type linkerContext struct {\n \tfs          fs.FS\n \tres         resolver.Resolver\n \tsymbols     js_ast.SymbolMap\n-\tentryPoints []uint32\n+\tentryPoints []entryMeta\n \tfiles       []file\n \thasErrors   bool\n \n@@ -113,13 +112,29 @@ const (\n \t//\n \t//   // foo.ts\n \t//   let require_foo = __commonJS((exports, module) => {\n-\t//     exports.foo = 123\n+\t//     exports.foo = 123;\n \t//   });\n \t//\n \t//   // bar.ts\n \t//   let foo = flag ? require_foo() : null;\n \t//\n \twrapCJS\n+\n+\t// The module will be bundled ESM-style like this:\n+\t//\n+\t//   // foo.ts\n+\t//   var foo, foo_exports = {};\n+\t//   __exports(foo_exports, {\n+\t//     foo: () => foo\n+\t//   });\n+\t//   let init_foo = __esm(() => {\n+\t//     foo = 123;\n+\t//   });\n+\t//\n+\t//   // bar.ts\n+\t//   let foo = flag ? (init_foo(), foo_exports) : null;\n+\t//\n+\twrapESM\n )\n \n // This contains linker-specific metadata corresponding to a \"file\" struct\n@@ -172,6 +187,8 @@ type fileMeta struct {\n \t// into two separate passes.\n \timportsToBind map[js_ast.Ref]importToBind\n \n+\tisAsyncOrHasAsyncDependency bool\n+\n \twrap wrapKind\n \n \t// If true, the \"__export(exports, { ... })\" call will be force-included even\n@@ -188,11 +205,11 @@ type fileMeta struct {\n \tneedsMarkAsModuleSymbolFromRuntime bool\n \n \t// The index of the automatically-generated part used to represent the\n-\t// CommonJS wrapper. This part is empty and is only useful for tree shaking\n-\t// and code splitting. The CommonJS wrapper can't be inserted into the part\n+\t// CommonJS or ESM wrapper. This part is empty and is only useful for tree\n+\t// shaking and code splitting. The wrapper can't be inserted into the part\n \t// because the wrapper contains other parts, which can't be represented by\n \t// the current part system.\n-\tcjsWrapperPartIndex ast.Index32\n+\twrapperPartIndex ast.Index32\n \n \t// This includes both named exports and re-exports.\n \t//\n@@ -369,7 +386,7 @@ func newLinkerContext(\n \tfs fs.FS,\n \tres resolver.Resolver,\n \tfiles []file,\n-\tentryPoints []uint32,\n+\tentryPoints []entryMeta,\n \treachableFiles []uint32,\n \tdataForSourceMaps func() []dataForSourceMap,\n ) linkerContext {\n@@ -379,7 +396,7 @@ func newLinkerContext(\n \t\tlog:               log,\n \t\tfs:                fs,\n \t\tres:               res,\n-\t\tentryPoints:       append([]uint32{}, entryPoints...),\n+\t\tentryPoints:       append([]entryMeta{}, entryPoints...),\n \t\tfiles:             make([]file, len(files)),\n \t\tsymbols:           js_ast.NewSymbolMap(len(files)),\n \t\treachableFiles:    reachableFiles,\n@@ -450,12 +467,10 @@ func newLinkerContext(\n \t\t\t}\n \n \t\t\t// Also associate some default metadata with the file\n-\t\t\trepr.meta = fileMeta{\n-\t\t\t\tpartMeta:                 make([]partMeta, len(repr.ast.Parts)),\n-\t\t\t\tresolvedExports:          resolvedExports,\n-\t\t\t\tisProbablyTypeScriptType: make(map[js_ast.Ref]bool),\n-\t\t\t\timportsToBind:            make(map[js_ast.Ref]importToBind),\n-\t\t\t}\n+\t\t\trepr.meta.partMeta = make([]partMeta, len(repr.ast.Parts))\n+\t\t\trepr.meta.resolvedExports = resolvedExports\n+\t\t\trepr.meta.isProbablyTypeScriptType = make(map[js_ast.Ref]bool)\n+\t\t\trepr.meta.importsToBind = make(map[js_ast.Ref]importToBind)\n \n \t\tcase *reprCSS:\n \t\t\t// Clone the representation\n@@ -483,9 +498,9 @@ func newLinkerContext(\n \t}\n \n \t// Mark all entry points so we don't add them again for import() expressions\n-\tfor _, sourceIndex := range entryPoints {\n-\t\tfile := &c.files[sourceIndex]\n-\t\tfile.isEntryPoint = true\n+\tfor _, entryPoint := range entryPoints {\n+\t\tfile := &c.files[entryPoint.sourceIndex]\n+\t\tfile.entryPointKind = entryPointUserSpecified\n \n \t\tif repr, ok := file.repr.(*reprJS); ok {\n \t\t\t// Loaders default to CommonJS when they are the entry point and the output\n@@ -526,45 +541,6 @@ func newLinkerContext(\n \treturn c\n }\n \n-// Find all files reachable from all entry points. This order should be\n-// deterministic given that the entry point order is deterministic, since the\n-// returned order is the postorder of the graph traversal and import record\n-// order within a given file is deterministic.\n-func findReachableFiles(files []file, entryPoints []uint32) []uint32 {\n-\tvisited := make(map[uint32]bool)\n-\tvar order []uint32\n-\tvar visit func(uint32)\n-\n-\t// Include this file and all files it imports\n-\tvisit = func(sourceIndex uint32) {\n-\t\tif !visited[sourceIndex] {\n-\t\t\tvisited[sourceIndex] = true\n-\t\t\tfile := &files[sourceIndex]\n-\t\t\tif repr, ok := file.repr.(*reprJS); ok && repr.cssSourceIndex.IsValid() {\n-\t\t\t\tvisit(repr.cssSourceIndex.GetIndex())\n-\t\t\t}\n-\t\t\tfor _, record := range *file.repr.importRecords() {\n-\t\t\t\tif record.SourceIndex.IsValid() {\n-\t\t\t\t\tvisit(record.SourceIndex.GetIndex())\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\t// Each file must come after its dependencies\n-\t\t\torder = append(order, sourceIndex)\n-\t\t}\n-\t}\n-\n-\t// The runtime is always included in case it's needed\n-\tvisit(runtime.SourceIndex)\n-\n-\t// Include all files reachable from any entry point\n-\tfor _, entryPoint := range entryPoints {\n-\t\tvisit(entryPoint)\n-\t}\n-\n-\treturn order\n-}\n-\n func (c *linkerContext) addRangeError(source logger.Source, r logger.Range, text string) {\n \tc.log.AddRangeError(&source, r, text)\n \tc.hasErrors = true\n@@ -618,7 +594,7 @@ func (c *linkerContext) link() []OutputFile {\n \n \tif c.options.Mode == config.ModePassThrough {\n \t\tfor _, entryPoint := range c.entryPoints {\n-\t\t\tc.preventExportsFromBeingRenamed(entryPoint)\n+\t\t\tc.preventExportsFromBeingRenamed(entryPoint.sourceIndex)\n \t\t}\n \t}\n \n@@ -826,7 +802,12 @@ func (c *linkerContext) pathBetweenChunks(fromRelDir string, toRelPath string) s\n // substituted into a path template without necessarily having a \"/\" after it.\n // Extra slashes should get cleaned up automatically when we join it with the\n // output directory.\n-func (c *linkerContext) pathRelativeToOutbase(sourceIndex uint32, stdExt string) (relDir string, baseName string, baseExt string) {\n+func (c *linkerContext) pathRelativeToOutbase(\n+\tsourceIndex uint32,\n+\tentryPointBit uint,\n+\tstdExt string,\n+\tavoidIndex bool,\n+) (relDir string, baseName string, baseExt string) {\n \tfile := &c.files[sourceIndex]\n \trelDir = \"/\"\n \tbaseExt = stdExt\n@@ -848,57 +829,80 @@ func (c *linkerContext) pathRelativeToOutbase(sourceIndex uint32, stdExt string)\n \t\treturn\n \t}\n \n-\t// Come up with a path for virtual paths (i.e. non-file-system paths)\n-\tif file.source.KeyPath.Namespace != \"file\" {\n-\t\tbaseName = baseFileNameForVirtualModulePath(file.source.KeyPath.Text)\n+\tabsPath := file.source.KeyPath.Text\n+\tisCustomOutputPath := false\n \n-\t\t// Swap the file extension for the standard one\n-\t\tbaseName = baseName[:len(baseName)-len(path.Ext(baseName))]\n+\tif outPath := c.entryPoints[entryPointBit].outputPath; outPath != \"\" {\n+\t\t// Use the configured output path if present\n+\t\tabsPath = outPath\n+\t\tif !c.fs.IsAbs(absPath) {\n+\t\t\tabsPath = c.fs.Join(c.options.AbsOutputBase, absPath)\n+\t\t}\n+\t\tisCustomOutputPath = true\n+\t} else if file.source.KeyPath.Namespace != \"file\" {\n+\t\t// Come up with a path for virtual paths (i.e. non-file-system paths)\n+\t\tdir, base, _ := logger.PlatformIndependentPathDirBaseExt(absPath)\n+\t\tif avoidIndex && base == \"index\" {\n+\t\t\t_, base, _ = logger.PlatformIndependentPathDirBaseExt(dir)\n+\t\t}\n+\t\tbaseName = sanitizeFilePathForVirtualModulePath(base)\n \t\treturn\n+\t} else {\n+\t\t// Heuristic: If the file is named something like \"index.js\", then use\n+\t\t// the name of the parent directory instead. This helps avoid the\n+\t\t// situation where many chunks are named \"index\" because of people\n+\t\t// dynamically-importing npm packages that make use of node's implicit\n+\t\t// \"index\" file name feature.\n+\t\tif avoidIndex {\n+\t\t\tbase := c.fs.Base(absPath)\n+\t\t\tbase = base[:len(base)-len(c.fs.Ext(base))]\n+\t\t\tif base == \"index\" {\n+\t\t\t\tabsPath = c.fs.Dir(absPath)\n+\t\t\t}\n+\t\t}\n \t}\n \n \t// Try to get a relative path to the base directory\n-\trelPath, ok := c.fs.Rel(c.options.AbsOutputBase, file.source.KeyPath.Text)\n+\trelPath, ok := c.fs.Rel(c.options.AbsOutputBase, absPath)\n \tif !ok {\n \t\t// This can fail in some situations such as on different drives on\n \t\t// Windows. In that case we just use the file name.\n-\t\tbaseName = c.fs.Base(file.source.KeyPath.Text)\n-\n-\t\t// Swap the file extension for the standard one\n-\t\tbaseName = baseName[:len(baseName)-len(c.fs.Ext(baseName))]\n-\t\treturn\n-\t}\n-\n-\t// Now we finally have a relative path\n-\trelDir = c.fs.Dir(relPath) + \"/\"\n-\tbaseName = c.fs.Base(relPath)\n+\t\tbaseName = c.fs.Base(absPath)\n+\t} else {\n+\t\t// Now we finally have a relative path\n+\t\trelDir = c.fs.Dir(relPath) + \"/\"\n+\t\tbaseName = c.fs.Base(relPath)\n \n-\t// Swap the file extension for the standard one\n-\tbaseName = baseName[:len(baseName)-len(c.fs.Ext(baseName))]\n+\t\t// Use platform-independent slashes\n+\t\trelDir = strings.ReplaceAll(relDir, \"\\\\\", \"/\")\n \n-\t// Use platform-independent slashes\n-\trelDir = strings.ReplaceAll(relDir, \"\\\\\", \"/\")\n+\t\t// Replace leading \"../\" so we don't try to write outside of the output\n+\t\t// directory. This normally can't happen because \"AbsOutputBase\" is\n+\t\t// automatically computed to contain all entry point files, but it can\n+\t\t// happen if someone sets it manually via the \"outbase\" API option.\n+\t\t//\n+\t\t// Note that we can't just strip any leading \"../\" because that could\n+\t\t// cause two separate entry point paths to collide. For example, there\n+\t\t// could be both \"src/index.js\" and \"../src/index.js\" as entry points.\n+\t\tdotDotCount := 0\n+\t\tfor strings.HasPrefix(relDir[dotDotCount*3:], \"../\") {\n+\t\t\tdotDotCount++\n+\t\t}\n+\t\tif dotDotCount > 0 {\n+\t\t\t// The use of \"_.._\" here is somewhat arbitrary but it is unlikely to\n+\t\t\t// collide with a folder named by a human and it works on Windows\n+\t\t\t// (Windows doesn't like names that end with a \".\"). And not starting\n+\t\t\t// with a \".\" means that it will not be hidden on Unix.\n+\t\t\trelDir = strings.Repeat(\"_.._/\", dotDotCount) + relDir[dotDotCount*3:]\n+\t\t}\n+\t\trelDir = \"/\" + relDir\n+\t}\n \n-\t// Replace leading \"../\" so we don't try to write outside of the output\n-\t// directory. This normally can't happen because \"AbsOutputBase\" is\n-\t// automatically computed to contain all entry point files, but it can\n-\t// happen if someone sets it manually via the \"outbase\" API option.\n-\t//\n-\t// Note that we can't just strip any leading \"../\" because that could\n-\t// cause two separate entry point paths to collide. For example, there\n-\t// could be both \"src/index.js\" and \"../src/index.js\" as entry points.\n-\tdotDotCount := 0\n-\tfor strings.HasPrefix(relDir[dotDotCount*3:], \"../\") {\n-\t\tdotDotCount++\n-\t}\n-\tif dotDotCount > 0 {\n-\t\t// The use of \"_.._\" here is somewhat arbitrary but it is unlikely to\n-\t\t// collide with a folder named by a human and it works on Windows\n-\t\t// (Windows doesn't like names that end with a \".\"). And not starting\n-\t\t// with a \".\" means that it will not be hidden on Unix.\n-\t\trelDir = strings.Repeat(\"_.._/\", dotDotCount) + relDir[dotDotCount*3:]\n-\t}\n-\trelDir = \"/\" + relDir\n+\t// Strip the file extension if the output path is an input file\n+\tif !isCustomOutputPath {\n+\t\text := c.fs.Ext(baseName)\n+\t\tbaseName = baseName[:len(baseName)-len(ext)]\n+\t}\n \treturn\n }\n \n@@ -1309,27 +1313,49 @@ func (c *linkerContext) scanImportsAndExports() {\n \t\t\t\t\t// In that case the module *is* considered a CommonJS module because\n \t\t\t\t\t// the namespace object must be created.\n \t\t\t\t\tif (record.ContainsImportStar || record.ContainsDefaultAlias) && otherRepr.ast.ExportsKind == js_ast.ExportsNone && !otherRepr.ast.HasLazyExport {\n+\t\t\t\t\t\totherRepr.meta.wrap = wrapCJS\n \t\t\t\t\t\totherRepr.ast.ExportsKind = js_ast.ExportsCommonJS\n \t\t\t\t\t}\n \n \t\t\t\tcase ast.ImportRequire:\n \t\t\t\t\t// Files that are imported with require() must be CommonJS modules\n-\t\t\t\t\totherRepr.ast.ExportsKind = js_ast.ExportsCommonJS\n+\t\t\t\t\tif otherRepr.ast.ExportsKind == js_ast.ExportsESM {\n+\t\t\t\t\t\totherRepr.meta.wrap = wrapESM\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\totherRepr.meta.wrap = wrapCJS\n+\t\t\t\t\t\totherRepr.ast.ExportsKind = js_ast.ExportsCommonJS\n+\t\t\t\t\t}\n \n \t\t\t\tcase ast.ImportDynamic:\n \t\t\t\t\tif c.options.CodeSplitting {\n \t\t\t\t\t\t// Files that are imported with import() must be entry points\n-\t\t\t\t\t\tif !otherFile.isEntryPoint {\n-\t\t\t\t\t\t\tc.entryPoints = append(c.entryPoints, record.SourceIndex.GetIndex())\n-\t\t\t\t\t\t\totherFile.isEntryPoint = true\n+\t\t\t\t\t\tif otherFile.entryPointKind == entryPointNone {\n+\t\t\t\t\t\t\tc.entryPoints = append(c.entryPoints, entryMeta{\n+\t\t\t\t\t\t\t\tsourceIndex: record.SourceIndex.GetIndex(),\n+\t\t\t\t\t\t\t})\n+\t\t\t\t\t\t\totherFile.entryPointKind = entryPointDynamicImport\n \t\t\t\t\t\t}\n \t\t\t\t\t} else {\n \t\t\t\t\t\t// If we're not splitting, then import() is just a require() that\n \t\t\t\t\t\t// returns a promise, so the imported file must be a CommonJS module\n-\t\t\t\t\t\totherRepr.ast.ExportsKind = js_ast.ExportsCommonJS\n+\t\t\t\t\t\tif otherRepr.ast.ExportsKind == js_ast.ExportsESM {\n+\t\t\t\t\t\t\totherRepr.meta.wrap = wrapESM\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\totherRepr.meta.wrap = wrapCJS\n+\t\t\t\t\t\t\totherRepr.ast.ExportsKind = js_ast.ExportsCommonJS\n+\t\t\t\t\t\t}\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n+\n+\t\t\t// If the output format doesn't have an implicit CommonJS wrapper, any file\n+\t\t\t// that uses CommonJS features will need to be wrapped, even though the\n+\t\t\t// resulting wrapper won't be invoked by other files. An exception is made\n+\t\t\t// for entry point files in CommonJS format (or when in pass-through mode).\n+\t\t\tif repr.ast.ExportsKind == js_ast.ExportsCommonJS && (!file.isEntryPoint() ||\n+\t\t\t\tc.options.OutputFormat == config.FormatIIFE || c.options.OutputFormat == config.FormatESModule) {\n+\t\t\t\trepr.meta.wrap = wrapCJS\n+\t\t\t}\n \t\t}\n \t}\n \n@@ -1338,37 +1364,18 @@ func (c *linkerContext) scanImportsAndExports() {\n \t// In this case the export star must be evaluated at run time instead of at\n \t// bundle time.\n \tfor _, sourceIndex := range c.reachableFiles {\n-\t\tif repr, ok := c.files[sourceIndex].repr.(*reprJS); ok && len(repr.ast.ExportStarImportRecords) > 0 {\n-\t\t\tvisited := make(map[uint32]bool)\n-\t\t\tc.hasDynamicExportsDueToExportStar(sourceIndex, visited)\n-\t\t}\n-\t}\n-\n-\t// Step 3: Resolve \"export * from\" statements. This must be done after we\n-\t// discover all modules that can have dynamic exports because export stars\n-\t// are ignored for those modules.\n-\texportStarStack := make([]uint32, 0, 32)\n-\tfor _, sourceIndex := range c.reachableFiles {\n-\t\tfile := &c.files[sourceIndex]\n-\t\trepr, ok := file.repr.(*reprJS)\n+\t\trepr, ok := c.files[sourceIndex].repr.(*reprJS)\n \t\tif !ok {\n \t\t\tcontinue\n \t\t}\n \n-\t\t// Expression-style loaders defer code generation until linking. Code\n-\t\t// generation is done here because at this point we know that the\n-\t\t// \"ExportsKind\" field has its final value and will not be changed.\n-\t\tif repr.ast.HasLazyExport {\n-\t\t\tc.generateCodeForLazyExport(sourceIndex)\n+\t\tif repr.meta.wrap != wrapNone {\n+\t\t\tc.recursivelyWrapDependencies(sourceIndex)\n \t\t}\n \n-\t\t// If the output format doesn't have an implicit CommonJS wrapper, any file\n-\t\t// that uses CommonJS features will need to be wrapped, even though the\n-\t\t// resulting wrapper won't be invoked by other files. An exception is made\n-\t\t// for entry point files in CommonJS format (or when in pass-through mode).\n-\t\tif repr.ast.ExportsKind == js_ast.ExportsCommonJS && (!file.isEntryPoint ||\n-\t\t\tc.options.OutputFormat == config.FormatIIFE || c.options.OutputFormat == config.FormatESModule) {\n-\t\t\trepr.meta.wrap = wrapCJS\n+\t\tif len(repr.ast.ExportStarImportRecords) > 0 {\n+\t\t\tvisited := make(map[uint32]bool)\n+\t\t\tc.hasDynamicExportsDueToExportStar(sourceIndex, visited)\n \t\t}\n \n \t\t// Even if the output file is CommonJS-like, we may still need to wrap\n@@ -1381,10 +1388,28 @@ func (c *linkerContext) scanImportsAndExports() {\n \t\t\tif record.SourceIndex.IsValid() {\n \t\t\t\totherRepr := c.files[record.SourceIndex.GetIndex()].repr.(*reprJS)\n \t\t\t\tif otherRepr.ast.ExportsKind == js_ast.ExportsCommonJS {\n-\t\t\t\t\totherRepr.meta.wrap = wrapCJS\n+\t\t\t\t\tc.recursivelyWrapDependencies(record.SourceIndex.GetIndex())\n \t\t\t\t}\n \t\t\t}\n \t\t}\n+\t}\n+\n+\t// Step 3: Resolve \"export * from\" statements. This must be done after we\n+\t// discover all modules that can have dynamic exports because export stars\n+\t// are ignored for those modules.\n+\texportStarStack := make([]uint32, 0, 32)\n+\tfor _, sourceIndex := range c.reachableFiles {\n+\t\trepr, ok := c.files[sourceIndex].repr.(*reprJS)\n+\t\tif !ok {\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\t// Expression-style loaders defer code generation until linking. Code\n+\t\t// generation is done here because at this point we know that the\n+\t\t// \"ExportsKind\" field has its final value and will not be changed.\n+\t\tif repr.ast.HasLazyExport {\n+\t\t\tc.generateCodeForLazyExport(sourceIndex)\n+\t\t}\n \n \t\t// Propagate exports for export star statements\n \t\tif len(repr.ast.ExportStarImportRecords) > 0 {\n@@ -1425,7 +1450,7 @@ func (c *linkerContext) scanImportsAndExports() {\n \t\t// symbols. In that case make sure to mark them as such so they don't\n \t\t// get minified.\n \t\tif (c.options.OutputFormat == config.FormatPreserve || c.options.OutputFormat == config.FormatCommonJS) &&\n-\t\t\trepr.meta.wrap == wrapNone && file.isEntryPoint {\n+\t\t\trepr.meta.wrap == wrapNone && file.isEntryPoint() {\n \t\t\texportsRef := js_ast.FollowSymbols(c.symbols, repr.ast.ExportsRef)\n \t\t\tmoduleRef := js_ast.FollowSymbols(c.symbols, repr.ast.ModuleRef)\n \t\t\tc.symbols.Get(exportsRef).Kind = js_ast.SymbolUnbound\n@@ -1503,7 +1528,7 @@ func (c *linkerContext) scanImportsAndExports() {\n \t\t// Pre-generate symbols for re-exports CommonJS symbols in case they\n \t\t// are necessary later. This is done now because the symbols map cannot be\n \t\t// mutated later due to parallelism.\n-\t\tif file.isEntryPoint && c.options.OutputFormat == config.FormatESModule {\n+\t\tif file.isEntryPoint() && c.options.OutputFormat == config.FormatESModule {\n \t\t\tcopies := make([]js_ast.Ref, len(repr.meta.sortedAndFilteredExportAliases))\n \t\t\tfor i, alias := range repr.meta.sortedAndFilteredExportAliases {\n \t\t\t\tsymbols := &c.symbols.Outer[sourceIndex]\n@@ -1523,12 +1548,17 @@ func (c *linkerContext) scanImportsAndExports() {\n \t\t\trepr.meta.cjsExportCopies = copies\n \t\t}\n \n+\t\t// Use \"init_*\" for ESM wrappers instead of \"require_*\"\n+\t\tif repr.meta.wrap == wrapESM {\n+\t\t\tc.symbols.Get(repr.ast.WrapperRef).OriginalName = \"init_\" + file.source.IdentifierName\n+\t\t}\n+\n \t\t// If this isn't CommonJS, then rename the unused \"exports\" and \"module\"\n \t\t// variables to avoid them causing the identically-named variables in\n \t\t// actual CommonJS files from being renamed. This is purely about\n \t\t// aesthetics and is not about correctness. This is done here because by\n \t\t// this point, we know the CommonJS status will not change further.\n-\t\tif repr.meta.wrap != wrapCJS && repr.ast.ExportsKind != js_ast.ExportsCommonJS && (!file.isEntryPoint ||\n+\t\tif repr.meta.wrap != wrapCJS && repr.ast.ExportsKind != js_ast.ExportsCommonJS && (!file.isEntryPoint() ||\n \t\t\tc.options.OutputFormat != config.FormatCommonJS) {\n \t\t\tname := file.source.IdentifierName\n \t\t\tc.symbols.Get(repr.ast.ExportsRef).OriginalName = name + \"_exports\"\n@@ -1661,7 +1691,7 @@ func (c *linkerContext) generateCodeForLazyExport(sourceIndex uint32) {\n \t\tclone := *object\n \t\tclone.Properties = append(make([]js_ast.Property, 0, len(clone.Properties)), clone.Properties...)\n \t\tfor i, property := range clone.Properties {\n-\t\t\tif str, ok := property.Key.Data.(*js_ast.EString); ok && (!file.isEntryPoint || js_lexer.IsIdentifierUTF16(str.Value)) {\n+\t\t\tif str, ok := property.Key.Data.(*js_ast.EString); ok && (!file.isEntryPoint() || js_lexer.IsIdentifierUTF16(str.Value)) {\n \t\t\t\tname := js_lexer.UTF16ToString(str.Value)\n \t\t\t\texport := generateExport(name, name, *property.Value, nil)\n \t\t\t\tprevExports = append(prevExports, export)\n@@ -1735,7 +1765,7 @@ func (c *linkerContext) createExportsForFile(sourceIndex uint32) {\n \t// Prefix this part with \"var exports = {}\" if this isn't a CommonJS module\n \tdeclaredSymbols := []js_ast.DeclaredSymbol{}\n \tvar nsExportStmts []js_ast.Stmt\n-\tif repr.ast.ExportsKind != js_ast.ExportsCommonJS && (!file.isEntryPoint || c.options.OutputFormat != config.FormatCommonJS) {\n+\tif repr.ast.ExportsKind != js_ast.ExportsCommonJS && (!file.isEntryPoint() || c.options.OutputFormat != config.FormatCommonJS) {\n \t\tnsExportStmts = append(nsExportStmts, js_ast.Stmt{Data: &js_ast.SLocal{Decls: []js_ast.Decl{{\n \t\t\tBinding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.ast.ExportsRef}},\n \t\t\tValue:   &js_ast.Expr{Data: &js_ast.EObject{}},\n@@ -1750,7 +1780,7 @@ func (c *linkerContext) createExportsForFile(sourceIndex uint32) {\n \t// \"__markAsModule\" which sets the \"__esModule\" property to true. This must\n \t// be done before any to \"require()\" or circular imports of multiple modules\n \t// that have been each converted from ESM to CommonJS may not work correctly.\n-\tif repr.ast.ExportKeyword.Len > 0 && (repr.ast.ExportsKind == js_ast.ExportsCommonJS || (file.isEntryPoint && c.options.OutputFormat == config.FormatCommonJS)) {\n+\tif repr.ast.ExportKeyword.Len > 0 && (repr.ast.ExportsKind == js_ast.ExportsCommonJS || (file.isEntryPoint() && c.options.OutputFormat == config.FormatCommonJS)) {\n \t\truntimeRepr := c.files[runtime.SourceIndex].repr.(*reprJS)\n \t\tmarkAsModuleRef := runtimeRepr.ast.ModuleScope.Members[\"__markAsModule\"].Ref\n \t\tnsExportStmts = append(nsExportStmts, js_ast.Stmt{Data: &js_ast.SExpr{Value: js_ast.Expr{Data: &js_ast.ECall{\n@@ -2121,6 +2151,35 @@ loop:\n \treturn\n }\n \n+func (c *linkerContext) recursivelyWrapDependencies(sourceIndex uint32) {\n+\trepr := c.files[sourceIndex].repr.(*reprJS)\n+\tif repr.didWrapDependencies {\n+\t\treturn\n+\t}\n+\trepr.didWrapDependencies = true\n+\n+\t// Never wrap the runtime file since it always comes first\n+\tif sourceIndex == runtime.SourceIndex {\n+\t\treturn\n+\t}\n+\n+\t// This module must be wrapped\n+\tif repr.meta.wrap == wrapNone {\n+\t\tif repr.ast.ExportsKind == js_ast.ExportsCommonJS {\n+\t\t\trepr.meta.wrap = wrapCJS\n+\t\t} else {\n+\t\t\trepr.meta.wrap = wrapESM\n+\t\t}\n+\t}\n+\n+\t// All dependencies must also be wrapped\n+\tfor _, record := range repr.ast.ImportRecords {\n+\t\tif record.SourceIndex.IsValid() {\n+\t\t\tc.recursivelyWrapDependencies(record.SourceIndex.GetIndex())\n+\t\t}\n+\t}\n+}\n+\n func (c *linkerContext) hasDynamicExportsDueToExportStar(sourceIndex uint32, visited map[uint32]bool) bool {\n \t// Terminate the traversal now if this file already has dynamic exports\n \trepr := c.files[sourceIndex].repr.(*reprJS)\n@@ -2141,7 +2200,7 @@ func (c *linkerContext) hasDynamicExportsDueToExportStar(sourceIndex uint32, vis\n \t\t// This file has dynamic exports if the exported imports are from a file\n \t\t// that either has dynamic exports directly or transitively by itself\n \t\t// having an export star from a file with dynamic exports.\n-\t\tif (!record.SourceIndex.IsValid() && (!c.files[sourceIndex].isEntryPoint || !c.options.OutputFormat.KeepES6ImportExportSyntax())) ||\n+\t\tif (!record.SourceIndex.IsValid() && (!c.files[sourceIndex].isEntryPoint() || !c.options.OutputFormat.KeepES6ImportExportSyntax())) ||\n \t\t\t(record.SourceIndex.IsValid() && record.SourceIndex.GetIndex() != sourceIndex && c.hasDynamicExportsDueToExportStar(record.SourceIndex.GetIndex(), visited)) {\n \t\t\trepr.ast.ExportsKind = js_ast.ExportsESMWithDynamicFallback\n \t\t\treturn true\n@@ -2380,19 +2439,58 @@ func (c *linkerContext) markPartsReachableFromEntryPoints() {\n \t\t\t\t}, partMeta{\n \t\t\t\t\tnonLocalDependencies: nonLocalDependencies,\n \t\t\t\t})\n-\t\t\t\trepr.meta.cjsWrapperPartIndex = ast.MakeIndex32(partIndex)\n+\t\t\t\trepr.meta.wrapperPartIndex = ast.MakeIndex32(partIndex)\n \t\t\t\trepr.ast.TopLevelSymbolToParts[repr.ast.WrapperRef] = []uint32{partIndex}\n \t\t\t\trepr.meta.importsToBind[commonJSRef] = importToBind{\n \t\t\t\t\tref:         commonJSRef,\n \t\t\t\t\tsourceIndex: runtime.SourceIndex,\n \t\t\t\t}\n \t\t\t}\n+\n+\t\t\t// If this is a lazily-initialized ESM file, we're going to need to\n+\t\t\t// generate a wrapper for the ESM closure. That will end up looking\n+\t\t\t// something like this:\n+\t\t\t//\n+\t\t\t//   var init_foo = __esm((exports, module) => {\n+\t\t\t//     ...\n+\t\t\t//   });\n+\t\t\t//\n+\t\t\t// This depends on the \"__esm\" symbol and declares the \"init_foo\" symbol\n+\t\t\t// for similar reasons to the CommonJS closure above.\n+\t\t\tif repr.meta.wrap == wrapESM {\n+\t\t\t\truntimeRepr := c.files[runtime.SourceIndex].repr.(*reprJS)\n+\t\t\t\tesmRef := runtimeRepr.ast.NamedExports[\"__esm\"].Ref\n+\t\t\t\tesmParts := runtimeRepr.ast.TopLevelSymbolToParts[esmRef]\n+\n+\t\t\t\t// Generate the dummy part\n+\t\t\t\tnonLocalDependencies := make([]partRef, len(esmParts))\n+\t\t\t\tfor i, partIndex := range esmParts {\n+\t\t\t\t\tnonLocalDependencies[i] = partRef{sourceIndex: runtime.SourceIndex, partIndex: partIndex}\n+\t\t\t\t}\n+\t\t\t\tpartIndex := c.addPartToFile(sourceIndex, js_ast.Part{\n+\t\t\t\t\tSymbolUses: map[js_ast.Ref]js_ast.SymbolUse{\n+\t\t\t\t\t\trepr.ast.WrapperRef: {CountEstimate: 1},\n+\t\t\t\t\t\tesmRef:              {CountEstimate: 1},\n+\t\t\t\t\t},\n+\t\t\t\t\tDeclaredSymbols: []js_ast.DeclaredSymbol{\n+\t\t\t\t\t\t{Ref: repr.ast.WrapperRef, IsTopLevel: true},\n+\t\t\t\t\t},\n+\t\t\t\t}, partMeta{\n+\t\t\t\t\tnonLocalDependencies: nonLocalDependencies,\n+\t\t\t\t})\n+\t\t\t\trepr.meta.wrapperPartIndex = ast.MakeIndex32(partIndex)\n+\t\t\t\trepr.ast.TopLevelSymbolToParts[repr.ast.WrapperRef] = []uint32{partIndex}\n+\t\t\t\trepr.meta.importsToBind[esmRef] = importToBind{\n+\t\t\t\t\tref:         esmRef,\n+\t\t\t\t\tsourceIndex: runtime.SourceIndex,\n+\t\t\t\t}\n+\t\t\t}\n \t\t}\n \t}\n \n \t// Each entry point marks all files reachable from itself\n \tfor i, entryPoint := range c.entryPoints {\n-\t\tc.includeFile(entryPoint, uint(i), 0)\n+\t\tc.includeFile(entryPoint.sourceIndex, uint(i), 0)\n \t}\n }\n \n@@ -2451,13 +2549,13 @@ func (c *linkerContext) includeFile(sourceIndex uint32, entryPointBit uint, dist\n \t\t\t// Include all parts in this file with side effects, or just include\n \t\t\t// everything if tree-shaking is disabled. Note that we still want to\n \t\t\t// perform tree-shaking on the runtime even if tree-shaking is disabled.\n-\t\t\tif !canBeRemovedIfUnused || (!part.ForceTreeShaking && !isTreeShakingEnabled && file.isEntryPoint) {\n+\t\t\tif !canBeRemovedIfUnused || (!part.ForceTreeShaking && !isTreeShakingEnabled && file.isEntryPoint()) {\n \t\t\t\tc.includePart(sourceIndex, uint32(partIndex), entryPointBit, distanceFromEntryPoint)\n \t\t\t}\n \t\t}\n \n \t\t// If this is an entry point, include all exports\n-\t\tif file.isEntryPoint {\n+\t\tif file.isEntryPoint() {\n \t\t\tfor _, alias := range repr.meta.sortedAndFilteredExportAliases {\n \t\t\t\texport := repr.meta.resolvedExports[alias]\n \t\t\t\ttargetSourceIndex := export.sourceIndex\n@@ -2484,7 +2582,7 @@ func (c *linkerContext) includeFile(sourceIndex uint32, entryPointBit uint, dist\n \n \t\t\t// Include the wrapper if present\n \t\t\tif repr.meta.wrap != wrapNone {\n-\t\t\t\tc.includePart(sourceIndex, repr.meta.cjsWrapperPartIndex.GetIndex(), entryPointBit, distanceFromEntryPoint)\n+\t\t\t\tc.includePart(sourceIndex, repr.meta.wrapperPartIndex.GetIndex(), entryPointBit, distanceFromEntryPoint)\n \t\t\t}\n \t\t}\n \n@@ -2531,7 +2629,7 @@ func (c *linkerContext) generateUseOfSymbolForInclude(\n }\n \n func (c *linkerContext) isExternalDynamicImport(record *ast.ImportRecord) bool {\n-\treturn record.Kind == ast.ImportDynamic && c.files[record.SourceIndex.GetIndex()].isEntryPoint\n+\treturn record.Kind == ast.ImportDynamic && c.files[record.SourceIndex.GetIndex()].isEntryPoint()\n }\n \n func (c *linkerContext) includePart(sourceIndex uint32, partIndex uint32, entryPointBit uint, distanceFromEntryPoint uint32) {\n@@ -2590,10 +2688,16 @@ func (c *linkerContext) includePart(sourceIndex uint32, partIndex uint32, entryP\n \n \t\t\t// This is an ES6 import of a CommonJS module, so it needs the\n \t\t\t// \"__toModule\" wrapper as long as it's not a bare \"require()\"\n-\t\t\tif record.Kind != ast.ImportRequire && otherRepr.ast.ExportKeyword.Len == 0 {\n+\t\t\tif record.Kind != ast.ImportRequire && otherRepr.ast.ExportsKind == js_ast.ExportsCommonJS {\n \t\t\t\trecord.WrapWithToModule = true\n \t\t\t\ttoModuleUses++\n \t\t\t}\n+\n+\t\t\t// If this is an ESM wrapper, also depend on the exports object\n+\t\t\t// since the final code will contain an inline reference to it\n+\t\t\tif otherRepr.meta.wrap == wrapESM {\n+\t\t\t\tc.includePart(otherSourceIndex, otherRepr.meta.nsExportPartIndex, entryPointBit, distanceFromEntryPoint)\n+\t\t\t}\n \t\t} else if record.Kind == ast.ImportStmt && otherRepr.ast.ExportsKind == js_ast.ExportsESMWithDynamicFallback {\n \t\t\t// This is an import of a module that has a dynamic export fallback\n \t\t\t// object. In that case we need to depend on that object in case\n@@ -2616,7 +2720,7 @@ func (c *linkerContext) includePart(sourceIndex uint32, partIndex uint32, entryP\n \t\trecord := &repr.ast.ImportRecords[importRecordIndex]\n \n \t\t// Is this export star evaluated at run time?\n-\t\thappensAtRunTime := !record.SourceIndex.IsValid() && (!file.isEntryPoint || !c.options.OutputFormat.KeepES6ImportExportSyntax())\n+\t\thappensAtRunTime := !record.SourceIndex.IsValid() && (!file.isEntryPoint() || !c.options.OutputFormat.KeepES6ImportExportSyntax())\n \t\tif record.SourceIndex.IsValid() {\n \t\t\totherSourceIndex := record.SourceIndex.GetIndex()\n \t\t\totherRepr := c.files[otherSourceIndex].repr.(*reprJS)\n@@ -2641,18 +2745,16 @@ func (c *linkerContext) includePart(sourceIndex uint32, partIndex uint32, entryP\n \tc.includePartsForRuntimeSymbol(part, &repr.meta, exportStarUses, \"__exportStar\", entryPointBit, distanceFromEntryPoint)\n }\n \n-func baseFileNameForVirtualModulePath(path string) string {\n-\t_, base, ext := logger.PlatformIndependentPathDirBaseExt(path)\n-\n-\t// Convert it to a safe file name. See: https://stackoverflow.com/a/31976060\n+func sanitizeFilePathForVirtualModulePath(path string) string {\n+\t// Convert it to a safe file path. See: https://stackoverflow.com/a/31976060\n \tsb := strings.Builder{}\n \tneedsGap := false\n-\tfor _, c := range base + ext {\n+\tfor _, c := range path {\n \t\tswitch c {\n-\t\tcase 0, '/':\n+\t\tcase 0:\n \t\t\t// These characters are forbidden on Unix and Windows\n \n-\t\tcase '<', '>', ':', '\"', '\\\\', '|', '?', '*':\n+\t\tcase '<', '>', ':', '\"', '|', '?', '*':\n \t\t\t// These characters are forbidden on Windows\n \n \t\tdefault:\n@@ -2691,9 +2793,9 @@ func (c *linkerContext) computeChunks() []chunkInfo {\n \tcssChunks := make(map[string]chunkInfo)\n \tneverReachedKey := string(newBitSet(uint(len(c.entryPoints))).entries)\n \n-\t// Compute entry point names\n+\t// Create chunks for entry points\n \tfor i, entryPoint := range c.entryPoints {\n-\t\tfile := &c.files[entryPoint]\n+\t\tfile := &c.files[entryPoint.sourceIndex]\n \n \t\t// Create a chunk for the entry point here to ensure that the chunk is\n \t\t// always generated even if the resulting file is empty\n@@ -2702,7 +2804,7 @@ func (c *linkerContext) computeChunks() []chunkInfo {\n \t\tinfo := chunkInfo{\n \t\t\tentryBits:             entryBits,\n \t\t\tisEntryPoint:          true,\n-\t\t\tsourceIndex:           entryPoint,\n+\t\t\tsourceIndex:           entryPoint.sourceIndex,\n \t\t\tentryPointBit:         uint(i),\n \t\t\tfilesWithPartsInChunk: make(map[uint32]bool),\n \t\t}\n@@ -2839,8 +2941,13 @@ func (c *linkerContext) computeChunks() []chunkInfo {\n \t\tvar dir, base, ext string\n \t\tvar template []config.PathTemplate\n \t\tif chunk.isEntryPoint {\n-\t\t\tdir, base, ext = c.pathRelativeToOutbase(chunk.sourceIndex, stdExt)\n-\t\t\ttemplate = c.options.EntryPathTemplate\n+\t\t\tif c.files[chunk.sourceIndex].entryPointKind == entryPointUserSpecified {\n+\t\t\t\tdir, base, ext = c.pathRelativeToOutbase(chunk.sourceIndex, chunk.entryPointBit, stdExt, false /* avoidIndex */)\n+\t\t\t\ttemplate = c.options.EntryPathTemplate\n+\t\t\t} else {\n+\t\t\t\tdir, base, ext = c.pathRelativeToOutbase(chunk.sourceIndex, chunk.entryPointBit, stdExt, true /* avoidIndex */)\n+\t\t\t\ttemplate = c.options.ChunkPathTemplate\n+\t\t\t}\n \t\t} else {\n \t\t\tdir = \"/\"\n \t\t\tbase = \"chunk\"\n@@ -2892,12 +2999,12 @@ func appendOrExtendPartRange(ranges []partRange, sourceIndex uint32, partIndex u\n \n func (c *linkerContext) shouldIncludePart(repr *reprJS, part js_ast.Part) bool {\n \t// As an optimization, ignore parts containing a single import statement to\n-\t// an internal non-CommonJS file. These will be ignored anyway and it's a\n+\t// an internal non-wrapped file. These will be ignored anyway and it's a\n \t// performance hit to spin up a goroutine only to discover this later.\n \tif len(part.Stmts) == 1 {\n \t\tif s, ok := part.Stmts[0].Data.(*js_ast.SImport); ok {\n \t\t\trecord := &repr.ast.ImportRecords[s.ImportRecordIndex]\n-\t\t\tif record.SourceIndex.IsValid() && c.files[record.SourceIndex.GetIndex()].repr.(*reprJS).ast.ExportsKind != js_ast.ExportsCommonJS {\n+\t\t\tif record.SourceIndex.IsValid() && c.files[record.SourceIndex.GetIndex()].repr.(*reprJS).meta.wrap == wrapNone {\n \t\t\t\treturn false\n \t\t\t}\n \t\t}\n@@ -3017,23 +3124,29 @@ func (c *linkerContext) chunkFileOrder(chunk *chunkInfo) (js []uint32, jsParts [\n func (c *linkerContext) shouldRemoveImportExportStmt(\n \tsourceIndex uint32,\n \tstmtList *stmtList,\n-\tpartStmts []js_ast.Stmt,\n \tloc logger.Loc,\n \tnamespaceRef js_ast.Ref,\n \timportRecordIndex uint32,\n ) bool {\n-\t// Is this an import from another module inside this bundle?\n \trepr := c.files[sourceIndex].repr.(*reprJS)\n \trecord := &repr.ast.ImportRecords[importRecordIndex]\n-\tif record.SourceIndex.IsValid() {\n-\t\tif c.files[record.SourceIndex.GetIndex()].repr.(*reprJS).ast.ExportsKind != js_ast.ExportsCommonJS {\n-\t\t\t// Remove the statement entirely if this is not a CommonJS module\n-\t\t\treturn true\n+\n+\t// Is this an external import?\n+\tif !record.SourceIndex.IsValid() {\n+\t\t// Keep the \"import\" statement if \"import\" statements are supported\n+\t\tif c.options.OutputFormat.KeepES6ImportExportSyntax() {\n+\t\t\treturn false\n \t\t}\n-\t} else if c.options.OutputFormat.KeepES6ImportExportSyntax() {\n-\t\t// If this is an external module and the output format allows ES6\n-\t\t// import/export syntax, then just keep the statement\n-\t\treturn false\n+\n+\t\t// Otherwise, replace this statement with a call to \"require()\"\n+\t\tstmtList.insideWrapperPrefix = append(stmtList.insideWrapperPrefix, js_ast.Stmt{\n+\t\t\tLoc: loc,\n+\t\t\tData: &js_ast.SLocal{Decls: []js_ast.Decl{{\n+\t\t\t\tBinding: js_ast.Binding{Loc: loc, Data: &js_ast.BIdentifier{Ref: namespaceRef}},\n+\t\t\t\tValue:   &js_ast.Expr{Loc: record.Range.Loc, Data: &js_ast.ERequire{ImportRecordIndex: importRecordIndex}},\n+\t\t\t}}},\n+\t\t})\n+\t\treturn true\n \t}\n \n \t// We don't need a call to \"require()\" if this is a self-import inside a\n@@ -3042,106 +3155,61 @@ func (c *linkerContext) shouldRemoveImportExportStmt(\n \t\treturn true\n \t}\n \n-\t// Replace the statement with a call to \"require()\"\n-\tstmtList.prefixStmts = append(stmtList.prefixStmts, js_ast.Stmt{\n-\t\tLoc: loc,\n-\t\tData: &js_ast.SLocal{Decls: []js_ast.Decl{{\n-\t\t\tBinding: js_ast.Binding{Loc: loc, Data: &js_ast.BIdentifier{Ref: namespaceRef}},\n-\t\t\tValue:   &js_ast.Expr{Loc: record.Range.Loc, Data: &js_ast.ERequire{ImportRecordIndex: importRecordIndex}},\n-\t\t}}},\n-\t})\n+\totherRepr := c.files[record.SourceIndex.GetIndex()].repr.(*reprJS)\n+\tswitch otherRepr.meta.wrap {\n+\tcase wrapNone:\n+\t\t// Remove the statement entirely if this module is not wrapped\n+\n+\tcase wrapCJS:\n+\t\t// Replace the statement with a call to \"require()\"\n+\t\tstmtList.insideWrapperPrefix = append(stmtList.insideWrapperPrefix, js_ast.Stmt{\n+\t\t\tLoc: loc,\n+\t\t\tData: &js_ast.SLocal{Decls: []js_ast.Decl{{\n+\t\t\t\tBinding: js_ast.Binding{Loc: loc, Data: &js_ast.BIdentifier{Ref: namespaceRef}},\n+\t\t\t\tValue:   &js_ast.Expr{Loc: record.Range.Loc, Data: &js_ast.ERequire{ImportRecordIndex: importRecordIndex}},\n+\t\t\t}}},\n+\t\t})\n+\n+\tcase wrapESM:\n+\t\t// Replace the statement with a call to \"init()\"\n+\t\tvalue := js_ast.Expr{Loc: loc, Data: &js_ast.ECall{Target: js_ast.Expr{Loc: loc, Data: &js_ast.EIdentifier{Ref: otherRepr.ast.WrapperRef}}}}\n+\t\tif otherRepr.meta.isAsyncOrHasAsyncDependency {\n+\t\t\t// This currently evaluates sibling dependencies in serial instead of in\n+\t\t\t// parallel, which is incorrect. This should be changed to store a promise\n+\t\t\t// and await all stored promises after all imports but before any code.\n+\t\t\tvalue.Data = &js_ast.EAwait{Value: value}\n+\t\t}\n+\t\tstmtList.insideWrapperPrefix = append(stmtList.insideWrapperPrefix, js_ast.Stmt{Loc: loc, Data: &js_ast.SExpr{Value: value}})\n+\t}\n+\n \treturn true\n }\n \n func (c *linkerContext) convertStmtsForChunk(sourceIndex uint32, stmtList *stmtList, partStmts []js_ast.Stmt) {\n \tfile := &c.files[sourceIndex]\n-\tshouldStripExports := c.options.Mode != config.ModePassThrough || !file.isEntryPoint\n+\tshouldStripExports := c.options.Mode != config.ModePassThrough || !file.isEntryPoint()\n \trepr := file.repr.(*reprJS)\n-\tshouldExtractES6StmtsForWrap := repr.meta.wrap != wrapNone\n+\tshouldExtractESMStmtsForWrap := repr.meta.wrap != wrapNone\n \n \tfor _, stmt := range partStmts {\n \t\tswitch s := stmt.Data.(type) {\n \t\tcase *js_ast.SImport:\n \t\t\t// \"import * as ns from 'path'\"\n \t\t\t// \"import {foo} from 'path'\"\n-\t\t\tif c.shouldRemoveImportExportStmt(sourceIndex, stmtList, partStmts, stmt.Loc, s.NamespaceRef, s.ImportRecordIndex) {\n+\t\t\tif c.shouldRemoveImportExportStmt(sourceIndex, stmtList, stmt.Loc, s.NamespaceRef, s.ImportRecordIndex) {\n \t\t\t\tcontinue\n \t\t\t}\n \n-\t\t\t// Make sure these don't end up in a CommonJS wrapper\n-\t\t\tif shouldExtractES6StmtsForWrap {\n-\t\t\t\tstmtList.es6StmtsForWrap = append(stmtList.es6StmtsForWrap, stmt)\n+\t\t\t// Make sure these don't end up in the wrapper closure\n+\t\t\tif shouldExtractESMStmtsForWrap {\n+\t\t\t\tstmtList.outsideWrapperPrefix = append(stmtList.outsideWrapperPrefix, stmt)\n \t\t\t\tcontinue\n \t\t\t}\n \n \t\tcase *js_ast.SExportStar:\n-\t\t\tif s.Alias == nil {\n-\t\t\t\t// \"export * from 'path'\"\n-\t\t\t\tif shouldStripExports {\n-\t\t\t\t\trecord := &repr.ast.ImportRecords[s.ImportRecordIndex]\n-\n-\t\t\t\t\t// Is this export star evaluated at run time?\n-\t\t\t\t\tif !record.SourceIndex.IsValid() && c.options.OutputFormat.KeepES6ImportExportSyntax() {\n-\t\t\t\t\t\tif record.CallsRunTimeExportStarFn {\n-\t\t\t\t\t\t\t// Turn this statement into \"import * as ns from 'path'\"\n-\t\t\t\t\t\t\tstmt.Data = &js_ast.SImport{\n-\t\t\t\t\t\t\t\tNamespaceRef:      s.NamespaceRef,\n-\t\t\t\t\t\t\t\tStarNameLoc:       &stmt.Loc,\n-\t\t\t\t\t\t\t\tImportRecordIndex: s.ImportRecordIndex,\n-\t\t\t\t\t\t\t}\n-\n-\t\t\t\t\t\t\t// Prefix this module with \"__exportStar(exports, ns)\"\n-\t\t\t\t\t\t\texportStarRef := c.files[runtime.SourceIndex].repr.(*reprJS).ast.ModuleScope.Members[\"__exportStar\"].Ref\n-\t\t\t\t\t\t\tstmtList.prefixStmts = append(stmtList.prefixStmts, js_ast.Stmt{\n-\t\t\t\t\t\t\t\tLoc: stmt.Loc,\n-\t\t\t\t\t\t\t\tData: &js_ast.SExpr{Value: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.ECall{\n-\t\t\t\t\t\t\t\t\tTarget: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: exportStarRef}},\n-\t\t\t\t\t\t\t\t\tArgs: []js_ast.Expr{\n-\t\t\t\t\t\t\t\t\t\t{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: repr.ast.ExportsRef}},\n-\t\t\t\t\t\t\t\t\t\t{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: s.NamespaceRef}},\n-\t\t\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\t\t}}},\n-\t\t\t\t\t\t\t})\n-\n-\t\t\t\t\t\t\t// Make sure these don't end up in a CommonJS wrapper\n-\t\t\t\t\t\t\tif shouldExtractES6StmtsForWrap {\n-\t\t\t\t\t\t\t\tstmtList.es6StmtsForWrap = append(stmtList.es6StmtsForWrap, stmt)\n-\t\t\t\t\t\t\t\tcontinue\n-\t\t\t\t\t\t\t}\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tif record.CallsRunTimeExportStarFn {\n-\t\t\t\t\t\t\tvar target js_ast.E\n-\t\t\t\t\t\t\tif record.SourceIndex.IsValid() {\n-\t\t\t\t\t\t\t\tif repr := c.files[record.SourceIndex.GetIndex()].repr.(*reprJS); repr.ast.ExportsKind == js_ast.ExportsESMWithDynamicFallback {\n-\t\t\t\t\t\t\t\t\t// Prefix this module with \"__exportStar(exports, otherExports)\"\n-\t\t\t\t\t\t\t\t\ttarget = &js_ast.EIdentifier{Ref: repr.ast.ExportsRef}\n-\t\t\t\t\t\t\t\t}\n-\t\t\t\t\t\t\t}\n-\t\t\t\t\t\t\tif target == nil {\n-\t\t\t\t\t\t\t\t// Prefix this module with \"__exportStar(exports, require(path))\"\n-\t\t\t\t\t\t\t\ttarget = &js_ast.ERequire{ImportRecordIndex: s.ImportRecordIndex}\n-\t\t\t\t\t\t\t}\n-\t\t\t\t\t\t\texportStarRef := c.files[runtime.SourceIndex].repr.(*reprJS).ast.ModuleScope.Members[\"__exportStar\"].Ref\n-\t\t\t\t\t\t\tstmtList.prefixStmts = append(stmtList.prefixStmts, js_ast.Stmt{\n-\t\t\t\t\t\t\t\tLoc: stmt.Loc,\n-\t\t\t\t\t\t\t\tData: &js_ast.SExpr{Value: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.ECall{\n-\t\t\t\t\t\t\t\t\tTarget: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: exportStarRef}},\n-\t\t\t\t\t\t\t\t\tArgs: []js_ast.Expr{\n-\t\t\t\t\t\t\t\t\t\t{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: repr.ast.ExportsRef}},\n-\t\t\t\t\t\t\t\t\t\t{Loc: record.Range.Loc, Data: target},\n-\t\t\t\t\t\t\t\t\t},\n-\t\t\t\t\t\t\t\t}}},\n-\t\t\t\t\t\t\t})\n-\t\t\t\t\t\t}\n-\n-\t\t\t\t\t\t// Remove the export star statement\n-\t\t\t\t\t\tcontinue\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\t// \"export * as ns from 'path'\"\n-\t\t\t\tif c.shouldRemoveImportExportStmt(sourceIndex, stmtList, partStmts, stmt.Loc, s.NamespaceRef, s.ImportRecordIndex) {\n+\t\t\t// \"export * as ns from 'path'\"\n+\t\t\tif s.Alias != nil {\n+\t\t\t\tif c.shouldRemoveImportExportStmt(sourceIndex, stmtList, stmt.Loc, s.NamespaceRef, s.ImportRecordIndex) {\n \t\t\t\t\tcontinue\n \t\t\t\t}\n \n@@ -3154,16 +3222,90 @@ func (c *linkerContext) convertStmtsForChunk(sourceIndex uint32, stmtList *stmtL\n \t\t\t\t\t}\n \t\t\t\t}\n \n-\t\t\t\t// Make sure these don't end up in a CommonJS wrapper\n-\t\t\t\tif shouldExtractES6StmtsForWrap {\n-\t\t\t\t\tstmtList.es6StmtsForWrap = append(stmtList.es6StmtsForWrap, stmt)\n+\t\t\t\t// Make sure these don't end up in the wrapper closure\n+\t\t\t\tif shouldExtractESMStmtsForWrap {\n+\t\t\t\t\tstmtList.outsideWrapperPrefix = append(stmtList.outsideWrapperPrefix, stmt)\n \t\t\t\t\tcontinue\n \t\t\t\t}\n+\t\t\t\tbreak\n+\t\t\t}\n+\n+\t\t\t// \"export * from 'path'\"\n+\t\t\tif !shouldStripExports {\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t\trecord := &repr.ast.ImportRecords[s.ImportRecordIndex]\n+\n+\t\t\t// Is this export star evaluated at run time?\n+\t\t\tif !record.SourceIndex.IsValid() && c.options.OutputFormat.KeepES6ImportExportSyntax() {\n+\t\t\t\tif record.CallsRunTimeExportStarFn {\n+\t\t\t\t\t// Turn this statement into \"import * as ns from 'path'\"\n+\t\t\t\t\tstmt.Data = &js_ast.SImport{\n+\t\t\t\t\t\tNamespaceRef:      s.NamespaceRef,\n+\t\t\t\t\t\tStarNameLoc:       &stmt.Loc,\n+\t\t\t\t\t\tImportRecordIndex: s.ImportRecordIndex,\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t// Prefix this module with \"__exportStar(exports, ns)\"\n+\t\t\t\t\texportStarRef := c.files[runtime.SourceIndex].repr.(*reprJS).ast.ModuleScope.Members[\"__exportStar\"].Ref\n+\t\t\t\t\tstmtList.insideWrapperPrefix = append(stmtList.insideWrapperPrefix, js_ast.Stmt{\n+\t\t\t\t\t\tLoc: stmt.Loc,\n+\t\t\t\t\t\tData: &js_ast.SExpr{Value: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.ECall{\n+\t\t\t\t\t\t\tTarget: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: exportStarRef}},\n+\t\t\t\t\t\t\tArgs: []js_ast.Expr{\n+\t\t\t\t\t\t\t\t{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: repr.ast.ExportsRef}},\n+\t\t\t\t\t\t\t\t{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: s.NamespaceRef}},\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t}}},\n+\t\t\t\t\t})\n+\n+\t\t\t\t\t// Make sure these don't end up in the wrapper closure\n+\t\t\t\t\tif shouldExtractESMStmtsForWrap {\n+\t\t\t\t\t\tstmtList.outsideWrapperPrefix = append(stmtList.outsideWrapperPrefix, stmt)\n+\t\t\t\t\t\tcontinue\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tif record.SourceIndex.IsValid() {\n+\t\t\t\t\tif otherRepr := c.files[record.SourceIndex.GetIndex()].repr.(*reprJS); otherRepr.meta.wrap == wrapESM {\n+\t\t\t\t\t\tstmtList.insideWrapperPrefix = append(stmtList.insideWrapperPrefix, js_ast.Stmt{Loc: stmt.Loc,\n+\t\t\t\t\t\t\tData: &js_ast.SExpr{Value: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.ECall{\n+\t\t\t\t\t\t\t\tTarget: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: otherRepr.ast.WrapperRef}}}}}})\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tif record.CallsRunTimeExportStarFn {\n+\t\t\t\t\tvar target js_ast.E\n+\t\t\t\t\tif record.SourceIndex.IsValid() {\n+\t\t\t\t\t\tif otherRepr := c.files[record.SourceIndex.GetIndex()].repr.(*reprJS); otherRepr.ast.ExportsKind == js_ast.ExportsESMWithDynamicFallback {\n+\t\t\t\t\t\t\t// Prefix this module with \"__exportStar(exports, otherExports)\"\n+\t\t\t\t\t\t\ttarget = &js_ast.EIdentifier{Ref: otherRepr.ast.ExportsRef}\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tif target == nil {\n+\t\t\t\t\t\t// Prefix this module with \"__exportStar(exports, require(path))\"\n+\t\t\t\t\t\ttarget = &js_ast.ERequire{ImportRecordIndex: s.ImportRecordIndex}\n+\t\t\t\t\t}\n+\t\t\t\t\texportStarRef := c.files[runtime.SourceIndex].repr.(*reprJS).ast.ModuleScope.Members[\"__exportStar\"].Ref\n+\t\t\t\t\tstmtList.insideWrapperPrefix = append(stmtList.insideWrapperPrefix, js_ast.Stmt{\n+\t\t\t\t\t\tLoc: stmt.Loc,\n+\t\t\t\t\t\tData: &js_ast.SExpr{Value: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.ECall{\n+\t\t\t\t\t\t\tTarget: js_ast.Expr{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: exportStarRef}},\n+\t\t\t\t\t\t\tArgs: []js_ast.Expr{\n+\t\t\t\t\t\t\t\t{Loc: stmt.Loc, Data: &js_ast.EIdentifier{Ref: repr.ast.ExportsRef}},\n+\t\t\t\t\t\t\t\t{Loc: record.Range.Loc, Data: target},\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t}}},\n+\t\t\t\t\t})\n+\t\t\t\t}\n+\n+\t\t\t\t// Remove the export star statement\n+\t\t\t\tcontinue\n \t\t\t}\n \n \t\tcase *js_ast.SExportFrom:\n \t\t\t// \"export {foo} from 'path'\"\n-\t\t\tif c.shouldRemoveImportExportStmt(sourceIndex, stmtList, partStmts, stmt.Loc, s.NamespaceRef, s.ImportRecordIndex) {\n+\t\t\tif c.shouldRemoveImportExportStmt(sourceIndex, stmtList, stmt.Loc, s.NamespaceRef, s.ImportRecordIndex) {\n \t\t\t\tcontinue\n \t\t\t}\n \n@@ -3180,9 +3322,9 @@ func (c *linkerContext) convertStmtsForChunk(sourceIndex uint32, stmtList *stmtL\n \t\t\t\t}\n \t\t\t}\n \n-\t\t\t// Make sure these don't end up in a CommonJS wrapper\n-\t\t\tif shouldExtractES6StmtsForWrap {\n-\t\t\t\tstmtList.es6StmtsForWrap = append(stmtList.es6StmtsForWrap, stmt)\n+\t\t\t// Make sure these don't end up in the wrapper closure\n+\t\t\tif shouldExtractESMStmtsForWrap {\n+\t\t\t\tstmtList.outsideWrapperPrefix = append(stmtList.outsideWrapperPrefix, stmt)\n \t\t\t\tcontinue\n \t\t\t}\n \n@@ -3192,9 +3334,9 @@ func (c *linkerContext) convertStmtsForChunk(sourceIndex uint32, stmtList *stmtL\n \t\t\t\tcontinue\n \t\t\t}\n \n-\t\t\t// Make sure these don't end up in a CommonJS wrapper\n-\t\t\tif shouldExtractES6StmtsForWrap {\n-\t\t\t\tstmtList.es6StmtsForWrap = append(stmtList.es6StmtsForWrap, stmt)\n+\t\t\t// Make sure these don't end up in the wrapper closure\n+\t\t\tif shouldExtractESMStmtsForWrap {\n+\t\t\t\tstmtList.outsideWrapperPrefix = append(stmtList.outsideWrapperPrefix, stmt)\n \t\t\t\tcontinue\n \t\t\t}\n \n@@ -3260,7 +3402,7 @@ func (c *linkerContext) convertStmtsForChunk(sourceIndex uint32, stmtList *stmtL\n \t\t\t}\n \t\t}\n \n-\t\tstmtList.normalStmts = append(stmtList.normalStmts, stmt)\n+\t\tstmtList.insideWrapperSuffix = append(stmtList.insideWrapperSuffix, stmt)\n \t}\n }\n \n@@ -3306,15 +3448,13 @@ func mergeAdjacentLocalStmts(stmts []js_ast.Stmt) []js_ast.Stmt {\n }\n \n type stmtList struct {\n-\t// These statements come first, and can be inside the CommonJS wrapper\n-\tprefixStmts []js_ast.Stmt\n+\t// These statements come first, and can be inside the wrapper\n+\tinsideWrapperPrefix []js_ast.Stmt\n \n-\t// These statements come last, and can be inside the CommonJS wrapper\n-\tnormalStmts []js_ast.Stmt\n+\t// These statements come last, and can be inside the wrapper\n+\tinsideWrapperSuffix []js_ast.Stmt\n \n-\t// Order doesn't matter for these statements, but they must be outside any\n-\t// CommonJS wrapper since they are top-level ES6 import/export statements\n-\tes6StmtsForWrap []js_ast.Stmt\n+\toutsideWrapperPrefix []js_ast.Stmt\n }\n \n type compileResultJS struct {\n@@ -3327,13 +3467,26 @@ type compileResultJS struct {\n \tgeneratedOffset sourcemap.LineColumnOffset\n }\n \n+func (c *linkerContext) requireOrImportMetaForSource(sourceIndex uint32) (meta js_printer.RequireOrImportMeta) {\n+\trepr := c.files[sourceIndex].repr.(*reprJS)\n+\tmeta.WrapperRef = repr.ast.WrapperRef\n+\tmeta.IsWrapperAsync = repr.meta.isAsyncOrHasAsyncDependency\n+\tif repr.meta.wrap == wrapESM {\n+\t\tmeta.ExportsRef = repr.ast.ExportsRef\n+\t} else {\n+\t\tmeta.ExportsRef = js_ast.InvalidRef\n+\t}\n+\treturn\n+}\n+\n func (c *linkerContext) generateCodeForFileInChunkJS(\n \tr renamer.Renamer,\n \twaitGroup *sync.WaitGroup,\n \tpartRange partRange,\n \tentryBits bitSet,\n \tchunkAbsDir string,\n \tcommonJSRef js_ast.Ref,\n+\tesmRef js_ast.Ref,\n \ttoModuleRef js_ast.Ref,\n \tresult *compileResultJS,\n \tdataForSourceMaps []dataForSourceMap,\n@@ -3351,8 +3504,12 @@ func (c *linkerContext) generateCodeForFileInChunkJS(\n \t\tc.convertStmtsForChunk(partRange.sourceIndex, &stmtList, repr.ast.Parts[nsExportPartIndex].Stmts)\n \n \t\t// Move everything to the prefix list\n-\t\tstmtList.prefixStmts = append(stmtList.prefixStmts, stmtList.normalStmts...)\n-\t\tstmtList.normalStmts = nil\n+\t\tif repr.meta.wrap == wrapESM {\n+\t\t\tstmtList.outsideWrapperPrefix = append(stmtList.outsideWrapperPrefix, stmtList.insideWrapperSuffix...)\n+\t\t} else {\n+\t\t\tstmtList.insideWrapperPrefix = append(stmtList.insideWrapperPrefix, stmtList.insideWrapperSuffix...)\n+\t\t}\n+\t\tstmtList.insideWrapperSuffix = nil\n \t}\n \n \t// Add all other parts in this chunk\n@@ -3368,8 +3525,8 @@ func (c *linkerContext) generateCodeForFileInChunkJS(\n \t\t\tcontinue\n \t\t}\n \n-\t\t// Mark if we hit the dummy part representing the CommonJS wrapper\n-\t\tif uint32(partIndex) == repr.meta.cjsWrapperPartIndex.GetIndex() {\n+\t\t// Mark if we hit the dummy part representing the wrapper\n+\t\tif uint32(partIndex) == repr.meta.wrapperPartIndex.GetIndex() {\n \t\t\tneedsWrapper = true\n \t\t\tcontinue\n \t\t}\n@@ -3383,46 +3540,119 @@ func (c *linkerContext) generateCodeForFileInChunkJS(\n \t// evaluated (well, except for cyclic import scenarios). We need to preserve\n \t// these semantics even when modules imported via ES6 import statements end\n \t// up being CommonJS modules.\n-\tstmts := stmtList.normalStmts\n-\tif len(stmtList.prefixStmts) > 0 {\n-\t\tstmts = append(stmtList.prefixStmts, stmts...)\n+\tstmts := stmtList.insideWrapperSuffix\n+\tif len(stmtList.insideWrapperPrefix) > 0 {\n+\t\tstmts = append(stmtList.insideWrapperPrefix, stmts...)\n \t}\n \tif c.options.MangleSyntax {\n \t\tstmts = mergeAdjacentLocalStmts(stmts)\n \t}\n \n-\t// Optionally wrap all statements in a closure for CommonJS\n+\t// Optionally wrap all statements in a closure\n \tif needsWrapper {\n-\t\t// Only include the arguments that are actually used\n-\t\targs := []js_ast.Arg{}\n-\t\tif repr.ast.UsesExportsRef || repr.ast.UsesModuleRef {\n-\t\t\targs = append(args, js_ast.Arg{Binding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.ast.ExportsRef}}})\n-\t\t\tif repr.ast.UsesModuleRef {\n-\t\t\t\targs = append(args, js_ast.Arg{Binding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.ast.ModuleRef}}})\n+\t\tswitch repr.meta.wrap {\n+\t\tcase wrapCJS:\n+\t\t\t// Only include the arguments that are actually used\n+\t\t\targs := []js_ast.Arg{}\n+\t\t\tif repr.ast.UsesExportsRef || repr.ast.UsesModuleRef {\n+\t\t\t\targs = append(args, js_ast.Arg{Binding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.ast.ExportsRef}}})\n+\t\t\t\tif repr.ast.UsesModuleRef {\n+\t\t\t\t\targs = append(args, js_ast.Arg{Binding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.ast.ModuleRef}}})\n+\t\t\t\t}\n \t\t\t}\n-\t\t}\n \n-\t\t// \"__commonJS((exports, module) => { ... })\"\n-\t\tvar value js_ast.Expr\n-\t\tif c.options.UnsupportedJSFeatures.Has(compat.Arrow) {\n-\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n-\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: commonJSRef}},\n-\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EFunction{Fn: js_ast.Fn{Args: args, Body: js_ast.FnBody{Stmts: stmts}}}}},\n-\t\t\t}}\n-\t\t} else {\n-\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n-\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: commonJSRef}},\n-\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EArrow{Args: args, Body: js_ast.FnBody{Stmts: stmts}}}},\n-\t\t\t}}\n-\t\t}\n+\t\t\t// \"__commonJS((exports, module) => { ... })\"\n+\t\t\tvar value js_ast.Expr\n+\t\t\tif c.options.UnsupportedJSFeatures.Has(compat.Arrow) {\n+\t\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n+\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: commonJSRef}},\n+\t\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EFunction{Fn: js_ast.Fn{Args: args, Body: js_ast.FnBody{Stmts: stmts}}}}},\n+\t\t\t\t}}\n+\t\t\t} else {\n+\t\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n+\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: commonJSRef}},\n+\t\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EArrow{Args: args, Body: js_ast.FnBody{Stmts: stmts}}}},\n+\t\t\t\t}}\n+\t\t\t}\n \n-\t\t// \"var require_foo = __commonJS((exports, module) => { ... });\"\n-\t\tstmts = append(stmtList.es6StmtsForWrap, js_ast.Stmt{Data: &js_ast.SLocal{\n-\t\t\tDecls: []js_ast.Decl{{\n-\t\t\t\tBinding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.ast.WrapperRef}},\n-\t\t\t\tValue:   &value,\n-\t\t\t}},\n-\t\t}})\n+\t\t\t// \"var require_foo = __commonJS((exports, module) => { ... });\"\n+\t\t\tstmts = append(stmtList.outsideWrapperPrefix, js_ast.Stmt{Data: &js_ast.SLocal{\n+\t\t\t\tDecls: []js_ast.Decl{{\n+\t\t\t\t\tBinding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.ast.WrapperRef}},\n+\t\t\t\t\tValue:   &value,\n+\t\t\t\t}},\n+\t\t\t}})\n+\n+\t\tcase wrapESM:\n+\t\t\t// The wrapper only needs to be \"async\" if there is a transitive async\n+\t\t\t// dependency. For correctness, we must not use \"async\" if the module\n+\t\t\t// isn't async because then calling \"require()\" on that module would\n+\t\t\t// swallow any exceptions thrown during module initialization.\n+\t\t\tisAsync := repr.meta.isAsyncOrHasAsyncDependency\n+\n+\t\t\t// Hoist all top-level \"var\" and \"function\" declarations out of the closure\n+\t\t\tvar decls []js_ast.Decl\n+\t\t\tend := 0\n+\t\t\tfor _, stmt := range stmts {\n+\t\t\t\tswitch s := stmt.Data.(type) {\n+\t\t\t\tcase *js_ast.SLocal:\n+\t\t\t\t\t// Convert the declarations to assignments\n+\t\t\t\t\twrapIdentifier := func(loc logger.Loc, ref js_ast.Ref) js_ast.Expr {\n+\t\t\t\t\t\tdecls = append(decls, js_ast.Decl{Binding: js_ast.Binding{Loc: loc, Data: &js_ast.BIdentifier{Ref: ref}}})\n+\t\t\t\t\t\treturn js_ast.Expr{Loc: loc, Data: &js_ast.EIdentifier{Ref: ref}}\n+\t\t\t\t\t}\n+\t\t\t\t\tvar value js_ast.Expr\n+\t\t\t\t\tfor _, decl := range s.Decls {\n+\t\t\t\t\t\tbinding := js_ast.ConvertBindingToExpr(decl.Binding, wrapIdentifier)\n+\t\t\t\t\t\tif decl.Value != nil {\n+\t\t\t\t\t\t\tvalue = js_ast.JoinWithComma(value, js_ast.Assign(binding, *decl.Value))\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tif value.Data == nil {\n+\t\t\t\t\t\tcontinue\n+\t\t\t\t\t}\n+\t\t\t\t\tstmt = js_ast.Stmt{Loc: stmt.Loc, Data: &js_ast.SExpr{Value: value}}\n+\n+\t\t\t\tcase *js_ast.SFunction:\n+\t\t\t\t\tstmtList.outsideWrapperPrefix = append(stmtList.outsideWrapperPrefix, stmt)\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\n+\t\t\t\tstmts[end] = stmt\n+\t\t\t\tend++\n+\t\t\t}\n+\t\t\tstmts = stmts[:end]\n+\n+\t\t\t// \"__esm(() => { ... })\"\n+\t\t\tvar value js_ast.Expr\n+\t\t\tif c.options.UnsupportedJSFeatures.Has(compat.Arrow) {\n+\t\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n+\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: esmRef}},\n+\t\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EFunction{Fn: js_ast.Fn{Body: js_ast.FnBody{Stmts: stmts}, IsAsync: isAsync}}}},\n+\t\t\t\t}}\n+\t\t\t} else {\n+\t\t\t\tvalue = js_ast.Expr{Data: &js_ast.ECall{\n+\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: esmRef}},\n+\t\t\t\t\tArgs:   []js_ast.Expr{{Data: &js_ast.EArrow{Body: js_ast.FnBody{Stmts: stmts}, IsAsync: isAsync}}},\n+\t\t\t\t}}\n+\t\t\t}\n+\n+\t\t\t// \"var foo, bar;\"\n+\t\t\tif !c.options.MangleSyntax && len(decls) > 0 {\n+\t\t\t\tstmtList.outsideWrapperPrefix = append(stmtList.outsideWrapperPrefix, js_ast.Stmt{Data: &js_ast.SLocal{\n+\t\t\t\t\tDecls: decls,\n+\t\t\t\t}})\n+\t\t\t\tdecls = nil\n+\t\t\t}\n+\n+\t\t\t// \"var init_foo = __esm(() => { ... });\"\n+\t\t\tstmts = append(stmtList.outsideWrapperPrefix, js_ast.Stmt{Data: &js_ast.SLocal{\n+\t\t\t\tDecls: append(decls, js_ast.Decl{\n+\t\t\t\t\tBinding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: repr.ast.WrapperRef}},\n+\t\t\t\t\tValue:   &value,\n+\t\t\t\t}),\n+\t\t\t}})\n+\t\t}\n \t}\n \n \t// Only generate a source map if needed\n@@ -3443,20 +3673,18 @@ func (c *linkerContext) generateCodeForFileInChunkJS(\n \n \t// Convert the AST to JavaScript code\n \tprintOptions := js_printer.Options{\n-\t\tIndent:              indent,\n-\t\tOutputFormat:        c.options.OutputFormat,\n-\t\tRemoveWhitespace:    c.options.RemoveWhitespace,\n-\t\tMangleSyntax:        c.options.MangleSyntax,\n-\t\tASCIIOnly:           c.options.ASCIIOnly,\n-\t\tToModuleRef:         toModuleRef,\n-\t\tExtractComments:     c.options.Mode == config.ModeBundle && c.options.RemoveWhitespace,\n-\t\tUnsupportedFeatures: c.options.UnsupportedJSFeatures,\n-\t\tAddSourceMappings:   addSourceMappings,\n-\t\tInputSourceMap:      inputSourceMap,\n-\t\tLineOffsetTables:    lineOffsetTables,\n-\t\tWrapperRefForSource: func(sourceIndex uint32) js_ast.Ref {\n-\t\t\treturn c.files[sourceIndex].repr.(*reprJS).ast.WrapperRef\n-\t\t},\n+\t\tIndent:                       indent,\n+\t\tOutputFormat:                 c.options.OutputFormat,\n+\t\tRemoveWhitespace:             c.options.RemoveWhitespace,\n+\t\tMangleSyntax:                 c.options.MangleSyntax,\n+\t\tASCIIOnly:                    c.options.ASCIIOnly,\n+\t\tToModuleRef:                  toModuleRef,\n+\t\tExtractComments:              c.options.Mode == config.ModeBundle && c.options.RemoveWhitespace,\n+\t\tUnsupportedFeatures:          c.options.UnsupportedJSFeatures,\n+\t\tAddSourceMappings:            addSourceMappings,\n+\t\tInputSourceMap:               inputSourceMap,\n+\t\tLineOffsetTables:             lineOffsetTables,\n+\t\tRequireOrImportMetaForSource: c.requireOrImportMetaForSource,\n \t}\n \ttree := repr.ast\n \ttree.Directive = \"\" // This is handled elsewhere\n@@ -3480,8 +3708,9 @@ func (c *linkerContext) generateEntryPointTailJS(\n \n \tswitch c.options.OutputFormat {\n \tcase config.FormatPreserve:\n-\t\tif repr.meta.wrap == wrapCJS {\n+\t\tif repr.meta.wrap != wrapNone {\n \t\t\t// \"require_foo();\"\n+\t\t\t// \"init_foo();\"\n \t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SExpr{Value: js_ast.Expr{Data: &js_ast.ECall{\n \t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: repr.ast.WrapperRef}},\n \t\t\t}}}})\n@@ -3500,11 +3729,19 @@ func (c *linkerContext) generateEntryPointTailJS(\n \t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: repr.ast.WrapperRef}},\n \t\t\t\t}}}})\n \t\t\t}\n-\t\t} else if repr.meta.forceIncludeExportsForEntryPoint && len(c.options.GlobalName) > 0 {\n-\t\t\t// \"return exports;\"\n-\t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SReturn{\n-\t\t\t\tValue: &js_ast.Expr{Data: &js_ast.EIdentifier{Ref: repr.ast.ExportsRef}},\n-\t\t\t}})\n+\t\t} else {\n+\t\t\tif repr.meta.wrap == wrapESM {\n+\t\t\t\t// \"init_foo();\"\n+\t\t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SExpr{Value: js_ast.Expr{Data: &js_ast.ECall{\n+\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: repr.ast.WrapperRef}},\n+\t\t\t\t}}}})\n+\t\t\t}\n+\t\t\tif repr.meta.forceIncludeExportsForEntryPoint && len(c.options.GlobalName) > 0 {\n+\t\t\t\t// \"return exports;\"\n+\t\t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SReturn{\n+\t\t\t\t\tValue: &js_ast.Expr{Data: &js_ast.EIdentifier{Ref: repr.ast.ExportsRef}},\n+\t\t\t\t}})\n+\t\t\t}\n \t\t}\n \n \tcase config.FormatCommonJS:\n@@ -3519,6 +3756,11 @@ func (c *linkerContext) generateEntryPointTailJS(\n \t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: repr.ast.WrapperRef}},\n \t\t\t\t}},\n \t\t\t))\n+\t\t} else if repr.meta.wrap == wrapESM {\n+\t\t\t// \"init_foo();\"\n+\t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SExpr{Value: js_ast.Expr{Data: &js_ast.ECall{\n+\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: repr.ast.WrapperRef}},\n+\t\t\t}}}})\n \t\t}\n \n \t\t// If we are generating CommonJS for node, encode the known export names in\n@@ -3599,107 +3841,116 @@ func (c *linkerContext) generateEntryPointTailJS(\n \t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SExportDefault{Value: js_ast.ExprOrStmt{Expr: &js_ast.Expr{Data: &js_ast.ECall{\n \t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: repr.ast.WrapperRef}},\n \t\t\t}}}}})\n-\t\t} else if len(repr.meta.sortedAndFilteredExportAliases) > 0 {\n-\t\t\t// If the output format is ES6 modules and we're an entry point, generate an\n-\t\t\t// ES6 export statement containing all exports. Except don't do that if this\n-\t\t\t// entry point is a CommonJS-style module, since that would generate an ES6\n-\t\t\t// export statement that's not top-level. Instead, we will export the CommonJS\n-\t\t\t// exports as a default export later on.\n-\t\t\tvar items []js_ast.ClauseItem\n+\t\t} else {\n+\t\t\tif repr.meta.wrap == wrapESM {\n+\t\t\t\t// \"init_foo();\"\n+\t\t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SExpr{Value: js_ast.Expr{Data: &js_ast.ECall{\n+\t\t\t\t\tTarget: js_ast.Expr{Data: &js_ast.EIdentifier{Ref: repr.ast.WrapperRef}},\n+\t\t\t\t}}}})\n+\t\t\t}\n \n-\t\t\tfor i, alias := range repr.meta.sortedAndFilteredExportAliases {\n-\t\t\t\texport := repr.meta.resolvedExports[alias]\n+\t\t\tif len(repr.meta.sortedAndFilteredExportAliases) > 0 {\n+\t\t\t\t// If the output format is ES6 modules and we're an entry point, generate an\n+\t\t\t\t// ES6 export statement containing all exports. Except don't do that if this\n+\t\t\t\t// entry point is a CommonJS-style module, since that would generate an ES6\n+\t\t\t\t// export statement that's not top-level. Instead, we will export the CommonJS\n+\t\t\t\t// exports as a default export later on.\n+\t\t\t\tvar items []js_ast.ClauseItem\n \n-\t\t\t\t// If this is an export of an import, reference the symbol that the import\n-\t\t\t\t// was eventually resolved to. We need to do this because imports have\n-\t\t\t\t// already been resolved by this point, so we can't generate a new import\n-\t\t\t\t// and have that be resolved later.\n-\t\t\t\tif importToBind, ok := c.files[export.sourceIndex].repr.(*reprJS).meta.importsToBind[export.ref]; ok {\n-\t\t\t\t\texport.ref = importToBind.ref\n-\t\t\t\t\texport.sourceIndex = importToBind.sourceIndex\n-\t\t\t\t}\n+\t\t\t\tfor i, alias := range repr.meta.sortedAndFilteredExportAliases {\n+\t\t\t\t\texport := repr.meta.resolvedExports[alias]\n \n-\t\t\t\t// Exports of imports need EImportIdentifier in case they need to be re-\n-\t\t\t\t// written to a property access later on\n-\t\t\t\tif c.symbols.Get(export.ref).NamespaceAlias != nil {\n-\t\t\t\t\t// Create both a local variable and an export clause for that variable.\n-\t\t\t\t\t// The local variable is initialized with the initial value of the\n-\t\t\t\t\t// export. This isn't fully correct because it's a \"dead\" binding and\n-\t\t\t\t\t// doesn't update with the \"live\" value as it changes. But ES6 modules\n-\t\t\t\t\t// don't have any syntax for bare named getter functions so this is the\n-\t\t\t\t\t// best we can do.\n-\t\t\t\t\t//\n-\t\t\t\t\t// These input files:\n-\t\t\t\t\t//\n-\t\t\t\t\t//   // entry_point.js\n-\t\t\t\t\t//   export {foo} from './cjs-format.js'\n-\t\t\t\t\t//\n-\t\t\t\t\t//   // cjs-format.js\n-\t\t\t\t\t//   Object.defineProperty(exports, 'foo', {\n-\t\t\t\t\t//     enumerable: true,\n-\t\t\t\t\t//     get: () => Math.random(),\n-\t\t\t\t\t//   })\n-\t\t\t\t\t//\n-\t\t\t\t\t// Become this output file:\n-\t\t\t\t\t//\n-\t\t\t\t\t//   // cjs-format.js\n-\t\t\t\t\t//   var require_cjs_format = __commonJS((exports) => {\n-\t\t\t\t\t//     Object.defineProperty(exports, \"foo\", {\n-\t\t\t\t\t//       enumerable: true,\n-\t\t\t\t\t//       get: () => Math.random()\n-\t\t\t\t\t//     });\n-\t\t\t\t\t//   });\n-\t\t\t\t\t//\n-\t\t\t\t\t//   // entry_point.js\n-\t\t\t\t\t//   var cjs_format = __toModule(require_cjs_format());\n-\t\t\t\t\t//   var export_foo = cjs_format.foo;\n-\t\t\t\t\t//   export {\n-\t\t\t\t\t//     export_foo as foo\n-\t\t\t\t\t//   };\n-\t\t\t\t\t//\n-\t\t\t\t\ttempRef := repr.meta.cjsExportCopies[i]\n-\t\t\t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SLocal{\n-\t\t\t\t\t\tDecls: []js_ast.Decl{{\n-\t\t\t\t\t\t\tBinding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: tempRef}},\n-\t\t\t\t\t\t\tValue:   &js_ast.Expr{Data: &js_ast.EImportIdentifier{Ref: export.ref}},\n-\t\t\t\t\t\t}},\n-\t\t\t\t\t}})\n-\t\t\t\t\titems = append(items, js_ast.ClauseItem{\n-\t\t\t\t\t\tName:  js_ast.LocRef{Ref: tempRef},\n-\t\t\t\t\t\tAlias: alias,\n-\t\t\t\t\t})\n-\t\t\t\t} else {\n-\t\t\t\t\t// Local identifiers can be exported using an export clause. This is done\n-\t\t\t\t\t// this way instead of leaving the \"export\" keyword on the local declaration\n-\t\t\t\t\t// itself both because it lets the local identifier be minified and because\n-\t\t\t\t\t// it works transparently for re-exports across files.\n-\t\t\t\t\t//\n-\t\t\t\t\t// These input files:\n-\t\t\t\t\t//\n-\t\t\t\t\t//   // entry_point.js\n-\t\t\t\t\t//   export * from './esm-format.js'\n-\t\t\t\t\t//\n-\t\t\t\t\t//   // esm-format.js\n-\t\t\t\t\t//   export let foo = 123\n-\t\t\t\t\t//\n-\t\t\t\t\t// Become this output file:\n-\t\t\t\t\t//\n-\t\t\t\t\t//   // esm-format.js\n-\t\t\t\t\t//   let foo = 123;\n-\t\t\t\t\t//\n-\t\t\t\t\t//   // entry_point.js\n-\t\t\t\t\t//   export {\n-\t\t\t\t\t//     foo\n-\t\t\t\t\t//   };\n-\t\t\t\t\t//\n-\t\t\t\t\titems = append(items, js_ast.ClauseItem{\n-\t\t\t\t\t\tName:  js_ast.LocRef{Ref: export.ref},\n-\t\t\t\t\t\tAlias: alias,\n-\t\t\t\t\t})\n+\t\t\t\t\t// If this is an export of an import, reference the symbol that the import\n+\t\t\t\t\t// was eventually resolved to. We need to do this because imports have\n+\t\t\t\t\t// already been resolved by this point, so we can't generate a new import\n+\t\t\t\t\t// and have that be resolved later.\n+\t\t\t\t\tif importToBind, ok := c.files[export.sourceIndex].repr.(*reprJS).meta.importsToBind[export.ref]; ok {\n+\t\t\t\t\t\texport.ref = importToBind.ref\n+\t\t\t\t\t\texport.sourceIndex = importToBind.sourceIndex\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t// Exports of imports need EImportIdentifier in case they need to be re-\n+\t\t\t\t\t// written to a property access later on\n+\t\t\t\t\tif c.symbols.Get(export.ref).NamespaceAlias != nil {\n+\t\t\t\t\t\t// Create both a local variable and an export clause for that variable.\n+\t\t\t\t\t\t// The local variable is initialized with the initial value of the\n+\t\t\t\t\t\t// export. This isn't fully correct because it's a \"dead\" binding and\n+\t\t\t\t\t\t// doesn't update with the \"live\" value as it changes. But ES6 modules\n+\t\t\t\t\t\t// don't have any syntax for bare named getter functions so this is the\n+\t\t\t\t\t\t// best we can do.\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t// These input files:\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t//   // entry_point.js\n+\t\t\t\t\t\t//   export {foo} from './cjs-format.js'\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t//   // cjs-format.js\n+\t\t\t\t\t\t//   Object.defineProperty(exports, 'foo', {\n+\t\t\t\t\t\t//     enumerable: true,\n+\t\t\t\t\t\t//     get: () => Math.random(),\n+\t\t\t\t\t\t//   })\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t// Become this output file:\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t//   // cjs-format.js\n+\t\t\t\t\t\t//   var require_cjs_format = __commonJS((exports) => {\n+\t\t\t\t\t\t//     Object.defineProperty(exports, \"foo\", {\n+\t\t\t\t\t\t//       enumerable: true,\n+\t\t\t\t\t\t//       get: () => Math.random()\n+\t\t\t\t\t\t//     });\n+\t\t\t\t\t\t//   });\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t//   // entry_point.js\n+\t\t\t\t\t\t//   var cjs_format = __toModule(require_cjs_format());\n+\t\t\t\t\t\t//   var export_foo = cjs_format.foo;\n+\t\t\t\t\t\t//   export {\n+\t\t\t\t\t\t//     export_foo as foo\n+\t\t\t\t\t\t//   };\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\ttempRef := repr.meta.cjsExportCopies[i]\n+\t\t\t\t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SLocal{\n+\t\t\t\t\t\t\tDecls: []js_ast.Decl{{\n+\t\t\t\t\t\t\t\tBinding: js_ast.Binding{Data: &js_ast.BIdentifier{Ref: tempRef}},\n+\t\t\t\t\t\t\t\tValue:   &js_ast.Expr{Data: &js_ast.EImportIdentifier{Ref: export.ref}},\n+\t\t\t\t\t\t\t}},\n+\t\t\t\t\t\t}})\n+\t\t\t\t\t\titems = append(items, js_ast.ClauseItem{\n+\t\t\t\t\t\t\tName:  js_ast.LocRef{Ref: tempRef},\n+\t\t\t\t\t\t\tAlias: alias,\n+\t\t\t\t\t\t})\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\t// Local identifiers can be exported using an export clause. This is done\n+\t\t\t\t\t\t// this way instead of leaving the \"export\" keyword on the local declaration\n+\t\t\t\t\t\t// itself both because it lets the local identifier be minified and because\n+\t\t\t\t\t\t// it works transparently for re-exports across files.\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t// These input files:\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t//   // entry_point.js\n+\t\t\t\t\t\t//   export * from './esm-format.js'\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t//   // esm-format.js\n+\t\t\t\t\t\t//   export let foo = 123\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t// Become this output file:\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t//   // esm-format.js\n+\t\t\t\t\t\t//   let foo = 123;\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\t//   // entry_point.js\n+\t\t\t\t\t\t//   export {\n+\t\t\t\t\t\t//     foo\n+\t\t\t\t\t\t//   };\n+\t\t\t\t\t\t//\n+\t\t\t\t\t\titems = append(items, js_ast.ClauseItem{\n+\t\t\t\t\t\t\tName:  js_ast.LocRef{Ref: export.ref},\n+\t\t\t\t\t\t\tAlias: alias,\n+\t\t\t\t\t\t})\n+\t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t}\n \n-\t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SExportClause{Items: items}})\n+\t\t\t\tstmts = append(stmts, js_ast.Stmt{Data: &js_ast.SExportClause{Items: items}})\n+\t\t\t}\n \t\t}\n \t}\n \n@@ -3718,17 +3969,15 @@ func (c *linkerContext) generateEntryPointTailJS(\n \n \t// Convert the AST to JavaScript code\n \tprintOptions := js_printer.Options{\n-\t\tIndent:              indent,\n-\t\tOutputFormat:        c.options.OutputFormat,\n-\t\tRemoveWhitespace:    c.options.RemoveWhitespace,\n-\t\tMangleSyntax:        c.options.MangleSyntax,\n-\t\tASCIIOnly:           c.options.ASCIIOnly,\n-\t\tToModuleRef:         toModuleRef,\n-\t\tExtractComments:     c.options.Mode == config.ModeBundle && c.options.RemoveWhitespace,\n-\t\tUnsupportedFeatures: c.options.UnsupportedJSFeatures,\n-\t\tWrapperRefForSource: func(sourceIndex uint32) js_ast.Ref {\n-\t\t\treturn c.files[sourceIndex].repr.(*reprJS).ast.WrapperRef\n-\t\t},\n+\t\tIndent:                       indent,\n+\t\tOutputFormat:                 c.options.OutputFormat,\n+\t\tRemoveWhitespace:             c.options.RemoveWhitespace,\n+\t\tMangleSyntax:                 c.options.MangleSyntax,\n+\t\tASCIIOnly:                    c.options.ASCIIOnly,\n+\t\tToModuleRef:                  toModuleRef,\n+\t\tExtractComments:              c.options.Mode == config.ModeBundle && c.options.RemoveWhitespace,\n+\t\tUnsupportedFeatures:          c.options.UnsupportedJSFeatures,\n+\t\tRequireOrImportMetaForSource: c.requireOrImportMetaForSource,\n \t}\n \tresult.PrintResult = js_printer.Print(tree, c.symbols, r, printOptions)\n \treturn\n@@ -3825,7 +4074,7 @@ func (c *linkerContext) renameSymbolsInChunk(chunk *chunkInfo, filesInOrder []ui\n \t\t//\n \t\t//   // foo.js\n \t\t//   var require_foo = __commonJS((exports, module) => {\n-\t\t//     ...\n+\t\t//     exports.foo = 123;\n \t\t//   });\n \t\t//\n \t\t// The symbol \"require_foo\" is stored in \"file.ast.WrapperRef\". We want\n@@ -3880,6 +4129,24 @@ func (c *linkerContext) renameSymbolsInChunk(chunk *chunkInfo, filesInOrder []ui\n \t\t\tcontinue\n \t\t}\n \n+\t\t// Modules wrapped in an ESM closure look like this:\n+\t\t//\n+\t\t//   // foo.js\n+\t\t//   var foo, foo_exports = {};\n+\t\t//   __exports(foo_exports, {\n+\t\t//     foo: () => foo\n+\t\t//   });\n+\t\t//   let init_foo = __esm(() => {\n+\t\t//     foo = 123;\n+\t\t//   });\n+\t\t//\n+\t\t// The symbol \"init_foo\" is stored in \"file.ast.WrapperRef\". We need to\n+\t\t// minify everything inside the closure without introducing a new scope\n+\t\t// since all top-level variables will be hoisted outside of the closure.\n+\t\tif repr.meta.wrap == wrapESM {\n+\t\t\tr.AddTopLevelSymbol(repr.ast.WrapperRef)\n+\t\t}\n+\n \t\t// Rename each top-level symbol declaration in this chunk\n \t\tfor partIndex, part := range repr.ast.Parts {\n \t\t\tif repr.meta.partMeta[partIndex].isLive() {\n@@ -3908,6 +4175,7 @@ func (c *linkerContext) generateChunkJS(chunks []chunkInfo, chunkIndex int, chun\n \tcompileResults := make([]compileResultJS, 0, len(chunk.partsInChunkInOrder))\n \truntimeMembers := c.files[runtime.SourceIndex].repr.(*reprJS).ast.ModuleScope.Members\n \tcommonJSRef := js_ast.FollowSymbols(c.symbols, runtimeMembers[\"__commonJS\"].Ref)\n+\tesmRef := js_ast.FollowSymbols(c.symbols, runtimeMembers[\"__esm\"].Ref)\n \ttoModuleRef := js_ast.FollowSymbols(c.symbols, runtimeMembers[\"__toModule\"].Ref)\n \tr := c.renameSymbolsInChunk(chunk, chunk.filesInChunkInOrder)\n \tdataForSourceMaps := c.dataForSourceMaps()\n@@ -3940,6 +4208,7 @@ func (c *linkerContext) generateChunkJS(chunks []chunkInfo, chunkIndex int, chun\n \t\t\tchunk.entryBits,\n \t\t\tchunkAbsDir,\n \t\t\tcommonJSRef,\n+\t\t\tesmRef,\n \t\t\ttoModuleRef,\n \t\t\tcompileResult,\n \t\t\tdataForSourceMaps,"},{"sha":"3e1051f0af1a7798ecca71f2c56dfaadcdba43a3","filename":"internal/bundler/snapshots/snapshots_dce.txt","status":"modified","additions":50,"deletions":22,"changes":72,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_dce.txt","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_dce.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_dce.txt?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -142,20 +142,21 @@ console.log(\"unused import\");\n TestPackageJsonSideEffectsArrayKeepMainImplicitMain\n ---------- /out.js ----------\n // Users/user/project/node_modules/demo-pkg/index-main.js\n-var require_index_main = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    foo: () => foo2\n-  });\n-  var foo2 = 123;\n+var index_main_exports = {};\n+__export(index_main_exports, {\n+  foo: () => foo\n+});\n+var foo;\n+var init_index_main = __esm(() => {\n+  foo = 123;\n   console.log(\"this should be kept\");\n });\n \n // Users/user/project/src/entry.js\n-var import_demo_pkg = require_index_main();\n+init_index_main();\n \n // Users/user/project/src/require-demo-pkg.js\n-require_index_main();\n+init_index_main();\n \n // Users/user/project/src/entry.js\n console.log(\"unused import\");\n@@ -185,17 +186,18 @@ console.log(\"unused import\");\n TestPackageJsonSideEffectsArrayKeepModuleImplicitMain\n ---------- /out.js ----------\n // Users/user/project/node_modules/demo-pkg/index-main.js\n-var require_index_main = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    foo: () => foo\n-  });\n-  var foo = 123;\n+var index_main_exports = {};\n+__export(index_main_exports, {\n+  foo: () => foo\n+});\n+var foo;\n+var init_index_main = __esm(() => {\n+  foo = 123;\n   console.log(\"this should be kept\");\n });\n \n // Users/user/project/src/require-demo-pkg.js\n-require_index_main();\n+init_index_main();\n \n // Users/user/project/src/entry.js\n console.log(\"unused import\");\n@@ -247,17 +249,18 @@ console.log(\"unused import\");\n TestPackageJsonSideEffectsFalseKeepBareImportAndRequireES6\n ---------- /out.js ----------\n // Users/user/project/node_modules/demo-pkg/index.js\n-var require_demo_pkg = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    foo: () => foo\n-  });\n-  var foo = 123;\n+var demo_pkg_exports = {};\n+__export(demo_pkg_exports, {\n+  foo: () => foo\n+});\n+var foo;\n+var init_demo_pkg = __esm(() => {\n+  foo = 123;\n   console.log(\"hello\");\n });\n \n // Users/user/project/src/entry.js\n-require_demo_pkg();\n+init_demo_pkg();\n console.log(\"unused import\");\n \n ================================================================================\n@@ -519,6 +522,31 @@ var Keep = class extends Base {\n // entry.js\n new Keep();\n \n+================================================================================\n+TestTreeShakingInESMWrapper\n+---------- /out.js ----------\n+// lib.js\n+var keep1, keep2;\n+var init_lib = __esm(() => {\n+  keep1 = () => \"keep1\";\n+  keep2 = () => \"keep2\";\n+});\n+\n+// cjs.js\n+var cjs_exports = {};\n+__export(cjs_exports, {\n+  default: () => cjs_default\n+});\n+var cjs_default;\n+var init_cjs = __esm(() => {\n+  init_lib();\n+  cjs_default = keep2();\n+});\n+\n+// entry.js\n+init_lib();\n+console.log(keep1(), (init_cjs(), cjs_exports));\n+\n ================================================================================\n TestTreeShakingNoBundleCJS\n ---------- /out.js ----------"},{"sha":"ac11f4fade074dc51fde06b94e20d02b850ab2b4","filename":"internal/bundler/snapshots/snapshots_default.txt","status":"modified","additions":226,"deletions":178,"changes":404,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_default.txt","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_default.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_default.txt?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -223,31 +223,31 @@ export {\n TestCommonJSFromES6\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    foo: () => foo2\n-  });\n-  function foo2() {\n-    return \"foo\";\n-  }\n+var foo_exports = {};\n+__export(foo_exports, {\n+  foo: () => foo\n+});\n+function foo() {\n+  return \"foo\";\n+}\n+var init_foo = __esm(() => {\n });\n \n // bar.js\n-var require_bar = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    bar: () => bar2\n-  });\n-  function bar2() {\n-    return \"bar\";\n-  }\n+var bar_exports = {};\n+__export(bar_exports, {\n+  bar: () => bar\n+});\n+function bar() {\n+  return \"bar\";\n+}\n+var init_bar = __esm(() => {\n });\n \n // entry.js\n-var {foo} = require_foo();\n-console.log(foo(), bar());\n-var {bar} = require_bar();\n+var {foo: foo2} = (init_foo(), foo_exports);\n+console.log(foo2(), bar2());\n+var {bar: bar2} = (init_bar(), bar_exports);\n \n ================================================================================\n TestConditionalImport\n@@ -399,6 +399,12 @@ var require_index = __commonJS((exports) => {\n var import__ = __toModule(require_index());\n console.log(import__.x);\n \n+================================================================================\n+TestDuplicateEntryPoint\n+---------- /out.js/entry.js ----------\n+// entry.js\n+console.log(123);\n+\n ================================================================================\n TestDynamicImportWithExpressionCJS\n ---------- /out.js ----------\n@@ -445,12 +451,12 @@ console.log((0, import_foo.foo)(), (0, import_bar.bar)());\n TestEmptyExportClauseBundleAsCommonJSIssue910\n ---------- /out.js ----------\n // types.mjs\n-var require_types = __commonJS((exports) => {\n-  __markAsModule(exports);\n+var types_exports = {};\n+var init_types = __esm(() => {\n });\n \n // entry.js\n-console.log(require_types());\n+console.log((init_types(), types_exports));\n \n ================================================================================\n TestExportChain\n@@ -488,113 +494,124 @@ export default require_entry();\n ================================================================================\n TestExportFormsCommonJS\n ---------- /out.js ----------\n+// a.js\n+var abc;\n+var init_a = __esm(() => {\n+  abc = void 0;\n+});\n+\n+// b.js\n+var b_exports = {};\n+__export(b_exports, {\n+  xyz: () => xyz\n+});\n+var xyz;\n+var init_b = __esm(() => {\n+  xyz = null;\n+});\n+\n // commonjs.js\n-var require_commonjs = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    C: () => Class,\n-    Class: () => Class,\n-    Fn: () => Fn,\n-    abc: () => abc,\n-    b: () => b_exports,\n-    c: () => c,\n-    default: () => commonjs_default,\n-    l: () => l,\n-    v: () => v\n-  });\n-  var commonjs_default = 123;\n-  var v = 234;\n-  var l = 234;\n-  var c = 234;\n-  function Fn() {\n-  }\n-  var Class = class {\n+var commonjs_exports = {};\n+__export(commonjs_exports, {\n+  C: () => Class,\n+  Class: () => Class,\n+  Fn: () => Fn,\n+  abc: () => abc,\n+  b: () => b_exports,\n+  c: () => c,\n+  default: () => commonjs_default,\n+  l: () => l,\n+  v: () => v\n+});\n+function Fn() {\n+}\n+var commonjs_default, v, l, c, Class;\n+var init_commonjs = __esm(() => {\n+  init_a();\n+  init_b();\n+  commonjs_default = 123;\n+  v = 234;\n+  l = 234;\n+  c = 234;\n+  Class = class {\n   };\n });\n \n // c.js\n-var require_c = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    default: () => c_default2\n-  });\n-  var c_default = class {\n+var c_exports = {};\n+__export(c_exports, {\n+  default: () => c_default2\n+});\n+var c_default, c_default2;\n+var init_c = __esm(() => {\n+  c_default = class {\n   };\n-  var c_default2 = c_default;\n+  c_default2 = c_default;\n });\n \n // d.js\n-var require_d = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    default: () => d_default\n-  });\n-  var Foo = class {\n+var d_exports = {};\n+__export(d_exports, {\n+  default: () => d_default\n+});\n+var Foo, d_default;\n+var init_d = __esm(() => {\n+  Foo = class {\n   };\n-  var d_default = Foo;\n+  d_default = Foo;\n   Foo.prop = 123;\n });\n \n // e.js\n-var require_e = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    default: () => e_default\n-  });\n-  function e_default() {\n-  }\n+var e_exports = {};\n+__export(e_exports, {\n+  default: () => e_default\n+});\n+function e_default() {\n+}\n+var init_e = __esm(() => {\n });\n \n // f.js\n-var require_f = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    default: () => foo\n-  });\n-  function foo() {\n-  }\n+var f_exports = {};\n+__export(f_exports, {\n+  default: () => foo\n+});\n+function foo() {\n+}\n+var init_f = __esm(() => {\n   foo.prop = 123;\n });\n \n // g.js\n-var require_g = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    default: () => g_default\n-  });\n-  async function g_default() {\n-  }\n+var g_exports = {};\n+__export(g_exports, {\n+  default: () => g_default\n+});\n+async function g_default() {\n+}\n+var init_g = __esm(() => {\n });\n \n // h.js\n-var require_h = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    default: () => foo\n-  });\n-  async function foo() {\n-  }\n-  foo.prop = 123;\n+var h_exports = {};\n+__export(h_exports, {\n+  default: () => foo2\n });\n-\n-// a.js\n-var abc = void 0;\n-\n-// b.js\n-var b_exports = {};\n-__export(b_exports, {\n-  xyz: () => xyz\n+async function foo2() {\n+}\n+var init_h = __esm(() => {\n+  foo2.prop = 123;\n });\n-var xyz = null;\n \n // entry.js\n-require_commonjs();\n-require_c();\n-require_d();\n-require_e();\n-require_f();\n-require_g();\n-require_h();\n+init_commonjs();\n+init_c();\n+init_d();\n+init_e();\n+init_f();\n+init_g();\n+init_h();\n \n ================================================================================\n TestExportFormsES6\n@@ -742,54 +759,54 @@ console.log(exports, module.exports, test_exports, test_exports2);\n TestExternalES6ConvertedToCommonJS\n ---------- /out.js ----------\n // a.js\n+var a_exports = {};\n+__export(a_exports, {\n+  ns: () => ns\n+});\n import * as ns from \"x\";\n-var require_a = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    ns: () => ns\n-  });\n+var init_a = __esm(() => {\n });\n \n // b.js\n+var b_exports = {};\n+__export(b_exports, {\n+  ns: () => ns2\n+});\n import * as ns2 from \"x\";\n-var require_b = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    ns: () => ns2\n-  });\n+var init_b = __esm(() => {\n });\n \n // c.js\n+var c_exports = {};\n+__export(c_exports, {\n+  ns: () => ns3\n+});\n import * as ns3 from \"x\";\n-var require_c = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    ns: () => ns3\n-  });\n+var init_c = __esm(() => {\n });\n \n // d.js\n+var d_exports = {};\n+__export(d_exports, {\n+  ns: () => ns4\n+});\n import {ns as ns4} from \"x\";\n-var require_d = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    ns: () => ns4\n-  });\n+var init_d = __esm(() => {\n });\n \n // e.js\n+var e_exports = {};\n import * as x_star from \"x\";\n-var require_e = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __exportStar(exports, x_star);\n+var init_e = __esm(() => {\n+  __exportStar(e_exports, x_star);\n });\n \n // entry.js\n-require_a();\n-require_b();\n-require_c();\n-require_d();\n-require_e();\n+init_a();\n+init_b();\n+init_c();\n+init_d();\n+init_e();\n \n ================================================================================\n TestExternalModuleExclusionPackage\n@@ -2445,29 +2462,30 @@ var require_cjs = __commonJS((exports) => {\n });\n \n // dummy.js\n-var require_dummy = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    dummy: () => dummy\n-  });\n-  var dummy = 123;\n+var dummy_exports = {};\n+__export(dummy_exports, {\n+  dummy: () => dummy\n+});\n+var dummy;\n+var init_dummy = __esm(() => {\n+  dummy = 123;\n });\n \n // es6-import-assign.ts\n var require_es6_import_assign = __commonJS((exports) => {\n-  var x2 = require_dummy();\n+  var x2 = (init_dummy(), dummy_exports);\n   console.log(exports);\n });\n \n // es6-import-dynamic.js\n var require_es6_import_dynamic = __commonJS((exports) => {\n-  Promise.resolve().then(() => require_dummy());\n+  Promise.resolve().then(() => init_dummy());\n   console.log(exports);\n });\n \n // es6-expr-import-dynamic.js\n var require_es6_expr_import_dynamic = __commonJS((exports) => {\n-  Promise.resolve().then(() => require_dummy());\n+  Promise.resolve().then(() => init_dummy());\n   console.log(exports);\n });\n \n@@ -2479,54 +2497,54 @@ var require_es6_export_assign = __commonJS((exports, module) => {\n \n // es6-ns-export-variable.ts\n var require_es6_ns_export_variable = __commonJS((exports) => {\n-  var ns2;\n-  (function(ns3) {\n-    ns3.foo = 123;\n-  })(ns2 || (ns2 = {}));\n+  var ns;\n+  (function(ns2) {\n+    ns2.foo = 123;\n+  })(ns || (ns = {}));\n   console.log(exports);\n });\n \n // es6-ns-export-function.ts\n var require_es6_ns_export_function = __commonJS((exports) => {\n-  var ns2;\n-  (function(ns3) {\n+  var ns;\n+  (function(ns2) {\n     function foo() {\n     }\n-    ns3.foo = foo;\n-  })(ns2 || (ns2 = {}));\n+    ns2.foo = foo;\n+  })(ns || (ns = {}));\n   console.log(exports);\n });\n \n // es6-ns-export-async-function.ts\n var require_es6_ns_export_async_function = __commonJS((exports) => {\n-  var ns2;\n-  (function(ns3) {\n+  var ns;\n+  (function(ns2) {\n     async function foo() {\n     }\n-    ns3.foo = foo;\n-  })(ns2 || (ns2 = {}));\n+    ns2.foo = foo;\n+  })(ns || (ns = {}));\n   console.log(exports);\n });\n \n // es6-ns-export-enum.ts\n var require_es6_ns_export_enum = __commonJS((exports) => {\n-  var ns2;\n-  (function(ns3) {\n+  var ns;\n+  (function(ns2) {\n     let Foo3;\n     (function(Foo4) {\n-    })(Foo3 = ns3.Foo || (ns3.Foo = {}));\n-  })(ns2 || (ns2 = {}));\n+    })(Foo3 = ns2.Foo || (ns2.Foo = {}));\n+  })(ns || (ns = {}));\n   console.log(exports);\n });\n \n // es6-ns-export-const-enum.ts\n var require_es6_ns_export_const_enum = __commonJS((exports) => {\n-  var ns2;\n-  (function(ns3) {\n+  var ns;\n+  (function(ns2) {\n     let Foo3;\n     (function(Foo4) {\n-    })(Foo3 = ns3.Foo || (ns3.Foo = {}));\n-  })(ns2 || (ns2 = {}));\n+    })(Foo3 = ns2.Foo || (ns2.Foo = {}));\n+  })(ns || (ns = {}));\n   console.log(exports);\n });\n \n@@ -2542,31 +2560,31 @@ var require_es6_ns_export_namespace = __commonJS((exports) => {\n \n // es6-ns-export-class.ts\n var require_es6_ns_export_class = __commonJS((exports) => {\n-  var ns2;\n-  (function(ns3) {\n+  var ns;\n+  (function(ns2) {\n     class Foo3 {\n     }\n-    ns3.Foo = Foo3;\n-  })(ns2 || (ns2 = {}));\n+    ns2.Foo = Foo3;\n+  })(ns || (ns = {}));\n   console.log(exports);\n });\n \n // es6-ns-export-abstract-class.ts\n var require_es6_ns_export_abstract_class = __commonJS((exports) => {\n-  var ns2;\n-  (function(ns3) {\n+  var ns;\n+  (function(ns2) {\n     class Foo3 {\n     }\n-    ns3.Foo = Foo3;\n-  })(ns2 || (ns2 = {}));\n+    ns2.Foo = Foo3;\n+  })(ns || (ns = {}));\n   console.log(exports);\n });\n \n // entry.js\n var import_cjs = __toModule(require_cjs());\n \n // es6-import-stmt.js\n-var import_dummy = require_dummy();\n+init_dummy();\n console.log(void 0);\n \n // entry.js\n@@ -2622,23 +2640,22 @@ console.log(void 0);\n console.log(void 0);\n \n // es6-export-clause-from.js\n-var import_dummy2 = require_dummy();\n+init_dummy();\n console.log(void 0);\n \n // es6-export-star.js\n-var es6_export_star_exports = {};\n-__exportStar(es6_export_star_exports, require_dummy());\n+init_dummy();\n console.log(void 0);\n \n // es6-export-star-as.js\n-var ns = require_dummy();\n+init_dummy();\n console.log(void 0);\n \n // entry.js\n var import_es6_export_assign = __toModule(require_es6_export_assign());\n \n // es6-export-import-assign.ts\n-var x = require_dummy();\n+var x = (init_dummy(), dummy_exports);\n console.log(void 0);\n \n // entry.js\n@@ -2656,29 +2673,60 @@ var import_es6_ns_export_abstract_class = __toModule(require_es6_ns_export_abstr\n TestTopLevelAwaitAllowedImportWithSplitting\n ---------- /out/entry.js ----------\n // entry.js\n-import(\"./a.js\");\n-import(\"./b.js\");\n-import(\"./c.js\");\n+import(\"./a-QJXNRG2U.js\");\n+import(\"./b-QJXNRG2U.js\");\n+import(\"./c-7Y4CCLAO.js\");\n import(\"./entry.js\");\n await 0;\n \n----------- /out/a.js ----------\n+---------- /out/a-QJXNRG2U.js ----------\n import \"./chunk-7VOEXAIV.js\";\n import \"./chunk-FLIOJ2XZ.js\";\n \n----------- /out/b.js ----------\n+---------- /out/b-QJXNRG2U.js ----------\n import \"./chunk-7VOEXAIV.js\";\n import \"./chunk-FLIOJ2XZ.js\";\n \n ---------- /out/chunk-7VOEXAIV.js ----------\n \n----------- /out/c.js ----------\n+---------- /out/c-7Y4CCLAO.js ----------\n import \"./chunk-FLIOJ2XZ.js\";\n \n ---------- /out/chunk-FLIOJ2XZ.js ----------\n // c.js\n await 0;\n \n+================================================================================\n+TestTopLevelAwaitAllowedImportWithoutSplitting\n+---------- /out.js ----------\n+// c.js\n+var c_exports = {};\n+var init_c = __esm(async () => {\n+  await 0;\n+});\n+\n+// b.js\n+var b_exports = {};\n+var init_b = __esm(async () => {\n+  await init_c();\n+});\n+\n+// a.js\n+var a_exports = {};\n+var init_a = __esm(async () => {\n+  await init_b();\n+});\n+\n+// entry.js\n+var init_entry = __esm(async () => {\n+  init_a();\n+  init_b();\n+  init_c();\n+  init_entry();\n+  await 0;\n+});\n+init_entry();\n+\n ================================================================================\n TestTopLevelAwaitESM\n ---------- /out.js ----------"},{"sha":"27a1fe98ccec900a458e99394aa88811eafa8b42","filename":"internal/bundler/snapshots/snapshots_importstar.txt","status":"modified","additions":19,"deletions":17,"changes":36,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar.txt","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar.txt?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -59,15 +59,16 @@ console.log(exports);\n TestExportSelfAndRequireSelfCommonJS\n ---------- /out.js ----------\n // entry.js\n-var require_entry = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    foo: () => foo\n-  });\n-  var foo = 123;\n-  console.log(require_entry());\n+__markAsModule(exports);\n+__export(exports, {\n+  foo: () => foo\n });\n-module.exports = require_entry();\n+var foo;\n+var init_entry = __esm(() => {\n+  foo = 123;\n+  console.log((init_entry(), exports));\n+});\n+init_entry();\n \n ================================================================================\n TestExportSelfAsNamespaceCommonJS\n@@ -332,18 +333,19 @@ module.exports = require_entry();\n TestImportStarAndCommonJS\n ---------- /out.js ----------\n // foo.js\n-var require_foo = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    foo: () => foo2\n-  });\n-  var foo2 = 123;\n+var foo_exports = {};\n+__export(foo_exports, {\n+  foo: () => foo\n+});\n+var foo;\n+var init_foo = __esm(() => {\n+  foo = 123;\n });\n \n // entry.js\n-var ns = require_foo();\n-var ns2 = require_foo();\n-console.log(ns.foo, ns2.foo);\n+init_foo();\n+var ns2 = (init_foo(), foo_exports);\n+console.log(foo, ns2.foo);\n \n ================================================================================\n TestImportStarCapture"},{"sha":"c9a040a21eac7f6b958e3dfece940f4e4541da2a","filename":"internal/bundler/snapshots/snapshots_importstar_ts.txt","status":"modified","additions":10,"deletions":9,"changes":19,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar_ts.txt","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar_ts.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_importstar_ts.txt?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -1,18 +1,19 @@\n TestTSImportStarAndCommonJS\n ---------- /out.js ----------\n // foo.ts\n-var require_foo = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    foo: () => foo2\n-  });\n-  var foo2 = 123;\n+var foo_exports = {};\n+__export(foo_exports, {\n+  foo: () => foo\n+});\n+var foo;\n+var init_foo = __esm(() => {\n+  foo = 123;\n });\n \n // entry.js\n-var ns = require_foo();\n-var ns2 = require_foo();\n-console.log(ns.foo, ns2.foo);\n+init_foo();\n+var ns2 = (init_foo(), foo_exports);\n+console.log(foo, ns2.foo);\n \n ================================================================================\n TestTSImportStarCapture"},{"sha":"95e6a01d8ec8f590cc6ee8ff7f479bc71ef7627c","filename":"internal/bundler/snapshots/snapshots_packagejson.txt","status":"modified","additions":20,"deletions":18,"changes":38,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_packagejson.txt","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_packagejson.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_packagejson.txt?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -328,20 +328,21 @@ console.log(import_demo_pkg.default);\n TestPackageJsonDualPackageHazardImportAndRequireForceModuleBeforeMain\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/module.js\n-var require_module = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    default: () => module_default\n-  });\n-  var module_default = \"module\";\n+var module_exports = {};\n+__export(module_exports, {\n+  default: () => module_default\n+});\n+var module_default;\n+var init_module = __esm(() => {\n+  module_default = \"module\";\n });\n \n // Users/user/project/src/test-main.js\n-console.log(require_module());\n+console.log((init_module(), module_exports));\n \n // Users/user/project/src/test-module.js\n-var import_demo_pkg = require_module();\n-console.log(import_demo_pkg.default);\n+init_module();\n+console.log(module_default);\n \n ================================================================================\n TestPackageJsonDualPackageHazardImportAndRequireImplicitMain\n@@ -362,20 +363,21 @@ console.log(import_demo_pkg.default);\n TestPackageJsonDualPackageHazardImportAndRequireImplicitMainForceModuleBeforeMain\n ---------- /Users/user/project/out.js ----------\n // Users/user/project/node_modules/demo-pkg/module.js\n-var require_module = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    default: () => module_default\n-  });\n-  var module_default = \"module\";\n+var module_exports = {};\n+__export(module_exports, {\n+  default: () => module_default\n+});\n+var module_default;\n+var init_module = __esm(() => {\n+  module_default = \"module\";\n });\n \n // Users/user/project/src/test-index.js\n-console.log(require_module());\n+console.log((init_module(), module_exports));\n \n // Users/user/project/src/test-module.js\n-var import_demo_pkg = require_module();\n-console.log(import_demo_pkg.default);\n+init_module();\n+console.log(module_default);\n \n ================================================================================\n TestPackageJsonDualPackageHazardImportAndRequireSameFile"},{"sha":"406c56bb4e9c39703aa27d186b230cb20c5413a6","filename":"internal/bundler/snapshots/snapshots_splitting.txt","status":"modified","additions":40,"deletions":35,"changes":75,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_splitting.txt","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_splitting.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_splitting.txt?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -205,19 +205,19 @@ TestSplittingDynamicAndNotDynamicCommonJSIntoES6\n import {\n   __toModule,\n   require_foo\n-} from \"./chunk-OSATKDXK.js\";\n+} from \"./chunk-EIGPJKCZ.js\";\n \n // entry.js\n var import_foo = __toModule(require_foo());\n-import(\"./foo.js\").then(({default: {bar: b}}) => console.log(import_foo.bar, b));\n+import(\"./foo-42KSISCA.js\").then(({default: {bar: b}}) => console.log(import_foo.bar, b));\n \n----------- /out/foo.js ----------\n+---------- /out/foo-42KSISCA.js ----------\n import {\n   require_foo\n-} from \"./chunk-OSATKDXK.js\";\n+} from \"./chunk-EIGPJKCZ.js\";\n export default require_foo();\n \n----------- /out/chunk-OSATKDXK.js ----------\n+---------- /out/chunk-EIGPJKCZ.js ----------\n // foo.js\n var require_foo = __commonJS((exports) => {\n   exports.bar = 123;\n@@ -236,9 +236,9 @@ import {\n } from \"./chunk-3CWABKVA.js\";\n \n // entry.js\n-import(\"./foo.js\").then(({bar: b}) => console.log(bar, b));\n+import(\"./foo-H5N7CGKD.js\").then(({bar: b}) => console.log(bar, b));\n \n----------- /out/foo.js ----------\n+---------- /out/foo-H5N7CGKD.js ----------\n import {\n   bar\n } from \"./chunk-3CWABKVA.js\";\n@@ -258,9 +258,9 @@ export {\n TestSplittingDynamicCommonJSIntoES6\n ---------- /out/entry.js ----------\n // entry.js\n-import(\"./foo.js\").then(({default: {bar}}) => console.log(bar));\n+import(\"./foo-3I42H3S6.js\").then(({default: {bar}}) => console.log(bar));\n \n----------- /out/foo.js ----------\n+---------- /out/foo-3I42H3S6.js ----------\n // foo.js\n var require_foo = __commonJS((exports) => {\n   exports.bar = 123;\n@@ -271,9 +271,9 @@ export default require_foo();\n TestSplittingDynamicES6IntoES6\n ---------- /out/entry.js ----------\n // entry.js\n-import(\"./foo.js\").then(({bar}) => console.log(bar));\n+import(\"./foo-3I42H3S6.js\").then(({bar}) => console.log(bar));\n \n----------- /out/foo.js ----------\n+---------- /out/foo-3I42H3S6.js ----------\n // foo.js\n var bar = 123;\n export {\n@@ -295,49 +295,54 @@ export {\n \n ================================================================================\n TestSplittingDynamicImportOutsideSourceTreeIssue264\n----------- /out/src/entry1.js ----------\n+---------- /out/entry1.js ----------\n // Users/user/project/src/entry1.js\n-import(\"../node_modules/package/index.js\");\n+import(\"./package-3I42H3S6.js\");\n \n----------- /out/src/entry2.js ----------\n+---------- /out/entry2.js ----------\n // Users/user/project/src/entry2.js\n-import(\"../node_modules/package/index.js\");\n+import(\"./package-3I42H3S6.js\");\n \n----------- /out/node_modules/package/index.js ----------\n+---------- /out/package-3I42H3S6.js ----------\n // Users/user/project/node_modules/package/index.js\n console.log(\"imported\");\n \n ================================================================================\n TestSplittingHybridESMAndCJSIssue617\n ---------- /out/a.js ----------\n import {\n-  require_a\n-} from \"./chunk-G6UP3R5O.js\";\n-export default require_a();\n+  foo,\n+  init_a\n+} from \"./chunk-XLWYRQ3W.js\";\n+init_a();\n+export {\n+  foo\n+};\n \n ---------- /out/b.js ----------\n import {\n-  require_a\n-} from \"./chunk-G6UP3R5O.js\";\n+  init_a\n+} from \"./chunk-XLWYRQ3W.js\";\n \n // b.js\n-var bar = require_a();\n+var bar = (init_a(), a_exports);\n export {\n   bar\n };\n \n----------- /out/chunk-G6UP3R5O.js ----------\n+---------- /out/chunk-XLWYRQ3W.js ----------\n // a.js\n-var require_a = __commonJS((exports) => {\n-  __markAsModule(exports);\n-  __export(exports, {\n-    foo: () => foo\n-  });\n-  var foo;\n+var a_exports = {};\n+__export(a_exports, {\n+  foo: () => foo\n+});\n+var foo;\n+var init_a = __esm(() => {\n });\n \n export {\n-  require_a\n+  foo,\n+  init_a\n };\n \n ================================================================================\n@@ -435,9 +440,9 @@ export {\n TestSplittingPublicPathEntryName\n ---------- /out/a.js ----------\n // a.js\n-import(\"/www/b.js\");\n+import(\"/www/b-3I42H3S6.js\");\n \n----------- /out/b.js ----------\n+---------- /out/b-3I42H3S6.js ----------\n // b.js\n console.log(\"b\");\n \n@@ -472,7 +477,7 @@ TestSplittingSharedCommonJSIntoES6\n ---------- /out/a.js ----------\n import {\n   require_shared\n-} from \"./chunk-ZJEKWK6W.js\";\n+} from \"./chunk-RRQSZPOJ.js\";\n \n // a.js\n var {foo} = require_shared();\n@@ -481,13 +486,13 @@ console.log(foo);\n ---------- /out/b.js ----------\n import {\n   require_shared\n-} from \"./chunk-ZJEKWK6W.js\";\n+} from \"./chunk-RRQSZPOJ.js\";\n \n // b.js\n var {foo} = require_shared();\n console.log(foo);\n \n----------- /out/chunk-ZJEKWK6W.js ----------\n+---------- /out/chunk-RRQSZPOJ.js ----------\n // shared.js\n var require_shared = __commonJS((exports) => {\n   exports.foo = 123;"},{"sha":"d83b3dea71a9a1738e38fbcc0930782b94830852","filename":"internal/js_ast/js_ast.go","status":"modified","additions":64,"deletions":4,"changes":68,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fjs_ast%2Fjs_ast.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fjs_ast%2Fjs_ast.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_ast%2Fjs_ast.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -897,15 +897,20 @@ func JoinWithLeftAssociativeOp(op OpCode, a Expr, b Expr) Expr {\n }\n \n func JoinWithComma(a Expr, b Expr) Expr {\n+\tif a.Data == nil {\n+\t\treturn b\n+\t}\n+\tif b.Data == nil {\n+\t\treturn a\n+\t}\n \treturn Expr{Loc: a.Loc, Data: &EBinary{Op: BinOpComma, Left: a, Right: b}}\n }\n \n-func JoinAllWithComma(all []Expr) Expr {\n-\tresult := all[0]\n-\tfor _, value := range all[1:] {\n+func JoinAllWithComma(all []Expr) (result Expr) {\n+\tfor _, value := range all {\n \t\tresult = JoinWithComma(result, value)\n \t}\n-\treturn result\n+\treturn\n }\n \n type ExprOrStmt struct {\n@@ -1942,3 +1947,58 @@ func EnsureValidIdentifier(base string) string {\n \t}\n \treturn string(bytes)\n }\n+\n+func ConvertBindingToExpr(binding Binding, wrapIdentifier func(logger.Loc, Ref) Expr) Expr {\n+\tloc := binding.Loc\n+\n+\tswitch b := binding.Data.(type) {\n+\tcase *BMissing:\n+\t\treturn Expr{Loc: loc, Data: &EMissing{}}\n+\n+\tcase *BIdentifier:\n+\t\tif wrapIdentifier != nil {\n+\t\t\treturn wrapIdentifier(loc, b.Ref)\n+\t\t}\n+\t\treturn Expr{Loc: loc, Data: &EIdentifier{Ref: b.Ref}}\n+\n+\tcase *BArray:\n+\t\texprs := make([]Expr, len(b.Items))\n+\t\tfor i, item := range b.Items {\n+\t\t\texpr := ConvertBindingToExpr(item.Binding, wrapIdentifier)\n+\t\t\tif b.HasSpread && i+1 == len(b.Items) {\n+\t\t\t\texpr = Expr{Loc: expr.Loc, Data: &ESpread{Value: expr}}\n+\t\t\t} else if item.DefaultValue != nil {\n+\t\t\t\texpr = Assign(expr, *item.DefaultValue)\n+\t\t\t}\n+\t\t\texprs[i] = expr\n+\t\t}\n+\t\treturn Expr{Loc: loc, Data: &EArray{\n+\t\t\tItems:        exprs,\n+\t\t\tIsSingleLine: b.IsSingleLine,\n+\t\t}}\n+\n+\tcase *BObject:\n+\t\tproperties := make([]Property, len(b.Properties))\n+\t\tfor i, property := range b.Properties {\n+\t\t\tvalue := ConvertBindingToExpr(property.Value, wrapIdentifier)\n+\t\t\tkind := PropertyNormal\n+\t\t\tif property.IsSpread {\n+\t\t\t\tkind = PropertySpread\n+\t\t\t}\n+\t\t\tproperties[i] = Property{\n+\t\t\t\tKind:        kind,\n+\t\t\t\tIsComputed:  property.IsComputed,\n+\t\t\t\tKey:         property.Key,\n+\t\t\t\tValue:       &value,\n+\t\t\t\tInitializer: property.DefaultValue,\n+\t\t\t}\n+\t\t}\n+\t\treturn Expr{Loc: loc, Data: &EObject{\n+\t\t\tProperties:   properties,\n+\t\t\tIsSingleLine: b.IsSingleLine,\n+\t\t}}\n+\n+\tdefault:\n+\t\tpanic(\"Internal error\")\n+\t}\n+}"},{"sha":"ac599b20e553268d0947b70ee97ef5405fcbef60","filename":"internal/js_parser/js_parser.go","status":"modified","additions":13,"deletions":78,"changes":91,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fjs_parser%2Fjs_parser.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fjs_parser%2Fjs_parser.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_parser%2Fjs_parser.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -2549,61 +2549,6 @@ func (p *parser) convertExprToBinding(expr js_ast.Expr, invalidLog []logger.Loc)\n \t}\n }\n \n-func (p *parser) convertBindingToExpr(binding js_ast.Binding, wrapIdentifier func(logger.Loc, js_ast.Ref) js_ast.Expr) js_ast.Expr {\n-\tloc := binding.Loc\n-\n-\tswitch b := binding.Data.(type) {\n-\tcase *js_ast.BMissing:\n-\t\treturn js_ast.Expr{Loc: loc, Data: &js_ast.EMissing{}}\n-\n-\tcase *js_ast.BIdentifier:\n-\t\tif wrapIdentifier != nil {\n-\t\t\treturn wrapIdentifier(loc, b.Ref)\n-\t\t}\n-\t\treturn js_ast.Expr{Loc: loc, Data: &js_ast.EIdentifier{Ref: b.Ref}}\n-\n-\tcase *js_ast.BArray:\n-\t\texprs := make([]js_ast.Expr, len(b.Items))\n-\t\tfor i, item := range b.Items {\n-\t\t\texpr := p.convertBindingToExpr(item.Binding, wrapIdentifier)\n-\t\t\tif b.HasSpread && i+1 == len(b.Items) {\n-\t\t\t\texpr = js_ast.Expr{Loc: expr.Loc, Data: &js_ast.ESpread{Value: expr}}\n-\t\t\t} else if item.DefaultValue != nil {\n-\t\t\t\texpr = js_ast.Assign(expr, *item.DefaultValue)\n-\t\t\t}\n-\t\t\texprs[i] = expr\n-\t\t}\n-\t\treturn js_ast.Expr{Loc: loc, Data: &js_ast.EArray{\n-\t\t\tItems:        exprs,\n-\t\t\tIsSingleLine: b.IsSingleLine,\n-\t\t}}\n-\n-\tcase *js_ast.BObject:\n-\t\tproperties := make([]js_ast.Property, len(b.Properties))\n-\t\tfor i, property := range b.Properties {\n-\t\t\tvalue := p.convertBindingToExpr(property.Value, wrapIdentifier)\n-\t\t\tkind := js_ast.PropertyNormal\n-\t\t\tif property.IsSpread {\n-\t\t\t\tkind = js_ast.PropertySpread\n-\t\t\t}\n-\t\t\tproperties[i] = js_ast.Property{\n-\t\t\t\tKind:        kind,\n-\t\t\t\tIsComputed:  property.IsComputed,\n-\t\t\t\tKey:         property.Key,\n-\t\t\t\tValue:       &value,\n-\t\t\t\tInitializer: property.DefaultValue,\n-\t\t\t}\n-\t\t}\n-\t\treturn js_ast.Expr{Loc: loc, Data: &js_ast.EObject{\n-\t\t\tProperties:   properties,\n-\t\t\tIsSingleLine: b.IsSingleLine,\n-\t\t}}\n-\n-\tdefault:\n-\t\tpanic(\"Internal error\")\n-\t}\n-}\n-\n type exprFlag uint8\n \n const (\n@@ -8201,7 +8146,7 @@ func (p *parser) visitAndAppendStmt(stmts []js_ast.Stmt, stmt js_ast.Stmt) []js_\n \t\t\t}\n \t\t\tfor _, decl := range s.Decls {\n \t\t\t\tif decl.Value != nil {\n-\t\t\t\t\ttarget := p.convertBindingToExpr(decl.Binding, wrapIdentifier)\n+\t\t\t\t\ttarget := js_ast.ConvertBindingToExpr(decl.Binding, wrapIdentifier)\n \t\t\t\t\tif result, ok := p.lowerAssign(target, *decl.Value, objRestReturnValueIsUnused); ok {\n \t\t\t\t\t\ttarget = result\n \t\t\t\t\t} else {\n@@ -8756,11 +8701,11 @@ func (p *parser) maybeRelocateVarsToTopLevel(decls []js_ast.Decl, mode relocateV\n \t}\n \tvar value js_ast.Expr\n \tfor _, decl := range decls {\n-\t\tbinding := p.convertBindingToExpr(decl.Binding, wrapIdentifier)\n+\t\tbinding := js_ast.ConvertBindingToExpr(decl.Binding, wrapIdentifier)\n \t\tif decl.Value != nil {\n-\t\t\tvalue = maybeJoinWithComma(value, js_ast.Assign(binding, *decl.Value))\n+\t\t\tvalue = js_ast.JoinWithComma(value, js_ast.Assign(binding, *decl.Value))\n \t\t} else if mode == relocateVarsForInOrForOf {\n-\t\t\tvalue = maybeJoinWithComma(value, binding)\n+\t\t\tvalue = js_ast.JoinWithComma(value, binding)\n \t\t}\n \t}\n \tif value.Data == nil {\n@@ -8816,16 +8761,6 @@ func (p *parser) maybeTransposeIfExprChain(expr js_ast.Expr, visit func(js_ast.E\n \treturn visit(expr)\n }\n \n-func maybeJoinWithComma(a js_ast.Expr, b js_ast.Expr) js_ast.Expr {\n-\tif a.Data == nil {\n-\t\treturn b\n-\t}\n-\tif b.Data == nil {\n-\t\treturn a\n-\t}\n-\treturn js_ast.JoinWithComma(a, b)\n-}\n-\n type captureValueMode uint8\n \n const (\n@@ -10878,7 +10813,7 @@ func (p *parser) visitExprInOut(expr js_ast.Expr, in exprIn) (js_ast.Expr, exprO\n \t\t\t\tif p.options.mangleSyntax {\n \t\t\t\t\t// \"(a, true) ? b : c\" => \"a, b\"\n \t\t\t\t\tif sideEffects == couldHaveSideEffects {\n-\t\t\t\t\t\treturn maybeJoinWithComma(p.simplifyUnusedExpr(e.Test), e.Yes), exprOut{}\n+\t\t\t\t\t\treturn js_ast.JoinWithComma(p.simplifyUnusedExpr(e.Test), e.Yes), exprOut{}\n \t\t\t\t\t}\n \n \t\t\t\t\t// \"(1 ? fn : 2)()\" => \"fn()\"\n@@ -10901,7 +10836,7 @@ func (p *parser) visitExprInOut(expr js_ast.Expr, in exprIn) (js_ast.Expr, exprO\n \t\t\t\tif p.options.mangleSyntax {\n \t\t\t\t\t// \"(a, false) ? b : c\" => \"a, c\"\n \t\t\t\t\tif sideEffects == couldHaveSideEffects {\n-\t\t\t\t\t\treturn maybeJoinWithComma(p.simplifyUnusedExpr(e.Test), e.No), exprOut{}\n+\t\t\t\t\t\treturn js_ast.JoinWithComma(p.simplifyUnusedExpr(e.Test), e.No), exprOut{}\n \t\t\t\t\t}\n \n \t\t\t\t\t// \"(0 ? 1 : fn)()\" => \"fn()\"\n@@ -12463,7 +12398,7 @@ func (p *parser) simplifyUnusedExpr(expr js_ast.Expr) js_ast.Expr {\n \t\t// array items with side effects. Apply this simplification recursively.\n \t\tvar result js_ast.Expr\n \t\tfor _, item := range e.Items {\n-\t\t\tresult = maybeJoinWithComma(result, p.simplifyUnusedExpr(item))\n+\t\t\tresult = js_ast.JoinWithComma(result, p.simplifyUnusedExpr(item))\n \t\t}\n \t\treturn result\n \n@@ -12503,13 +12438,13 @@ func (p *parser) simplifyUnusedExpr(expr js_ast.Expr) js_ast.Expr {\n \t\tfor _, property := range e.Properties {\n \t\t\tif property.IsComputed {\n \t\t\t\t// Make sure \"ToString\" is still evaluated on the key\n-\t\t\t\tresult = maybeJoinWithComma(result, js_ast.Expr{Loc: property.Key.Loc, Data: &js_ast.EBinary{\n+\t\t\t\tresult = js_ast.JoinWithComma(result, js_ast.Expr{Loc: property.Key.Loc, Data: &js_ast.EBinary{\n \t\t\t\t\tOp:    js_ast.BinOpAdd,\n \t\t\t\t\tLeft:  property.Key,\n \t\t\t\t\tRight: js_ast.Expr{Loc: property.Key.Loc, Data: &js_ast.EString{}},\n \t\t\t\t}})\n \t\t\t}\n-\t\t\tresult = maybeJoinWithComma(result, p.simplifyUnusedExpr(*property.Value))\n+\t\t\tresult = js_ast.JoinWithComma(result, p.simplifyUnusedExpr(*property.Value))\n \t\t}\n \t\treturn result\n \n@@ -12554,15 +12489,15 @@ func (p *parser) simplifyUnusedExpr(expr js_ast.Expr) js_ast.Expr {\n \t\t// These operators must not have any type conversions that can execute code\n \t\t// such as \"toString\" or \"valueOf\". They must also never throw any exceptions.\n \t\tcase js_ast.BinOpStrictEq, js_ast.BinOpStrictNe, js_ast.BinOpComma:\n-\t\t\treturn maybeJoinWithComma(p.simplifyUnusedExpr(e.Left), p.simplifyUnusedExpr(e.Right))\n+\t\t\treturn js_ast.JoinWithComma(p.simplifyUnusedExpr(e.Left), p.simplifyUnusedExpr(e.Right))\n \n \t\t// We can simplify \"==\" and \"!=\" even though they can call \"toString\" and/or\n \t\t// \"valueOf\" if we can statically determine that the types of both sides are\n \t\t// primitives. In that case there won't be any chance for user-defined\n \t\t// \"toString\" and/or \"valueOf\" to be called.\n \t\tcase js_ast.BinOpLooseEq, js_ast.BinOpLooseNe:\n \t\t\tif isPrimitiveWithSideEffects(e.Left.Data) && isPrimitiveWithSideEffects(e.Right.Data) {\n-\t\t\t\treturn maybeJoinWithComma(p.simplifyUnusedExpr(e.Left), p.simplifyUnusedExpr(e.Right))\n+\t\t\t\treturn js_ast.JoinWithComma(p.simplifyUnusedExpr(e.Left), p.simplifyUnusedExpr(e.Right))\n \t\t\t}\n \n \t\tcase js_ast.BinOpLogicalAnd, js_ast.BinOpLogicalOr, js_ast.BinOpNullishCoalescing:\n@@ -12586,7 +12521,7 @@ func (p *parser) simplifyUnusedExpr(expr js_ast.Expr) js_ast.Expr {\n \t\tif e.CanBeUnwrappedIfUnused {\n \t\t\texpr = js_ast.Expr{}\n \t\t\tfor _, arg := range e.Args {\n-\t\t\t\texpr = maybeJoinWithComma(expr, p.simplifyUnusedExpr(arg))\n+\t\t\t\texpr = js_ast.JoinWithComma(expr, p.simplifyUnusedExpr(arg))\n \t\t\t}\n \t\t}\n \n@@ -12596,7 +12531,7 @@ func (p *parser) simplifyUnusedExpr(expr js_ast.Expr) js_ast.Expr {\n \t\tif e.CanBeUnwrappedIfUnused {\n \t\t\texpr = js_ast.Expr{}\n \t\t\tfor _, arg := range e.Args {\n-\t\t\t\texpr = maybeJoinWithComma(expr, p.simplifyUnusedExpr(arg))\n+\t\t\t\texpr = js_ast.JoinWithComma(expr, p.simplifyUnusedExpr(arg))\n \t\t\t}\n \t\t}\n \t}"},{"sha":"e5e6fa55cd03f90fe859922a4f279256f25a2ddc","filename":"internal/js_parser/js_parser_lower.go","status":"modified","additions":5,"deletions":5,"changes":10,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fjs_parser%2Fjs_parser_lower.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fjs_parser%2Fjs_parser_lower.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_parser%2Fjs_parser_lower.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -263,7 +263,7 @@ func (p *parser) lowerFunction(\n \t\tfor i, arg := range *args {\n \t\t\tif bindingHasObjectRest(arg.Binding) {\n \t\t\t\tref := p.generateTempRef(tempRefNoDeclare, \"\")\n-\t\t\t\ttarget := p.convertBindingToExpr(arg.Binding, nil)\n+\t\t\t\ttarget := js_ast.ConvertBindingToExpr(arg.Binding, nil)\n \t\t\t\tinit := js_ast.Expr{Loc: arg.Binding.Loc, Data: &js_ast.EIdentifier{Ref: ref}}\n \t\t\t\tp.recordUsage(ref)\n \n@@ -1135,7 +1135,7 @@ func (p *parser) lowerObjectRestInDecls(decls []js_ast.Decl) []js_ast.Decl {\n \t\t\tclone := append([]js_ast.Decl{}, decls[:i]...)\n \t\t\tfor _, decl := range decls[i:] {\n \t\t\t\tif decl.Value != nil {\n-\t\t\t\t\ttarget := p.convertBindingToExpr(decl.Binding, nil)\n+\t\t\t\t\ttarget := js_ast.ConvertBindingToExpr(decl.Binding, nil)\n \t\t\t\t\tif result, ok := p.lowerObjectRestToDecls(target, *decl.Value, clone); ok {\n \t\t\t\t\t\tclone = result\n \t\t\t\t\t\tcontinue\n@@ -1224,7 +1224,7 @@ func (p *parser) lowerAssign(rootExpr js_ast.Expr, rootInit js_ast.Expr, mode ob\n \n \tvar expr js_ast.Expr\n \tassign := func(left js_ast.Expr, right js_ast.Expr) {\n-\t\texpr = maybeJoinWithComma(expr, js_ast.Assign(left, right))\n+\t\texpr = js_ast.JoinWithComma(expr, js_ast.Assign(left, right))\n \t}\n \n \tif initWrapFunc, ok := p.lowerObjectRestHelper(rootExpr, rootInit, assign, tempRefNeedsDeclare, mode); ok {\n@@ -1838,11 +1838,11 @@ func (p *parser) lowerClass(stmt js_ast.Stmt, expr js_ast.Expr, shadowRef js_ast\n \n \t\t\tif !needsKey {\n \t\t\t\t// Just evaluate the key for its side effects\n-\t\t\t\tcomputedPropertyCache = maybeJoinWithComma(computedPropertyCache, prop.Key)\n+\t\t\t\tcomputedPropertyCache = js_ast.JoinWithComma(computedPropertyCache, prop.Key)\n \t\t\t} else {\n \t\t\t\t// Store the key in a temporary so we can assign to it later\n \t\t\t\tref := p.generateTempRef(tempRefNeedsDeclare, \"\")\n-\t\t\t\tcomputedPropertyCache = maybeJoinWithComma(computedPropertyCache,\n+\t\t\t\tcomputedPropertyCache = js_ast.JoinWithComma(computedPropertyCache,\n \t\t\t\t\tjs_ast.Assign(js_ast.Expr{Loc: prop.Key.Loc, Data: &js_ast.EIdentifier{Ref: ref}}, prop.Key))\n \t\t\t\tprop.Key = js_ast.Expr{Loc: prop.Key.Loc, Data: &js_ast.EIdentifier{Ref: ref}}\n \t\t\t\tkeyExprNoSideEffects = prop.Key"},{"sha":"2073f827a46c81fd0b8232710723928e10099aa5","filename":"internal/js_printer/js_printer.go","status":"modified","additions":142,"deletions":91,"changes":233,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fjs_printer%2Fjs_printer.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fjs_printer%2Fjs_printer.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fjs_printer%2Fjs_printer.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -1211,12 +1211,33 @@ type requireCallArgs struct {\n \tmustReturnPromise bool\n }\n \n-func (p *printer) printRequireOrImportExpr(importRecordIndex uint32, leadingInteriorComments []js_ast.Comment) {\n+func (p *printer) printRequireOrImportExpr(importRecordIndex uint32, leadingInteriorComments []js_ast.Comment, level js_ast.L, flags int) {\n \trecord := &p.importRecords[importRecordIndex]\n-\tp.printSpaceBeforeIdentifier()\n \n-\t// Preserve \"import()\" expressions that don't point inside the bundle\n-\tif !record.SourceIndex.IsValid() && record.Kind == ast.ImportDynamic {\n+\tif level >= js_ast.LNew || (flags&forbidCall) != 0 {\n+\t\tp.print(\"(\")\n+\t\tdefer p.print(\")\")\n+\t\tlevel = js_ast.LLowest\n+\t}\n+\n+\tif !record.SourceIndex.IsValid() {\n+\t\t// External \"require()\"\n+\t\tif record.Kind != ast.ImportDynamic {\n+\t\t\tif record.WrapWithToModule {\n+\t\t\t\tp.printSymbol(p.options.ToModuleRef)\n+\t\t\t\tp.print(\"(\")\n+\t\t\t\tdefer p.print(\")\")\n+\t\t\t}\n+\t\t\tp.printSpaceBeforeIdentifier()\n+\t\t\tp.print(\"require(\")\n+\t\t\tp.addSourceMapping(record.Range.Loc)\n+\t\t\tp.printQuotedUTF8(record.Path.Text, true /* allowBacktick */)\n+\t\t\tp.print(\")\")\n+\t\t\treturn\n+\t\t}\n+\n+\t\t// External \"import()\"\n+\t\tp.printSpaceBeforeIdentifier()\n \t\tp.print(\"import(\")\n \t\tif len(leadingInteriorComments) > 0 {\n \t\t\tp.printNewline()\n@@ -1237,68 +1258,96 @@ func (p *printer) printRequireOrImportExpr(importRecordIndex uint32, leadingInte\n \t\treturn\n \t}\n \n-\t// Make sure \"import()\" expressions return promises\n-\tif record.Kind == ast.ImportDynamic {\n-\t\tif p.options.UnsupportedFeatures.Has(compat.Arrow) {\n-\t\t\tp.print(\"Promise.resolve().then(function()\")\n-\t\t\tp.printSpace()\n-\t\t\tp.print(\"{\")\n-\t\t\tp.printNewline()\n-\t\t\tp.options.Indent++\n-\t\t\tp.printIndent()\n-\t\t\tp.print(\"return \")\n-\t\t} else {\n-\t\t\tif p.options.RemoveWhitespace {\n-\t\t\t\tp.print(\"Promise.resolve().then(()=>\")\n-\t\t\t} else {\n-\t\t\t\tp.print(\"Promise.resolve().then(() => \")\n-\t\t\t}\n+\tmeta := p.options.RequireOrImportMetaForSource(record.SourceIndex.GetIndex())\n+\n+\t// Don't need the namespace object if the result is unused anyway\n+\tif (flags & exprResultIsUnused) != 0 {\n+\t\tmeta.ExportsRef = js_ast.InvalidRef\n+\t}\n+\n+\t// Internal \"import()\" of async ESM\n+\tif record.Kind == ast.ImportDynamic && meta.IsWrapperAsync {\n+\t\tp.printSymbol(meta.WrapperRef)\n+\t\tp.print(\"()\")\n+\t\tif meta.ExportsRef != js_ast.InvalidRef {\n+\t\t\tp.printDotThenPrefix()\n+\t\t\tp.printSymbol(meta.ExportsRef)\n+\t\t\tp.printDotThenSuffix()\n \t\t}\n+\t\treturn\n \t}\n \n-\t// Make sure CommonJS imports are converted to ES6 if necessary\n+\t// Internal \"require()\" or \"import()\"\n+\tif record.Kind == ast.ImportDynamic {\n+\t\tp.print(\"Promise.resolve()\")\n+\t\tlevel = p.printDotThenPrefix()\n+\t\tdefer p.printDotThenSuffix()\n+\t}\n+\n+\t// Make sure the comma operator is propertly wrapped\n+\tif meta.ExportsRef != js_ast.InvalidRef && level >= js_ast.LComma {\n+\t\tp.print(\"(\")\n+\t\tdefer p.print(\")\")\n+\t}\n+\n+\t// Wrap this with a call to \"__toModule()\" if this is a CommonJS file\n \tif record.WrapWithToModule {\n \t\tp.printSymbol(p.options.ToModuleRef)\n \t\tp.print(\"(\")\n+\t\tdefer p.print(\")\")\n \t}\n \n-\t// If this import points inside the bundle, then call the \"require()\"\n-\t// function for that module directly. The linker must ensure that the\n-\t// module's require function exists by this point. Otherwise, fall back to a\n-\t// bare \"require()\" call. Then it's up to the user to provide it.\n-\tif record.SourceIndex.IsValid() {\n-\t\tp.printSymbol(p.options.WrapperRefForSource(record.SourceIndex.GetIndex()))\n-\t\tp.print(\"()\")\n-\t} else {\n-\t\tp.print(\"require(\")\n-\t\tp.addSourceMapping(record.Range.Loc)\n-\t\tp.printQuotedUTF8(record.Path.Text, true /* allowBacktick */)\n-\t\tp.print(\")\")\n+\t// Call the wrapper\n+\tp.printSymbol(meta.WrapperRef)\n+\tp.print(\"()\")\n+\n+\t// Return the namespace object if this is an ESM file\n+\tif meta.ExportsRef != js_ast.InvalidRef {\n+\t\tp.print(\",\")\n+\t\tp.printSpace()\n+\t\tp.printSymbol(meta.ExportsRef)\n \t}\n+}\n \n-\tif record.WrapWithToModule {\n-\t\tp.print(\")\")\n+func (p *printer) printDotThenPrefix() js_ast.L {\n+\tif p.options.UnsupportedFeatures.Has(compat.Arrow) {\n+\t\tp.print(\".then(function()\")\n+\t\tp.printSpace()\n+\t\tp.print(\"{\")\n+\t\tp.printNewline()\n+\t\tp.options.Indent++\n+\t\tp.printIndent()\n+\t\tp.print(\"return\")\n+\t\tp.printSpace()\n+\t\treturn js_ast.LLowest\n+\t} else {\n+\t\tp.print(\".then(()\")\n+\t\tp.printSpace()\n+\t\tp.print(\"=>\")\n+\t\tp.printSpace()\n+\t\treturn js_ast.LComma\n \t}\n+}\n \n-\tif record.Kind == ast.ImportDynamic {\n-\t\tif p.options.UnsupportedFeatures.Has(compat.Arrow) {\n-\t\t\tif !p.options.RemoveWhitespace {\n-\t\t\t\tp.print(\";\")\n-\t\t\t}\n-\t\t\tp.printNewline()\n-\t\t\tp.options.Indent--\n-\t\t\tp.printIndent()\n-\t\t\tp.print(\"})\")\n-\t\t} else {\n-\t\t\tp.print(\")\")\n+func (p *printer) printDotThenSuffix() {\n+\tif p.options.UnsupportedFeatures.Has(compat.Arrow) {\n+\t\tif !p.options.RemoveWhitespace {\n+\t\t\tp.print(\";\")\n \t\t}\n+\t\tp.printNewline()\n+\t\tp.options.Indent--\n+\t\tp.printIndent()\n+\t\tp.print(\"})\")\n+\t} else {\n+\t\tp.print(\")\")\n \t}\n }\n \n const (\n \tforbidCall = 1 << iota\n \tforbidIn\n \thasNonOptionalChainParent\n+\texprResultIsUnused\n )\n \n func (p *printer) printUndefined(level js_ast.L) {\n@@ -1439,14 +1488,7 @@ func (p *printer) printExpr(expr js_ast.Expr, level js_ast.L, flags int) {\n \t\t}\n \n \tcase *js_ast.ERequire:\n-\t\twrap := level >= js_ast.LNew || (flags&forbidCall) != 0\n-\t\tif wrap {\n-\t\t\tp.print(\"(\")\n-\t\t}\n-\t\tp.printRequireOrImportExpr(e.ImportRecordIndex, nil)\n-\t\tif wrap {\n-\t\t\tp.print(\")\")\n-\t\t}\n+\t\tp.printRequireOrImportExpr(e.ImportRecordIndex, nil, level, flags)\n \n \tcase *js_ast.ERequireResolve:\n \t\twrap := level >= js_ast.LNew || (flags&forbidCall) != 0\n@@ -1462,41 +1504,41 @@ func (p *printer) printExpr(expr js_ast.Expr, level js_ast.L, flags int) {\n \t\t}\n \n \tcase *js_ast.EImport:\n-\t\twrap := level >= js_ast.LNew || (flags&forbidCall) != 0\n-\t\tif wrap {\n-\t\t\tp.print(\"(\")\n-\t\t}\n-\n \t\tvar leadingInteriorComments []js_ast.Comment\n \t\tif !p.options.RemoveWhitespace {\n \t\t\tleadingInteriorComments = e.LeadingInteriorComments\n \t\t}\n \n \t\tif e.ImportRecordIndex.IsValid() {\n-\t\t\tp.printRequireOrImportExpr(e.ImportRecordIndex.GetIndex(), leadingInteriorComments)\n+\t\t\tp.printRequireOrImportExpr(e.ImportRecordIndex.GetIndex(), leadingInteriorComments, level, flags)\n \t\t} else {\n \t\t\t// Handle non-string expressions\n-\t\t\tp.printSpaceBeforeIdentifier()\n-\t\t\tp.print(\"import(\")\n-\t\t\tif len(leadingInteriorComments) > 0 {\n-\t\t\t\tp.printNewline()\n-\t\t\t\tp.options.Indent++\n-\t\t\t\tfor _, comment := range e.LeadingInteriorComments {\n-\t\t\t\t\tp.printIndentedComment(comment.Text)\n+\t\t\tif !e.ImportRecordIndex.IsValid() {\n+\t\t\t\twrap := level >= js_ast.LNew || (flags&forbidCall) != 0\n+\t\t\t\tif wrap {\n+\t\t\t\t\tp.print(\"(\")\n+\t\t\t\t}\n+\t\t\t\tp.printSpaceBeforeIdentifier()\n+\t\t\t\tp.print(\"import(\")\n+\t\t\t\tif len(leadingInteriorComments) > 0 {\n+\t\t\t\t\tp.printNewline()\n+\t\t\t\t\tp.options.Indent++\n+\t\t\t\t\tfor _, comment := range e.LeadingInteriorComments {\n+\t\t\t\t\t\tp.printIndentedComment(comment.Text)\n+\t\t\t\t\t}\n+\t\t\t\t\tp.printIndent()\n+\t\t\t\t}\n+\t\t\t\tp.printExpr(e.Expr, js_ast.LComma, 0)\n+\t\t\t\tif len(leadingInteriorComments) > 0 {\n+\t\t\t\t\tp.printNewline()\n+\t\t\t\t\tp.options.Indent--\n+\t\t\t\t\tp.printIndent()\n+\t\t\t\t}\n+\t\t\t\tp.print(\")\")\n+\t\t\t\tif wrap {\n+\t\t\t\t\tp.print(\")\")\n \t\t\t\t}\n-\t\t\t\tp.printIndent()\n-\t\t\t}\n-\t\t\tp.printExpr(e.Expr, js_ast.LComma, 0)\n-\t\t\tif len(leadingInteriorComments) > 0 {\n-\t\t\t\tp.printNewline()\n-\t\t\t\tp.options.Indent--\n-\t\t\t\tp.printIndent()\n \t\t\t}\n-\t\t\tp.print(\")\")\n-\t\t}\n-\n-\t\tif wrap {\n-\t\t\tp.print(\")\")\n \t\t}\n \n \tcase *js_ast.EDot:\n@@ -2248,7 +2290,7 @@ func (p *printer) printDeclStmt(isExport bool, keyword string, decls []js_ast.De\n func (p *printer) printForLoopInit(init js_ast.Stmt) {\n \tswitch s := init.Data.(type) {\n \tcase *js_ast.SExpr:\n-\t\tp.printExpr(s.Value, js_ast.LLowest, forbidIn)\n+\t\tp.printExpr(s.Value, js_ast.LLowest, forbidIn|exprResultIsUnused)\n \tcase *js_ast.SLocal:\n \t\tswitch s.Kind {\n \t\tcase js_ast.LocalVar:\n@@ -2964,7 +3006,7 @@ func (p *printer) printStmt(stmt js_ast.Stmt) {\n \tcase *js_ast.SExpr:\n \t\tp.printIndent()\n \t\tp.stmtStart = len(p.js)\n-\t\tp.printExpr(s.Value, js_ast.LLowest, 0)\n+\t\tp.printExpr(s.Value, js_ast.LLowest, exprResultIsUnused)\n \t\tp.printSemicolonAfterStatement()\n \n \tdefault:\n@@ -2982,16 +3024,16 @@ func (p *printer) shouldIgnoreSourceMap() bool {\n }\n \n type Options struct {\n-\tOutputFormat        config.Format\n-\tRemoveWhitespace    bool\n-\tMangleSyntax        bool\n-\tASCIIOnly           bool\n-\tExtractComments     bool\n-\tAddSourceMappings   bool\n-\tIndent              int\n-\tToModuleRef         js_ast.Ref\n-\tWrapperRefForSource func(uint32) js_ast.Ref\n-\tUnsupportedFeatures compat.JSFeature\n+\tOutputFormat                 config.Format\n+\tRemoveWhitespace             bool\n+\tMangleSyntax                 bool\n+\tASCIIOnly                    bool\n+\tExtractComments              bool\n+\tAddSourceMappings            bool\n+\tIndent                       int\n+\tToModuleRef                  js_ast.Ref\n+\tUnsupportedFeatures          compat.JSFeature\n+\tRequireOrImportMetaForSource func(uint32) RequireOrImportMeta\n \n \t// If we're writing out a source map, this table of line start indices lets\n \t// us do binary search on to figure out what line a given AST node came from\n@@ -3002,6 +3044,15 @@ type Options struct {\n \tInputSourceMap *sourcemap.SourceMap\n }\n \n+type RequireOrImportMeta struct {\n+\t// CommonJS files will return the \"require_*\" wrapper function and an invalid\n+\t// exports object reference. Lazily-initialized ESM files will return the\n+\t// \"init_*\" wrapper function and the exports object for that file.\n+\tWrapperRef     js_ast.Ref\n+\tExportsRef     js_ast.Ref\n+\tIsWrapperAsync bool\n+}\n+\n type SourceMapChunk struct {\n \tBuffer []byte\n "},{"sha":"102772288430c5ed8a368ea7d9065a819ab55f7e","filename":"internal/runtime/runtime.go","status":"modified","additions":3,"deletions":0,"changes":3,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fruntime%2Fruntime.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/internal%2Fruntime%2Fruntime.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fruntime%2Fruntime.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -99,6 +99,9 @@ func code(isES6 bool) string {\n \t\t\treturn target\n \t\t}\n \n+\t\t// This is for lazily-initialized ESM code\n+\t\texport var __esm = (fn, res) => () => (fn && (res = fn(fn = 0)), res)\n+\n \t\t// Wraps a CommonJS closure and returns a require() function\n \t\texport var __commonJS = (cb, mod) => () => (mod || cb((mod = {exports: {}}).exports, mod), mod.exports)\n "},{"sha":"5322de3a1f3645ff1cd7cf83cd8d2f63721a1292","filename":"lib/common.ts","status":"modified","additions":17,"deletions":5,"changes":22,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/lib%2Fcommon.ts","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/lib%2Fcommon.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Fcommon.ts?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -35,6 +35,9 @@ let mustBeArray = <T>(value: T[] | undefined): string | null =>\n let mustBeObject = (value: Object | undefined): string | null =>\n   typeof value === 'object' && value !== null && !Array.isArray(value) ? null : 'an object';\n \n+let mustBeArrayOrRecord = <T extends string>(value: T[] | Record<T, T> | undefined): string | null =>\n+  typeof value === 'object' && value !== null ? null : 'an array or an object';\n+\n let mustBeObjectOrNull = (value: Object | null | undefined): string | null =>\n   typeof value === 'object' && !Array.isArray(value) ? null : 'an object or null';\n \n@@ -146,6 +149,7 @@ function flagsForBuildOptions(\n   logLevelDefault: types.LogLevel,\n   writeDefault: boolean,\n ): {\n+  entries: [string, string][],\n   flags: string[],\n   write: boolean,\n   stdinContents: string | null,\n@@ -156,6 +160,7 @@ function flagsForBuildOptions(\n   watch: types.WatchMode | null,\n } {\n   let flags: string[] = [];\n+  let entries: [string, string][] = [];\n   let keys: OptionKeys = Object.create(null);\n   let stdinContents: string | null = null;\n   let stdinResolveDir: string | null = null;\n@@ -188,7 +193,7 @@ function flagsForBuildOptions(\n   let inject = getFlag(options, keys, 'inject', mustBeArray);\n   let banner = getFlag(options, keys, 'banner', mustBeObject);\n   let footer = getFlag(options, keys, 'footer', mustBeObject);\n-  let entryPoints = getFlag(options, keys, 'entryPoints', mustBeArray);\n+  let entryPoints = getFlag(options, keys, 'entryPoints', mustBeArrayOrRecord);\n   let absWorkingDir = getFlag(options, keys, 'absWorkingDir', mustBeString);\n   let stdin = getFlag(options, keys, 'stdin', mustBeObject);\n   let write = getFlag(options, keys, 'write', mustBeBoolean) ?? writeDefault; // Default to true if not specified\n@@ -276,10 +281,14 @@ function flagsForBuildOptions(\n   }\n \n   if (entryPoints) {\n-    for (let entryPoint of entryPoints) {\n-      entryPoint += '';\n-      if (entryPoint.startsWith('-')) throw new Error(`Invalid entry point: ${entryPoint}`);\n-      flags.push(entryPoint);\n+    if (Array.isArray(entryPoints)) {\n+      for (let entryPoint of entryPoints) {\n+        entries.push(['', entryPoint + '']);\n+      }\n+    } else {\n+      for (let [key, value] of Object.entries(entryPoints)) {\n+        entries.push([key + '', value + '']);\n+      }\n     }\n   }\n \n@@ -306,6 +315,7 @@ function flagsForBuildOptions(\n   }\n \n   return {\n+    entries,\n     flags,\n     write,\n     stdinContents,\n@@ -844,6 +854,7 @@ export function createChannel(streamIn: StreamIn): StreamOut {\n             [requestPlugins, pluginRefs] = handlePlugins(options, plugins, key, details);\n           }\n           let {\n+            entries,\n             flags,\n             write,\n             stdinContents,\n@@ -856,6 +867,7 @@ export function createChannel(streamIn: StreamIn): StreamOut {\n           let request: protocol.BuildRequest = {\n             command: 'build',\n             key,\n+            entries,\n             flags,\n             write,\n             stdinContents,"},{"sha":"bdf38152b553b900cc14c4aa2d97033badb9d7a9","filename":"lib/stdio_protocol.ts","status":"modified","additions":1,"deletions":0,"changes":1,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/lib%2Fstdio_protocol.ts","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/lib%2Fstdio_protocol.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Fstdio_protocol.ts?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -9,6 +9,7 @@ import * as types from \"./types\";\n export interface BuildRequest {\n   command: 'build';\n   key: number;\n+  entries: [string, string][]; // Use an array instead of a map to preserve order\n   flags: string[];\n   write: boolean;\n   stdinContents: string | null;"},{"sha":"ff8f2cbd900b4431af70c02d11c6ffdbdb41b009","filename":"lib/types.ts","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/lib%2Ftypes.ts","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/lib%2Ftypes.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Ftypes.ts?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -57,7 +57,7 @@ export interface BuildOptions extends CommonOptions {\n   banner?: { [type: string]: string };\n   footer?: { [type: string]: string };\n   incremental?: boolean;\n-  entryPoints?: string[];\n+  entryPoints?: string[] | Record<string, string>;\n   stdin?: StdinOptions;\n   plugins?: Plugin[];\n   absWorkingDir?: string;"},{"sha":"1207bb205323137c6709373899321f84f685c2de","filename":"pkg/api/api.go","status":"modified","additions":8,"deletions":1,"changes":9,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/pkg%2Fapi%2Fapi.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/pkg%2Fapi%2Fapi.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fapi%2Fapi.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -271,7 +271,9 @@ type BuildOptions struct {\n \tChunkNames string\n \tAssetNames string\n \n-\tEntryPoints []string\n+\tEntryPoints         []string\n+\tEntryPointsAdvanced []EntryPoint\n+\n \tStdin       *StdinOptions\n \tWrite       bool\n \tIncremental bool\n@@ -280,6 +282,11 @@ type BuildOptions struct {\n \tWatch *WatchMode\n }\n \n+type EntryPoint struct {\n+\tInputPath  string\n+\tOutputPath string\n+}\n+\n type WatchMode struct {\n \tOnRebuild func(BuildResult)\n }"},{"sha":"9a0ec98e60c5aab378f4c95cb8ea37841a2892c6","filename":"pkg/api/api_impl.go","status":"modified","additions":7,"deletions":1,"changes":8,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/pkg%2Fapi%2Fapi_impl.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/pkg%2Fapi%2Fapi_impl.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fapi%2Fapi_impl.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -792,7 +792,13 @@ func rebuildImpl(\n \tfor i, path := range buildOpts.NodePaths {\n \t\toptions.AbsNodePaths[i] = validatePath(log, realFS, path, \"node path\")\n \t}\n-\tentryPoints := append([]string{}, buildOpts.EntryPoints...)\n+\tentryPoints := make([]bundler.EntryPoint, 0, len(buildOpts.EntryPoints)+len(buildOpts.EntryPointsAdvanced))\n+\tfor _, ep := range buildOpts.EntryPoints {\n+\t\tentryPoints = append(entryPoints, bundler.EntryPoint{InputPath: ep})\n+\t}\n+\tfor _, ep := range buildOpts.EntryPointsAdvanced {\n+\t\tentryPoints = append(entryPoints, bundler.EntryPoint{InputPath: ep.InputPath, OutputPath: ep.OutputPath})\n+\t}\n \tentryPointCount := len(entryPoints)\n \tif buildOpts.Stdin != nil {\n \t\tentryPointCount++"},{"sha":"5ecd6f428f2fd0e01b6e1fc2f893d1d7ea6cbc4b","filename":"pkg/cli/cli_impl.go","status":"modified","additions":9,"deletions":2,"changes":11,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/pkg%2Fcli%2Fcli_impl.go","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/pkg%2Fcli%2Fcli_impl.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fcli%2Fcli_impl.go?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -458,7 +458,14 @@ func parseOptionsImpl(\n \t\t\treturn fmt.Errorf(\"Unexpected single quote character before flag (use \\\\\\\" to escape double quotes): %s\", arg), nil\n \n \t\tcase !strings.HasPrefix(arg, \"-\") && buildOpts != nil:\n-\t\t\tbuildOpts.EntryPoints = append(buildOpts.EntryPoints, arg)\n+\t\t\tif equals := strings.IndexByte(arg, '='); equals != -1 {\n+\t\t\t\tbuildOpts.EntryPointsAdvanced = append(buildOpts.EntryPointsAdvanced, api.EntryPoint{\n+\t\t\t\t\tOutputPath: arg[:equals],\n+\t\t\t\t\tInputPath:  arg[equals+1:],\n+\t\t\t\t})\n+\t\t\t} else {\n+\t\t\t\tbuildOpts.EntryPoints = append(buildOpts.EntryPoints, arg)\n+\t\t\t}\n \n \t\tdefault:\n \t\t\tif buildOpts != nil {\n@@ -606,7 +613,7 @@ func runImpl(osArgs []string) int {\n \t\t}\n \n \t\t// Read from stdin when there are no entry points\n-\t\tif len(buildOptions.EntryPoints) == 0 {\n+\t\tif len(buildOptions.EntryPoints)+len(buildOptions.EntryPointsAdvanced) == 0 {\n \t\t\tif buildOptions.Stdin == nil {\n \t\t\t\tbuildOptions.Stdin = &api.StdinOptions{}\n \t\t\t}"},{"sha":"915f31823d66a44466171c8d3580da8289c6956d","filename":"scripts/end-to-end-tests.js","status":"modified","additions":94,"deletions":6,"changes":100,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/scripts%2Fend-to-end-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/scripts%2Fend-to-end-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fend-to-end-tests.js?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -183,6 +183,13 @@\n     )\n   }\n \n+  // Test custom output paths\n+  tests.push(\n+    test(['node=entry.js', '--outdir=.'], {\n+      'entry.js': ``,\n+    }),\n+  )\n+\n   // Make sure that the \"asm.js\" directive is removed\n   tests.push(\n     test(['in.js', '--outfile=node.js'], {\n@@ -362,6 +369,21 @@\n       'foo.js': `let fn = (m, x) => m.exports = x; fn(module, 123)`,\n       'node.js': `if (require('./out').default !== 123) throw 'fail'`,\n     }),\n+\n+    // Deferred require shouldn't affect import\n+    test(['--bundle', 'in.js', '--outfile=node.js', '--format=cjs'], {\n+      'in.js': `\n+        import { foo } from './a'\n+        import './b'\n+        if (foo !== 123) throw 'fail'\n+      `,\n+      'a.js': `\n+        export let foo = 123\n+      `,\n+      'b.js': `\n+        setTimeout(() => require('./a'), 0)\n+      `,\n+    }),\n   )\n \n   // Test internal CommonJS export\n@@ -375,11 +397,11 @@\n       'foo.js': `module.exports = 123`,\n     }),\n     test(['--bundle', 'in.js', '--outfile=node.js'], {\n-      'in.js': `const out = require('./foo'); if (!out.__esModule || out.foo !== 123) throw 'fail'`,\n+      'in.js': `const out = require('./foo'); if (out.__esModule || out.foo !== 123) throw 'fail'`,\n       'foo.js': `export const foo = 123`,\n     }),\n     test(['--bundle', 'in.js', '--outfile=node.js'], {\n-      'in.js': `const out = require('./foo'); if (!out.__esModule || out.default !== 123) throw 'fail'`,\n+      'in.js': `const out = require('./foo'); if (out.__esModule || out.default !== 123) throw 'fail'`,\n       'foo.js': `export default 123`,\n     }),\n \n@@ -390,12 +412,18 @@\n     test(['--bundle', 'in.js', '--outfile=node.js'], {\n       'in.js': `module.exports = 123; const out = require('./in'); if (out.__esModule || out !== 123) throw 'fail'`,\n     }),\n-    test(['--bundle', 'in.js', '--outfile=node.js'], {\n+    test(['--bundle', 'in.js', '--outfile=node.js', '--format=cjs'], {\n       'in.js': `export const foo = 123; const out = require('./in'); if (!out.__esModule || out.foo !== 123) throw 'fail'`,\n     }),\n-    test(['--bundle', 'in.js', '--outfile=node.js'], {\n+    test(['--bundle', 'in.js', '--outfile=node.js', '--format=cjs'], {\n       'in.js': `export default 123; const out = require('./in'); if (!out.__esModule || out.default !== 123) throw 'fail'`,\n     }),\n+    test(['--bundle', 'in.js', '--outfile=node.js', '--format=esm'], {\n+      'in.js': `export const foo = 123; const out = require('./in'); if (out.__esModule || out.foo !== 123) throw 'fail'`,\n+    }),\n+    test(['--bundle', 'in.js', '--outfile=node.js', '--format=esm'], {\n+      'in.js': `export default 123; const out = require('./in'); if (out.__esModule || out.default !== 123) throw 'fail'`,\n+    }),\n \n     // Test bundled and non-bundled double export star\n     test(['node.ts', '--bundle', '--format=cjs', '--outdir=.'], {\n@@ -419,7 +447,7 @@\n         import {a, b} from './re-export'\n         if (a !== 'a' || b !== 'b') throw 'fail'\n \n-        // Try forcing all of these modules to be CommonJS wrappers\n+        // Try forcing all of these modules to be wrappers\n         require('./node')\n         require('./re-export')\n         require('./a')\n@@ -436,6 +464,36 @@\n         export let b = 'b'\n       `,\n     }),\n+    test(['node.ts', '--bundle', '--format=cjs', '--outdir=.'], {\n+      'node.ts': `\n+        import {a, b, c, d} from './re-export'\n+        if (a !== 'a' || b !== 'b' || c !== 'c' || d !== 'd') throw 'fail'\n+\n+        // Try forcing all of these modules to be wrappers\n+        require('./node')\n+        require('./re-export')\n+        require('./a')\n+        require('./b')\n+      `,\n+      're-export.ts': `\n+        export * from './a'\n+        export * from './b'\n+        export * from './d'\n+      `,\n+      'a.ts': `\n+        export let a = 'a'\n+      `,\n+      'b.ts': `\n+        exports.b = 'b'\n+      `,\n+      'c.ts': `\n+        exports.c = 'c'\n+      `,\n+      'd.ts': `\n+        export * from './c'\n+        export let d = 'd'\n+      `,\n+    }),\n     test(['node.ts', 're-export.ts', 'a.ts', 'b.ts', '--format=cjs', '--outdir=.'], {\n       'node.ts': `\n         import {a, b} from './re-export'\n@@ -505,7 +563,7 @@\n         let fn = a()\n         if (fn === a || fn() !== a) throw 'fail'\n \n-        // Try forcing all of these modules to be CommonJS wrappers\n+        // Try forcing all of these modules to be wrappers\n         require('./node')\n         require('./re-export')\n         require('./a')\n@@ -3488,6 +3546,36 @@\n     )\n   }\n \n+  // Top-level await tests\n+  tests.push(\n+    test(['in.js', '--outdir=out', '--format=esm', '--bundle'], {\n+      'in.js': `\n+        function foo() {\n+          globalThis.tlaTrace.push(2)\n+          return import('./a.js')\n+        }\n+\n+        globalThis.tlaTrace = []\n+        globalThis.tlaTrace.push(1)\n+        const it = (await foo()).default\n+        globalThis.tlaTrace.push(6)\n+        if (it !== 123 || globalThis.tlaTrace.join(',') !== '1,2,3,4,5,6') throw 'fail'\n+      `,\n+      'a.js': `\n+        globalThis.tlaTrace.push(5)\n+        export { default } from './b.js'\n+      `,\n+      'b.js': `\n+        globalThis.tlaTrace.push(3)\n+        export default await Promise.resolve(123)\n+        globalThis.tlaTrace.push(4)\n+      `,\n+      'node.js': `\n+        import './out/in.js'\n+      `,\n+    }),\n+  )\n+\n   // Test writing to stdout\n   tests.push(\n     // These should succeed"},{"sha":"1f60309b1b0e7f8364f45ec803311f6f1bfe199f","filename":"scripts/js-api-tests.js","status":"modified","additions":79,"deletions":3,"changes":82,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/scripts%2Fjs-api-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/scripts%2Fjs-api-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fjs-api-tests.js?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -22,7 +22,7 @@ let buildTests = {\n       })\n       throw new Error('Expected build failure');\n     } catch (e) {\n-      if (!e.errors || !e.errors[0] || e.errors[0].text !== '\"entryPoints\" must be an array') {\n+      if (!e.errors || !e.errors[0] || e.errors[0].text !== '\"entryPoints\" must be an array or an object') {\n         throw e;\n       }\n     }\n@@ -930,8 +930,8 @@ body {\n     const inShared = makeInPath(shared);\n     const chunk = 'chunk-HPFXYN2E.js';\n     const outEntry = makeOutPath(path.relative(testDir, entry));\n-    const outImport1 = makeOutPath(path.relative(testDir, import1));\n-    const outImport2 = makeOutPath(path.relative(testDir, import2));\n+    const outImport1 = makeOutPath('import1-5CIBHJEX.js');\n+    const outImport2 = makeOutPath('import2-5CIBHJEX.js');\n     const outChunk = makeOutPath(chunk);\n \n     assert.deepStrictEqual(json.inputs[inEntry], {\n@@ -2145,6 +2145,82 @@ console.log(\"success\");\n     assert.strictEqual(outputFiles.length, 1)\n     new Function(outputFiles[0].text)()\n   },\n+\n+  async automaticEntryPointOutputPathsWithDot({ esbuild, testDir }) {\n+    const input = path.join(testDir, 'in.file.ts')\n+    const css = path.join(testDir, 'file.css')\n+    await writeFileAsync(input, `import './file.css'; console.log('test')`)\n+    await writeFileAsync(css, `body { color: red }`)\n+    var { outputFiles } = await esbuild.build({\n+      entryPoints: [input],\n+      outdir: testDir,\n+      bundle: true,\n+      write: false,\n+    })\n+    assert.strictEqual(outputFiles.length, 2)\n+    assert.strictEqual(outputFiles[0].path, path.join(testDir, 'in.file.js'))\n+    assert.strictEqual(outputFiles[1].path, path.join(testDir, 'in.file.css'))\n+  },\n+\n+  async customEntryPointOutputPathsWithDot({ esbuild, testDir }) {\n+    const input = path.join(testDir, 'in.file.ts')\n+    const css = path.join(testDir, 'file.css')\n+    await writeFileAsync(input, `import './file.css'; console.log('test')`)\n+    await writeFileAsync(css, `body { color: red }`)\n+    var { outputFiles } = await esbuild.build({\n+      entryPoints: {\n+        'out.test': input,\n+      },\n+      outdir: testDir,\n+      bundle: true,\n+      write: false,\n+    })\n+    assert.strictEqual(outputFiles.length, 2)\n+    assert.strictEqual(outputFiles[0].path, path.join(testDir, 'out.test.js'))\n+    assert.strictEqual(outputFiles[1].path, path.join(testDir, 'out.test.css'))\n+  },\n+\n+  async customEntryPointOutputPathsRel({ esbuild, testDir }) {\n+    const input1 = path.join(testDir, 'in1.js')\n+    const input2 = path.join(testDir, 'in2.js')\n+    const output1 = 'out/1.cjs'\n+    const output2 = 'out/2.mjs'\n+    await writeFileAsync(input1, `console.log('in1')`)\n+    await writeFileAsync(input2, `console.log('in2')`)\n+    var { outputFiles } = await esbuild.build({\n+      entryPoints: {\n+        [output1]: input1,\n+        [output2]: input2,\n+      },\n+      entryNames: 'entry/[dir]/[hash]-[name]',\n+      outdir: testDir,\n+      write: false,\n+    })\n+    assert.strictEqual(outputFiles.length, 2)\n+    assert.strictEqual(outputFiles[0].path, path.join(testDir, 'entry', 'out', '55DD6UTG-1.cjs.js'))\n+    assert.strictEqual(outputFiles[1].path, path.join(testDir, 'entry', 'out', 'PBNYN6W7-2.mjs.js'))\n+  },\n+\n+  async customEntryPointOutputPathsAbs({ esbuild, testDir }) {\n+    const input1 = path.join(testDir, 'in1.js')\n+    const input2 = path.join(testDir, 'in2.js')\n+    const output1 = path.join(testDir, 'out/1')\n+    const output2 = path.join(testDir, 'out/2')\n+    await writeFileAsync(input1, `console.log('in1')`)\n+    await writeFileAsync(input2, `console.log('in2')`)\n+    var { outputFiles } = await esbuild.build({\n+      entryPoints: {\n+        [output1]: input1,\n+        [output2]: input2,\n+      },\n+      entryNames: 'entry/[dir]/[hash]-[name]',\n+      outdir: testDir,\n+      write: false,\n+    })\n+    assert.strictEqual(outputFiles.length, 2)\n+    assert.strictEqual(outputFiles[0].path, path.join(testDir, 'entry', 'out', 'NNGUQQ6B-1.js'))\n+    assert.strictEqual(outputFiles[1].path, path.join(testDir, 'entry', 'out', 'UP345ZY4-2.js'))\n+  },\n }\n \n function fetch(host, port, path) {"},{"sha":"8f5d3d92c1834354c38a11631e61543e7b96a6fa","filename":"scripts/plugin-tests.js","status":"modified","additions":44,"deletions":4,"changes":48,"blob_url":"https://github.com/evanw/esbuild/blob/413eb705870925b0e83c4b0990793de7bb3656b5/scripts%2Fplugin-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/413eb705870925b0e83c4b0990793de7bb3656b5/scripts%2Fplugin-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fplugin-tests.js?ref=413eb705870925b0e83c4b0990793de7bb3656b5","patch":"@@ -853,16 +853,35 @@ let pluginTests = {\n       }],\n     })\n     assert.strictEqual(result.outputFiles.length, 4)\n-    assert.strictEqual(result.outputFiles[0].path, path.join(testDir, 'input 1.js'))\n-    assert.strictEqual(result.outputFiles[1].path, path.join(testDir, 'input 2.js'))\n-    assert.strictEqual(result.outputFiles[2].path, path.join(testDir, 'input a_b.js'))\n-    assert.strictEqual(result.outputFiles[3].path, path.join(testDir, 'c.d.js'))\n+    assert.strictEqual(result.outputFiles[0].path, path.join(testDir, '1.js'))\n+    assert.strictEqual(result.outputFiles[1].path, path.join(testDir, '2.js'))\n+    assert.strictEqual(result.outputFiles[2].path, path.join(testDir, 'a_b.js'))\n+    assert.strictEqual(result.outputFiles[3].path, path.join(testDir, 'a/b/c.d.js'))\n     assert.strictEqual(result.outputFiles[0].text, `// virtual-ns:input 1\\nconsole.log(\"input 1\");\\n`)\n     assert.strictEqual(result.outputFiles[1].text, `// virtual-ns:input 2\\nconsole.log(\"input 2\");\\n`)\n     assert.strictEqual(result.outputFiles[2].text, `// virtual-ns:input a<>:\"|?*b\\nconsole.log('input a<>:\"|?*b');\\n`)\n     assert.strictEqual(result.outputFiles[3].text, `// virtual-ns:input a/b/c.d.e\\nconsole.log(\"input a/b/c.d.e\");\\n`)\n   },\n \n+  async entryPointFileNamespace({ esbuild, testDir }) {\n+    const input = path.join(testDir, 'in.js')\n+    let worked = false\n+    await writeFileAsync(input, 'stuff')\n+    await esbuild.build({\n+      entryPoints: [input],\n+      write: false,\n+      plugins: [{\n+        name: 'name',\n+        setup(build) {\n+          build.onResolve({ filter: /.*/, namespace: 'file' }, () => {\n+            worked = true\n+          })\n+        },\n+      }],\n+    })\n+    assert(worked)\n+  },\n+\n   async stdinImporter({ esbuild, testDir }) {\n     const output = path.join(testDir, 'out.js')\n     await esbuild.build({\n@@ -1823,6 +1842,27 @@ let pluginTests = {\n     })\n     assert.strictEqual(build.warnings.length, 0)\n   },\n+\n+  async onResolvePreserveOriginalEntryPointNameIssue945({ esbuild, testDir }) {\n+    const build = await esbuild.build({\n+      entryPoints: ['first'],\n+      write: false,\n+      logLevel: 'silent',\n+      outdir: testDir,\n+      plugins: [{\n+        name: 'plugin',\n+        setup(build) {\n+          build.onResolve({ filter: /.*/ }, () => {\n+            return { path: 'second', namespace: 'what' }\n+          })\n+          build.onLoad({ filter: /.*/ }, () => {\n+            return { contents: `` }\n+          })\n+        },\n+      }],\n+    })\n+    assert.strictEqual(build.outputFiles[0].path, path.join(testDir, 'first.js'))\n+  },\n }\n \n // These tests have to run synchronously"}]},{"url":"https://api.github.com/repos/evanw/esbuild/issues/924","repository_url":"https://api.github.com/repos/evanw/esbuild","labels_url":"https://api.github.com/repos/evanw/esbuild/issues/924/labels{/name}","comments_url":"https://api.github.com/repos/evanw/esbuild/issues/924/comments","events_url":"https://api.github.com/repos/evanw/esbuild/issues/924/events","html_url":"https://github.com/evanw/esbuild/pull/924","id":823599088,"node_id":"MDExOlB1bGxSZXF1ZXN0NTg2MDI2ODQ4","number":924,"title":"WIP for version 0.9.0","user":{"login":"evanw","id":406394,"node_id":"MDQ6VXNlcjQwNjM5NA==","avatar_url":"https://avatars.githubusercontent.com/u/406394?v=4","gravatar_id":"","url":"https://api.github.com/users/evanw","html_url":"https://github.com/evanw","followers_url":"https://api.github.com/users/evanw/followers","following_url":"https://api.github.com/users/evanw/following{/other_user}","gists_url":"https://api.github.com/users/evanw/gists{/gist_id}","starred_url":"https://api.github.com/users/evanw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/evanw/subscriptions","organizations_url":"https://api.github.com/users/evanw/orgs","repos_url":"https://api.github.com/users/evanw/repos","events_url":"https://api.github.com/users/evanw/events{/privacy}","received_events_url":"https://api.github.com/users/evanw/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":10,"created_at":"2021-03-06T08:48:43Z","updated_at":"2021-03-09T04:51:37Z","closed_at":"2021-03-09T04:51:30Z","author_association":"OWNER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/evanw/esbuild/pulls/924","html_url":"https://github.com/evanw/esbuild/pull/924","diff_url":"https://github.com/evanw/esbuild/pull/924.diff","patch_url":"https://github.com/evanw/esbuild/pull/924.patch","merged_at":"2021-03-09T04:51:30Z"},"body":"I'm using this PR to put together the next breaking change release as I build it. Not sure if a PR is the best format for this but I'm giving it a shot. So this PR exists to publicly document what's going into the upcoming version 0.9.0 release. I will be updating it as I go.\r\n\r\nFor context: I have been trying to batch breaking changes together so that they are less disruptive. But they have been piling up because one of the big changes (the linker rewrite) is unfortunately taking longer than I had hoped. I'd like to do a breaking change release now to get some of these breaking changes out even though it won't contain the linker rewrite just to keep other things moving along. This might mean there are at least two breaking change releases coming up: this one and another one with the linker rewrite. Note that the next version after version 0.9.0 will be version 0.10.0, not version 1.0.0. It's definitely getting close to 1.0.0 but it's not quite that close.\r\n\r\nThe rewrite of the linker is being done to address many shortcomings of the current linker all at once. However, that has involved some significant R&D effort (e.g. [1](https://github.com/evanw/esbuild/issues/253#issuecomment-768842454), [2](https://github.com/evanw/esbuild/issues/399#issuecomment-782587966), [3](https://github.com/evanw/esbuild/issues/465#issuecomment-778761208), [4](https://github.com/evanw/esbuild/issues/518#issuecomment-781818245)) and it is unfortunately still a work in progress. I did a brain dump of some information about the linker rewrite at the end of this post.\r\n\r\n## Definitely in version 0.9.0\r\n\r\n- [x] Remove the now-unused `--avoid-tdz` flag\r\n\r\n    This flag no longer does anything because this transformation is now always applied during bundling. It hasn't been removed yet to avoid a breaking change.\r\n\r\n- [x] Remove `SpinnerBusy` and `SpinnerIdle` from the Go API\r\n\r\n    These options were part of an experiment with the CLI that didn't work out. Watch mode no longer uses a spinner because it turns out people want to be able to interleave esbuild's stderr pipe with other tools and were getting tripped up by the spinner animation. These options are currently ignored but haven't been removed yet to avoid a breaking change.\r\n\r\n- [x] Remove the `--summary` flag and instead just always print a summary (#704)\r\n\r\n    The summary can be disabled if you don't want it by passing `--log-level=warning` instead. And it can be enabled in the API by setting `logLevel: 'info'`. I'm going to try this because I believe it will improve the UX. People have this problem with esbuild when they first try it where it runs so quickly that they think it must be broken, only to later discover that it actually worked fine. While this is funny, it seems like a good indication that the UX could be improved. So I'm going to try automatically printing a summary to see how that goes.\r\n\r\n- [x] Remove the `startService()` API, leaving only `build()` and `transform()`\r\n\r\n    The context is that the `startService()` API [was added quickly in response to a user request](https://github.com/evanw/esbuild/issues/75#issuecomment-624300019) and at the time I was unaware of [`unref()`](https://nodejs.org/api/child_process.html#child_process_subprocess_unref) which makes it possible to use a child process without requiring people to call `service.stop()`. Many thanks to @SalvatorePreviti who contributed this change in #656. Calling `service.stop()` no longer does anything, so there is no longer a strong reason for keeping the `startService()` API around. The primary thing it currently does is just make the API more complicated and harder to use. I plan to add an `initialize({ wasmURL })` API to replace the configuration of `wasmURL` in the browser that used to be done by `startService()`. And the `buildSync()` and `transformSync()` APIs will still exist on node.\r\n\r\n- [x] Split the banner and footer features into separate values for JS and CSS (#712)\r\n\r\n    I have been trying to make sure all of the features added are language-agnostic where it makes sense. However, the banner and footer features were an oversight and were added as a JavaScript-specific feature. They don't currently work with CSS. I plan to change the API to make it a mapping of language to value to make it more language-agnostic, which is a breaking change.\r\n\r\n## Probably in version 0.9.0\r\n\r\n- [x] Remove the implicit `.mjs` and `.cjs` extensions\r\n\r\n    I added these because Webpack has implicit `.mjs` extensions and it seemed like a reasonable idea to support these at the time. However, doing this can actually break packages that have `some-file.mjs` and `some-file.js` sitting side-by-side. This also isn't how node works so doing this breaks compatibility with node. So it feels like this should be an opt-in change instead of an opt-out change. I'm going to try removing them from the default configuration. You can still configure them yourself with the \"resolve extensions\" setting if you'd like, although it might break stuff. Otherwise you should use the `.mjs` and `.cjs` extensions explicitly instead of omitting them.\r\n\r\n- [ ] Remove the ability to use `require(...)` on a file in ESM (ECMAScript module) format\r\n\r\n    I had originally enabled this because it seemed reasonable to support. You can just convert the ESM file to a CommonJS file when you hit this case and then load it as CommonJS instead. However, this has a few problems:\r\n\r\n    * This isn't how node works. Doing this in node is impossible and will cause a syntax error. So it's kind of a weird thing to support and there isn't really a precedent that says how it should behave. I want esbuild to follow existing conventions instead of inventing new ones, and it turns out this was kind of inventing a new convention. It feels best for esbuild and for the ecosystem if people don't come to rely on this weird thing actually working, so I'm going to try disabling this.\r\n\r\n    * Doing this makes import order really confusing to reason about. Part of what I am doing with the linker rewrite is to be much more strict about having esbuild follow the correct import order, but this edge case doesn't have a well-defined import ordering. The problem is that ESM import order is determined by a depth-first traversal of the import graph and is entirely statically determined at link time, but `require(...)` is dynamically-determined at run time. Where do ESM imports in the required file end up in the static module initialization order? Do they even end up in the static module initialization order at all? Should they also be converted from ESM to CommonJS recursively, potentially contaminating a large part of the bundle? There isn't really any existing ESM-native platform that behaves this way.\r\n\r\n    * It also causes extra issues now that TLA (top-level await) is a part of JavaScript. TLA is only available in ESM files and means that loading them can now be asynchronous. But `require(...)` is synchronous so loading an ESM file with a TLA file anywhere in its dependency chain must be forbidden. If using `require(...)` with ESM were to be supported then you may be seemingly arbitrarily prevented from adding an `await` to a file because some other file in a seemingly unrelated place happened to use a `require(...)` call. It seems better for code health to just avoid this possibility in the first place. This constraint also makes the bundler simpler to implement.\r\n\r\n    Getting this change out should hopefully make the linker rewrite go more smoothly.\r\n\r\n## Maybe in version 0.9.0\r\n\r\n- [x] Add support for node's `exports` field in `package.json` (#187)\r\n\r\n    This feature was recently added to node. It allows you to rewrite what import paths inside your package map to as well as to prevent people from importing certain files in your package. Adding support for this to esbuild is a breaking change (i.e. code that was working fine before can easily stop working) so it must be done in a breaking change release.\r\n- [x] Remove the `metafile` from `outputFiles` (#633)\r\n\r\n    Right now using `metafile` with the API is unnecessarily cumbersome because you have to extract the JSON metadata from the output file yourself instead of it just being provided to you as a return value. This is especially a bummer if you are using `write: false` because then you need to use a for loop over the output files and do string comparisons with the file paths to try to find the one corresponding to the `metafile`. Returning the metadata directly is an important UX improvement for the API. This hasn't been done yet because doing this is a breaking change.\r\n\r\n\r\n- [ ] Support content hashes in entry point names (#518)\r\n\r\n    Support for this is already planned. The plan is to add the `--entry-names=` flag and let you put the `[hash]` placeholder somewhere inside it to cause esbuild to include the content hash in entry point names. You can then use the `metafile` to figure out what the output path was for each entry point. However, this would introduce cycles into the content hash calculation as the content hash includes not just the current file but also all of the content hashes of all transitive dependencies and entry points can reference each other using dynamic `import(...)` expressions.\r\n\r\n    Addressing this requires a different approach to chunk generation that is part of the linker rewrite. This technically isn't a breaking change but it has a strong possibility of accidentally introducing bugs (especially with source maps) since it's a lot of new code, so it may also be appropriate for a breaking change release. Although it could potentially make sense to hold this back for the next breaking change release to avoid delays.\r\n\r\n## Hopefully in version 0.10.0\r\n\r\n- Code splitting for all output formats (#16)\r\n\r\n    Right now code splitting only works for the `esm` output format, and only works for JavaScript. It should also work for the `iife` and `cjs` output formats, and also for CSS. I have a plan to address this and it is a part of the linker redesign.\r\n\r\n- Manual chunk labels (#207)\r\n\r\n    This feature isn't implemented yet because it creates import cycles and the content hashing algorithm can't deal with cycles yet. But this is being kept in mind during the linker rewrite so this should be relatively easy to add when the new linker is ready.\r\n\r\n- Collapse duplicate external imports (#475)\r\n\r\n    Right now each individual `import` statement for an external module ends up in the bundle even though they all reference the same external path and the external file is only ever imported once. I plan to collapse this into as few import statements as possible (usually one but may be up to three) as part of the rewrite of the linker.\r\n\r\n- Bundling with top-level await (#253)\r\n\r\n    It's important to have esbuild support top-level await now that it's officially a part of JavaScript and usable in both node and in the browser. Unfortunately the semantics are extremely complicated (and not even implemented correctly in V8 yet!) so esbuild's initial implementation may not be totally accurate. It will at least contain the important parts (`await` works and sibling modules go in parallel). Currently all implementations behave slightly differently so there isn't yet common consensus about exact behavior among implementations. My current plan is to bundle files into groups by what asynchronous files they transitively depend on to reduce the overall number of files, then evaluate files within those groups in the order they would have been evalauted in if there was no top-level await. Cross-group ordering will depend on the order of promise resolutions.\r\n\r\n- Fix import ordering issues with internal code (#399, #465)\r\n\r\n    Right now import order is not accurate when code splitting is active. The fundamental issue is that code in chunks is eagerly evaluated when that chunk is imported but different parts of the chunk need to be evaluated at different times for correctness. Either the chunk needs to be split into smaller chunks or code in chunks must be lazily evaluated to fix import order. I'm currently planning to lazily evaluate code to avoid additional chunk splits.\r\n\r\n- Potentially break the ordering of external imports\r\n\r\n    External imports cannot be lazily evaluated in `esm` and respecting the correct import order would hurt bundle optimization and make the bundler more complicated. Either chunks would have to be split into further chunks or code would potentially need to be awkwardly stuffed into `import` statements containing data URLs, both of which would bloat code and hurt bundle download performance. I'm currently considering having external import order still be incorrect (i.e. hoisted to the top) since that's much simpler and seems to be what some other bundlers do anyway.\r\n\r\n- Potentially roll back the file splitting optimization\r\n\r\n    Currently esbuild contains an optimization that no other bundler supports: individual unrelated statements within a file can end up in separate chunks when code splitting is active if they are used by a disjoint set of entry points. This means you can have a big library file of functions and potentially not have any shared chunks if no two entry points use any of the same functions. However, the blocking for top-level await works at the file boundary and this optimization made thinking through top-level await evaluation order too complicated. I'm seriously considering removing this optimization to restore my sanity and get top-level await out the door. I don't feel too bad about this because no other bundler does this yet anyway.\r\n","reactions":{"url":"https://api.github.com/repos/evanw/esbuild/issues/924/reactions","total_count":30,"+1":3,"-1":0,"laugh":0,"hooray":2,"confused":0,"heart":20,"rocket":3,"eyes":2},"timeline_url":"https://api.github.com/repos/evanw/esbuild/issues/924/timeline","performed_via_github_app":null,"state_reason":null,"score":1,"files":[{"sha":"f55a62207493e5e820a1db816663a8fa99de422f","filename":"CHANGELOG.md","status":"modified","additions":110,"deletions":0,"changes":110,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/CHANGELOG.md","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/CHANGELOG.md","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/CHANGELOG.md?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -1,5 +1,115 @@\n # Changelog\n \n+## Breaking changes\n+\n+* Remove the deprecated `--avoid-tdz` option\n+\n+    This option is now always enabled and cannot be disabled, so it is being removed from the API. The existing API parameter no longer does anything so this removal has no effect the generated output.\n+\n+* Remove `SpinnerBusy` and `SpinnerIdle` from the Go API\n+\n+    These options were part of an experiment with the CLI that didn't work out. Watch mode no longer uses a spinner because it turns out people want to be able to interleave esbuild's stderr pipe with other tools and were getting tripped up by the spinner animation. These options no longer do anything and have been removed.\n+\n+* Remove the `--summary` flag and instead just always print a summary ([#704](https://github.com/evanw/esbuild/issues/704))\n+\n+    The summary can be disabled if you don't want it by passing `--log-level=warning` instead. And it can be enabled in the API by setting `logLevel: 'info'`. I'm going to try this because I believe it will improve the UX. People have this problem with esbuild when they first try it where it runs so quickly that they think it must be broken, only to later discover that it actually worked fine. While this is funny, it seems like a good indication that the UX could be improved. So I'm going to try automatically printing a summary to see how that goes. Note that the summary is not printed if incremental builds are active (this includes the watch and serve modes).\n+\n+* Remove the `esbuild.startService()` API\n+\n+    Due to [#656](https://github.com/evanw/esbuild/issues/656), Calling `service.stop()` no longer does anything, so there is no longer a strong reason for keeping the `esbuild.startService()` API around. The primary thing it currently does is just make the API more complicated and harder to use. You can now just call `esbuild.build()` and `esbuild.transform()` directly instead of calling `esbuild.startService().then(service => service.build())` or `esbuild.startService().then(service => service.transform())`.\n+\n+    If you are using esbuild in the browser, you now need to call `esbuild.initialize({ wasmURL })` and wait for the returned promise before calling `esbuild.transform()`. It takes the same options that `esbuild.startService()` used to take. Note that the `esbuild.buildSync()` and `esbuild.transformSync()` APIs still exist when using esbuild in node. Nothing has changed about the synchronous esbuild APIs.\n+\n+* The banner and footer options are now language-specific ([#712](https://github.com/evanw/esbuild/issues/712))\n+\n+    The `--banner=` and `--footer=` options now require you to pass the file type:\n+\n+    * CLI:\n+\n+        ```\n+        esbuild --banner:js=//banner --footer:js=//footer\n+        esbuild --banner:css=/*banner*/ --footer:css=/*footer*/\n+        ```\n+\n+    * JavaScript\n+\n+        ```js\n+        esbuild.build({\n+          banner: { js: '//banner', css: '/*banner*/' },\n+          footer: { js: '//footer', css: '/*footer*/' },\n+        })\n+        ```\n+\n+    * Go\n+\n+        ```go\n+        api.Build(api.BuildOptions{\n+          Banner: map[string]string{\"js\": \"//banner\"},\n+          Footer: map[string]string{\"js\": \"//footer\"},\n+        })\n+        api.Build(api.BuildOptions{\n+          Banner: map[string]string{\"css\": \"/*banner*/\"},\n+          Footer: map[string]string{\"css\": \"/*footer*/\"},\n+        })\n+        ```\n+\n+    This was changed because the feature was originally added in a JavaScript-specific manner, which was an oversight. CSS banners and footers must be separate from JavaScript banners and footers to avoid injecting JavaScript syntax into your CSS files.\n+\n+* The extensions `.mjs` and `.cjs` are no longer implicit\n+\n+    Previously the \"resolve extensions\" setting included `.mjs` and `.cjs` but this is no longer the case. This wasn't a good default because it doesn't match node's behavior and could break some packages. You now have to either explicitly specify these extensions or configure the \"resolve extensions\" setting yourself.\n+\n+* Add support for node's `exports` field in `package.json` files ([#187](https://github.com/evanw/esbuild/issues/187))\n+\n+    This feature was recently added to node. It allows you to rewrite what import paths inside your package map to as well as to prevent people from importing certain files in your package. Adding support for this to esbuild is a breaking change (i.e. code that was working fine before can easily stop working) so adding support for it has been delayed until this breaking change release.\n+\n+    One way to use this feature is to remap import paths for your package. For example, this would remap an import of `your-pkg/esm/lib.js` (the \"public\" import path) to `your-pkg/dist/esm/lib.js` (the \"private\" file system path):\n+\n+    ```json\n+    {\n+      \"name\": \"your-pkg\",\n+      \"exports\": {\n+        \"./esm/*\": \"./dist/esm/*\",\n+        \"./cjs/*\": \"./dist/cjs/*\"\n+      }\n+    }\n+    ```\n+\n+    Another way to use this feature is to have conditional imports where the same import path can mean different things in different situations. For example, this would remap `require('your-pkg')` to `your-pkg/required.cjs` and `import 'your-pkg'` to `your-pkg/imported.mjs`:\n+\n+    ```json\n+    {\n+      \"name\": \"your-pkg\",\n+      \"exports\": {\n+        \"import\": \"./imported.mjs\",\n+        \"require\": \"./required.cjs\"\n+      }\n+    }\n+    ```\n+\n+    There is built-in support for the `import` and `require` conditions depending on the kind of import and the `browser` and `node` conditions depending on the current platform. In addition, the `default` condition always applies regardless of the current configuration settings and can be used as a catch-all fallback condition.\n+\n+    Note that when you use conditions, _your package may end up in the bundle multiple times!_ This is a subtle issue that can cause bugs due to duplicate copies of your code's state in addition to bloating the resulting bundle. This is commonly known as the [dual package hazard](https://nodejs.org/docs/latest/api/packages.html#packages_dual_package_hazard). The primary way of avoiding this is to put all of your code in the `require` condition and have the `import` condition just be a light wrapper that calls `require` on your package and re-exports the package using ESM syntax.\n+\n+    There is also support for custom conditions with the `--conditions=` flag. The meaning of these is entirely up to package authors. For example, you could imagine a package that requires you to configure `--conditions=test,en-US`. Node has currently only endorsed the `development` and `production` custom conditions for recommended use.\n+\n+* Remove the `metafile` from `outputFiles` (#633)\n+\n+    Previously using `metafile` with the API is unnecessarily cumbersome because you have to extract the JSON metadata from the output file yourself instead of it just being provided to you as a return value. This is especially a bummer if you are using `write: false` because then you need to use a for loop over the output files and do string comparisons with the file paths to try to find the one corresponding to the `metafile`. Returning the metadata directly is an important UX improvement for the API. It means you can now do this:\n+\n+    ```js\n+    const result = await esbuild.build({\n+      entryPoints: ['entry.js'],\n+      bundle: true,\n+      metafile: true,\n+    })\n+    console.log(metafile.outputs)\n+    ```\n+\n+* Rename `--error-limit=` to `--log-limit=`\n+\n+    This parameter has been renamed because it now applies to both warnings and errors, not just to errors. Previously setting the error limit did not apply any limits to the number of warnings printed, which could sometimes result in a deluge of warnings that are problematic for Windows Command Prompt, which is very slow to print to and has very limited scrollback. Now the log limit applies to the total number of log messages including both errors and warnings, so no more than that number of messages will be printed. The log usually prints log messages immediately but it will now intentionally hold back warnings when approaching the limit to make room for possible future errors during a build. So if a build fails you should be guaranteed to see an error message (i.e. warnings can't use up the entire log limit and then prevent errors from being printed).\n+\n ## 0.8.57\n \n * Fix overlapping chunk names when code splitting is active ([#928](https://github.com/evanw/esbuild/issues/928))"},{"sha":"cec63c3244deb62dbe836baca057c5920684f387","filename":"Makefile","status":"modified","additions":10,"deletions":8,"changes":18,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/Makefile","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/Makefile","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/Makefile?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -7,11 +7,11 @@ test:\n \tmake -j6 test-common\n \n # These tests are for development\n-test-common: test-go vet-go no-filepath verify-source-map end-to-end-tests js-api-tests plugin-tests register-test\n+test-common: test-go vet-go no-filepath verify-source-map end-to-end-tests js-api-tests plugin-tests register-test node-unref-tests\n \n # These tests are for release (the extra tests are not included in \"test\" because they are pretty slow)\n test-all:\n-\tmake -j6 test-common ts-type-tests test-wasm-node test-wasm-browser\n+\tmake -j6 test-common ts-type-tests test-wasm-node test-wasm-browser lib-typecheck\n \n # This includes tests of some 3rd-party libraries, which can be very slow\n test-prepublish: check-go-version test-all test-preact-splitting test-sucrase bench-rome-esbuild test-esprima test-rollup\n@@ -67,6 +67,9 @@ plugin-tests: cmd/esbuild/version.go | scripts/node_modules\n ts-type-tests: | scripts/node_modules\n \tnode scripts/ts-type-tests.js\n \n+node-unref-tests:\n+\tnode scripts/node-unref-tests.js\n+\n lib-typecheck: | lib/node_modules\n \tcd lib && node_modules/.bin/tsc -noEmit -p .\n \n@@ -471,13 +474,13 @@ demo-three: demo-three-esbuild demo-three-rollup demo-three-webpack demo-three-w\n \n demo-three-esbuild: esbuild | demo/three\n \trm -fr demo/three/esbuild\n-\ttime -p ./esbuild --bundle --summary --global-name=THREE --sourcemap --minify demo/three/src/Three.js --outfile=demo/three/esbuild/Three.esbuild.js\n+\ttime -p ./esbuild --bundle --global-name=THREE --sourcemap --minify demo/three/src/Three.js --outfile=demo/three/esbuild/Three.esbuild.js\n \tdu -h demo/three/esbuild/Three.esbuild.js*\n \tshasum demo/three/esbuild/Three.esbuild.js*\n \n demo-three-eswasm: platform-wasm | demo/three\n \trm -fr demo/three/eswasm\n-\ttime -p ./npm/esbuild-wasm/bin/esbuild --bundle --summary --global-name=THREE \\\n+\ttime -p ./npm/esbuild-wasm/bin/esbuild --bundle --global-name=THREE \\\n \t\t--sourcemap --minify demo/three/src/Three.js --outfile=demo/three/eswasm/Three.eswasm.js\n \tdu -h demo/three/eswasm/Three.eswasm.js*\n \tshasum demo/three/eswasm/Three.eswasm.js*\n@@ -560,13 +563,13 @@ bench-three: bench-three-esbuild bench-three-rollup bench-three-webpack bench-th\n \n bench-three-esbuild: esbuild | bench/three\n \trm -fr bench/three/esbuild\n-\ttime -p ./esbuild --bundle --summary --global-name=THREE --sourcemap --minify bench/three/src/entry.js --outfile=bench/three/esbuild/entry.esbuild.js\n+\ttime -p ./esbuild --bundle --global-name=THREE --sourcemap --minify bench/three/src/entry.js --outfile=bench/three/esbuild/entry.esbuild.js\n \tdu -h bench/three/esbuild/entry.esbuild.js*\n \tshasum bench/three/esbuild/entry.esbuild.js*\n \n bench-three-eswasm: platform-wasm | bench/three\n \trm -fr bench/three/eswasm\n-\ttime -p ./npm/esbuild-wasm/bin/esbuild --bundle --summary --global-name=THREE \\\n+\ttime -p ./npm/esbuild-wasm/bin/esbuild --bundle --global-name=THREE \\\n \t\t--sourcemap --minify bench/three/src/entry.js --outfile=bench/three/eswasm/entry.eswasm.js\n \tdu -h bench/three/eswasm/entry.eswasm.js*\n \tshasum bench/three/eswasm/entry.eswasm.js*\n@@ -669,7 +672,7 @@ bench-rome: bench-rome-esbuild bench-rome-webpack bench-rome-webpack5 bench-rome\n \n bench-rome-esbuild: esbuild | bench/rome bench/rome-verify\n \trm -fr bench/rome/esbuild\n-\ttime -p ./esbuild --bundle --summary --sourcemap --minify bench/rome/src/entry.ts --outfile=bench/rome/esbuild/rome.esbuild.js --platform=node\n+\ttime -p ./esbuild --bundle --sourcemap --minify bench/rome/src/entry.ts --outfile=bench/rome/esbuild/rome.esbuild.js --platform=node\n \tdu -h bench/rome/esbuild/rome.esbuild.js*\n \tshasum bench/rome/esbuild/rome.esbuild.js*\n \tcd bench/rome-verify && rm -fr esbuild && ROME_CACHE=0 node ../rome/esbuild/rome.esbuild.js bundle packages/rome esbuild\n@@ -810,7 +813,6 @@ READMIN_ESBUILD_FLAGS += --define:process.env.NODE_ENV='\"production\"'\n READMIN_ESBUILD_FLAGS += --loader:.js=jsx\n READMIN_ESBUILD_FLAGS += --minify\n READMIN_ESBUILD_FLAGS += --sourcemap\n-READMIN_ESBUILD_FLAGS += --summary\n \n bench-readmin-esbuild: esbuild | bench/readmin\n \trm -fr bench/readmin/esbuild"},{"sha":"84d7f5a42522e8e654474462f812ee7872e997b6","filename":"cmd/esbuild/main.go","status":"modified","additions":6,"deletions":5,"changes":11,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/cmd%2Fesbuild%2Fmain.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/cmd%2Fesbuild%2Fmain.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/cmd%2Fesbuild%2Fmain.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -40,17 +40,18 @@ var helpText = func(colors logger.Colors) string {\n   --serve=...           Start a local HTTP server on this host:port for outputs\n   --sourcemap           Emit a source map\n   --splitting           Enable code splitting (currently only for esm)\n-  --summary             Print some helpful information at the end of a build\n   --target=...          Environment target (e.g. es2017, chrome58, firefox57,\n                         safari11, edge16, node10, default esnext)\n   --watch               Watch mode: rebuild on file system changes\n \n ` + colors.Bold + `Advanced options:` + colors.Default + `\n-  --banner=...              Text to be prepended to each output file\n+  --banner:T=...            Text to be prepended to each output file of type T\n+                            where T is one of: css | js\n   --charset=utf8            Do not escape UTF-8 code points\n   --color=...               Force use of color terminal escapes (true | false)\n-  --error-limit=...         Maximum error count or 0 to disable (default 10)\n-  --footer=...              Text to be appended to each output file\n+  --log-limit=...           Maximum message count or 0 to disable (default 10)\n+  --footer:T=...            Text to be appended to each output file of type T\n+                            where T is one of: css | js\n   --global-name=...         The name of the global for the IIFE format\n   --inject:F                Import the file F into all input files and\n                             automatically replace matching globals with imports\n@@ -73,7 +74,7 @@ var helpText = func(colors logger.Colors) string {\n   --public-path=...         Set the base URL for the \"file\" loader\n   --pure:N                  Mark the name N as a pure function for tree shaking\n   --resolve-extensions=...  A comma-separated list of implicit extensions\n-                            (default \".tsx,.ts,.jsx,.mjs,.cjs,.js,.css,.json\")\n+                            (default \".tsx,.ts,.jsx,.js,.css,.json\")\n   --servedir=...            What to serve in addition to generated output files\n   --sourcefile=...          Set the source file for the source map (for stdin)\n   --sourcemap=external      Do not link to the source map with a comment"},{"sha":"8907b3b631de0dd3d7338712d029ab7edba96560","filename":"cmd/esbuild/service.go","status":"modified","additions":12,"deletions":10,"changes":22,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/cmd%2Fesbuild%2Fservice.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/cmd%2Fesbuild%2Fservice.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/cmd%2Fesbuild%2Fservice.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -356,15 +356,9 @@ func (service *serviceType) handleBuildRequest(id uint32, request map[string]int\n \t// Normally when \"write\" is true and there is no output file/directory then\n \t// the output is written to stdout instead. However, we're currently using\n \t// stdout as a communication channel and writing the build output to stdout\n-\t// would corrupt our protocol.\n-\t//\n-\t// While we could channel this back to the host process and write it to\n-\t// stdout there, the public Go API we're about to call doesn't have an option\n-\t// for \"write to stdout but don't actually write\" and I don't think it should.\n-\t// For now let's just forbid this case because it's not even that useful.\n-\tif err == nil && !isServe && write && options.Outfile == \"\" && options.Outdir == \"\" {\n-\t\terr = errors.New(\"Either provide \\\"outfile\\\" or set \\\"write\\\" to false\")\n-\t}\n+\t// would corrupt our protocol. Special-case this to channel this back to the\n+\t// host process and write it to stdout there.\n+\twriteToStdout := err == nil && !isServe && write && options.Outfile == \"\" && options.Outdir == \"\"\n \n \tif err != nil {\n \t\treturn outgoingPacket{bytes: encodeErrorPacket(id, err)}\n@@ -417,6 +411,12 @@ func (service *serviceType) handleBuildRequest(id uint32, request map[string]int\n \t\tif options.Watch != nil {\n \t\t\tresponse[\"watchID\"] = watchID\n \t\t}\n+\t\tif options.Metafile {\n+\t\t\tresponse[\"metafile\"] = result.Metafile\n+\t\t}\n+\t\tif writeToStdout && len(result.OutputFiles) == 1 {\n+\t\t\tresponse[\"writeToStdout\"] = result.OutputFiles[0].Contents\n+\t\t}\n \t\treturn response\n \t}\n \n@@ -430,7 +430,9 @@ func (service *serviceType) handleBuildRequest(id uint32, request map[string]int\n \t\t}\n \t}\n \n-\toptions.Write = write\n+\tif !writeToStdout {\n+\t\toptions.Write = write\n+\t}\n \toptions.Incremental = incremental\n \tresult := api.Build(options)\n \tresponse := resultToResponse(result)"},{"sha":"1a5adb590fd51a6e2da4fdd005b0074b3c5ce60f","filename":"internal/bundler/bundler.go","status":"modified","additions":102,"deletions":89,"changes":191,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Fbundler.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Fbundler.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -50,7 +50,7 @@ type file struct {\n \t// If \"AbsMetadataFile\" is present, this will be filled out with information\n \t// about this file in JSON format. This is a partial JSON file that will be\n \t// fully assembled later.\n-\tjsonMetadataChunk []byte\n+\tjsonMetadataChunk string\n \n \t// The path of this entry point relative to the lowest common ancestor\n \t// directory containing all entry points. Note: this must have OS-independent\n@@ -65,11 +65,19 @@ type file struct {\n \tisEntryPoint bool\n \n \t// If true, this file was listed as not having side effects by a package.json\n-\t// file in one of our containing directories with a \"sideEffects\" field.\n+\t// file in one of our containing directories with a \"sideEffects\" field, or\n+\t// this was a data-oriented loader (e.g. \"text\") that is known to not have\n+\t// side effects.\n \tignoreIfUnused bool\n \n+\t// If this is true and this file is imported without any import names, issue\n+\t// a warning. This is different than the flag above because imports of files\n+\t// generated by plugins do not cause a warning (since running the plugin is\n+\t// a side effect).\n+\twarnIfUnused bool\n+\n \t// This is optional additional information about \"ignoreIfUnused\" for errors\n-\tignoreIfUnusedData *resolver.IgnoreIfUnusedData\n+\twarnIfUnusedData *resolver.IgnoreIfUnusedData\n }\n \n type fileRepr interface {\n@@ -126,22 +134,22 @@ type Bundle struct {\n }\n \n type parseArgs struct {\n-\tfs                 fs.FS\n-\tlog                logger.Log\n-\tres                resolver.Resolver\n-\tcaches             *cache.CacheSet\n-\tkeyPath            logger.Path\n-\tprettyPath         string\n-\tsourceIndex        uint32\n-\timportSource       *logger.Source\n-\tignoreIfUnused     bool\n-\tignoreIfUnusedData *resolver.IgnoreIfUnusedData\n-\timportPathRange    logger.Range\n-\tpluginData         interface{}\n-\toptions            config.Options\n-\tresults            chan parseResult\n-\tinject             chan config.InjectedFile\n-\tskipResolve        bool\n+\tfs               fs.FS\n+\tlog              logger.Log\n+\tres              resolver.Resolver\n+\tcaches           *cache.CacheSet\n+\tkeyPath          logger.Path\n+\tprettyPath       string\n+\tsourceIndex      uint32\n+\timportSource     *logger.Source\n+\tignoreIfUnused   bool\n+\twarnIfUnusedData *resolver.IgnoreIfUnusedData\n+\timportPathRange  logger.Range\n+\tpluginData       interface{}\n+\toptions          config.Options\n+\tresults          chan parseResult\n+\tinject           chan config.InjectedFile\n+\tskipResolve      bool\n }\n \n type parseResult struct {\n@@ -214,8 +222,9 @@ func parseFile(args parseArgs) {\n \t\t\tpluginData: pluginData,\n \n \t\t\t// Record information from \"sideEffects\" in \"package.json\"\n-\t\t\tignoreIfUnused:     args.ignoreIfUnused,\n-\t\t\tignoreIfUnusedData: args.ignoreIfUnusedData,\n+\t\t\tignoreIfUnused:   args.ignoreIfUnused,\n+\t\t\twarnIfUnused:     args.ignoreIfUnused,\n+\t\t\twarnIfUnusedData: args.warnIfUnusedData,\n \t\t},\n \t}\n \n@@ -257,6 +266,7 @@ func parseFile(args parseArgs) {\n \t\texpr, ok := args.caches.JSONCache.Parse(args.log, source, js_parser.JSONOptions{})\n \t\tast := js_parser.LazyExportAST(args.log, source, js_parser.OptionsFromConfig(&args.options), expr, \"\")\n \t\tresult.file.ignoreIfUnused = true\n+\t\tresult.file.warnIfUnused = pluginName == \"\"\n \t\tresult.file.repr = &reprJS{ast: ast}\n \t\tresult.ok = ok\n \n@@ -266,6 +276,7 @@ func parseFile(args parseArgs) {\n \t\tast := js_parser.LazyExportAST(args.log, source, js_parser.OptionsFromConfig(&args.options), expr, \"\")\n \t\tast.URLForCSS = \"data:text/plain;base64,\" + encoded\n \t\tresult.file.ignoreIfUnused = true\n+\t\tresult.file.warnIfUnused = pluginName == \"\"\n \t\tresult.file.repr = &reprJS{ast: ast}\n \t\tresult.ok = true\n \n@@ -276,6 +287,7 @@ func parseFile(args parseArgs) {\n \t\tast := js_parser.LazyExportAST(args.log, source, js_parser.OptionsFromConfig(&args.options), expr, \"\")\n \t\tast.URLForCSS = \"data:\" + mimeType + \";base64,\" + encoded\n \t\tresult.file.ignoreIfUnused = true\n+\t\tresult.file.warnIfUnused = pluginName == \"\"\n \t\tresult.file.repr = &reprJS{ast: ast}\n \t\tresult.ok = true\n \n@@ -285,6 +297,7 @@ func parseFile(args parseArgs) {\n \t\tast := js_parser.LazyExportAST(args.log, source, js_parser.OptionsFromConfig(&args.options), expr, \"__toBinary\")\n \t\tast.URLForCSS = \"data:application/octet-stream;base64,\" + encoded\n \t\tresult.file.ignoreIfUnused = true\n+\t\tresult.file.warnIfUnused = pluginName == \"\"\n \t\tresult.file.repr = &reprJS{ast: ast}\n \t\tresult.ok = true\n \n@@ -296,6 +309,7 @@ func parseFile(args parseArgs) {\n \t\tast := js_parser.LazyExportAST(args.log, source, js_parser.OptionsFromConfig(&args.options), expr, \"\")\n \t\tast.URLForCSS = url\n \t\tresult.file.ignoreIfUnused = true\n+\t\tresult.file.warnIfUnused = pluginName == \"\"\n \t\tresult.file.repr = &reprJS{ast: ast}\n \t\tresult.ok = true\n \n@@ -326,21 +340,22 @@ func parseFile(args parseArgs) {\n \t\tast := js_parser.LazyExportAST(args.log, source, js_parser.OptionsFromConfig(&args.options), expr, \"\")\n \t\tast.URLForCSS = publicPath\n \t\tresult.file.ignoreIfUnused = true\n+\t\tresult.file.warnIfUnused = pluginName == \"\"\n \t\tresult.file.repr = &reprJS{ast: ast}\n \t\tresult.ok = true\n \n \t\t// Optionally add metadata about the file\n-\t\tvar jsonMetadataChunk []byte\n-\t\tif args.options.AbsMetadataFile != \"\" {\n+\t\tvar jsonMetadataChunk string\n+\t\tif args.options.NeedsMetafile {\n \t\t\tinputs := fmt.Sprintf(\"{\\n        %s: {\\n          \\\"bytesInOutput\\\": %d\\n        }\\n      }\",\n \t\t\t\tjs_printer.QuoteForJSON(source.PrettyPath, args.options.ASCIIOnly),\n \t\t\t\tlen(source.Contents),\n \t\t\t)\n-\t\t\tjsonMetadataChunk = []byte(fmt.Sprintf(\n+\t\t\tjsonMetadataChunk = fmt.Sprintf(\n \t\t\t\t\"{\\n      \\\"imports\\\": [],\\n      \\\"exports\\\": [],\\n      \\\"inputs\\\": %s,\\n      \\\"bytes\\\": %d\\n    }\",\n \t\t\t\tinputs,\n \t\t\t\tlen(source.Contents),\n-\t\t\t))\n+\t\t\t)\n \t\t}\n \n \t\t// Copy the file using an additional file payload to make sure we only copy\n@@ -421,7 +436,7 @@ func parseFile(args parseArgs) {\n \t\t\t\t}\n \n \t\t\t\t// Run the resolver and log an error if the path couldn't be resolved\n-\t\t\t\tresolveResult, didLogError := runOnResolvePlugins(\n+\t\t\t\tresolveResult, didLogError, notes := runOnResolvePlugins(\n \t\t\t\t\targs.options.Plugins,\n \t\t\t\t\targs.res,\n \t\t\t\t\targs.log,\n@@ -468,8 +483,8 @@ func parseFile(args parseArgs) {\n \t\t\t\t\t\tif absResolveDir == \"\" && pluginName != \"\" {\n \t\t\t\t\t\t\thint = fmt.Sprintf(\" (the plugin %q didn't set a resolve directory)\", pluginName)\n \t\t\t\t\t\t}\n-\t\t\t\t\t\targs.log.AddRangeError(&source, record.Range,\n-\t\t\t\t\t\t\tfmt.Sprintf(\"Could not resolve %q%s\", record.Path.Text, hint))\n+\t\t\t\t\t\targs.log.AddRangeErrorWithNotes(&source, record.Range,\n+\t\t\t\t\t\t\tfmt.Sprintf(\"Could not resolve %q%s\", record.Path.Text, hint), notes)\n \t\t\t\t\t}\n \t\t\t\t\tcontinue\n \t\t\t\t}\n@@ -637,7 +652,7 @@ func runOnResolvePlugins(\n \tkind ast.ImportKind,\n \tabsResolveDir string,\n \tpluginData interface{},\n-) (*resolver.ResolveResult, bool) {\n+) (*resolver.ResolveResult, bool, []logger.MsgData) {\n \tresolverArgs := config.OnResolveArgs{\n \t\tPath:       path,\n \t\tResolveDir: absResolveDir,\n@@ -666,7 +681,7 @@ func runOnResolvePlugins(\n \n \t\t\t// Stop now if there was an error\n \t\t\tif didLogError {\n-\t\t\t\treturn nil, true\n+\t\t\t\treturn nil, true, nil\n \t\t\t}\n \n \t\t\t// The \"file\" namespace is the default for non-external paths, but not\n@@ -695,21 +710,21 @@ func runOnResolvePlugins(\n \t\t\t\t\tlog.AddRangeError(importSource, importPathRange,\n \t\t\t\t\t\tfmt.Sprintf(\"Plugin %q returned a non-absolute path: %s (set a namespace if this is not a file path)\", pluginName, result.Path.Text))\n \t\t\t\t}\n-\t\t\t\treturn nil, true\n+\t\t\t\treturn nil, true, nil\n \t\t\t}\n \n \t\t\treturn &resolver.ResolveResult{\n \t\t\t\tPathPair:   resolver.PathPair{Primary: result.Path},\n \t\t\t\tIsExternal: result.External,\n \t\t\t\tPluginData: result.PluginData,\n-\t\t\t}, false\n+\t\t\t}, false, nil\n \t\t}\n \t}\n \n \t// Resolve relative to the resolve directory by default. All paths in the\n \t// \"file\" namespace automatically have a resolve directory. Loader plugins\n \t// can also configure a custom resolve directory for files in other namespaces.\n-\tresult := res.Resolve(absResolveDir, path, kind)\n+\tresult, notes := res.Resolve(absResolveDir, path, kind)\n \n \t// Warn when the case used for importing differs from the actual file name\n \tif result != nil && result.DifferentCase != nil && !resolver.IsInsideNodeModules(absResolveDir) {\n@@ -721,7 +736,7 @@ func runOnResolvePlugins(\n \t\t))\n \t}\n \n-\treturn result, false\n+\treturn result, false, notes\n }\n \n type loaderPluginResult struct {\n@@ -1006,22 +1021,22 @@ func (s *scanner) maybeParseFile(\n \t}\n \n \tgo parseFile(parseArgs{\n-\t\tfs:                 s.fs,\n-\t\tlog:                s.log,\n-\t\tres:                s.res,\n-\t\tcaches:             s.caches,\n-\t\tkeyPath:            path,\n-\t\tprettyPath:         prettyPath,\n-\t\tsourceIndex:        sourceIndex,\n-\t\timportSource:       importSource,\n-\t\tignoreIfUnused:     resolveResult.IgnorePrimaryIfUnused != nil,\n-\t\tignoreIfUnusedData: resolveResult.IgnorePrimaryIfUnused,\n-\t\timportPathRange:    importPathRange,\n-\t\tpluginData:         pluginData,\n-\t\toptions:            optionsClone,\n-\t\tresults:            s.resultChannel,\n-\t\tinject:             inject,\n-\t\tskipResolve:        skipResolve,\n+\t\tfs:               s.fs,\n+\t\tlog:              s.log,\n+\t\tres:              s.res,\n+\t\tcaches:           s.caches,\n+\t\tkeyPath:          path,\n+\t\tprettyPath:       prettyPath,\n+\t\tsourceIndex:      sourceIndex,\n+\t\timportSource:     importSource,\n+\t\tignoreIfUnused:   resolveResult.IgnorePrimaryIfUnused != nil,\n+\t\twarnIfUnusedData: resolveResult.IgnorePrimaryIfUnused,\n+\t\timportPathRange:  importPathRange,\n+\t\tpluginData:       pluginData,\n+\t\toptions:          optionsClone,\n+\t\tresults:          s.resultChannel,\n+\t\tinject:           inject,\n+\t\tskipResolve:      skipResolve,\n \t})\n \n \treturn sourceIndex\n@@ -1187,7 +1202,7 @@ func (s *scanner) addEntryPoints(entryPoints []string) []uint32 {\n \tfor i, path := range entryPoints {\n \t\tgo func(i int, path string) {\n \t\t\t// Run the resolver and log an error if the path couldn't be resolved\n-\t\t\tresolveResult, didLogError := runOnResolvePlugins(\n+\t\t\tresolveResult, didLogError, notes := runOnResolvePlugins(\n \t\t\t\ts.options.Plugins,\n \t\t\t\ts.res,\n \t\t\t\ts.log,\n@@ -1212,7 +1227,7 @@ func (s *scanner) addEntryPoints(entryPoints []string) []uint32 {\n \t\t\t\t\t\thint = fmt.Sprintf(\" (use %q to reference the file %q)\", \"./\"+path, s.res.PrettyPath(query.PathPair.Primary))\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t\ts.log.AddError(nil, logger.Loc{}, fmt.Sprintf(\"Could not resolve %q%s\", path, hint))\n+\t\t\t\ts.log.AddErrorWithNotes(nil, logger.Loc{}, fmt.Sprintf(\"Could not resolve %q%s\", path, hint), notes)\n \t\t\t}\n \t\t\tentryPointWaitGroup.Done()\n \t\t}(i, path)\n@@ -1296,13 +1311,13 @@ func (s *scanner) processScannedFiles() []file {\n \t\t\tcontinue\n \t\t}\n \n-\t\tj := js_printer.Joiner{}\n+\t\tsb := strings.Builder{}\n \t\tisFirstImport := true\n \n \t\t// Begin the metadata chunk\n-\t\tif s.options.AbsMetadataFile != \"\" {\n-\t\t\tj.AddBytes(js_printer.QuoteForJSON(result.file.source.PrettyPath, s.options.ASCIIOnly))\n-\t\t\tj.AddString(fmt.Sprintf(\": {\\n      \\\"bytes\\\": %d,\\n      \\\"imports\\\": [\", len(result.file.source.Contents)))\n+\t\tif s.options.NeedsMetafile {\n+\t\t\tsb.Write(js_printer.QuoteForJSON(result.file.source.PrettyPath, s.options.ASCIIOnly))\n+\t\t\tsb.WriteString(fmt.Sprintf(\": {\\n      \\\"bytes\\\": %d,\\n      \\\"imports\\\": [\", len(result.file.source.Contents)))\n \t\t}\n \n \t\t// Don't try to resolve paths if we're not bundling\n@@ -1337,14 +1352,14 @@ func (s *scanner) processScannedFiles() []file {\n \t\t\t\t}\n \n \t\t\t\t// Generate metadata about each import\n-\t\t\t\tif s.options.AbsMetadataFile != \"\" {\n+\t\t\t\tif s.options.NeedsMetafile {\n \t\t\t\t\tif isFirstImport {\n \t\t\t\t\t\tisFirstImport = false\n-\t\t\t\t\t\tj.AddString(\"\\n        \")\n+\t\t\t\t\t\tsb.WriteString(\"\\n        \")\n \t\t\t\t\t} else {\n-\t\t\t\t\t\tj.AddString(\",\\n        \")\n+\t\t\t\t\t\tsb.WriteString(\",\\n        \")\n \t\t\t\t\t}\n-\t\t\t\t\tj.AddString(fmt.Sprintf(\"{\\n          \\\"path\\\": %s,\\n          \\\"kind\\\": %s\\n        }\",\n+\t\t\t\t\tsb.WriteString(fmt.Sprintf(\"{\\n          \\\"path\\\": %s,\\n          \\\"kind\\\": %s\\n        }\",\n \t\t\t\t\t\tjs_printer.QuoteForJSON(s.results[record.SourceIndex.GetIndex()].file.source.PrettyPath, s.options.ASCIIOnly),\n \t\t\t\t\t\tjs_printer.QuoteForJSON(record.Kind.StringForMetafile(), s.options.ASCIIOnly)))\n \t\t\t\t}\n@@ -1416,16 +1431,16 @@ func (s *scanner) processScannedFiles() []file {\n \t\t\t\t// Don't include this module for its side effects if it can be\n \t\t\t\t// considered to have no side effects\n \t\t\t\tif record.WasOriginallyBareImport && !s.options.IgnoreDCEAnnotations {\n-\t\t\t\t\tif otherFile := &s.results[record.SourceIndex.GetIndex()].file; otherFile.ignoreIfUnused {\n+\t\t\t\t\tif otherFile := &s.results[record.SourceIndex.GetIndex()].file; otherFile.warnIfUnused {\n \t\t\t\t\t\tvar notes []logger.MsgData\n-\t\t\t\t\t\tif otherFile.ignoreIfUnusedData != nil {\n+\t\t\t\t\t\tif otherFile.warnIfUnusedData != nil {\n \t\t\t\t\t\t\tvar text string\n-\t\t\t\t\t\t\tif otherFile.ignoreIfUnusedData.IsSideEffectsArrayInJSON {\n+\t\t\t\t\t\t\tif otherFile.warnIfUnusedData.IsSideEffectsArrayInJSON {\n \t\t\t\t\t\t\t\ttext = \"It was excluded from the \\\"sideEffects\\\" array in the enclosing \\\"package.json\\\" file\"\n \t\t\t\t\t\t\t} else {\n \t\t\t\t\t\t\t\ttext = \"\\\"sideEffects\\\" is false in the enclosing \\\"package.json\\\" file\"\n \t\t\t\t\t\t\t}\n-\t\t\t\t\t\t\tnotes = append(notes, logger.RangeData(otherFile.ignoreIfUnusedData.Source, otherFile.ignoreIfUnusedData.Range, text))\n+\t\t\t\t\t\t\tnotes = append(notes, logger.RangeData(otherFile.warnIfUnusedData.Source, otherFile.warnIfUnusedData.Range, text))\n \t\t\t\t\t\t}\n \t\t\t\t\t\ts.log.AddRangeWarningWithNotes(&result.file.source, record.Range,\n \t\t\t\t\t\t\tfmt.Sprintf(\"Ignoring this import because %q was marked as having no side effects\",\n@@ -1436,14 +1451,14 @@ func (s *scanner) processScannedFiles() []file {\n \t\t}\n \n \t\t// End the metadata chunk\n-\t\tif s.options.AbsMetadataFile != \"\" {\n+\t\tif s.options.NeedsMetafile {\n \t\t\tif !isFirstImport {\n-\t\t\t\tj.AddString(\"\\n      \")\n+\t\t\t\tsb.WriteString(\"\\n      \")\n \t\t\t}\n-\t\t\tj.AddString(\"]\\n    }\")\n+\t\t\tsb.WriteString(\"]\\n    }\")\n \t\t}\n \n-\t\ts.results[i].file.jsonMetadataChunk = j.Done()\n+\t\ts.results[i].file.jsonMetadataChunk = sb.String()\n \t}\n \n \t// The linker operates on an array of files, so construct that now. This\n@@ -1479,7 +1494,7 @@ type OutputFile struct {\n \t// If \"AbsMetadataFile\" is present, this will be filled out with information\n \t// about this file in JSON format. This is a partial JSON file that will be\n \t// fully assembled later.\n-\tjsonMetadataChunk []byte\n+\tjsonMetadataChunk string\n \n \tIsExecutable bool\n }\n@@ -1510,7 +1525,7 @@ func applyOptionDefaults(options *config.Options) {\n \t}\n }\n \n-func (b *Bundle) Compile(log logger.Log, options config.Options) []OutputFile {\n+func (b *Bundle) Compile(log logger.Log, options config.Options) ([]OutputFile, string) {\n \tapplyOptionDefaults(&options)\n \n \t// The format can't be \"preserve\" while bundling\n@@ -1556,11 +1571,9 @@ func (b *Bundle) Compile(log logger.Log, options config.Options) []OutputFile {\n \t}\n \n \t// Also generate the metadata file if necessary\n-\tif options.AbsMetadataFile != \"\" {\n-\t\toutputFiles = append(outputFiles, OutputFile{\n-\t\t\tAbsPath:  options.AbsMetadataFile,\n-\t\t\tContents: b.generateMetadataJSON(outputFiles, allReachableFiles, options.ASCIIOnly),\n-\t\t})\n+\tvar metafileJSON string\n+\tif options.NeedsMetafile {\n+\t\tmetafileJSON = b.generateMetadataJSON(outputFiles, allReachableFiles, options.ASCIIOnly)\n \t}\n \n \tif !options.WriteToStdout {\n@@ -1615,7 +1628,7 @@ func (b *Bundle) Compile(log logger.Log, options config.Options) []OutputFile {\n \t\toutputFiles = outputFiles[:end]\n \t}\n \n-\treturn outputFiles\n+\treturn outputFiles, metafileJSON\n }\n \n // This is done in parallel with linking because linking is a mostly serial\n@@ -1755,9 +1768,9 @@ func (b *Bundle) lowestCommonAncestorDirectory(codeSplitting bool, allReachableF\n \treturn lowestAbsDir\n }\n \n-func (b *Bundle) generateMetadataJSON(results []OutputFile, allReachableFiles []uint32, asciiOnly bool) []byte {\n-\tj := js_printer.Joiner{}\n-\tj.AddString(\"{\\n  \\\"inputs\\\": {\")\n+func (b *Bundle) generateMetadataJSON(results []OutputFile, allReachableFiles []uint32, asciiOnly bool) string {\n+\tsb := strings.Builder{}\n+\tsb.WriteString(\"{\\n  \\\"inputs\\\": {\")\n \n \t// Write inputs\n \tisFirst := true\n@@ -1768,15 +1781,15 @@ func (b *Bundle) generateMetadataJSON(results []OutputFile, allReachableFiles []\n \t\tif file := &b.files[sourceIndex]; len(file.jsonMetadataChunk) > 0 {\n \t\t\tif isFirst {\n \t\t\t\tisFirst = false\n-\t\t\t\tj.AddString(\"\\n    \")\n+\t\t\t\tsb.WriteString(\"\\n    \")\n \t\t\t} else {\n-\t\t\t\tj.AddString(\",\\n    \")\n+\t\t\t\tsb.WriteString(\",\\n    \")\n \t\t\t}\n-\t\t\tj.AddBytes(file.jsonMetadataChunk)\n+\t\t\tsb.WriteString(file.jsonMetadataChunk)\n \t\t}\n \t}\n \n-\tj.AddString(\"\\n  },\\n  \\\"outputs\\\": {\")\n+\tsb.WriteString(\"\\n  },\\n  \\\"outputs\\\": {\")\n \n \t// Write outputs\n \tisFirst = true\n@@ -1790,18 +1803,18 @@ func (b *Bundle) generateMetadataJSON(results []OutputFile, allReachableFiles []\n \t\t\t}\n \t\t\tif isFirst {\n \t\t\t\tisFirst = false\n-\t\t\t\tj.AddString(\"\\n    \")\n+\t\t\t\tsb.WriteString(\"\\n    \")\n \t\t\t} else {\n-\t\t\t\tj.AddString(\",\\n    \")\n+\t\t\t\tsb.WriteString(\",\\n    \")\n \t\t\t}\n \t\t\tpaths[path] = true\n-\t\t\tj.AddString(fmt.Sprintf(\"%s: \", js_printer.QuoteForJSON(path, asciiOnly)))\n-\t\t\tj.AddBytes(result.jsonMetadataChunk)\n+\t\t\tsb.WriteString(fmt.Sprintf(\"%s: \", js_printer.QuoteForJSON(path, asciiOnly)))\n+\t\t\tsb.WriteString(result.jsonMetadataChunk)\n \t\t}\n \t}\n \n-\tj.AddString(\"\\n  }\\n}\\n\")\n-\treturn j.Done()\n+\tsb.WriteString(\"\\n  }\\n}\\n\")\n+\treturn sb.String()\n }\n \n type runtimeCacheKey struct {"},{"sha":"33bfc0d7e6d92cc32f81d3c0fd8b357b848a9f76","filename":"internal/bundler/bundler_packagejson_test.go","status":"modified","additions":497,"deletions":0,"changes":497,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Fbundler_packagejson_test.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Fbundler_packagejson_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler_packagejson_test.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -1194,3 +1194,500 @@ func TestPackageJsonNeutralExplicitMainFields(t *testing.T) {\n \t\t},\n \t})\n }\n+\n+func TestPackageJsonExportsErrorInvalidModuleSpecifier(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1'\n+\t\t\t\timport 'pkg2'\n+\t\t\t\timport 'pkg3'\n+\t\t\t\timport 'pkg4'\n+\t\t\t\timport 'pkg5'\n+\t\t\t\timport 'pkg6'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./%%\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg2/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./%2f\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg3/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./%2F\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg4/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./%5c\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg5/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./%5C\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg6/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./%31.js\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg6/1.js\": `\n+\t\t\t\tconsole.log(1)\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t\texpectedScanLog: `Users/user/project/src/entry.js: error: Could not resolve \"pkg1\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg1/package.json: note: The module specifier \"./%%\" is invalid\n+Users/user/project/src/entry.js: error: Could not resolve \"pkg2\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg2/package.json: note: The module specifier \"./%2f\" is invalid\n+Users/user/project/src/entry.js: error: Could not resolve \"pkg3\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg3/package.json: note: The module specifier \"./%2F\" is invalid\n+Users/user/project/src/entry.js: error: Could not resolve \"pkg4\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg4/package.json: note: The module specifier \"./%5c\" is invalid\n+Users/user/project/src/entry.js: error: Could not resolve \"pkg5\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg5/package.json: note: The module specifier \"./%5C\" is invalid\n+`,\n+\t})\n+}\n+\n+func TestPackageJsonExportsErrorInvalidPackageConfiguration(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1'\n+\t\t\t\timport 'pkg2/foo'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": false } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg2/package.json\": `\n+\t\t\t\t{ \"exports\": { \"./foo\": false } }\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t\texpectedScanLog: `Users/user/project/node_modules/pkg1/package.json: warning: This value must be a string, an object, an array, or null\n+Users/user/project/node_modules/pkg2/package.json: warning: This value must be a string, an object, an array, or null\n+Users/user/project/src/entry.js: error: Could not resolve \"pkg1\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg1/package.json: note: The package configuration has an invalid value here\n+Users/user/project/src/entry.js: error: Could not resolve \"pkg2/foo\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg2/package.json: note: The package configuration has an invalid value here\n+`,\n+\t})\n+}\n+\n+func TestPackageJsonExportsErrorInvalidPackageTarget(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1'\n+\t\t\t\timport 'pkg2'\n+\t\t\t\timport 'pkg3'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"invalid\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg2/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"../pkg3\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg3/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./node_modules/pkg\" } }\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t\texpectedScanLog: `Users/user/project/src/entry.js: error: Could not resolve \"pkg1\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg1/package.json: note: The package target \"invalid\" is invalid\n+Users/user/project/src/entry.js: error: Could not resolve \"pkg2\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg2/package.json: note: The package target \"../pkg3\" is invalid\n+Users/user/project/src/entry.js: error: Could not resolve \"pkg3\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg3/package.json: note: The package target \"./node_modules/pkg\" is invalid\n+`,\n+\t})\n+}\n+\n+func TestPackageJsonExportsErrorPackagePathNotExported(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1/foo'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": {} } }\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t\texpectedScanLog: `Users/user/project/src/entry.js: error: Could not resolve \"pkg1/foo\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg1/package.json: note: The path \"./foo\" is not exported by \"pkg1\"\n+`,\n+\t})\n+}\n+\n+func TestPackageJsonExportsErrorModuleNotFound(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./foo.js\" } }\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t\texpectedScanLog: `Users/user/project/src/entry.js: error: Could not resolve \"pkg1\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg1/package.json: note: The module \"./foo.js\" was not found\n+`,\n+\t})\n+}\n+\n+func TestPackageJsonExportsErrorUnsupportedDirectoryImport(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1'\n+\t\t\t\timport 'pkg2'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./foo/\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg2/package.json\": `\n+\t\t\t\t{ \"exports\": { \".\": \"./foo\" } }\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg2/foo/bar.js\": `\n+\t\t\t\tconsole.log(bar)\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t\texpectedScanLog: `Users/user/project/src/entry.js: error: Could not resolve \"pkg1\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg1/package.json: note: The module \"./foo\" was not found\n+Users/user/project/src/entry.js: error: Could not resolve \"pkg2\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg2/package.json: note: Importing the directory \"./foo\" is not supported\n+`,\n+\t})\n+}\n+\n+func TestPackageJsonExportsRequireOverImport(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\trequire('pkg')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"import\": \"./import.js\",\n+\t\t\t\t\t\t\"require\": \"./require.js\",\n+\t\t\t\t\t\t\"default\": \"./default.js\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/import.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/require.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t})\n+}\n+\n+func TestPackageJsonExportsImportOverRequire(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"require\": \"./require.js\",\n+\t\t\t\t\t\t\"import\": \"./import.js\",\n+\t\t\t\t\t\t\"default\": \"./default.js\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/require.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/import.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t})\n+}\n+\n+func TestPackageJsonExportsDefaultOverImportAndRequire(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"default\": \"./default.js\",\n+\t\t\t\t\t\t\"import\": \"./import.js\",\n+\t\t\t\t\t\t\"require\": \"./require.js\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/require.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/import.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/default.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t})\n+}\n+\n+func TestPackageJsonExportsBrowser(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"node\": \"./node.js\",\n+\t\t\t\t\t\t\"browser\": \"./browser.js\",\n+\t\t\t\t\t\t\"default\": \"./default.js\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/node.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/browser.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t\tPlatform:      config.PlatformBrowser,\n+\t\t},\n+\t})\n+}\n+\n+func TestPackageJsonExportsNode(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"browser\": \"./browser.js\",\n+\t\t\t\t\t\t\"node\": \"./node.js\",\n+\t\t\t\t\t\t\"default\": \"./default.js\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/browser.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/node.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t\tPlatform:      config.PlatformNode,\n+\t\t},\n+\t})\n+}\n+\n+func TestPackageJsonExportsNeutral(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"node\": \"./node.js\",\n+\t\t\t\t\t\t\"browser\": \"./browser.js\",\n+\t\t\t\t\t\t\"default\": \"./default.js\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/node.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/browser.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg/default.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t\tPlatform:      config.PlatformNeutral,\n+\t\t},\n+\t})\n+}\n+\n+func TestPackageJsonExportsOrderIndependent(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1/foo/bar.js'\n+\t\t\t\timport 'pkg2/foo/bar.js'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"./\": \"./1/\",\n+\t\t\t\t\t\t\"./foo/\": \"./2/\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/1/foo/bar.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/2/bar.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg2/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"./foo/\": \"./1/\",\n+\t\t\t\t\t\t\"./\": \"./2/\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg2/1/bar.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg2/2/foo/bar.js\": `\n+\t\t\t\tconsole.log('FAILURE')\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t})\n+}\n+\n+func TestPackageJsonExportsWildcard(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1/foo'\n+\t\t\t\timport 'pkg1/foo2'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"./foo*\": \"./file*.js\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/file2.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t\texpectedScanLog: `Users/user/project/src/entry.js: error: Could not resolve \"pkg1/foo\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg1/package.json: note: The path \"./foo\" is not exported by \"pkg1\"\n+`,\n+\t})\n+}\n+\n+func TestPackageJsonExportsErrorMissingTrailingSlash(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1/foo/bar'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{ \"exports\": { \"./foo/\": \"./test\" } }\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t},\n+\t\texpectedScanLog: `Users/user/project/src/entry.js: error: Could not resolve \"pkg1/foo/bar\" (mark it as external to exclude it from the bundle)\n+Users/user/project/node_modules/pkg1/package.json: note: The module specifier \"./test\" is invalid\n+`,\n+\t})\n+}\n+\n+func TestPackageJsonExportsCustomConditions(t *testing.T) {\n+\tpackagejson_suite.expectBundled(t, bundled{\n+\t\tfiles: map[string]string{\n+\t\t\t\"/Users/user/project/src/entry.js\": `\n+\t\t\t\timport 'pkg1'\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/package.json\": `\n+\t\t\t\t{\n+\t\t\t\t\t\"exports\": {\n+\t\t\t\t\t\t\"custom1\": \"./custom1.js\",\n+\t\t\t\t\t\t\"custom2\": \"./custom2.js\",\n+\t\t\t\t\t\t\"default\": \"./default.js\"\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t`,\n+\t\t\t\"/Users/user/project/node_modules/pkg1/custom2.js\": `\n+\t\t\t\tconsole.log('SUCCESS')\n+\t\t\t`,\n+\t\t},\n+\t\tentryPaths: []string{\"/Users/user/project/src/entry.js\"},\n+\t\toptions: config.Options{\n+\t\t\tMode:          config.ModeBundle,\n+\t\t\tAbsOutputFile: \"/Users/user/project/out.js\",\n+\t\t\tConditions:    []string{\"custom2\"},\n+\t\t},\n+\t})\n+}"},{"sha":"9784ddf1fb34b619b212fb700a2d94fb9f9be33b","filename":"internal/bundler/bundler_test.go","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Fbundler_test.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Fbundler_test.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fbundler_test.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -104,7 +104,7 @@ func (s *suite) expectBundled(t *testing.T, args bundled) {\n \n \t\tlog = logger.NewDeferLog()\n \t\targs.options.OmitRuntimeForTests = true\n-\t\tresults := bundle.Compile(log, args.options)\n+\t\tresults, _ := bundle.Compile(log, args.options)\n \t\tmsgs = log.Done()\n \t\tassertLog(t, msgs, args.expectedCompileLog)\n "},{"sha":"cab7e6c0c01dac710aa5091cd83c9221f31fe15d","filename":"internal/bundler/linker.go","status":"modified","additions":57,"deletions":47,"changes":104,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Flinker.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Flinker.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Flinker.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -3751,10 +3751,10 @@ func (repr *chunkReprJS) generate(c *linkerContext, chunk *chunkInfo) func(gener\n \t\t\t}\n \t\t}\n \n-\t\tif len(c.options.Banner) > 0 {\n-\t\t\tprevOffset.advanceString(c.options.Banner)\n+\t\tif len(c.options.JSBanner) > 0 {\n+\t\t\tprevOffset.advanceString(c.options.JSBanner)\n \t\t\tprevOffset.advanceString(\"\\n\")\n-\t\t\tj.AddString(c.options.Banner)\n+\t\t\tj.AddString(c.options.JSBanner)\n \t\t\tj.AddString(\"\\n\")\n \t\t}\n \n@@ -3783,27 +3783,27 @@ func (repr *chunkReprJS) generate(c *linkerContext, chunk *chunkInfo) func(gener\n \t\t}\n \n \t\t// Start the metadata\n-\t\tjMeta := js_printer.Joiner{}\n-\t\tif c.options.AbsMetadataFile != \"\" {\n+\t\tsbMeta := strings.Builder{}\n+\t\tif c.options.NeedsMetafile {\n \t\t\t// Print imports\n \t\t\tisFirstMeta := true\n-\t\t\tjMeta.AddString(\"{\\n      \\\"imports\\\": [\")\n+\t\t\tsbMeta.WriteString(\"{\\n      \\\"imports\\\": [\")\n \t\t\tfor i, importAbsPath := range continueData.crossChunkAbsPaths {\n \t\t\t\tif isFirstMeta {\n \t\t\t\t\tisFirstMeta = false\n \t\t\t\t} else {\n-\t\t\t\t\tjMeta.AddString(\",\")\n+\t\t\t\t\tsbMeta.WriteString(\",\")\n \t\t\t\t}\n-\t\t\t\tjMeta.AddString(fmt.Sprintf(\"\\n        {\\n          \\\"path\\\": %s,\\n          \\\"kind\\\": %s\\n        }\",\n+\t\t\t\tsbMeta.WriteString(fmt.Sprintf(\"\\n        {\\n          \\\"path\\\": %s,\\n          \\\"kind\\\": %s\\n        }\",\n \t\t\t\t\tjs_printer.QuoteForJSON(c.res.PrettyPath(logger.Path{Text: importAbsPath, Namespace: \"file\"}), c.options.ASCIIOnly),\n \t\t\t\t\tjs_printer.QuoteForJSON(continueData.crossChunkImportRecords[i].Kind.StringForMetafile(), c.options.ASCIIOnly)))\n \t\t\t}\n \t\t\tif !isFirstMeta {\n-\t\t\t\tjMeta.AddString(\"\\n      \")\n+\t\t\t\tsbMeta.WriteString(\"\\n      \")\n \t\t\t}\n \n \t\t\t// Print exports\n-\t\t\tjMeta.AddString(\"],\\n      \\\"exports\\\": [\")\n+\t\t\tsbMeta.WriteString(\"],\\n      \\\"exports\\\": [\")\n \t\t\tvar aliases []string\n \t\t\tif c.options.OutputFormat.KeepES6ImportExportSyntax() {\n \t\t\t\tif chunk.isEntryPoint {\n@@ -3831,19 +3831,19 @@ func (repr *chunkReprJS) generate(c *linkerContext, chunk *chunkInfo) func(gener\n \t\t\t\tif isFirstMeta {\n \t\t\t\t\tisFirstMeta = false\n \t\t\t\t} else {\n-\t\t\t\t\tjMeta.AddString(\",\")\n+\t\t\t\t\tsbMeta.WriteString(\",\")\n \t\t\t\t}\n-\t\t\t\tjMeta.AddString(fmt.Sprintf(\"\\n        %s\",\n+\t\t\t\tsbMeta.WriteString(fmt.Sprintf(\"\\n        %s\",\n \t\t\t\t\tjs_printer.QuoteForJSON(alias, c.options.ASCIIOnly)))\n \t\t\t}\n \t\t\tif !isFirstMeta {\n-\t\t\t\tjMeta.AddString(\"\\n      \")\n+\t\t\t\tsbMeta.WriteString(\"\\n      \")\n \t\t\t}\n \t\t\tif chunk.isEntryPoint {\n \t\t\t\tentryPoint := c.files[chunk.sourceIndex].source.PrettyPath\n-\t\t\t\tjMeta.AddString(fmt.Sprintf(\"],\\n      \\\"entryPoint\\\": %s,\\n      \\\"inputs\\\": {\", js_printer.QuoteForJSON(entryPoint, c.options.ASCIIOnly)))\n+\t\t\t\tsbMeta.WriteString(fmt.Sprintf(\"],\\n      \\\"entryPoint\\\": %s,\\n      \\\"inputs\\\": {\", js_printer.QuoteForJSON(entryPoint, c.options.ASCIIOnly)))\n \t\t\t} else {\n-\t\t\t\tjMeta.AddString(\"],\\n      \\\"inputs\\\": {\")\n+\t\t\t\tsbMeta.WriteString(\"],\\n      \\\"inputs\\\": {\")\n \t\t\t}\n \t\t}\n \n@@ -3855,7 +3855,7 @@ func (repr *chunkReprJS) generate(c *linkerContext, chunk *chunkInfo) func(gener\n \t\tvar metaByteCount map[string]int\n \t\tcommentSet := make(map[string]bool)\n \t\tprevComment := uint32(0)\n-\t\tif c.options.AbsMetadataFile != \"\" {\n+\t\tif c.options.NeedsMetafile {\n \t\t\tmetaOrder = make([]string, 0, len(compileResults))\n \t\t\tmetaByteCount = make(map[string]int, len(compileResults))\n \t\t}\n@@ -3919,7 +3919,7 @@ func (repr *chunkReprJS) generate(c *linkerContext, chunk *chunkInfo) func(gener\n \t\t\t\t}\n \n \t\t\t\t// Include this file in the metadata\n-\t\t\t\tif c.options.AbsMetadataFile != \"\" {\n+\t\t\t\tif c.options.NeedsMetafile {\n \t\t\t\t\t// Accumulate file sizes since a given file may be split into multiple parts\n \t\t\t\t\tpath := c.files[compileResult.sourceIndex].source.PrettyPath\n \t\t\t\t\tif count, ok := metaByteCount[path]; ok {\n@@ -3972,8 +3972,8 @@ func (repr *chunkReprJS) generate(c *linkerContext, chunk *chunkInfo) func(gener\n \t\t\tj.AddString(\"\\n\")\n \t\t}\n \n-\t\tif len(c.options.Footer) > 0 {\n-\t\t\tj.AddString(c.options.Footer)\n+\t\tif len(c.options.JSFooter) > 0 {\n+\t\t\tj.AddString(c.options.JSFooter)\n \t\t\tj.AddString(\"\\n\")\n \t\t}\n \n@@ -4001,10 +4001,10 @@ func (repr *chunkReprJS) generate(c *linkerContext, chunk *chunkInfo) func(gener\n \t\t\t// Write the generated source map as an external file\n \t\t\tif writeFile {\n \t\t\t\t// Optionally add metadata about the file\n-\t\t\t\tvar jsonMetadataChunk []byte\n-\t\t\t\tif c.options.AbsMetadataFile != \"\" {\n-\t\t\t\t\tjsonMetadataChunk = []byte(fmt.Sprintf(\n-\t\t\t\t\t\t\"{\\n      \\\"imports\\\": [],\\n      \\\"exports\\\": [],\\n      \\\"inputs\\\": {},\\n      \\\"bytes\\\": %d\\n    }\", len(sourceMap)))\n+\t\t\t\tvar jsonMetadataChunk string\n+\t\t\t\tif c.options.NeedsMetafile {\n+\t\t\t\t\tjsonMetadataChunk = fmt.Sprintf(\n+\t\t\t\t\t\t\"{\\n      \\\"imports\\\": [],\\n      \\\"exports\\\": [],\\n      \\\"inputs\\\": {},\\n      \\\"bytes\\\": %d\\n    }\", len(sourceMap))\n \t\t\t\t}\n \n \t\t\t\t// Figure out the base name for the source map which may include the content hash\n@@ -4063,23 +4063,23 @@ func (repr *chunkReprJS) generate(c *linkerContext, chunk *chunkInfo) func(gener\n \t\t}\n \n \t\t// End the metadata\n-\t\tvar jsonMetadataChunk []byte\n-\t\tif c.options.AbsMetadataFile != \"\" {\n+\t\tvar jsonMetadataChunk string\n+\t\tif c.options.NeedsMetafile {\n \t\t\tisFirstMeta := true\n \t\t\tfor _, path := range metaOrder {\n \t\t\t\tif isFirstMeta {\n \t\t\t\t\tisFirstMeta = false\n \t\t\t\t} else {\n-\t\t\t\t\tjMeta.AddString(\",\")\n+\t\t\t\t\tsbMeta.WriteString(\",\")\n \t\t\t\t}\n-\t\t\t\tjMeta.AddString(fmt.Sprintf(\"\\n        %s: {\\n          \\\"bytesInOutput\\\": %d\\n        }\",\n+\t\t\t\tsbMeta.WriteString(fmt.Sprintf(\"\\n        %s: {\\n          \\\"bytesInOutput\\\": %d\\n        }\",\n \t\t\t\t\tjs_printer.QuoteForJSON(path, c.options.ASCIIOnly), metaByteCount[path]))\n \t\t\t}\n \t\t\tif !isFirstMeta {\n-\t\t\t\tjMeta.AddString(\"\\n      \")\n+\t\t\t\tsbMeta.WriteString(\"\\n      \")\n \t\t\t}\n-\t\t\tjMeta.AddString(fmt.Sprintf(\"},\\n      \\\"bytes\\\": %d\\n    }\", len(jsContents)))\n-\t\t\tjsonMetadataChunk = jMeta.Done()\n+\t\t\tsbMeta.WriteString(fmt.Sprintf(\"},\\n      \\\"bytes\\\": %d\\n    }\", len(jsContents)))\n+\t\t\tjsonMetadataChunk = sbMeta.String()\n \t\t}\n \n \t\tresults = append(results, OutputFile{\n@@ -4188,6 +4188,11 @@ func (repr *chunkReprCSS) generate(c *linkerContext, chunk *chunkInfo) func(gene\n \t\tj := js_printer.Joiner{}\n \t\tnewlineBeforeComment := false\n \n+\t\tif len(c.options.CSSBanner) > 0 {\n+\t\t\tj.AddString(c.options.CSSBanner)\n+\t\t\tj.AddString(\"\\n\")\n+\t\t}\n+\n \t\t// Generate any prefix rules now\n \t\t{\n \t\t\tast := css_ast.AST{}\n@@ -4221,22 +4226,22 @@ func (repr *chunkReprCSS) generate(c *linkerContext, chunk *chunkInfo) func(gene\n \t\t}\n \n \t\t// Start the metadata\n-\t\tjMeta := js_printer.Joiner{}\n-\t\tif c.options.AbsMetadataFile != \"\" {\n+\t\tsbMeta := strings.Builder{}\n+\t\tif c.options.NeedsMetafile {\n \t\t\tisFirstMeta := true\n-\t\t\tjMeta.AddString(\"{\\n      \\\"imports\\\": [\")\n+\t\t\tsbMeta.WriteString(\"{\\n      \\\"imports\\\": [\")\n \t\t\tfor i, importAbsPath := range continueData.crossChunkAbsPaths {\n \t\t\t\tif isFirstMeta {\n \t\t\t\t\tisFirstMeta = false\n \t\t\t\t} else {\n-\t\t\t\t\tjMeta.AddString(\",\")\n+\t\t\t\t\tsbMeta.WriteString(\",\")\n \t\t\t\t}\n-\t\t\t\tjMeta.AddString(fmt.Sprintf(\"\\n        {\\n          \\\"path\\\": %s,\\n          \\\"kind\\\": %s\\n        }\",\n+\t\t\t\tsbMeta.WriteString(fmt.Sprintf(\"\\n        {\\n          \\\"path\\\": %s,\\n          \\\"kind\\\": %s\\n        }\",\n \t\t\t\t\tjs_printer.QuoteForJSON(c.res.PrettyPath(logger.Path{Text: importAbsPath, Namespace: \"file\"}), c.options.ASCIIOnly),\n \t\t\t\t\tjs_printer.QuoteForJSON(continueData.crossChunkImportRecords[i].Kind.StringForMetafile(), c.options.ASCIIOnly)))\n \t\t\t}\n \t\t\tif !isFirstMeta {\n-\t\t\t\tjMeta.AddString(\"\\n      \")\n+\t\t\t\tsbMeta.WriteString(\"\\n      \")\n \t\t\t}\n \t\t\tif chunk.isEntryPoint {\n \t\t\t\tfile := &c.files[chunk.sourceIndex]\n@@ -4245,13 +4250,13 @@ func (repr *chunkReprCSS) generate(c *linkerContext, chunk *chunkInfo) func(gene\n \t\t\t\t// importing CSS into JavaScript. We want this to be a 1:1 relationship\n \t\t\t\t// and there is already an output file for the JavaScript entry point.\n \t\t\t\tif _, ok := file.repr.(*reprCSS); ok {\n-\t\t\t\t\tjMeta.AddString(fmt.Sprintf(\"],\\n      \\\"entryPoint\\\": %s,\\n      \\\"inputs\\\": {\",\n+\t\t\t\t\tsbMeta.WriteString(fmt.Sprintf(\"],\\n      \\\"entryPoint\\\": %s,\\n      \\\"inputs\\\": {\",\n \t\t\t\t\t\tjs_printer.QuoteForJSON(file.source.PrettyPath, c.options.ASCIIOnly)))\n \t\t\t\t} else {\n-\t\t\t\t\tjMeta.AddString(\"],\\n      \\\"inputs\\\": {\")\n+\t\t\t\t\tsbMeta.WriteString(\"],\\n      \\\"inputs\\\": {\")\n \t\t\t\t}\n \t\t\t} else {\n-\t\t\t\tjMeta.AddString(\"],\\n      \\\"inputs\\\": {\")\n+\t\t\t\tsbMeta.WriteString(\"],\\n      \\\"inputs\\\": {\")\n \t\t\t}\n \t\t}\n \t\tisFirstMeta := true\n@@ -4270,13 +4275,13 @@ func (repr *chunkReprCSS) generate(c *linkerContext, chunk *chunkInfo) func(gene\n \t\t\tj.AddString(compileResult.printedCSS)\n \n \t\t\t// Include this file in the metadata\n-\t\t\tif c.options.AbsMetadataFile != \"\" {\n+\t\t\tif c.options.NeedsMetafile {\n \t\t\t\tif isFirstMeta {\n \t\t\t\t\tisFirstMeta = false\n \t\t\t\t} else {\n-\t\t\t\t\tjMeta.AddString(\",\")\n+\t\t\t\t\tsbMeta.WriteString(\",\")\n \t\t\t\t}\n-\t\t\t\tjMeta.AddString(fmt.Sprintf(\"\\n        %s: {\\n          \\\"bytesInOutput\\\": %d\\n        }\",\n+\t\t\t\tsbMeta.WriteString(fmt.Sprintf(\"\\n        %s: {\\n          \\\"bytesInOutput\\\": %d\\n        }\",\n \t\t\t\t\tjs_printer.QuoteForJSON(c.files[compileResult.sourceIndex].source.PrettyPath, c.options.ASCIIOnly),\n \t\t\t\t\tlen(compileResult.printedCSS)))\n \t\t\t}\n@@ -4287,6 +4292,11 @@ func (repr *chunkReprCSS) generate(c *linkerContext, chunk *chunkInfo) func(gene\n \t\t\tj.AddString(\"\\n\")\n \t\t}\n \n+\t\tif len(c.options.CSSFooter) > 0 {\n+\t\t\tj.AddString(c.options.CSSFooter)\n+\t\t\tj.AddString(\"\\n\")\n+\t\t}\n+\n \t\t// The CSS contents are done now that the source map comment is in\n \t\tcssContents := j.Done()\n \n@@ -4308,13 +4318,13 @@ func (repr *chunkReprCSS) generate(c *linkerContext, chunk *chunkInfo) func(gene\n \t\t}\n \n \t\t// End the metadata\n-\t\tvar jsonMetadataChunk []byte\n-\t\tif c.options.AbsMetadataFile != \"\" {\n+\t\tvar jsonMetadataChunk string\n+\t\tif c.options.NeedsMetafile {\n \t\t\tif !isFirstMeta {\n-\t\t\t\tjMeta.AddString(\"\\n      \")\n+\t\t\t\tsbMeta.WriteString(\"\\n      \")\n \t\t\t}\n-\t\t\tjMeta.AddString(fmt.Sprintf(\"},\\n      \\\"bytes\\\": %d\\n    }\", len(cssContents)))\n-\t\t\tjsonMetadataChunk = jMeta.Done()\n+\t\t\tsbMeta.WriteString(fmt.Sprintf(\"},\\n      \\\"bytes\\\": %d\\n    }\", len(cssContents)))\n+\t\t\tjsonMetadataChunk = sbMeta.String()\n \t\t}\n \n \t\tresults = append(results, OutputFile{"},{"sha":"9b139b29ab8ad9c57f68da45bacec5b9fcdfc4c6","filename":"internal/bundler/snapshots/snapshots_packagejson.txt","status":"modified","additions":56,"deletions":0,"changes":56,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_packagejson.txt","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fbundler%2Fsnapshots%2Fsnapshots_packagejson.txt","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fbundler%2Fsnapshots%2Fsnapshots_packagejson.txt?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -424,6 +424,62 @@ var require_main = __commonJS((exports, module) => {\n // Users/user/project/src/entry.js\n console.log(require_main());\n \n+================================================================================\n+TestPackageJsonExportsBrowser\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/node_modules/pkg/browser.js\n+console.log(\"SUCCESS\");\n+\n+================================================================================\n+TestPackageJsonExportsCustomConditions\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/node_modules/pkg1/custom2.js\n+console.log(\"SUCCESS\");\n+\n+================================================================================\n+TestPackageJsonExportsDefaultOverImportAndRequire\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/node_modules/pkg/default.js\n+console.log(\"SUCCESS\");\n+\n+================================================================================\n+TestPackageJsonExportsImportOverRequire\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/node_modules/pkg/import.js\n+console.log(\"SUCCESS\");\n+\n+================================================================================\n+TestPackageJsonExportsNeutral\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/node_modules/pkg/default.js\n+console.log(\"SUCCESS\");\n+\n+================================================================================\n+TestPackageJsonExportsNode\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/node_modules/pkg/node.js\n+console.log(\"SUCCESS\");\n+\n+================================================================================\n+TestPackageJsonExportsOrderIndependent\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/node_modules/pkg1/2/bar.js\n+console.log(\"SUCCESS\");\n+\n+// Users/user/project/node_modules/pkg2/1/bar.js\n+console.log(\"SUCCESS\");\n+\n+================================================================================\n+TestPackageJsonExportsRequireOverImport\n+---------- /Users/user/project/out.js ----------\n+// Users/user/project/node_modules/pkg/require.js\n+var require_require = __commonJS(() => {\n+  console.log(\"SUCCESS\");\n+});\n+\n+// Users/user/project/src/entry.js\n+require_require();\n+\n ================================================================================\n TestPackageJsonMain\n ---------- /Users/user/project/out.js ----------"},{"sha":"4fdd2db313ec24639af0294a889ddf109d4e7e10","filename":"internal/compat/css_table.go","status":"modified","additions":4,"deletions":0,"changes":4,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fcompat%2Fcss_table.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fcompat%2Fcss_table.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fcompat%2Fcss_table.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -48,6 +48,10 @@ var cssTable = map[CSSFeature]map[Engine][]int{\n func UnsupportedCSSFeatures(constraints map[Engine][]int) (unsupported CSSFeature) {\n \tfor feature, engines := range cssTable {\n \t\tfor engine, version := range constraints {\n+\t\t\tif engine == ES || engine == Node {\n+\t\t\t\t// Specifying \"--target=es2020\" shouldn't affect CSS\n+\t\t\t\tcontinue\n+\t\t\t}\n \t\t\tif minVersion, ok := engines[engine]; !ok || isVersionLessThan(version, minVersion) {\n \t\t\t\tunsupported |= feature\n \t\t\t}"},{"sha":"e0eaac0e985706d51208e35ee1d5c1e3a03f4cdf","filename":"internal/config/config.go","status":"modified","additions":7,"deletions":4,"changes":11,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fconfig%2Fconfig.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fconfig%2Fconfig.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fconfig%2Fconfig.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -201,6 +201,7 @@ type Options struct {\n \n \tExtensionOrder  []string\n \tMainFields      []string\n+\tConditions      []string\n \tAbsNodePaths    []string // The \"NODE_PATH\" variable from Node.js\n \tExternalModules ExternalModules\n \n@@ -217,16 +218,18 @@ type Options struct {\n \tInjectAbsPaths     []string\n \tInjectedDefines    []InjectedDefine\n \tInjectedFiles      []InjectedFile\n-\tBanner             string\n-\tFooter             string\n+\n+\tJSBanner  string\n+\tJSFooter  string\n+\tCSSBanner string\n+\tCSSFooter string\n \n \tChunkPathTemplate []PathTemplate\n \tAssetPathTemplate []PathTemplate\n \n \tPlugins []Plugin\n \n-\t// If present, metadata about the bundle is written as JSON here\n-\tAbsMetadataFile string\n+\tNeedsMetafile bool\n \n \tSourceMap             SourceMap\n \tExcludeSourcesContent bool"},{"sha":"a8e3e80a394a6a108c2139820262bb158941baa0","filename":"internal/logger/logger.go","status":"modified","additions":16,"deletions":11,"changes":27,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Flogger%2Flogger.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Flogger%2Flogger.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Flogger%2Flogger.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -375,7 +375,7 @@ func NewStderrLog(options OutputOptions) Log {\n \n \t\t// Print out a summary\n \t\tif options.MessageLimit > 0 && errors+warnings > options.MessageLimit {\n-\t\t\twriteStringWithColor(os.Stderr, fmt.Sprintf(\"%s shown (disable the message limit with --error-limit=0)\\n\",\n+\t\t\twriteStringWithColor(os.Stderr, fmt.Sprintf(\"%s shown (disable the message limit with --log-limit=0)\\n\",\n \t\t\t\terrorAndWarningSummary(errors, warnings, shownErrors, shownWarnings)))\n \t\t} else if options.LogLevel <= LevelInfo && (warnings != 0 || errors != 0) {\n \t\t\twriteStringWithColor(os.Stderr, fmt.Sprintf(\"%s\\n\",\n@@ -608,8 +608,8 @@ func (t SummaryTable) Less(i int, j int) bool {\n // Show a warning icon next to output files that are 1mb or larger\n const sizeWarningThreshold = 1024 * 1024\n \n-func PrintSummary(osArgs []string, table SummaryTable, start time.Time) {\n-\tPrintText(os.Stderr, LevelInfo, osArgs, func(colors Colors) string {\n+func PrintSummary(useColor UseColor, table SummaryTable, start *time.Time) {\n+\tPrintTextWithColor(os.Stderr, useColor, func(colors Colors) string {\n \t\tisProbablyWindowsCommandPrompt := false\n \t\tsb := strings.Builder{}\n \n@@ -631,7 +631,7 @@ func PrintSummary(osArgs []string, table SummaryTable, start time.Time) {\n \t\t\tinfo := GetTerminalInfo(os.Stderr)\n \n \t\t\t// Truncate the table in case it's really long\n-\t\t\tmaxLength := info.Height - 10\n+\t\t\tmaxLength := info.Height / 2\n \t\t\tif info.Height == 0 {\n \t\t\t\tmaxLength = 20\n \t\t\t} else if maxLength < 5 {\n@@ -675,7 +675,7 @@ func PrintSummary(osArgs []string, table SummaryTable, start time.Time) {\n \t\t\tif layoutWidth > maxPath+maxSize {\n \t\t\t\tlayoutWidth = maxPath + maxSize\n \t\t\t}\n-\t\t\tsb.WriteString(\"\\n\")\n+\t\t\tsb.WriteByte('\\n')\n \n \t\t\tfor _, entry := range table {\n \t\t\t\tdir, base := entry.Dir, entry.Base\n@@ -743,6 +743,7 @@ func PrintSummary(osArgs []string, table SummaryTable, start time.Time) {\n \t\t\t\tsb.WriteString(fmt.Sprintf(\"%s%s...and %d more output file%s...%s\\n\", margin, colors.Dim, length-maxLength, plural, colors.Default))\n \t\t\t}\n \t\t}\n+\t\tsb.WriteByte('\\n')\n \n \t\tlightningSymbol := \"⚡ \"\n \n@@ -751,12 +752,16 @@ func PrintSummary(osArgs []string, table SummaryTable, start time.Time) {\n \t\t\tlightningSymbol = \"\"\n \t\t}\n \n-\t\tsb.WriteString(fmt.Sprintf(\"\\n%s%sDone in %dms%s\\n\\n\",\n-\t\t\tlightningSymbol,\n-\t\t\tcolors.Green,\n-\t\t\ttime.Since(start).Milliseconds(),\n-\t\t\tcolors.Default,\n-\t\t))\n+\t\t// Printing the time taken is optional\n+\t\tif start != nil {\n+\t\t\tsb.WriteString(fmt.Sprintf(\"%s%sDone in %dms%s\\n\",\n+\t\t\t\tlightningSymbol,\n+\t\t\t\tcolors.Green,\n+\t\t\t\ttime.Since(*start).Milliseconds(),\n+\t\t\t\tcolors.Default,\n+\t\t\t))\n+\t\t}\n+\n \t\treturn sb.String()\n \t})\n }"},{"sha":"4323c8a690091134687620dc7bbc48c6bb1eb98f","filename":"internal/resolver/package_json.go","status":"added","additions":697,"deletions":0,"changes":697,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fresolver%2Fpackage_json.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fresolver%2Fpackage_json.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fresolver%2Fpackage_json.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -0,0 +1,697 @@\n+package resolver\n+\n+import (\n+\t\"fmt\"\n+\t\"net/url\"\n+\t\"path\"\n+\t\"regexp\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"syscall\"\n+\n+\t\"github.com/evanw/esbuild/internal/config\"\n+\t\"github.com/evanw/esbuild/internal/js_ast\"\n+\t\"github.com/evanw/esbuild/internal/js_lexer\"\n+\t\"github.com/evanw/esbuild/internal/js_parser\"\n+\t\"github.com/evanw/esbuild/internal/logger\"\n+)\n+\n+type packageJSON struct {\n+\tsource        logger.Source\n+\tabsMainFields map[string]string\n+\n+\t// Present if the \"browser\" field is present. This field is intended to be\n+\t// used by bundlers and lets you redirect the paths of certain 3rd-party\n+\t// modules that don't work in the browser to other modules that shim that\n+\t// functionality. That way you don't have to rewrite the code for those 3rd-\n+\t// party modules. For example, you might remap the native \"util\" node module\n+\t// to something like https://www.npmjs.com/package/util so it works in the\n+\t// browser.\n+\t//\n+\t// This field contains a mapping of absolute paths to absolute paths. Mapping\n+\t// to an empty path indicates that the module is disabled. As far as I can\n+\t// tell, the official spec is a GitHub repo hosted by a user account:\n+\t// https://github.com/defunctzombie/package-browser-field-spec. The npm docs\n+\t// say almost nothing: https://docs.npmjs.com/files/package.json.\n+\t//\n+\t// Note that the non-package \"browser\" map has to be checked twice to match\n+\t// Webpack's behavior: once before resolution and once after resolution. It\n+\t// leads to some unintuitive failure cases that we must emulate around missing\n+\t// file extensions:\n+\t//\n+\t// * Given the mapping \"./no-ext\": \"./no-ext-browser.js\" the query \"./no-ext\"\n+\t//   should match but the query \"./no-ext.js\" should NOT match.\n+\t//\n+\t// * Given the mapping \"./ext.js\": \"./ext-browser.js\" the query \"./ext.js\"\n+\t//   should match and the query \"./ext\" should ALSO match.\n+\t//\n+\tbrowserNonPackageMap map[string]*string\n+\tbrowserPackageMap    map[string]*string\n+\n+\t// If this is non-nil, each entry in this map is the absolute path of a file\n+\t// with side effects. Any entry not in this map should be considered to have\n+\t// no side effects, which means import statements for these files can be\n+\t// removed if none of the imports are used. This is a convention from Webpack:\n+\t// https://webpack.js.org/guides/tree-shaking/.\n+\t//\n+\t// Note that if a file is included, all statements that can't be proven to be\n+\t// free of side effects must be included. This convention does not say\n+\t// anything about whether any statements within the file have side effects or\n+\t// not.\n+\tsideEffectsMap     map[string]bool\n+\tsideEffectsRegexps []*regexp.Regexp\n+\tignoreIfUnusedData *IgnoreIfUnusedData\n+\n+\t// This represents the \"exports\" field in this package.json file.\n+\texportsMap *peMap\n+}\n+\n+func (r *resolver) parsePackageJSON(path string) *packageJSON {\n+\tpackageJSONPath := r.fs.Join(path, \"package.json\")\n+\tcontents, err := r.caches.FSCache.ReadFile(r.fs, packageJSONPath)\n+\tif err != nil {\n+\t\tr.log.AddError(nil, logger.Loc{},\n+\t\t\tfmt.Sprintf(\"Cannot read file %q: %s\",\n+\t\t\t\tr.PrettyPath(logger.Path{Text: packageJSONPath, Namespace: \"file\"}), err.Error()))\n+\t\treturn nil\n+\t}\n+\n+\tkeyPath := logger.Path{Text: packageJSONPath, Namespace: \"file\"}\n+\tjsonSource := logger.Source{\n+\t\tKeyPath:    keyPath,\n+\t\tPrettyPath: r.PrettyPath(keyPath),\n+\t\tContents:   contents,\n+\t}\n+\n+\tjson, ok := r.caches.JSONCache.Parse(r.log, jsonSource, js_parser.JSONOptions{})\n+\tif !ok {\n+\t\treturn nil\n+\t}\n+\n+\ttoAbsPath := func(pathText string, pathRange logger.Range) *string {\n+\t\t// Is it a file?\n+\t\tif absolute, ok, _ := r.loadAsFile(pathText, r.options.ExtensionOrder); ok {\n+\t\t\treturn &absolute\n+\t\t}\n+\n+\t\t// Is it a directory?\n+\t\tif mainEntries, err := r.fs.ReadDirectory(pathText); err == nil {\n+\t\t\t// Look for an \"index\" file with known extensions\n+\t\t\tif absolute, ok, _ := r.loadAsIndex(pathText, mainEntries); ok {\n+\t\t\t\treturn &absolute\n+\t\t\t}\n+\t\t} else if err != syscall.ENOENT {\n+\t\t\tr.log.AddRangeError(&jsonSource, pathRange,\n+\t\t\t\tfmt.Sprintf(\"Cannot read directory %q: %s\",\n+\t\t\t\t\tr.PrettyPath(logger.Path{Text: pathText, Namespace: \"file\"}), err.Error()))\n+\t\t}\n+\t\treturn nil\n+\t}\n+\n+\tpackageJSON := &packageJSON{source: jsonSource}\n+\n+\t// Read the \"main\" fields\n+\tmainFields := r.options.MainFields\n+\tif mainFields == nil {\n+\t\tmainFields = defaultMainFields[r.options.Platform]\n+\t}\n+\tfor _, field := range mainFields {\n+\t\tif mainJSON, _, ok := getProperty(json, field); ok {\n+\t\t\tif main, ok := getString(mainJSON); ok {\n+\t\t\t\tif packageJSON.absMainFields == nil {\n+\t\t\t\t\tpackageJSON.absMainFields = make(map[string]string)\n+\t\t\t\t}\n+\t\t\t\tif absPath := toAbsPath(r.fs.Join(path, main), jsonSource.RangeOfString(mainJSON.Loc)); absPath != nil {\n+\t\t\t\t\tpackageJSON.absMainFields[field] = *absPath\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Read the \"browser\" property, but only when targeting the browser\n+\tif browserJSON, _, ok := getProperty(json, \"browser\"); ok && r.options.Platform == config.PlatformBrowser {\n+\t\t// We both want the ability to have the option of CJS vs. ESM and the\n+\t\t// option of having node vs. browser. The way to do this is to use the\n+\t\t// object literal form of the \"browser\" field like this:\n+\t\t//\n+\t\t//   \"main\": \"dist/index.node.cjs.js\",\n+\t\t//   \"module\": \"dist/index.node.esm.js\",\n+\t\t//   \"browser\": {\n+\t\t//     \"./dist/index.node.cjs.js\": \"./dist/index.browser.cjs.js\",\n+\t\t//     \"./dist/index.node.esm.js\": \"./dist/index.browser.esm.js\"\n+\t\t//   },\n+\t\t//\n+\t\tif browser, ok := browserJSON.Data.(*js_ast.EObject); ok {\n+\t\t\t// The value is an object\n+\t\t\tbrowserPackageMap := make(map[string]*string)\n+\t\t\tbrowserNonPackageMap := make(map[string]*string)\n+\n+\t\t\t// Remap all files in the browser field\n+\t\t\tfor _, prop := range browser.Properties {\n+\t\t\t\tif key, ok := getString(prop.Key); ok && prop.Value != nil {\n+\t\t\t\t\tisPackagePath := IsPackagePath(key)\n+\n+\t\t\t\t\t// Make this an absolute path if it's not a package\n+\t\t\t\t\tif !isPackagePath {\n+\t\t\t\t\t\tkey = r.fs.Join(path, key)\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif value, ok := getString(*prop.Value); ok {\n+\t\t\t\t\t\t// If this is a string, it's a replacement package\n+\t\t\t\t\t\tif isPackagePath {\n+\t\t\t\t\t\t\tbrowserPackageMap[key] = &value\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tbrowserNonPackageMap[key] = &value\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else if value, ok := getBool(*prop.Value); ok && !value {\n+\t\t\t\t\t\t// If this is false, it means the package is disabled\n+\t\t\t\t\t\tif isPackagePath {\n+\t\t\t\t\t\t\tbrowserPackageMap[key] = nil\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tbrowserNonPackageMap[key] = nil\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tpackageJSON.browserPackageMap = browserPackageMap\n+\t\t\tpackageJSON.browserNonPackageMap = browserNonPackageMap\n+\t\t}\n+\t}\n+\n+\t// Read the \"sideEffects\" property\n+\tif sideEffectsJSON, sideEffectsLoc, ok := getProperty(json, \"sideEffects\"); ok {\n+\t\tswitch data := sideEffectsJSON.Data.(type) {\n+\t\tcase *js_ast.EBoolean:\n+\t\t\tif !data.Value {\n+\t\t\t\t// Make an empty map for \"sideEffects: false\", which indicates all\n+\t\t\t\t// files in this module can be considered to not have side effects.\n+\t\t\t\tpackageJSON.sideEffectsMap = make(map[string]bool)\n+\t\t\t\tpackageJSON.ignoreIfUnusedData = &IgnoreIfUnusedData{\n+\t\t\t\t\tIsSideEffectsArrayInJSON: false,\n+\t\t\t\t\tSource:                   &jsonSource,\n+\t\t\t\t\tRange:                    jsonSource.RangeOfString(sideEffectsLoc),\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\tcase *js_ast.EArray:\n+\t\t\t// The \"sideEffects: []\" format means all files in this module but not in\n+\t\t\t// the array can be considered to not have side effects.\n+\t\t\tpackageJSON.sideEffectsMap = make(map[string]bool)\n+\t\t\tpackageJSON.ignoreIfUnusedData = &IgnoreIfUnusedData{\n+\t\t\t\tIsSideEffectsArrayInJSON: true,\n+\t\t\t\tSource:                   &jsonSource,\n+\t\t\t\tRange:                    jsonSource.RangeOfString(sideEffectsLoc),\n+\t\t\t}\n+\t\t\tfor _, itemJSON := range data.Items {\n+\t\t\t\titem, ok := itemJSON.Data.(*js_ast.EString)\n+\t\t\t\tif !ok || item.Value == nil {\n+\t\t\t\t\tr.log.AddWarning(&jsonSource, itemJSON.Loc,\n+\t\t\t\t\t\t\"Expected string in array for \\\"sideEffects\\\"\")\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\n+\t\t\t\tabsPattern := r.fs.Join(path, js_lexer.UTF16ToString(item.Value))\n+\t\t\t\tre, hadWildcard := globToEscapedRegexp(absPattern)\n+\n+\t\t\t\t// Wildcard patterns require more expensive matching\n+\t\t\t\tif hadWildcard {\n+\t\t\t\t\tpackageJSON.sideEffectsRegexps = append(packageJSON.sideEffectsRegexps, regexp.MustCompile(re))\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\n+\t\t\t\t// Normal strings can be matched with a map lookup\n+\t\t\t\tpackageJSON.sideEffectsMap[absPattern] = true\n+\t\t\t}\n+\n+\t\tdefault:\n+\t\t\tr.log.AddWarning(&jsonSource, sideEffectsJSON.Loc,\n+\t\t\t\t\"The value for \\\"sideEffects\\\" must be a boolean or an array\")\n+\t\t}\n+\t}\n+\n+\t// Read the \"exports\" map\n+\tif exportsJSON, exportsRange, ok := getProperty(json, \"exports\"); ok {\n+\t\tif exportsMap := parseExportsMap(jsonSource, r.log, exportsJSON); exportsMap != nil {\n+\t\t\texportsMap.exportsRange = jsonSource.RangeOfString(exportsRange)\n+\t\t\tpackageJSON.exportsMap = exportsMap\n+\t\t}\n+\t}\n+\n+\treturn packageJSON\n+}\n+\n+func globToEscapedRegexp(glob string) (string, bool) {\n+\tsb := strings.Builder{}\n+\tsb.WriteByte('^')\n+\thadWildcard := false\n+\n+\tfor _, c := range glob {\n+\t\tswitch c {\n+\t\tcase '\\\\', '^', '$', '.', '+', '|', '(', ')', '[', ']', '{', '}':\n+\t\t\tsb.WriteByte('\\\\')\n+\t\t\tsb.WriteRune(c)\n+\n+\t\tcase '*':\n+\t\t\tsb.WriteString(\".*\")\n+\t\t\thadWildcard = true\n+\n+\t\tcase '?':\n+\t\t\tsb.WriteByte('.')\n+\t\t\thadWildcard = true\n+\n+\t\tdefault:\n+\t\t\tsb.WriteRune(c)\n+\t\t}\n+\t}\n+\n+\tsb.WriteByte('$')\n+\treturn sb.String(), hadWildcard\n+}\n+\n+// Reference: https://nodejs.org/api/esm.html#esm_resolver_algorithm_specification\n+type peMap struct {\n+\texportsRange logger.Range\n+\troot         peEntry\n+}\n+\n+type peKind uint8\n+\n+const (\n+\tpeNull peKind = iota\n+\tpeString\n+\tpeArray\n+\tpeObject\n+\tpeInvalid\n+)\n+\n+type peEntry struct {\n+\tstrData       string\n+\tarrData       []peEntry\n+\tmapData       []peMapEntry // Can't be a \"map\" because order matters\n+\texpansionKeys expansionKeysArray\n+\tfirstToken    logger.Range\n+\tkind          peKind\n+}\n+\n+type peMapEntry struct {\n+\tkey      string\n+\tkeyRange logger.Range\n+\tvalue    peEntry\n+}\n+\n+// This type is just so we can use Go's native sort function\n+type expansionKeysArray []peMapEntry\n+\n+func (a expansionKeysArray) Len() int          { return len(a) }\n+func (a expansionKeysArray) Swap(i int, j int) { a[i], a[j] = a[j], a[i] }\n+\n+func (a expansionKeysArray) Less(i int, j int) bool {\n+\treturn len(a[i].key) > len(a[j].key)\n+}\n+\n+func (entry peEntry) valueForKey(key string) (peEntry, bool) {\n+\tfor _, item := range entry.mapData {\n+\t\tif item.key == key {\n+\t\t\treturn item.value, true\n+\t\t}\n+\t}\n+\treturn peEntry{}, false\n+}\n+\n+func parseExportsMap(source logger.Source, log logger.Log, json js_ast.Expr) *peMap {\n+\tvar visit func(expr js_ast.Expr) peEntry\n+\n+\tvisit = func(expr js_ast.Expr) peEntry {\n+\t\tvar firstToken logger.Range\n+\n+\t\tswitch e := expr.Data.(type) {\n+\t\tcase *js_ast.ENull:\n+\t\t\treturn peEntry{\n+\t\t\t\tkind:       peNull,\n+\t\t\t\tfirstToken: js_lexer.RangeOfIdentifier(source, expr.Loc),\n+\t\t\t}\n+\n+\t\tcase *js_ast.EString:\n+\t\t\treturn peEntry{\n+\t\t\t\tkind:       peString,\n+\t\t\t\tfirstToken: source.RangeOfString(expr.Loc),\n+\t\t\t\tstrData:    js_lexer.UTF16ToString(e.Value),\n+\t\t\t}\n+\n+\t\tcase *js_ast.EArray:\n+\t\t\tarrData := make([]peEntry, len(e.Items))\n+\t\t\tfor i, item := range e.Items {\n+\t\t\t\tarrData[i] = visit(item)\n+\t\t\t}\n+\t\t\treturn peEntry{\n+\t\t\t\tkind:       peArray,\n+\t\t\t\tfirstToken: logger.Range{Loc: expr.Loc, Len: 1},\n+\t\t\t\tarrData:    arrData,\n+\t\t\t}\n+\n+\t\tcase *js_ast.EObject:\n+\t\t\tmapData := make([]peMapEntry, len(e.Properties))\n+\t\t\texpansionKeys := make(expansionKeysArray, 0, len(e.Properties))\n+\t\t\tfirstToken := logger.Range{Loc: expr.Loc, Len: 1}\n+\t\t\tisConditionalSugar := false\n+\n+\t\t\tfor i, property := range e.Properties {\n+\t\t\t\tkeyStr, _ := property.Key.Data.(*js_ast.EString)\n+\t\t\t\tkey := js_lexer.UTF16ToString(keyStr.Value)\n+\t\t\t\tkeyRange := source.RangeOfString(property.Key.Loc)\n+\n+\t\t\t\t// If exports is an Object with both a key starting with \".\" and a key\n+\t\t\t\t// not starting with \".\", throw an Invalid Package Configuration error.\n+\t\t\t\tcurIsConditionalSugar := !strings.HasPrefix(key, \".\")\n+\t\t\t\tif i == 0 {\n+\t\t\t\t\tisConditionalSugar = curIsConditionalSugar\n+\t\t\t\t} else if isConditionalSugar != curIsConditionalSugar {\n+\t\t\t\t\tprevEntry := mapData[i-1]\n+\t\t\t\t\tlog.AddRangeWarningWithNotes(&source, keyRange,\n+\t\t\t\t\t\t\"This object cannot contain keys that both start with \\\".\\\" and don't start with \\\".\\\"\",\n+\t\t\t\t\t\t[]logger.MsgData{logger.RangeData(&source, prevEntry.keyRange,\n+\t\t\t\t\t\t\tfmt.Sprintf(\"The previous key %q is incompatible with the current key %q\", prevEntry.key, key))})\n+\t\t\t\t\treturn peEntry{\n+\t\t\t\t\t\tkind:       peInvalid,\n+\t\t\t\t\t\tfirstToken: firstToken,\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tentry := peMapEntry{\n+\t\t\t\t\tkey:      key,\n+\t\t\t\t\tkeyRange: keyRange,\n+\t\t\t\t\tvalue:    visit(*property.Value),\n+\t\t\t\t}\n+\n+\t\t\t\tif strings.HasSuffix(key, \"/\") || strings.HasSuffix(key, \"*\") {\n+\t\t\t\t\texpansionKeys = append(expansionKeys, entry)\n+\t\t\t\t}\n+\n+\t\t\t\tmapData[i] = entry\n+\t\t\t}\n+\n+\t\t\t// Let expansionKeys be the list of keys of matchObj ending in \"/\" or \"*\",\n+\t\t\t// sorted by length descending.\n+\t\t\tsort.Stable(expansionKeys)\n+\n+\t\t\treturn peEntry{\n+\t\t\t\tkind:          peObject,\n+\t\t\t\tfirstToken:    firstToken,\n+\t\t\t\tmapData:       mapData,\n+\t\t\t\texpansionKeys: expansionKeys,\n+\t\t\t}\n+\n+\t\tcase *js_ast.EBoolean:\n+\t\t\tfirstToken = js_lexer.RangeOfIdentifier(source, expr.Loc)\n+\n+\t\tcase *js_ast.ENumber:\n+\t\t\tfirstToken = source.RangeOfNumber(expr.Loc)\n+\n+\t\tdefault:\n+\t\t\tfirstToken.Loc = expr.Loc\n+\t\t}\n+\n+\t\tlog.AddRangeWarning(&source, firstToken, \"This value must be a string, an object, an array, or null\")\n+\t\treturn peEntry{\n+\t\t\tkind:       peInvalid,\n+\t\t\tfirstToken: firstToken,\n+\t\t}\n+\t}\n+\n+\troot := visit(json)\n+\n+\tif root.kind == peNull {\n+\t\treturn nil\n+\t}\n+\n+\treturn &peMap{root: root}\n+}\n+\n+func (entry peEntry) keysStartWithDot() bool {\n+\treturn len(entry.mapData) > 0 && strings.HasPrefix(entry.mapData[0].key, \".\")\n+}\n+\n+type peStatus uint8\n+\n+const (\n+\tpeStatusUndefined peStatus = iota\n+\tpeStatusNull\n+\tpeStatusOk\n+\n+\t// Module specifier is an invalid URL, package name or package subpath specifier.\n+\tpeStatusInvalidModuleSpecifier\n+\n+\t// package.json configuration is invalid or contains an invalid configuration.\n+\tpeStatusInvalidPackageConfiguration\n+\n+\t// Package exports or imports define a target module for the package that is an invalid type or string target.\n+\tpeStatusInvalidPackageTarget\n+\n+\t// Package exports do not define or permit a target subpath in the package for the given module.\n+\tpeStatusPackagePathNotExported\n+\n+\t// The package or module requested does not exist.\n+\tpeStatusModuleNotFound\n+\n+\t// The resolved path corresponds to a directory, which is not a supported target for module imports.\n+\tpeStatusUnsupportedDirectoryImport\n+)\n+\n+func esmPackageExportsResolveWithPostConditions(\n+\tpackageURL string,\n+\tsubpath string,\n+\texports peEntry,\n+\tconditions map[string]bool,\n+) (string, peStatus, logger.Range) {\n+\tresolved, status, token := esmPackageExportsResolve(packageURL, subpath, exports, conditions)\n+\tif status != peStatusOk {\n+\t\treturn resolved, status, token\n+\t}\n+\n+\t// If resolved contains any percent encodings of \"/\" or \"\\\" (\"%2f\" and \"%5C\"\n+\t// respectively), then throw an Invalid Module Specifier error.\n+\tresolvedPath, err := url.PathUnescape(resolved)\n+\tif err != nil {\n+\t\treturn resolved, peStatusInvalidModuleSpecifier, token\n+\t}\n+\tif strings.Contains(resolved, \"%2f\") || strings.Contains(resolved, \"%2F\") ||\n+\t\tstrings.Contains(resolved, \"%5c\") || strings.Contains(resolved, \"%5C\") {\n+\t\treturn resolved, peStatusInvalidModuleSpecifier, token\n+\t}\n+\n+\t// If the file at resolved is a directory, then throw an Unsupported Directory\n+\t// Import error.\n+\tif strings.HasSuffix(resolvedPath, \"/\") || strings.HasSuffix(resolvedPath, \"\\\\\") {\n+\t\treturn resolved, peStatusUnsupportedDirectoryImport, token\n+\t}\n+\n+\t// Set resolved to the real path of resolved.\n+\treturn resolvedPath, peStatusOk, token\n+}\n+\n+func esmPackageExportsResolve(\n+\tpackageURL string,\n+\tsubpath string,\n+\texports peEntry,\n+\tconditions map[string]bool,\n+) (string, peStatus, logger.Range) {\n+\tif exports.kind == peInvalid {\n+\t\treturn \"\", peStatusInvalidPackageConfiguration, exports.firstToken\n+\t}\n+\tif subpath == \".\" {\n+\t\tmainExport := peEntry{kind: peNull}\n+\t\tif exports.kind == peString || exports.kind == peArray || (exports.kind == peObject && !exports.keysStartWithDot()) {\n+\t\t\tmainExport = exports\n+\t\t} else if exports.kind == peObject {\n+\t\t\tif dot, ok := exports.valueForKey(\".\"); ok {\n+\t\t\t\tmainExport = dot\n+\t\t\t}\n+\t\t}\n+\t\tif mainExport.kind != peNull {\n+\t\t\tresolved, status, token := esmPackageTargetResolve(packageURL, mainExport, \"\", false, conditions)\n+\t\t\tif status != peStatusNull && status != peStatusUndefined {\n+\t\t\t\treturn resolved, status, token\n+\t\t\t}\n+\t\t}\n+\t} else if exports.kind == peObject && exports.keysStartWithDot() {\n+\t\tresolved, status, token := esmPackageImportsExportsResolve(subpath, exports, packageURL, conditions)\n+\t\tif status != peStatusNull && status != peStatusUndefined {\n+\t\t\treturn resolved, status, token\n+\t\t}\n+\t}\n+\treturn \"\", peStatusPackagePathNotExported, exports.firstToken\n+}\n+\n+func esmPackageImportsExportsResolve(\n+\tmatchKey string,\n+\tmatchObj peEntry,\n+\tpackageURL string,\n+\tconditions map[string]bool,\n+) (string, peStatus, logger.Range) {\n+\tif !strings.HasSuffix(matchKey, \"*\") {\n+\t\tif target, ok := matchObj.valueForKey(matchKey); ok {\n+\t\t\treturn esmPackageTargetResolve(packageURL, target, \"\", false, conditions)\n+\t\t}\n+\t}\n+\n+\tfor _, expansion := range matchObj.expansionKeys {\n+\t\t// If expansionKey ends in \"*\" and matchKey starts with but is not equal to\n+\t\t// the substring of expansionKey excluding the last \"*\" character\n+\t\tif strings.HasSuffix(expansion.key, \"*\") {\n+\t\t\tif substr := expansion.key[:len(expansion.key)-1]; strings.HasPrefix(matchKey, substr) && matchKey != substr {\n+\t\t\t\ttarget := expansion.value\n+\t\t\t\tsubpath := matchKey[len(expansion.key)-1:]\n+\t\t\t\treturn esmPackageTargetResolve(packageURL, target, subpath, true, conditions)\n+\t\t\t}\n+\t\t}\n+\n+\t\tif strings.HasPrefix(matchKey, expansion.key) {\n+\t\t\ttarget := expansion.value\n+\t\t\tsubpath := matchKey[len(expansion.key):]\n+\t\t\treturn esmPackageTargetResolve(packageURL, target, subpath, false, conditions)\n+\t\t}\n+\t}\n+\n+\treturn \"\", peStatusNull, matchObj.firstToken\n+}\n+\n+// If path split on \"/\" or \"\\\" contains any \".\", \"..\" or \"node_modules\"\n+// segments after the first segment, throw an Invalid Package Target error.\n+func hasInvalidSegment(path string) bool {\n+\tslash := strings.IndexAny(path, \"/\\\\\")\n+\tif slash == -1 {\n+\t\treturn false\n+\t}\n+\tpath = path[slash+1:]\n+\tfor path != \"\" {\n+\t\tslash := strings.IndexAny(path, \"/\\\\\")\n+\t\tsegment := path\n+\t\tif slash != -1 {\n+\t\t\tsegment = path[:slash]\n+\t\t\tpath = path[slash+1:]\n+\t\t} else {\n+\t\t\tpath = \"\"\n+\t\t}\n+\t\tif segment == \".\" || segment == \"..\" || segment == \"node_modules\" {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+func esmPackageTargetResolve(\n+\tpackageURL string,\n+\ttarget peEntry,\n+\tsubpath string,\n+\tpattern bool,\n+\tconditions map[string]bool,\n+) (string, peStatus, logger.Range) {\n+\tswitch target.kind {\n+\tcase peString:\n+\t\t// If pattern is false, subpath has non-zero length and target\n+\t\t// does not end with \"/\", throw an Invalid Module Specifier error.\n+\t\tif !pattern && subpath != \"\" && !strings.HasSuffix(target.strData, \"/\") {\n+\t\t\treturn target.strData, peStatusInvalidModuleSpecifier, target.firstToken\n+\t\t}\n+\n+\t\tif !strings.HasPrefix(target.strData, \"./\") {\n+\t\t\treturn target.strData, peStatusInvalidPackageTarget, target.firstToken\n+\t\t}\n+\n+\t\t// If target split on \"/\" or \"\\\" contains any \".\", \"..\" or \"node_modules\"\n+\t\t// segments after the first segment, throw an Invalid Package Target error.\n+\t\tif hasInvalidSegment(target.strData) {\n+\t\t\treturn target.strData, peStatusInvalidPackageTarget, target.firstToken\n+\t\t}\n+\n+\t\t// Let resolvedTarget be the URL resolution of the concatenation of packageURL and target.\n+\t\tresolvedTarget := path.Join(packageURL, target.strData)\n+\n+\t\t// If subpath split on \"/\" or \"\\\" contains any \".\", \"..\" or \"node_modules\"\n+\t\t// segments, throw an Invalid Module Specifier error.\n+\t\tif hasInvalidSegment(subpath) {\n+\t\t\treturn subpath, peStatusInvalidModuleSpecifier, target.firstToken\n+\t\t}\n+\n+\t\tif pattern {\n+\t\t\t// Return the URL resolution of resolvedTarget with every instance of \"*\" replaced with subpath.\n+\t\t\treturn strings.ReplaceAll(resolvedTarget, \"*\", subpath), peStatusOk, target.firstToken\n+\t\t} else {\n+\t\t\t// Return the URL resolution of the concatenation of subpath and resolvedTarget.\n+\t\t\treturn path.Join(resolvedTarget, subpath), peStatusOk, target.firstToken\n+\t\t}\n+\n+\tcase peObject:\n+\t\tfor _, p := range target.mapData {\n+\t\t\tif p.key == \"default\" || conditions[p.key] {\n+\t\t\t\ttargetValue := p.value\n+\t\t\t\tresolved, status, token := esmPackageTargetResolve(packageURL, targetValue, subpath, pattern, conditions)\n+\t\t\t\tif status == peStatusUndefined {\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\treturn resolved, status, token\n+\t\t\t}\n+\t\t}\n+\t\treturn \"\", peStatusUndefined, target.firstToken\n+\n+\tcase peArray:\n+\t\tif len(target.arrData) == 0 {\n+\t\t\treturn \"\", peStatusNull, target.firstToken\n+\t\t}\n+\t\tlastException := peStatusUndefined\n+\t\tlastToken := target.firstToken\n+\t\tfor _, targetValue := range target.arrData {\n+\t\t\t// Let resolved be the result, continuing the loop on any Invalid Package Target error.\n+\t\t\tresolved, status, token := esmPackageTargetResolve(packageURL, targetValue, subpath, pattern, conditions)\n+\t\t\tif status == peStatusInvalidPackageTarget || status == peStatusNull {\n+\t\t\t\tlastException = status\n+\t\t\t\tlastToken = token\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tif status == peStatusUndefined {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\treturn resolved, status, token\n+\t\t}\n+\n+\t\t// Return or throw the last fallback resolution null return or error.\n+\t\treturn \"\", lastException, lastToken\n+\n+\tcase peNull:\n+\t\treturn \"\", peStatusNull, target.firstToken\n+\t}\n+\n+\treturn \"\", peStatusInvalidPackageTarget, target.firstToken\n+}\n+\n+func esmParsePackageName(packageSpecifier string) (packageName string, packageSubpath string, ok bool) {\n+\tif packageSpecifier == \"\" {\n+\t\treturn\n+\t}\n+\n+\tslash := strings.IndexByte(packageSpecifier, '/')\n+\tif !strings.HasPrefix(packageSpecifier, \"@\") {\n+\t\tif slash == -1 {\n+\t\t\tslash = len(packageSpecifier)\n+\t\t}\n+\t\tpackageName = packageSpecifier[:slash]\n+\t} else {\n+\t\tif slash == -1 {\n+\t\t\treturn\n+\t\t}\n+\t\tslash2 := strings.IndexByte(packageSpecifier[slash+1:], '/')\n+\t\tif slash2 == -1 {\n+\t\t\tslash2 = len(packageSpecifier[slash+1:])\n+\t\t}\n+\t\tpackageName = packageSpecifier[:slash]\n+\t}\n+\n+\tif strings.HasPrefix(packageName, \".\") || strings.ContainsAny(packageName, \"\\\\%\") {\n+\t\treturn\n+\t}\n+\n+\tpackageSubpath = \".\" + packageSpecifier[len(packageName):]\n+\tok = true\n+\treturn\n+}"},{"sha":"c0e7bcafa93943e22f3149b64588a7c2902b8188","filename":"internal/resolver/resolver.go","status":"modified","additions":158,"deletions":289,"changes":447,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fresolver%2Fresolver.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/internal%2Fresolver%2Fresolver.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/internal%2Fresolver%2Fresolver.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -3,7 +3,6 @@ package resolver\n import (\n \t\"errors\"\n \t\"fmt\"\n-\t\"regexp\"\n \t\"strings\"\n \t\"sync\"\n \t\"syscall\"\n@@ -14,7 +13,6 @@ import (\n \t\"github.com/evanw/esbuild/internal/fs\"\n \t\"github.com/evanw/esbuild/internal/js_ast\"\n \t\"github.com/evanw/esbuild/internal/js_lexer\"\n-\t\"github.com/evanw/esbuild/internal/js_parser\"\n \t\"github.com/evanw/esbuild/internal/logger\"\n )\n \n@@ -112,7 +110,7 @@ type ResolveResult struct {\n }\n \n type Resolver interface {\n-\tResolve(sourceDir string, importPath string, kind ast.ImportKind) *ResolveResult\n+\tResolve(sourceDir string, importPath string, kind ast.ImportKind) (result *ResolveResult, notes []logger.MsgData)\n \tResolveAbs(absPath string) *ResolveResult\n \tPrettyPath(path logger.Path) string\n \n@@ -127,6 +125,12 @@ type resolver struct {\n \tcaches  *cache.CacheSet\n \toptions config.Options\n \n+\t// These are sets that represent various conditions for the \"exports\" field\n+\t// in package.json.\n+\tesmConditionsDefault map[string]bool\n+\tesmConditionsImport  map[string]bool\n+\tesmConditionsRequire map[string]bool\n+\n \t// A special filtered import order for CSS \"@import\" imports.\n \t//\n \t// The \"resolve extensions\" setting determines the order of implicit\n@@ -190,17 +194,38 @@ func NewResolver(fs fs.FS, log logger.Log, caches *cache.CacheSet, options confi\n \t\tatImportExtensionOrder = append(atImportExtensionOrder, ext)\n \t}\n \n+\t// Generate the condition sets for interpreting the \"exports\" field\n+\tesmConditionsDefault := map[string]bool{}\n+\tesmConditionsImport := map[string]bool{\"import\": true}\n+\tesmConditionsRequire := map[string]bool{\"require\": true}\n+\tfor _, condition := range options.Conditions {\n+\t\tesmConditionsDefault[condition] = true\n+\t}\n+\tswitch options.Platform {\n+\tcase config.PlatformBrowser:\n+\t\tesmConditionsDefault[\"browser\"] = true\n+\tcase config.PlatformNode:\n+\t\tesmConditionsDefault[\"node\"] = true\n+\t}\n+\tfor key := range esmConditionsDefault {\n+\t\tesmConditionsImport[key] = true\n+\t\tesmConditionsRequire[key] = true\n+\t}\n+\n \treturn &resolver{\n \t\tfs:                     fs,\n \t\tlog:                    log,\n \t\toptions:                options,\n \t\tcaches:                 caches,\n \t\tdirCache:               make(map[string]*dirInfo),\n \t\tatImportExtensionOrder: atImportExtensionOrder,\n+\t\tesmConditionsDefault:   esmConditionsDefault,\n+\t\tesmConditionsImport:    esmConditionsImport,\n+\t\tesmConditionsRequire:   esmConditionsRequire,\n \t}\n }\n \n-func (r *resolver) Resolve(sourceDir string, importPath string, kind ast.ImportKind) *ResolveResult {\n+func (r *resolver) Resolve(sourceDir string, importPath string, kind ast.ImportKind) (*ResolveResult, []logger.MsgData) {\n \t// Certain types of URLs default to being external for convenience\n \tif r.isExternalPattern(importPath) ||\n \n@@ -219,7 +244,7 @@ func (r *resolver) Resolve(sourceDir string, importPath string, kind ast.ImportK\n \t\treturn &ResolveResult{\n \t\t\tPathPair:   PathPair{Primary: logger.Path{Text: importPath}},\n \t\t\tIsExternal: true,\n-\t\t}\n+\t\t}, nil\n \t}\n \n \tif parsed, ok := ParseDataURL(importPath); ok {\n@@ -228,45 +253,47 @@ func (r *resolver) Resolve(sourceDir string, importPath string, kind ast.ImportK\n \t\tif parsed.DecodeMIMEType() != MIMETypeUnsupported {\n \t\t\treturn &ResolveResult{\n \t\t\t\tPathPair: PathPair{Primary: logger.Path{Text: importPath, Namespace: \"dataurl\"}},\n-\t\t\t}\n+\t\t\t}, nil\n \t\t}\n \n \t\t// \"background: url(data:image/png;base64,iVBORw0KGgo=);\"\n \t\treturn &ResolveResult{\n \t\t\tPathPair:   PathPair{Primary: logger.Path{Text: importPath}},\n \t\t\tIsExternal: true,\n-\t\t}\n+\t\t}, nil\n \t}\n \n \t// Fail now if there is no directory to resolve in. This can happen for\n \t// virtual modules (e.g. stdin) if a resolve directory is not specified.\n \tif sourceDir == \"\" {\n-\t\treturn nil\n+\t\treturn nil, nil\n \t}\n \n \tr.mutex.Lock()\n \tdefer r.mutex.Unlock()\n \n-\tresult := r.resolveWithoutSymlinks(sourceDir, importPath, kind)\n+\tresult, notes := r.resolveWithoutSymlinks(sourceDir, importPath, kind)\n \tif result == nil {\n \t\t// If resolution failed, try again with the URL query and/or hash removed\n \t\tsuffix := strings.IndexAny(importPath, \"?#\")\n \t\tif suffix < 1 {\n-\t\t\treturn nil\n-\t\t}\n-\t\tresult = r.resolveWithoutSymlinks(sourceDir, importPath[:suffix], kind)\n-\t\tif result == nil {\n-\t\t\treturn nil\n+\t\t\treturn nil, notes\n \t\t}\n-\t\tresult.PathPair.Primary.IgnoredSuffix = importPath[suffix:]\n-\t\tif result.PathPair.HasSecondary() {\n-\t\t\tresult.PathPair.Secondary.IgnoredSuffix = importPath[suffix:]\n+\t\tif result2, notes2 := r.resolveWithoutSymlinks(sourceDir, importPath[:suffix], kind); result2 == nil {\n+\t\t\treturn nil, notes\n+\t\t} else {\n+\t\t\tresult = result2\n+\t\t\tnotes = notes2\n+\t\t\tresult.PathPair.Primary.IgnoredSuffix = importPath[suffix:]\n+\t\t\tif result.PathPair.HasSecondary() {\n+\t\t\t\tresult.PathPair.Secondary.IgnoredSuffix = importPath[suffix:]\n+\t\t\t}\n \t\t}\n \t}\n \n \t// If successful, resolve symlinks using the directory info cache\n \tr.finalizeResolve(result)\n-\treturn result\n+\treturn result, notes\n }\n \n func (r *resolver) isExternalPattern(path string) bool {\n@@ -388,7 +415,7 @@ func (r *resolver) finalizeResolve(result *ResolveResult) {\n \t}\n }\n \n-func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, kind ast.ImportKind) *ResolveResult {\n+func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, kind ast.ImportKind) (*ResolveResult, []logger.MsgData) {\n \t// This implements the module resolution algorithm from node.js, which is\n \t// described here: https://nodejs.org/api/modules.html#modules_all_together\n \tvar result ResolveResult\n@@ -406,7 +433,7 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \t\t// First, check path overrides from the nearest enclosing TypeScript \"tsconfig.json\" file\n \t\tif dirInfo := r.dirInfoCached(sourceDir); dirInfo != nil && dirInfo.tsConfigJSON != nil && dirInfo.tsConfigJSON.Paths != nil {\n \t\t\tif absolute, ok, diffCase := r.matchTSConfigPaths(dirInfo.tsConfigJSON, importPath, kind); ok {\n-\t\t\t\treturn &ResolveResult{PathPair: absolute, DifferentCase: diffCase}\n+\t\t\t\treturn &ResolveResult{PathPair: absolute, DifferentCase: diffCase}, nil\n \t\t\t}\n \t\t}\n \n@@ -415,14 +442,14 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \t\t\t// been marked as an external module, mark it as *not* an absolute path.\n \t\t\t// That way we preserve the literal text in the output and don't generate\n \t\t\t// a relative path from the output directory to that path.\n-\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: importPath}}, IsExternal: true}\n+\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: importPath}}, IsExternal: true}, nil\n \t\t}\n \n \t\t// Run node's resolution rules (e.g. adding \".js\")\n \t\tif absolute, ok, diffCase := r.loadAsFileOrDirectory(importPath, kind); ok {\n-\t\t\treturn &ResolveResult{PathPair: absolute, DifferentCase: diffCase}\n+\t\t\treturn &ResolveResult{PathPair: absolute, DifferentCase: diffCase}, nil\n \t\t}\n-\t\treturn nil\n+\t\treturn nil, nil\n \t}\n \n \t// Check both relative and package paths for CSS URL tokens, with relative\n@@ -436,7 +463,7 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \n \t\t// Check for external packages first\n \t\tif r.options.ExternalModules.AbsPaths != nil && r.options.ExternalModules.AbsPaths[absPath] {\n-\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: absPath, Namespace: \"file\"}}, IsExternal: true}\n+\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: absPath, Namespace: \"file\"}}, IsExternal: true}, nil\n \t\t}\n \n \t\t// Check the non-package \"browser\" map for the first time (1 out of 2)\n@@ -445,8 +472,8 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \t\t\tif packageJSON := importDirInfo.enclosingBrowserScope.packageJSON; packageJSON.browserNonPackageMap != nil {\n \t\t\t\tif remapped, ok := packageJSON.browserNonPackageMap[absPath]; ok {\n \t\t\t\t\tif remapped == nil {\n-\t\t\t\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: absPath, Namespace: \"file\", Flags: logger.PathDisabled}}}\n-\t\t\t\t\t} else if remappedResult, ok, diffCase := r.resolveWithoutRemapping(importDirInfo.enclosingBrowserScope, *remapped, kind); ok {\n+\t\t\t\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: absPath, Namespace: \"file\", Flags: logger.PathDisabled}}}, nil\n+\t\t\t\t\t} else if remappedResult, ok, diffCase, _ := r.resolveWithoutRemapping(importDirInfo.enclosingBrowserScope, *remapped, kind); ok {\n \t\t\t\t\t\tresult = ResolveResult{PathPair: remappedResult, DifferentCase: diffCase}\n \t\t\t\t\t\tcheckRelative = false\n \t\t\t\t\t\tcheckPackage = false\n@@ -460,7 +487,7 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \t\t\t\tcheckPackage = false\n \t\t\t\tresult = ResolveResult{PathPair: absolute, DifferentCase: diffCase}\n \t\t\t} else if !checkPackage {\n-\t\t\t\treturn nil\n+\t\t\t\treturn nil, nil\n \t\t\t}\n \t\t}\n \t}\n@@ -471,7 +498,7 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \t\t\tquery := importPath\n \t\t\tfor {\n \t\t\t\tif r.options.ExternalModules.NodeModules[query] {\n-\t\t\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: importPath}}, IsExternal: true}\n+\t\t\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: importPath}}, IsExternal: true}, nil\n \t\t\t\t}\n \n \t\t\t\t// If the module \"foo\" has been marked as external, we also want to treat\n@@ -487,7 +514,7 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \t\tsourceDirInfo := r.dirInfoCached(sourceDir)\n \t\tif sourceDirInfo == nil {\n \t\t\t// Bail if the directory is missing for some reason\n-\t\t\treturn nil\n+\t\t\treturn nil, nil\n \t\t}\n \n \t\t// Support remapping one package path to another via the \"browser\" field\n@@ -497,14 +524,14 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \t\t\t\tif remapped, ok := packageJSON.browserPackageMap[importPath]; ok {\n \t\t\t\t\tif remapped == nil {\n \t\t\t\t\t\t// \"browser\": {\"module\": false}\n-\t\t\t\t\t\tif absolute, ok, diffCase := r.loadNodeModules(importPath, kind, sourceDirInfo); ok {\n+\t\t\t\t\t\tif absolute, ok, diffCase, _ := r.loadNodeModules(importPath, kind, sourceDirInfo); ok {\n \t\t\t\t\t\t\tabsolute.Primary = logger.Path{Text: absolute.Primary.Text, Namespace: \"file\", Flags: logger.PathDisabled}\n \t\t\t\t\t\t\tif absolute.HasSecondary() {\n \t\t\t\t\t\t\t\tabsolute.Secondary = logger.Path{Text: absolute.Secondary.Text, Namespace: \"file\", Flags: logger.PathDisabled}\n \t\t\t\t\t\t\t}\n-\t\t\t\t\t\t\treturn &ResolveResult{PathPair: absolute, DifferentCase: diffCase}\n+\t\t\t\t\t\t\treturn &ResolveResult{PathPair: absolute, DifferentCase: diffCase}, nil\n \t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: importPath, Flags: logger.PathDisabled}}, DifferentCase: diffCase}\n+\t\t\t\t\t\t\treturn &ResolveResult{PathPair: PathPair{Primary: logger.Path{Text: importPath, Flags: logger.PathDisabled}}, DifferentCase: diffCase}, nil\n \t\t\t\t\t\t}\n \t\t\t\t\t} else {\n \t\t\t\t\t\t// \"browser\": {\"module\": \"./some-file\"}\n@@ -516,11 +543,11 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \t\t\t}\n \t\t}\n \n-\t\tif absolute, ok, diffCase := r.resolveWithoutRemapping(sourceDirInfo, importPath, kind); ok {\n+\t\tif absolute, ok, diffCase, notes := r.resolveWithoutRemapping(sourceDirInfo, importPath, kind); ok {\n \t\t\tresult = ResolveResult{PathPair: absolute, DifferentCase: diffCase}\n \t\t} else {\n \t\t\t// Note: node's \"self references\" are not currently supported\n-\t\t\treturn nil\n+\t\t\treturn nil, notes\n \t\t}\n \t}\n \n@@ -536,24 +563,25 @@ func (r *resolver) resolveWithoutSymlinks(sourceDir string, importPath string, k\n \t\t\t\tif remapped, ok := packageJSON.browserNonPackageMap[path.Text]; ok {\n \t\t\t\t\tif remapped == nil {\n \t\t\t\t\t\tpath.Flags |= logger.PathDisabled\n-\t\t\t\t\t} else if remappedResult, ok, _ := r.resolveWithoutRemapping(resultDirInfo.enclosingBrowserScope, *remapped, kind); ok {\n+\t\t\t\t\t} else if remappedResult, ok, _, _ := r.resolveWithoutRemapping(resultDirInfo.enclosingBrowserScope, *remapped, kind); ok {\n \t\t\t\t\t\t*path = remappedResult.Primary\n \t\t\t\t\t} else {\n-\t\t\t\t\t\treturn nil\n+\t\t\t\t\t\treturn nil, nil\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n \t\t}\n \t}\n \n-\treturn &result\n+\treturn &result, nil\n }\n \n-func (r *resolver) resolveWithoutRemapping(sourceDirInfo *dirInfo, importPath string, kind ast.ImportKind) (PathPair, bool, *fs.DifferentCase) {\n+func (r *resolver) resolveWithoutRemapping(sourceDirInfo *dirInfo, importPath string, kind ast.ImportKind) (PathPair, bool, *fs.DifferentCase, []logger.MsgData) {\n \tif IsPackagePath(importPath) {\n \t\treturn r.loadNodeModules(importPath, kind, sourceDirInfo)\n \t} else {\n-\t\treturn r.loadAsFileOrDirectory(r.fs.Join(sourceDirInfo.absPath, importPath), kind)\n+\t\tpair, ok, diffCase := r.loadAsFileOrDirectory(r.fs.Join(sourceDirInfo.absPath, importPath), kind)\n+\t\treturn pair, ok, diffCase, nil\n \t}\n }\n \n@@ -582,52 +610,6 @@ func (r *resolver) PrettyPath(path logger.Path) string {\n \n ////////////////////////////////////////////////////////////////////////////////\n \n-type packageJSON struct {\n-\tabsMainFields map[string]string\n-\n-\t// Present if the \"browser\" field is present. This field is intended to be\n-\t// used by bundlers and lets you redirect the paths of certain 3rd-party\n-\t// modules that don't work in the browser to other modules that shim that\n-\t// functionality. That way you don't have to rewrite the code for those 3rd-\n-\t// party modules. For example, you might remap the native \"util\" node module\n-\t// to something like https://www.npmjs.com/package/util so it works in the\n-\t// browser.\n-\t//\n-\t// This field contains a mapping of absolute paths to absolute paths. Mapping\n-\t// to an empty path indicates that the module is disabled. As far as I can\n-\t// tell, the official spec is a GitHub repo hosted by a user account:\n-\t// https://github.com/defunctzombie/package-browser-field-spec. The npm docs\n-\t// say almost nothing: https://docs.npmjs.com/files/package.json.\n-\t//\n-\t// Note that the non-package \"browser\" map has to be checked twice to match\n-\t// Webpack's behavior: once before resolution and once after resolution. It\n-\t// leads to some unintuitive failure cases that we must emulate around missing\n-\t// file extensions:\n-\t//\n-\t// * Given the mapping \"./no-ext\": \"./no-ext-browser.js\" the query \"./no-ext\"\n-\t//   should match but the query \"./no-ext.js\" should NOT match.\n-\t//\n-\t// * Given the mapping \"./ext.js\": \"./ext-browser.js\" the query \"./ext.js\"\n-\t//   should match and the query \"./ext\" should ALSO match.\n-\t//\n-\tbrowserNonPackageMap map[string]*string\n-\tbrowserPackageMap    map[string]*string\n-\n-\t// If this is non-nil, each entry in this map is the absolute path of a file\n-\t// with side effects. Any entry not in this map should be considered to have\n-\t// no side effects, which means import statements for these files can be\n-\t// removed if none of the imports are used. This is a convention from Webpack:\n-\t// https://webpack.js.org/guides/tree-shaking/.\n-\t//\n-\t// Note that if a file is included, all statements that can't be proven to be\n-\t// free of side effects must be included. This convention does not say\n-\t// anything about whether any statements within the file have side effects or\n-\t// not.\n-\tsideEffectsMap     map[string]bool\n-\tsideEffectsRegexps []*regexp.Regexp\n-\tignoreIfUnusedData *IgnoreIfUnusedData\n-}\n-\n type dirInfo struct {\n \t// These objects are immutable, so we can just point to the parent directory\n \t// and avoid having to lock the cache again\n@@ -891,201 +873,6 @@ func (r *resolver) dirInfoUncached(path string) *dirInfo {\n \treturn info\n }\n \n-func (r *resolver) parsePackageJSON(path string) *packageJSON {\n-\tpackageJsonPath := r.fs.Join(path, \"package.json\")\n-\tcontents, err := r.caches.FSCache.ReadFile(r.fs, packageJsonPath)\n-\tif err != nil {\n-\t\tr.log.AddError(nil, logger.Loc{},\n-\t\t\tfmt.Sprintf(\"Cannot read file %q: %s\",\n-\t\t\t\tr.PrettyPath(logger.Path{Text: packageJsonPath, Namespace: \"file\"}), err.Error()))\n-\t\treturn nil\n-\t}\n-\n-\tkeyPath := logger.Path{Text: packageJsonPath, Namespace: \"file\"}\n-\tjsonSource := logger.Source{\n-\t\tKeyPath:    keyPath,\n-\t\tPrettyPath: r.PrettyPath(keyPath),\n-\t\tContents:   contents,\n-\t}\n-\n-\tjson, ok := r.caches.JSONCache.Parse(r.log, jsonSource, js_parser.JSONOptions{})\n-\tif !ok {\n-\t\treturn nil\n-\t}\n-\n-\ttoAbsPath := func(pathText string, pathRange logger.Range) *string {\n-\t\t// Is it a file?\n-\t\tif absolute, ok, _ := r.loadAsFile(pathText, r.options.ExtensionOrder); ok {\n-\t\t\treturn &absolute\n-\t\t}\n-\n-\t\t// Is it a directory?\n-\t\tif mainEntries, err := r.fs.ReadDirectory(pathText); err == nil {\n-\t\t\t// Look for an \"index\" file with known extensions\n-\t\t\tif absolute, ok, _ := r.loadAsIndex(pathText, mainEntries); ok {\n-\t\t\t\treturn &absolute\n-\t\t\t}\n-\t\t} else if err != syscall.ENOENT {\n-\t\t\tr.log.AddRangeError(&jsonSource, pathRange,\n-\t\t\t\tfmt.Sprintf(\"Cannot read directory %q: %s\",\n-\t\t\t\t\tr.PrettyPath(logger.Path{Text: pathText, Namespace: \"file\"}), err.Error()))\n-\t\t}\n-\t\treturn nil\n-\t}\n-\n-\tpackageJSON := &packageJSON{}\n-\n-\t// Read the \"main\" fields\n-\tmainFields := r.options.MainFields\n-\tif mainFields == nil {\n-\t\tmainFields = defaultMainFields[r.options.Platform]\n-\t}\n-\tfor _, field := range mainFields {\n-\t\tif mainJson, _, ok := getProperty(json, field); ok {\n-\t\t\tif main, ok := getString(mainJson); ok {\n-\t\t\t\tif packageJSON.absMainFields == nil {\n-\t\t\t\t\tpackageJSON.absMainFields = make(map[string]string)\n-\t\t\t\t}\n-\t\t\t\tif absPath := toAbsPath(r.fs.Join(path, main), jsonSource.RangeOfString(mainJson.Loc)); absPath != nil {\n-\t\t\t\t\tpackageJSON.absMainFields[field] = *absPath\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\t// Read the \"browser\" property, but only when targeting the browser\n-\tif browserJson, _, ok := getProperty(json, \"browser\"); ok && r.options.Platform == config.PlatformBrowser {\n-\t\t// We both want the ability to have the option of CJS vs. ESM and the\n-\t\t// option of having node vs. browser. The way to do this is to use the\n-\t\t// object literal form of the \"browser\" field like this:\n-\t\t//\n-\t\t//   \"main\": \"dist/index.node.cjs.js\",\n-\t\t//   \"module\": \"dist/index.node.esm.js\",\n-\t\t//   \"browser\": {\n-\t\t//     \"./dist/index.node.cjs.js\": \"./dist/index.browser.cjs.js\",\n-\t\t//     \"./dist/index.node.esm.js\": \"./dist/index.browser.esm.js\"\n-\t\t//   },\n-\t\t//\n-\t\tif browser, ok := browserJson.Data.(*js_ast.EObject); ok {\n-\t\t\t// The value is an object\n-\t\t\tbrowserPackageMap := make(map[string]*string)\n-\t\t\tbrowserNonPackageMap := make(map[string]*string)\n-\n-\t\t\t// Remap all files in the browser field\n-\t\t\tfor _, prop := range browser.Properties {\n-\t\t\t\tif key, ok := getString(prop.Key); ok && prop.Value != nil {\n-\t\t\t\t\tisPackagePath := IsPackagePath(key)\n-\n-\t\t\t\t\t// Make this an absolute path if it's not a package\n-\t\t\t\t\tif !isPackagePath {\n-\t\t\t\t\t\tkey = r.fs.Join(path, key)\n-\t\t\t\t\t}\n-\n-\t\t\t\t\tif value, ok := getString(*prop.Value); ok {\n-\t\t\t\t\t\t// If this is a string, it's a replacement package\n-\t\t\t\t\t\tif isPackagePath {\n-\t\t\t\t\t\t\tbrowserPackageMap[key] = &value\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tbrowserNonPackageMap[key] = &value\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else if value, ok := getBool(*prop.Value); ok && !value {\n-\t\t\t\t\t\t// If this is false, it means the package is disabled\n-\t\t\t\t\t\tif isPackagePath {\n-\t\t\t\t\t\t\tbrowserPackageMap[key] = nil\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tbrowserNonPackageMap[key] = nil\n-\t\t\t\t\t\t}\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\tpackageJSON.browserPackageMap = browserPackageMap\n-\t\t\tpackageJSON.browserNonPackageMap = browserNonPackageMap\n-\t\t}\n-\t}\n-\n-\t// Read the \"sideEffects\" property\n-\tif sideEffectsJson, sideEffectsLoc, ok := getProperty(json, \"sideEffects\"); ok {\n-\t\tswitch data := sideEffectsJson.Data.(type) {\n-\t\tcase *js_ast.EBoolean:\n-\t\t\tif !data.Value {\n-\t\t\t\t// Make an empty map for \"sideEffects: false\", which indicates all\n-\t\t\t\t// files in this module can be considered to not have side effects.\n-\t\t\t\tpackageJSON.sideEffectsMap = make(map[string]bool)\n-\t\t\t\tpackageJSON.ignoreIfUnusedData = &IgnoreIfUnusedData{\n-\t\t\t\t\tIsSideEffectsArrayInJSON: false,\n-\t\t\t\t\tSource:                   &jsonSource,\n-\t\t\t\t\tRange:                    jsonSource.RangeOfString(sideEffectsLoc),\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\tcase *js_ast.EArray:\n-\t\t\t// The \"sideEffects: []\" format means all files in this module but not in\n-\t\t\t// the array can be considered to not have side effects.\n-\t\t\tpackageJSON.sideEffectsMap = make(map[string]bool)\n-\t\t\tpackageJSON.ignoreIfUnusedData = &IgnoreIfUnusedData{\n-\t\t\t\tIsSideEffectsArrayInJSON: true,\n-\t\t\t\tSource:                   &jsonSource,\n-\t\t\t\tRange:                    jsonSource.RangeOfString(sideEffectsLoc),\n-\t\t\t}\n-\t\t\tfor _, itemJson := range data.Items {\n-\t\t\t\titem, ok := itemJson.Data.(*js_ast.EString)\n-\t\t\t\tif !ok || item.Value == nil {\n-\t\t\t\t\tr.log.AddWarning(&jsonSource, itemJson.Loc,\n-\t\t\t\t\t\t\"Expected string in array for \\\"sideEffects\\\"\")\n-\t\t\t\t\tcontinue\n-\t\t\t\t}\n-\n-\t\t\t\tabsPattern := r.fs.Join(path, js_lexer.UTF16ToString(item.Value))\n-\t\t\t\tre, hadWildcard := globToEscapedRegexp(absPattern)\n-\n-\t\t\t\t// Wildcard patterns require more expensive matching\n-\t\t\t\tif hadWildcard {\n-\t\t\t\t\tpackageJSON.sideEffectsRegexps = append(packageJSON.sideEffectsRegexps, regexp.MustCompile(re))\n-\t\t\t\t\tcontinue\n-\t\t\t\t}\n-\n-\t\t\t\t// Normal strings can be matched with a map lookup\n-\t\t\t\tpackageJSON.sideEffectsMap[absPattern] = true\n-\t\t\t}\n-\n-\t\tdefault:\n-\t\t\tr.log.AddWarning(&jsonSource, sideEffectsJson.Loc,\n-\t\t\t\t\"The value for \\\"sideEffects\\\" must be a boolean or an array\")\n-\t\t}\n-\t}\n-\n-\treturn packageJSON\n-}\n-\n-func globToEscapedRegexp(glob string) (string, bool) {\n-\tsb := strings.Builder{}\n-\tsb.WriteByte('^')\n-\thadWildcard := false\n-\n-\tfor _, c := range glob {\n-\t\tswitch c {\n-\t\tcase '\\\\', '^', '$', '.', '+', '|', '(', ')', '[', ']', '{', '}':\n-\t\t\tsb.WriteByte('\\\\')\n-\t\t\tsb.WriteRune(c)\n-\n-\t\tcase '*':\n-\t\t\tsb.WriteString(\".*\")\n-\t\t\thadWildcard = true\n-\n-\t\tcase '?':\n-\t\t\tsb.WriteByte('.')\n-\t\t\thadWildcard = true\n-\n-\t\tdefault:\n-\t\t\tsb.WriteRune(c)\n-\t\t}\n-\t}\n-\n-\tsb.WriteByte('$')\n-\treturn sb.String(), hadWildcard\n-}\n-\n func (r *resolver) loadAsFile(path string, extensionOrder []string) (string, bool, *fs.DifferentCase) {\n \t// Read the directory entries once to minimize locking\n \tdirPath := r.fs.Dir(path)\n@@ -1348,21 +1135,21 @@ func (r *resolver) matchTSConfigPaths(tsConfigJSON *TSConfigJSON, path string, k\n \treturn PathPair{}, false, nil\n }\n \n-func (r *resolver) loadNodeModules(path string, kind ast.ImportKind, dirInfo *dirInfo) (PathPair, bool, *fs.DifferentCase) {\n+func (r *resolver) loadNodeModules(path string, kind ast.ImportKind, dirInfo *dirInfo) (PathPair, bool, *fs.DifferentCase, []logger.MsgData) {\n \t// First, check path overrides from the nearest enclosing TypeScript \"tsconfig.json\" file\n \tif dirInfo.tsConfigJSON != nil {\n \t\t// Try path substitutions first\n \t\tif dirInfo.tsConfigJSON.Paths != nil {\n \t\t\tif absolute, ok, diffCase := r.matchTSConfigPaths(dirInfo.tsConfigJSON, path, kind); ok {\n-\t\t\t\treturn absolute, true, diffCase\n+\t\t\t\treturn absolute, true, diffCase, nil\n \t\t\t}\n \t\t}\n \n \t\t// Try looking up the path relative to the base URL\n \t\tif dirInfo.tsConfigJSON.BaseURL != nil {\n \t\t\tbasePath := r.fs.Join(*dirInfo.tsConfigJSON.BaseURL, path)\n \t\t\tif absolute, ok, diffCase := r.loadAsFileOrDirectory(basePath, kind); ok {\n-\t\t\t\treturn absolute, true, diffCase\n+\t\t\t\treturn absolute, true, diffCase, nil\n \t\t\t}\n \t\t}\n \t}\n@@ -1371,33 +1158,115 @@ func (r *resolver) loadNodeModules(path string, kind ast.ImportKind, dirInfo *di\n \tfor _, absDir := range r.options.AbsNodePaths {\n \t\tabsPath := r.fs.Join(absDir, path)\n \t\tif absolute, ok, diffCase := r.loadAsFileOrDirectory(absPath, kind); ok {\n-\t\t\treturn absolute, true, diffCase\n+\t\t\treturn absolute, true, diffCase, nil\n \t\t}\n \t}\n \n+\tesmPackageName, esmPackageSubpath, esmOK := esmParsePackageName(path)\n+\n \t// Then check for the package in any enclosing \"node_modules\" directories\n \tfor {\n \t\t// Skip directories that are themselves called \"node_modules\", since we\n \t\t// don't ever want to search for \"node_modules/node_modules\"\n \t\tif dirInfo.hasNodeModules {\n \t\t\tabsPath := r.fs.Join(dirInfo.absPath, \"node_modules\", path)\n \n+\t\t\t// Check for an \"exports\" map in the package's package.json folder\n+\t\t\tif esmOK {\n+\t\t\t\tabsPkgPath := r.fs.Join(dirInfo.absPath, \"node_modules\", esmPackageName)\n+\t\t\t\tif pkgDirInfo := r.dirInfoCached(absPkgPath); pkgDirInfo != nil {\n+\t\t\t\t\tif pkgJSON := pkgDirInfo.packageJSON; pkgJSON != nil && pkgJSON.exportsMap != nil {\n+\t\t\t\t\t\t// The condition set is determined by the kind of import\n+\t\t\t\t\t\tconditions := r.esmConditionsDefault\n+\t\t\t\t\t\tswitch kind {\n+\t\t\t\t\t\tcase ast.ImportStmt, ast.ImportDynamic:\n+\t\t\t\t\t\t\tconditions = r.esmConditionsImport\n+\t\t\t\t\t\tcase ast.ImportRequire, ast.ImportRequireResolve:\n+\t\t\t\t\t\t\tconditions = r.esmConditionsRequire\n+\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t// Resolve against the path \"/\", then join it with the absolute\n+\t\t\t\t\t\t// directory path. This is done because ESM package resolution uses\n+\t\t\t\t\t\t// URLs while our path resolution uses file system paths. We don't\n+\t\t\t\t\t\t// want problems due to Windows paths, which are very unlike URL\n+\t\t\t\t\t\t// paths. We also want to avoid any \"%\" characters in the absolute\n+\t\t\t\t\t\t// directory path accidentally being interpreted as URL escapes.\n+\t\t\t\t\t\tresolvedPath, status, token := esmPackageExportsResolveWithPostConditions(\"/\", esmPackageSubpath, pkgJSON.exportsMap.root, conditions)\n+\t\t\t\t\t\tif status == peStatusOk && strings.HasPrefix(resolvedPath, \"/\") {\n+\t\t\t\t\t\t\tabsResolvedPath := r.fs.Join(absPkgPath, resolvedPath[1:])\n+\t\t\t\t\t\t\tresolvedDirInfo := r.dirInfoCached(r.fs.Dir(absResolvedPath))\n+\t\t\t\t\t\t\tif resolvedDirInfo == nil {\n+\t\t\t\t\t\t\t\tstatus = peStatusModuleNotFound\n+\t\t\t\t\t\t\t} else if entry, diffCase := resolvedDirInfo.entries.Get(r.fs.Base(absResolvedPath)); entry == nil {\n+\t\t\t\t\t\t\t\tstatus = peStatusModuleNotFound\n+\t\t\t\t\t\t\t} else if kind := entry.Kind(r.fs); kind == fs.DirEntry {\n+\t\t\t\t\t\t\t\tstatus = peStatusUnsupportedDirectoryImport\n+\t\t\t\t\t\t\t} else if kind != fs.FileEntry {\n+\t\t\t\t\t\t\t\tstatus = peStatusModuleNotFound\n+\t\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t\treturn PathPair{Primary: logger.Path{Text: absResolvedPath, Namespace: \"file\"}}, true, diffCase, nil\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\tvar notes []logger.MsgData\n+\t\t\t\t\t\tif strings.HasPrefix(resolvedPath, \"/\") {\n+\t\t\t\t\t\t\tresolvedPath = \".\" + resolvedPath\n+\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t// Provide additional details about the failure to help with debugging\n+\t\t\t\t\t\tswitch status {\n+\t\t\t\t\t\tcase peStatusInvalidModuleSpecifier:\n+\t\t\t\t\t\t\tnotes = []logger.MsgData{logger.RangeData(&pkgJSON.source, token,\n+\t\t\t\t\t\t\t\tfmt.Sprintf(\"The module specifier %q is invalid\", resolvedPath))}\n+\n+\t\t\t\t\t\tcase peStatusInvalidPackageConfiguration:\n+\t\t\t\t\t\t\tnotes = []logger.MsgData{logger.RangeData(&pkgJSON.source, token,\n+\t\t\t\t\t\t\t\t\"The package configuration has an invalid value here\")}\n+\n+\t\t\t\t\t\tcase peStatusInvalidPackageTarget:\n+\t\t\t\t\t\t\twhy := fmt.Sprintf(\"The package target %q is invalid\", resolvedPath)\n+\t\t\t\t\t\t\tif resolvedPath == \"\" {\n+\t\t\t\t\t\t\t\t// \"PACKAGE_TARGET_RESOLVE\" is specified to throw an \"Invalid\n+\t\t\t\t\t\t\t\t// Package Target\" error for what is actually an invalid package\n+\t\t\t\t\t\t\t\t// configuration error\n+\t\t\t\t\t\t\t\twhy = \"The package configuration has an invalid value here\"\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\tnotes = []logger.MsgData{logger.RangeData(&pkgJSON.source, token, why)}\n+\n+\t\t\t\t\t\tcase peStatusPackagePathNotExported:\n+\t\t\t\t\t\t\tnotes = []logger.MsgData{logger.RangeData(&pkgJSON.source, token,\n+\t\t\t\t\t\t\t\tfmt.Sprintf(\"The path %q is not exported by %q\", esmPackageSubpath, esmPackageName))}\n+\n+\t\t\t\t\t\tcase peStatusModuleNotFound:\n+\t\t\t\t\t\t\tnotes = []logger.MsgData{logger.RangeData(&pkgJSON.source, token,\n+\t\t\t\t\t\t\t\tfmt.Sprintf(\"The module %q was not found\", resolvedPath))}\n+\n+\t\t\t\t\t\tcase peStatusUnsupportedDirectoryImport:\n+\t\t\t\t\t\t\tnotes = []logger.MsgData{logger.RangeData(&pkgJSON.source, token,\n+\t\t\t\t\t\t\t\tfmt.Sprintf(\"Importing the directory %q is not supported\", resolvedPath))}\n+\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\treturn PathPair{}, false, nil, notes\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n \t\t\t// Check the non-package \"browser\" map for the first time (1 out of 2)\n \t\t\timportDirInfo := r.dirInfoCached(r.fs.Dir(absPath))\n \t\t\tif importDirInfo != nil && importDirInfo.enclosingBrowserScope != nil {\n \t\t\t\tif packageJSON := importDirInfo.enclosingBrowserScope.packageJSON; packageJSON.browserNonPackageMap != nil {\n \t\t\t\t\tif remapped, ok := packageJSON.browserNonPackageMap[absPath]; ok {\n \t\t\t\t\t\tif remapped == nil {\n-\t\t\t\t\t\t\treturn PathPair{Primary: logger.Path{Text: absPath, Namespace: \"file\", Flags: logger.PathDisabled}}, true, nil\n-\t\t\t\t\t\t} else if remappedResult, ok, diffCase := r.resolveWithoutRemapping(importDirInfo.enclosingBrowserScope, *remapped, kind); ok {\n-\t\t\t\t\t\t\treturn remappedResult, true, diffCase\n+\t\t\t\t\t\t\treturn PathPair{Primary: logger.Path{Text: absPath, Namespace: \"file\", Flags: logger.PathDisabled}}, true, nil, nil\n+\t\t\t\t\t\t} else if remappedResult, ok, diffCase, notes := r.resolveWithoutRemapping(importDirInfo.enclosingBrowserScope, *remapped, kind); ok {\n+\t\t\t\t\t\t\treturn remappedResult, true, diffCase, notes\n \t\t\t\t\t\t}\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n \n \t\t\tif absolute, ok, diffCase := r.loadAsFileOrDirectory(absPath, kind); ok {\n-\t\t\t\treturn absolute, true, diffCase\n+\t\t\t\treturn absolute, true, diffCase, nil\n \t\t\t}\n \t\t}\n \n@@ -1408,7 +1277,7 @@ func (r *resolver) loadNodeModules(path string, kind ast.ImportKind, dirInfo *di\n \t\t}\n \t}\n \n-\treturn PathPair{}, false, nil\n+\treturn PathPair{}, false, nil, nil\n }\n \n // Package paths are loaded from a \"node_modules\" directory. Non-package paths"},{"sha":"4b62c16194c2269ddf0791d3bfcec7ac979fc1be","filename":"lib/browser.ts","status":"modified","additions":33,"deletions":27,"changes":60,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Fbrowser.ts","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Fbrowser.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Fbrowser.ts?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -6,17 +6,15 @@ declare let WEB_WORKER_SOURCE_CODE: string\n \n export let version = ESBUILD_VERSION;\n \n-export const build: typeof types.build = () => {\n-  throw new Error(`The \"build\" API only works in node`);\n-};\n+export let build: typeof types.build = (options: types.BuildOptions): Promise<any> =>\n+  ensureServiceIsRunning().build(options);\n \n export const serve: typeof types.serve = () => {\n   throw new Error(`The \"serve\" API only works in node`);\n };\n \n-export const transform: typeof types.transform = () => {\n-  throw new Error(`The \"transform\" API only works in node`);\n-};\n+export const transform: typeof types.transform = (input, options) =>\n+  ensureServiceIsRunning().transform(input, options);\n \n export const buildSync: typeof types.buildSync = () => {\n   throw new Error(`The \"buildSync\" API only works in node`);\n@@ -26,13 +24,36 @@ export const transformSync: typeof types.transformSync = () => {\n   throw new Error(`The \"transformSync\" API only works in node`);\n };\n \n-export const startService: typeof types.startService = common.longLivedService(() => '', async (options) => {\n-  if (!options) throw new Error('Must provide an options object to \"startService\"');\n-  options = common.validateServiceOptions(options)!;\n+interface Service {\n+  build: typeof types.build;\n+  transform: typeof types.transform;\n+}\n+\n+let initializePromise: Promise<void> | undefined;\n+let longLivedService: Service | undefined;\n+\n+let ensureServiceIsRunning = (): Service => {\n+  if (longLivedService) return longLivedService;\n+  if (initializePromise) throw new Error('You need to wait for the promise returned from \"initialize\" to be resolved before calling this');\n+  throw new Error('You need to call \"initialize\" before calling this');\n+}\n+\n+export const initialize: typeof types.initialize = options => {\n+  options = common.validateInitializeOptions(options || {});\n   let wasmURL = options.wasmURL;\n   let useWorker = options.worker !== false;\n   if (!wasmURL) throw new Error('Must provide the \"wasmURL\" option');\n   wasmURL += '';\n+  if (initializePromise) throw new Error('Cannot call \"initialize\" more than once');\n+  initializePromise = startRunningService(wasmURL, useWorker);\n+  initializePromise.catch(() => {\n+    // Let the caller try again if this fails\n+    initializePromise = void 0;\n+  });\n+  return initializePromise;\n+}\n+\n+const startRunningService = async (wasmURL: string, useWorker: boolean): Promise<void> => {\n   let res = await fetch(wasmURL);\n   if (!res.ok) throw new Error(`Failed to download ${JSON.stringify(wasmURL)}`);\n   let wasm = await res.arrayBuffer();\n@@ -69,40 +90,25 @@ export const startService: typeof types.startService = common.longLivedService((\n   worker.postMessage(wasm)\n   worker.onmessage = ({ data }) => readFromStdout(data)\n \n-  let { readFromStdout, afterClose, service } = common.createChannel({\n+  let { readFromStdout, service } = common.createChannel({\n     writeToStdin(bytes) {\n       worker.postMessage(bytes)\n     },\n     isSync: false,\n     isBrowser: true,\n   })\n \n-  return {\n+  longLivedService = {\n     build: (options: types.BuildOptions): Promise<any> =>\n       new Promise<types.BuildResult>((resolve, reject) =>\n         service.buildOrServe('build', null, null, options, false, '/', (err, res) =>\n           err ? reject(err) : resolve(res as types.BuildResult))),\n     transform: (input, options) => {\n-      input += '';\n       return new Promise((resolve, reject) =>\n         service.transform('transform', null, input, options || {}, false, {\n           readFile(_, callback) { callback(new Error('Internal error'), null); },\n           writeFile(_, callback) { callback(null); },\n         }, (err, res) => err ? reject(err) : resolve(res!)))\n     },\n-    serve() {\n-      throw new Error(`The \"serve\" API only works in node`)\n-    },\n-    buildSync() {\n-      throw new Error(`The \"buildSync\" API only works in node`);\n-    },\n-    transformSync() {\n-      throw new Error(`The \"transformSync\" API only works in node`);\n-    },\n-    stop() {\n-      // Note: This is now never called\n-      worker.terminate()\n-      afterClose()\n-    },\n   }\n-});\n+}"},{"sha":"a1f67adf54a47c4b189987269895bbae22a70485","filename":"lib/common.ts","status":"modified","additions":38,"deletions":84,"changes":122,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Fcommon.ts","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Fcommon.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Fcommon.ts?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -69,7 +69,7 @@ function checkForInvalidFlags(object: Object, keys: OptionKeys, where: string):\n   }\n }\n \n-export function validateServiceOptions(options: types.ServiceOptions): types.ServiceOptions {\n+export function validateInitializeOptions(options: types.InitializeOptions): types.InitializeOptions {\n   let keys: OptionKeys = Object.create(null);\n   let wasmURL = getFlag(options, keys, 'wasmURL', mustBeString);\n   let worker = getFlag(options, keys, 'worker', mustBeBoolean);\n@@ -85,12 +85,12 @@ type CommonOptions = types.BuildOptions | types.TransformOptions;\n function pushLogFlags(flags: string[], options: CommonOptions, keys: OptionKeys, isTTY: boolean, logLevelDefault: types.LogLevel): void {\n   let color = getFlag(options, keys, 'color', mustBeBoolean);\n   let logLevel = getFlag(options, keys, 'logLevel', mustBeString);\n-  let errorLimit = getFlag(options, keys, 'errorLimit', mustBeInteger);\n+  let logLimit = getFlag(options, keys, 'logLimit', mustBeInteger);\n \n   if (color) flags.push(`--color=${color}`);\n   else if (isTTY) flags.push(`--color=true`); // This is needed to fix \"execFileSync\" which buffers stderr\n   flags.push(`--log-level=${logLevel || logLevelDefault}`);\n-  flags.push(`--error-limit=${errorLimit || 0}`);\n+  flags.push(`--log-limit=${logLimit || 0}`);\n }\n \n function pushCommonFlags(flags: string[], options: CommonOptions, keys: OptionKeys): void {\n@@ -108,10 +108,7 @@ function pushCommonFlags(flags: string[], options: CommonOptions, keys: OptionKe\n   let jsxFragment = getFlag(options, keys, 'jsxFragment', mustBeString);\n   let define = getFlag(options, keys, 'define', mustBeObject);\n   let pure = getFlag(options, keys, 'pure', mustBeArray);\n-  let avoidTDZ = getFlag(options, keys, 'avoidTDZ', mustBeBoolean);\n   let keepNames = getFlag(options, keys, 'keepNames', mustBeBoolean);\n-  let banner = getFlag(options, keys, 'banner', mustBeString);\n-  let footer = getFlag(options, keys, 'footer', mustBeString);\n \n   if (sourcesContent !== void 0) flags.push(`--sources-content=${sourcesContent}`);\n   if (target) {\n@@ -137,11 +134,7 @@ function pushCommonFlags(flags: string[], options: CommonOptions, keys: OptionKe\n     }\n   }\n   if (pure) for (let fn of pure) flags.push(`--pure:${fn}`);\n-  if (avoidTDZ) flags.push(`--avoid-tdz`);\n   if (keepNames) flags.push(`--keep-names`);\n-\n-  if (banner) flags.push(`--banner=${banner}`);\n-  if (footer) flags.push(`--footer=${footer}`);\n }\n \n function flagsForBuildOptions(\n@@ -174,7 +167,7 @@ function flagsForBuildOptions(\n   let watch = getFlag(options, keys, 'watch', mustBeBooleanOrObject);\n   let splitting = getFlag(options, keys, 'splitting', mustBeBoolean);\n   let preserveSymlinks = getFlag(options, keys, 'preserveSymlinks', mustBeBoolean);\n-  let metafile = getFlag(options, keys, 'metafile', mustBeString);\n+  let metafile = getFlag(options, keys, 'metafile', mustBeBoolean);\n   let outfile = getFlag(options, keys, 'outfile', mustBeString);\n   let outdir = getFlag(options, keys, 'outdir', mustBeString);\n   let outbase = getFlag(options, keys, 'outbase', mustBeString);\n@@ -183,13 +176,16 @@ function flagsForBuildOptions(\n   let resolveExtensions = getFlag(options, keys, 'resolveExtensions', mustBeArray);\n   let nodePathsInput = getFlag(options, keys, 'nodePaths', mustBeArray);\n   let mainFields = getFlag(options, keys, 'mainFields', mustBeArray);\n+  let conditions = getFlag(options, keys, 'conditions', mustBeArray);\n   let external = getFlag(options, keys, 'external', mustBeArray);\n   let loader = getFlag(options, keys, 'loader', mustBeObject);\n   let outExtension = getFlag(options, keys, 'outExtension', mustBeObject);\n   let publicPath = getFlag(options, keys, 'publicPath', mustBeString);\n   let chunkNames = getFlag(options, keys, 'chunkNames', mustBeString);\n   let assetNames = getFlag(options, keys, 'assetNames', mustBeString);\n   let inject = getFlag(options, keys, 'inject', mustBeArray);\n+  let banner = getFlag(options, keys, 'banner', mustBeObject);\n+  let footer = getFlag(options, keys, 'footer', mustBeObject);\n   let entryPoints = getFlag(options, keys, 'entryPoints', mustBeArray);\n   let absWorkingDir = getFlag(options, keys, 'absWorkingDir', mustBeString);\n   let stdin = getFlag(options, keys, 'stdin', mustBeObject);\n@@ -213,7 +209,7 @@ function flagsForBuildOptions(\n   }\n   if (splitting) flags.push('--splitting');\n   if (preserveSymlinks) flags.push('--preserve-symlinks');\n-  if (metafile) flags.push(`--metafile=${metafile}`);\n+  if (metafile) flags.push(`--metafile`);\n   if (outfile) flags.push(`--outfile=${outfile}`);\n   if (outdir) flags.push(`--outdir=${outdir}`);\n   if (outbase) flags.push(`--outbase=${outbase}`);\n@@ -240,7 +236,28 @@ function flagsForBuildOptions(\n     }\n     flags.push(`--main-fields=${values.join(',')}`);\n   }\n+  if (conditions) {\n+    let values: string[] = [];\n+    for (let value of conditions) {\n+      value += '';\n+      if (value.indexOf(',') >= 0) throw new Error(`Invalid condition: ${value}`);\n+      values.push(value);\n+    }\n+    flags.push(`--conditions=${values.join(',')}`);\n+  }\n   if (external) for (let name of external) flags.push(`--external:${name}`);\n+  if (banner) {\n+    for (let type in banner) {\n+      if (type.indexOf('=') >= 0) throw new Error(`Invalid banner file type: ${type}`);\n+      flags.push(`--banner:${type}=${banner[type]}`);\n+    }\n+  }\n+  if (footer) {\n+    for (let type in footer) {\n+      if (type.indexOf('=') >= 0) throw new Error(`Invalid footer file type: ${type}`);\n+      flags.push(`--footer:${type}=${footer[type]}`);\n+    }\n+  }\n   if (inject) for (let path of inject) flags.push(`--inject:${path}`);\n   if (loader) {\n     for (let ext in loader) {\n@@ -313,12 +330,16 @@ function flagsForTransformOptions(\n   let tsconfigRaw = getFlag(options, keys, 'tsconfigRaw', mustBeStringOrObject);\n   let sourcefile = getFlag(options, keys, 'sourcefile', mustBeString);\n   let loader = getFlag(options, keys, 'loader', mustBeString);\n+  let banner = getFlag(options, keys, 'banner', mustBeString);\n+  let footer = getFlag(options, keys, 'footer', mustBeString);\n   checkForInvalidFlags(options, keys, `in ${callName}() call`);\n \n   if (sourcemap) flags.push(`--sourcemap=${sourcemap === true ? 'external' : sourcemap}`);\n   if (tsconfigRaw) flags.push(`--tsconfig-raw=${typeof tsconfigRaw === 'string' ? tsconfigRaw : JSON.stringify(tsconfigRaw)}`);\n   if (sourcefile) flags.push(`--sourcefile=${sourcefile}`);\n   if (loader) flags.push(`--loader=${loader}`);\n+  if (banner) flags.push(`--banner=${banner}`);\n+  if (footer) flags.push(`--footer=${footer}`);\n \n   return flags;\n }\n@@ -774,7 +795,7 @@ export function createChannel(streamIn: StreamIn): StreamOut {\n       buildOrServe(callName, callerRefs, serveOptions, options, isTTY, defaultWD, callback) {\n         let pluginRefs: Refs | undefined;\n         const details = createObjectStash();\n-        const logLevelDefault = 'info';\n+        const logLevelDefault = 'warning';\n         const refs = {\n           ref() {\n             if (pluginRefs) pluginRefs.ref()\n@@ -826,6 +847,8 @@ export function createChannel(streamIn: StreamIn): StreamOut {\n             if (errors.length > 0) return callback(failureErrorWithLog('Build failed', errors, warnings), null);\n             let result: types.BuildResult = { warnings };\n             if (response!.outputFiles) result.outputFiles = response!.outputFiles.map(convertOutputFiles);\n+            if (response!.metafile) result.metafile = JSON.parse(response!.metafile);\n+            if (response!.writeToStdout !== void 0) console.log(protocol.decodeUTF8(response!.writeToStdout).replace(/\\n$/, ''));\n \n             // Handle incremental rebuilds\n             if (response!.rebuildID !== void 0) {\n@@ -955,6 +978,7 @@ export function createChannel(streamIn: StreamIn): StreamOut {\n         // that doesn't work.\n         let start = (inputPath: string | null) => {\n           try {\n+            if (typeof input !== 'string') throw new Error('The input to \"transform\" must be a string');\n             let flags = flagsForTransformOptions(callName, options, isTTY, logLevelDefault);\n             let request: protocol.TransformRequest = {\n               command: 'transform',\n@@ -1008,7 +1032,7 @@ export function createChannel(streamIn: StreamIn): StreamOut {\n             });\n           }\n         };\n-        if (input.length > 1024 * 1024) {\n+        if (typeof input === 'string' && input.length > 1024 * 1024) {\n           let next = start;\n           start = () => fs.writeFile(input, next);\n         }\n@@ -1216,73 +1240,3 @@ function convertOutputFiles({ path, contents }: protocol.BuildOutputFile): types\n     },\n   }\n }\n-\n-// This function serves two purposes:\n-//\n-//   a) Only create one long-lived service for each unique value of \"options\".\n-//      This is useful because creating a service is expensive and it's\n-//      sometimes convenient for multiple independent libraries to create\n-//      esbuild services without coordinating with each other. This pooling\n-//      optimization makes this use case efficient.\n-//\n-//   b) Set the default working directory to the value of the current working\n-//      directory at the time \"startService()\" was called. This means each call\n-//      to \"startService()\" can potentially have a different default working\n-//      directory.\n-//\n-//      TODO: This is legacy behavior that originated because \"startService()\"\n-//      used to correspond to creating a new child process. That is no longer\n-//      the case because child processes are now pooled. This behavior is\n-//      being preserved for compatibility with Snowpack for now. I would like\n-//      to remove this strange behavior in a future release now that we have\n-//      the \"absWorkingDir\" API option.\n-//\n-export function longLivedService(getwd: () => string, startService: typeof types.startService): typeof types.startService {\n-  let entries = new Map<string, Promise<types.Service>>();\n-  return async (options) => {\n-    let cwd = getwd();\n-    let optionsJSON = JSON.stringify(options || {});\n-    let key = optionsJSON;\n-    let entry = entries.get(key);\n-\n-    if (entry === void 0) {\n-      // Store the promise used to create the service so that multiple\n-      // concurrent calls to \"startService()\" will share the same promise.\n-      entry = startService(JSON.parse(optionsJSON));\n-      entries.set(key, entry);\n-    }\n-\n-    try {\n-      let service = await entry;\n-      return {\n-        build: (options: any = {}): any => {\n-          if (cwd) {\n-            let absWorkingDir = options.absWorkingDir\n-            if (!absWorkingDir) options = { ...options, absWorkingDir: cwd }\n-          }\n-          return service.build(options);\n-        },\n-        serve(serveOptions, buildOptions: any = {}) {\n-          if (cwd) {\n-            let absWorkingDir = buildOptions.absWorkingDir\n-            if (!absWorkingDir) buildOptions = { ...buildOptions, absWorkingDir: cwd }\n-          }\n-          return service.serve(serveOptions, buildOptions);\n-        },\n-        transform(input, options) {\n-          return service.transform(input, options);\n-        },\n-        stop() {\n-          // This is now a no-op\n-        },\n-      };\n-    }\n-\n-    catch (e) {\n-      // Remove the entry if loading fails, which allows\n-      // us to try again (only happens in the browser)\n-      entries.delete(key);\n-      throw e;\n-    }\n-  };\n-}"},{"sha":"f765353106dbaa1ceee78d92d416bdd4ead6ecff","filename":"lib/node.ts","status":"modified","additions":31,"deletions":22,"changes":53,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Fnode.ts","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Fnode.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Fnode.ts?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -61,18 +61,13 @@ let isTTY = () => tty.isatty(2);\n export let version = ESBUILD_VERSION;\n \n export let build: typeof types.build = (options: types.BuildOptions): Promise<any> =>\n-  startService().then<types.BuildResult>(service =>\n-    service.build(options));\n+  ensureServiceIsRunning().build(options);\n \n export let serve: typeof types.serve = (serveOptions, buildOptions) =>\n-  startService().then(service =>\n-    service.serve(serveOptions, buildOptions));\n+  ensureServiceIsRunning().serve(serveOptions, buildOptions);\n \n-export let transform: typeof types.transform = (input, options) => {\n-  input += '';\n-  return startService().then(service =>\n-    service.transform(input, options));\n-};\n+export let transform: typeof types.transform = (input, options) =>\n+  ensureServiceIsRunning().transform(input, options);\n \n export let buildSync: typeof types.buildSync = (options: types.BuildOptions): any => {\n   let result: types.BuildResult;\n@@ -84,7 +79,6 @@ export let buildSync: typeof types.buildSync = (options: types.BuildOptions): an\n };\n \n export let transformSync: typeof types.transformSync = (input, options) => {\n-  input += '';\n   let result: types.TransformResult;\n   runServiceSync(service => service.transform('transformSync', null, input, options || {}, isTTY(), {\n     readFile(tempFile, callback) {\n@@ -115,12 +109,33 @@ export let transformSync: typeof types.transformSync = (input, options) => {\n   return result!;\n };\n \n-export let startService: typeof types.startService = common.longLivedService(() => process.cwd(), options => {\n-  options = common.validateServiceOptions(options || {});\n+let initializeWasCalled = false;\n+\n+export let initialize: typeof types.initialize = options => {\n+  options = common.validateInitializeOptions(options || {});\n   if (options.wasmURL) throw new Error(`The \"wasmURL\" option only works in the browser`)\n   if (options.worker) throw new Error(`The \"worker\" option only works in the browser`)\n+  if (initializeWasCalled) throw new Error('Cannot call \"initialize\" more than once')\n+  initializeWasCalled = true\n+  return Promise.resolve();\n+}\n+\n+interface Service {\n+  build: typeof types.build;\n+  serve: typeof types.serve;\n+  transform: typeof types.transform;\n+}\n+\n+let defaultWD = process.cwd();\n+let longLivedService: Service | undefined;\n+\n+let ensureServiceIsRunning = (): Service => {\n+  if (!longLivedService) longLivedService = startRunningService();\n+  return longLivedService;\n+}\n+\n+let startRunningService = (): Service => {\n   let [command, args] = esbuildCommandAndArgs();\n-  let defaultWD = process.cwd();\n   let child = child_process.spawn(command, args.concat(`--service=${ESBUILD_VERSION}`, '--ping'), {\n     windowsHide: true,\n     stdio: ['pipe', 'pipe', 'inherit'],\n@@ -155,8 +170,7 @@ export let startService: typeof types.startService = common.longLivedService(()\n     unref() { if (--refCount === 0) child.unref(); },\n   }\n \n-  // Create an asynchronous Promise-based API\n-  return Promise.resolve({\n+  return {\n     build: (options: types.BuildOptions): Promise<any> => {\n       return new Promise<types.BuildResult>((resolve, reject) => {\n         service.buildOrServe('build', refs, null, options, isTTY(), defaultWD, (err, res) => {\n@@ -181,7 +195,6 @@ export let startService: typeof types.startService = common.longLivedService(()\n         }))\n     },\n     transform: (input, options) => {\n-      input += '';\n       return new Promise((resolve, reject) =>\n         service.transform('transform', refs, input, options || {}, isTTY(), {\n           readFile(tempFile, callback) {\n@@ -208,12 +221,8 @@ export let startService: typeof types.startService = common.longLivedService(()\n           },\n         }, (err, res) => err ? reject(err) : resolve(res!)));\n     },\n-    stop() {\n-      // Note: This is now never called\n-      child.kill();\n-    },\n-  });\n-});\n+  };\n+}\n \n let runServiceSync = (callback: (service: common.StreamService) => void): void => {\n   let [command, args] = esbuildCommandAndArgs();"},{"sha":"3e96a8679f2a0774f5e0541f5c45c01089d4d8dd","filename":"lib/stdio_protocol.ts","status":"modified","additions":3,"deletions":1,"changes":4,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Fstdio_protocol.ts","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Fstdio_protocol.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Fstdio_protocol.ts?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -48,6 +48,8 @@ export interface BuildResponse {\n   errors: types.Message[];\n   warnings: types.Message[];\n   outputFiles: BuildOutputFile[];\n+  metafile: string;\n+  writeToStdout?: Uint8Array;\n   rebuildID?: number;\n   watchID?: number;\n }\n@@ -120,7 +122,7 @@ export interface OnResolveRequest {\n   importer: string;\n   namespace: string;\n   resolveDir: string;\n-  kind: types.ResolveKind;\n+  kind: types.ImportKind;\n   pluginData: number;\n }\n "},{"sha":"94ddc4e4ece3ab8f4d85e053e2e632e917faf22e","filename":"lib/types.ts","status":"modified","additions":18,"deletions":39,"changes":57,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Ftypes.ts","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/lib%2Ftypes.ts","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/lib%2Ftypes.ts?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -24,36 +24,36 @@ interface CommonOptions {\n   jsxFragment?: string;\n   define?: { [key: string]: string };\n   pure?: string[];\n-  avoidTDZ?: boolean;\n   keepNames?: boolean;\n-  banner?: string;\n-  footer?: string;\n \n   color?: boolean;\n   logLevel?: LogLevel;\n-  errorLimit?: number;\n+  logLimit?: number;\n }\n \n export interface BuildOptions extends CommonOptions {\n   bundle?: boolean;\n   splitting?: boolean;\n   preserveSymlinks?: boolean;\n   outfile?: string;\n-  metafile?: string;\n+  metafile?: boolean;\n   outdir?: string;\n   outbase?: string;\n   platform?: Platform;\n   external?: string[];\n   loader?: { [ext: string]: Loader };\n   resolveExtensions?: string[];\n   mainFields?: string[];\n+  conditions?: string[];\n   write?: boolean;\n   tsconfig?: string;\n   outExtension?: { [ext: string]: string };\n   publicPath?: string;\n   chunkNames?: string;\n   assetNames?: string;\n   inject?: string[];\n+  banner?: { [type: string]: string };\n+  footer?: { [type: string]: string };\n   incremental?: boolean;\n   entryPoints?: string[];\n   stdin?: StdinOptions;\n@@ -118,6 +118,7 @@ export interface BuildResult {\n   outputFiles?: OutputFile[]; // Only when \"write: false\"\n   rebuild?: BuildInvalidate; // Only when \"incremental: true\"\n   stop?: () => void; // Only when \"watch: true\"\n+  metafile?: Metafile; // Only when \"metafile: true\"\n }\n \n export interface BuildFailure extends Error {\n@@ -159,6 +160,8 @@ export interface TransformOptions extends CommonOptions {\n \n   sourcefile?: string;\n   loader?: Loader;\n+  banner?: string;\n+  footer?: string;\n }\n \n export interface TransformResult {\n@@ -194,11 +197,11 @@ export interface OnResolveArgs {\n   importer: string;\n   namespace: string;\n   resolveDir: string;\n-  kind: ResolveKind;\n+  kind: ImportKind;\n   pluginData: any;\n }\n \n-export type ResolveKind =\n+export type ImportKind =\n   | 'entry-point'\n \n   // JS\n@@ -258,25 +261,13 @@ export interface PartialNote {\n   location?: Partial<Location> | null;\n }\n \n-export type MetadataImportKind =\n-  // JS\n-  | 'import-statement'\n-  | 'require-call'\n-  | 'dynamic-import'\n-  | 'require-resolve'\n-\n-  // CSS\n-  | 'import-rule'\n-  | 'url-token'\n-\n-// This is the type information for the \"metafile\" JSON format\n-export interface Metadata {\n+export interface Metafile {\n   inputs: {\n     [path: string]: {\n       bytes: number\n       imports: {\n         path: string\n-        kind: MetadataImportKind\n+        kind: ImportKind\n       }[]\n     }\n   }\n@@ -290,26 +281,14 @@ export interface Metadata {\n       }\n       imports: {\n         path: string\n-        kind: MetadataImportKind\n+        kind: ImportKind\n       }[]\n       exports: string[]\n       entryPoint?: string\n     }\n   }\n }\n \n-export interface Service {\n-  build(options: BuildOptions & { write: false }): Promise<BuildResult & { outputFiles: OutputFile[] }>;\n-  build(options: BuildOptions & { incremental: true }): Promise<BuildIncremental>;\n-  build(options: BuildOptions): Promise<BuildResult>;\n-  serve(serveOptions: ServeOptions, buildOptions: BuildOptions): Promise<ServeResult>;\n-  transform(input: string, options?: TransformOptions): Promise<TransformResult>;\n-\n-  // This stops the service, which kills the long-lived child process. Any\n-  // pending requests will be aborted.\n-  stop(): void;\n-}\n-\n // This function invokes the \"esbuild\" command-line tool for you. It returns a\n // promise that either resolves with a \"BuildResult\" object or rejects with a\n // \"BuildFailure\" object.\n@@ -349,15 +328,15 @@ export declare function buildSync(options: BuildOptions): BuildResult;\n // Works in browser: no\n export declare function transformSync(input: string, options?: TransformOptions): TransformResult;\n \n-// This starts \"esbuild\" as a long-lived child process that is then reused, so\n-// you can call methods on the service many times without the overhead of\n-// starting up a new child process each time.\n+// This configures the browser-based version of esbuild. It is necessary to\n+// call this first and wait for the returned promise to be resolved before\n+// making other API calls when using esbuild in the browser.\n //\n // Works in node: yes\n // Works in browser: yes (\"options\" is required)\n-export declare function startService(options?: ServiceOptions): Promise<Service>;\n+export declare function initialize(options: InitializeOptions): Promise<void>;\n \n-export interface ServiceOptions {\n+export interface InitializeOptions {\n   // The URL of the \"esbuild.wasm\" file. This must be provided when running\n   // esbuild in the browser.\n   wasmURL?: string"},{"sha":"99820b87c5fd67df4def9169a13c685862150510","filename":"pkg/api/api.go","status":"modified","additions":12,"deletions":14,"changes":26,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/pkg%2Fapi%2Fapi.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/pkg%2Fapi%2Fapi.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fapi%2Fapi.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -218,9 +218,9 @@ const (\n // Build API\n \n type BuildOptions struct {\n-\tColor      StderrColor\n-\tErrorLimit int\n-\tLogLevel   LogLevel\n+\tColor    StderrColor\n+\tLogLimit int\n+\tLogLevel LogLevel\n \n \tSourcemap      SourceMap\n \tSourcesContent SourcesContent\n@@ -239,30 +239,30 @@ type BuildOptions struct {\n \n \tDefine    map[string]string\n \tPure      []string\n-\tAvoidTDZ  bool\n \tKeepNames bool\n \n \tGlobalName        string\n \tBundle            bool\n \tPreserveSymlinks  bool\n \tSplitting         bool\n \tOutfile           string\n-\tMetafile          string\n+\tMetafile          bool\n \tOutdir            string\n \tOutbase           string\n \tAbsWorkingDir     string\n \tPlatform          Platform\n \tFormat            Format\n \tExternal          []string\n \tMainFields        []string\n+\tConditions        []string // For the \"exports\" field in \"package.json\"\n \tLoader            map[string]Loader\n \tResolveExtensions []string\n \tTsconfig          string\n \tOutExtensions     map[string]string\n \tPublicPath        string\n \tInject            []string\n-\tBanner            string\n-\tFooter            string\n+\tBanner            map[string]string\n+\tFooter            map[string]string\n \tNodePaths         []string // The \"NODE_PATH\" variable from Node.js\n \n \tChunkNames string\n@@ -278,9 +278,7 @@ type BuildOptions struct {\n }\n \n type WatchMode struct {\n-\tSpinnerBusy string\n-\tSpinnerIdle []string\n-\tOnRebuild   func(BuildResult)\n+\tOnRebuild func(BuildResult)\n }\n \n type StdinOptions struct {\n@@ -295,6 +293,7 @@ type BuildResult struct {\n \tWarnings []Message\n \n \tOutputFiles []OutputFile\n+\tMetafile    string\n \n \tRebuild func() BuildResult // Only when \"Incremental: true\"\n \tStop    func()             // Only when \"Watch: true\"\n@@ -313,9 +312,9 @@ func Build(options BuildOptions) BuildResult {\n // Transform API\n \n type TransformOptions struct {\n-\tColor      StderrColor\n-\tErrorLimit int\n-\tLogLevel   LogLevel\n+\tColor    StderrColor\n+\tLogLimit int\n+\tLogLevel LogLevel\n \n \tSourcemap      SourceMap\n \tSourcesContent SourcesContent\n@@ -339,7 +338,6 @@ type TransformOptions struct {\n \n \tDefine    map[string]string\n \tPure      []string\n-\tAvoidTDZ  bool\n \tKeepNames bool\n \n \tSourcefile string"},{"sha":"9b0ea30177e3911ba85bd02ede6044bf03105804","filename":"pkg/api/api_impl.go","status":"modified","additions":98,"deletions":14,"changes":112,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/pkg%2Fapi%2Fapi_impl.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/pkg%2Fapi%2Fapi_impl.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fapi%2Fapi_impl.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -338,7 +338,7 @@ func isValidExtension(ext string) bool {\n \n func validateResolveExtensions(log logger.Log, order []string) []string {\n \tif order == nil {\n-\t\treturn []string{\".tsx\", \".ts\", \".jsx\", \".mjs\", \".cjs\", \".js\", \".css\", \".json\"}\n+\t\treturn []string{\".tsx\", \".ts\", \".jsx\", \".js\", \".css\", \".json\"}\n \t}\n \tfor _, ext := range order {\n \t\tif !isValidExtension(ext) {\n@@ -503,6 +503,20 @@ func validateOutputExtensions(log logger.Log, outExtensions map[string]string) (\n \treturn\n }\n \n+func validateBannerOrFooter(log logger.Log, name string, values map[string]string) (js string, css string) {\n+\tfor key, value := range values {\n+\t\tswitch key {\n+\t\tcase \"js\":\n+\t\t\tjs = value\n+\t\tcase \"css\":\n+\t\t\tcss = value\n+\t\tdefault:\n+\t\t\tlog.AddError(nil, logger.Loc{}, fmt.Sprintf(\"Invalid %s file type: %q (valid: css, js)\", name, key))\n+\t\t}\n+\t}\n+\treturn\n+}\n+\n func convertLocationToPublic(loc *logger.MsgLocation) *Location {\n \tif loc != nil {\n \t\treturn &Location{\n@@ -589,9 +603,10 @@ type internalBuildResult struct {\n }\n \n func buildImpl(buildOpts BuildOptions) internalBuildResult {\n+\tstart := time.Now()\n \tlogOptions := logger.OutputOptions{\n \t\tIncludeSource: true,\n-\t\tMessageLimit:  buildOpts.ErrorLimit,\n+\t\tMessageLimit:  buildOpts.LogLimit,\n \t\tColor:         validateColor(buildOpts.Color),\n \t\tLogLevel:      validateLogLevel(buildOpts.LogLevel),\n \t}\n@@ -608,7 +623,63 @@ func buildImpl(buildOpts BuildOptions) internalBuildResult {\n \n \t// Do not re-evaluate plugins when rebuilding\n \tplugins := loadPlugins(realFS, log, buildOpts.Plugins)\n-\treturn rebuildImpl(buildOpts, cache.MakeCacheSet(), plugins, logOptions, log, false /* isRebuild */)\n+\tinternalResult := rebuildImpl(buildOpts, cache.MakeCacheSet(), plugins, logOptions, log, false /* isRebuild */)\n+\n+\t// Print a summary of the generated files to stderr. Except don't do\n+\t// this if the terminal is already being used for something else.\n+\tif logOptions.LogLevel <= logger.LevelInfo && len(internalResult.result.OutputFiles) > 0 &&\n+\t\tbuildOpts.Watch == nil && !buildOpts.Incremental && !internalResult.options.WriteToStdout {\n+\t\tprintSummary(logOptions, internalResult.result.OutputFiles, start)\n+\t}\n+\n+\treturn internalResult\n+}\n+\n+func printSummary(logOptions logger.OutputOptions, outputFiles []OutputFile, start time.Time) {\n+\tvar table logger.SummaryTable = make([]logger.SummaryTableEntry, len(outputFiles))\n+\n+\tif len(outputFiles) > 0 {\n+\t\tif cwd, err := os.Getwd(); err == nil {\n+\t\t\tif realFS, err := fs.RealFS(fs.RealFSOptions{AbsWorkingDir: cwd}); err == nil {\n+\t\t\t\tfor i, file := range outputFiles {\n+\t\t\t\t\tpath, ok := realFS.Rel(realFS.Cwd(), file.Path)\n+\t\t\t\t\tif !ok {\n+\t\t\t\t\t\tpath = file.Path\n+\t\t\t\t\t}\n+\t\t\t\t\tbase := realFS.Base(path)\n+\t\t\t\t\tn := len(file.Contents)\n+\t\t\t\t\tvar size string\n+\t\t\t\t\tif n < 1024 {\n+\t\t\t\t\t\tsize = fmt.Sprintf(\"%db \", n)\n+\t\t\t\t\t} else if n < 1024*1024 {\n+\t\t\t\t\t\tsize = fmt.Sprintf(\"%.1fkb\", float64(n)/(1024))\n+\t\t\t\t\t} else if n < 1024*1024*1024 {\n+\t\t\t\t\t\tsize = fmt.Sprintf(\"%.1fmb\", float64(n)/(1024*1024))\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tsize = fmt.Sprintf(\"%.1fgb\", float64(n)/(1024*1024*1024))\n+\t\t\t\t\t}\n+\t\t\t\t\ttable[i] = logger.SummaryTableEntry{\n+\t\t\t\t\t\tDir:         path[:len(path)-len(base)],\n+\t\t\t\t\t\tBase:        base,\n+\t\t\t\t\t\tSize:        size,\n+\t\t\t\t\t\tBytes:       n,\n+\t\t\t\t\t\tIsSourceMap: strings.HasSuffix(base, \".map\"),\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Don't print the time taken by the build if we're running under Yarn 1\n+\t// since Yarn 1 always prints its own copy of the time taken by each command\n+\tfor _, env := range os.Environ() {\n+\t\tif strings.HasPrefix(env, \"npm_config_user_agent=\") && strings.Contains(env, \"yarn/1.\") {\n+\t\t\tlogger.PrintSummary(logOptions.Color, table, nil)\n+\t\t\treturn\n+\t\t}\n+\t}\n+\n+\tlogger.PrintSummary(logOptions.Color, table, &start)\n }\n \n func rebuildImpl(\n@@ -630,6 +701,8 @@ func rebuildImpl(\n \t}\n \tjsFeatures, cssFeatures := validateFeatures(log, buildOpts.Target, buildOpts.Engines)\n \toutJS, outCSS := validateOutputExtensions(log, buildOpts.OutExtensions)\n+\tbannerJS, bannerCSS := validateBannerOrFooter(log, \"banner\", buildOpts.Banner)\n+\tfooterJS, footerCSS := validateBannerOrFooter(log, \"footer\", buildOpts.Footer)\n \tdefines, injectedDefines := validateDefines(log, buildOpts.Define, buildOpts.Pure)\n \toptions := config.Options{\n \t\tUnsupportedJSFeatures:  jsFeatures,\n@@ -654,7 +727,7 @@ func rebuildImpl(\n \t\tAbsOutputFile:         validatePath(log, realFS, buildOpts.Outfile, \"outfile path\"),\n \t\tAbsOutputDir:          validatePath(log, realFS, buildOpts.Outdir, \"outdir path\"),\n \t\tAbsOutputBase:         validatePath(log, realFS, buildOpts.Outbase, \"outbase path\"),\n-\t\tAbsMetadataFile:       validatePath(log, realFS, buildOpts.Metafile, \"metafile path\"),\n+\t\tNeedsMetafile:         buildOpts.Metafile,\n \t\tChunkPathTemplate:     validatePathTemplate(buildOpts.ChunkNames),\n \t\tAssetPathTemplate:     validatePathTemplate(buildOpts.AssetNames),\n \t\tOutputExtensionJS:     outJS,\n@@ -664,16 +737,22 @@ func rebuildImpl(\n \t\tExternalModules:       validateExternals(log, realFS, buildOpts.External),\n \t\tTsConfigOverride:      validatePath(log, realFS, buildOpts.Tsconfig, \"tsconfig path\"),\n \t\tMainFields:            buildOpts.MainFields,\n+\t\tConditions:            append([]string{}, buildOpts.Conditions...),\n \t\tPublicPath:            buildOpts.PublicPath,\n \t\tKeepNames:             buildOpts.KeepNames,\n \t\tInjectAbsPaths:        make([]string, len(buildOpts.Inject)),\n \t\tAbsNodePaths:          make([]string, len(buildOpts.NodePaths)),\n-\t\tBanner:                buildOpts.Banner,\n-\t\tFooter:                buildOpts.Footer,\n+\t\tJSBanner:              bannerJS,\n+\t\tJSFooter:              footerJS,\n+\t\tCSSBanner:             bannerCSS,\n+\t\tCSSFooter:             footerCSS,\n \t\tPreserveSymlinks:      buildOpts.PreserveSymlinks,\n \t\tWatchMode:             buildOpts.Watch != nil,\n \t\tPlugins:               plugins,\n \t}\n+\tif options.MainFields != nil {\n+\t\toptions.MainFields = append([]string{}, options.MainFields...)\n+\t}\n \tfor i, path := range buildOpts.Inject {\n \t\toptions.InjectAbsPaths[i] = validatePath(log, realFS, path, \"inject path\")\n \t}\n@@ -713,9 +792,6 @@ func rebuildImpl(\n \t\tif options.SourceMap != config.SourceMapNone && options.SourceMap != config.SourceMapInline {\n \t\t\tlog.AddError(nil, logger.Loc{}, \"Cannot use an external source map without an output path\")\n \t\t}\n-\t\tif options.AbsMetadataFile != \"\" {\n-\t\t\tlog.AddError(nil, logger.Loc{}, \"Cannot use \\\"metafile\\\" without an output path\")\n-\t\t}\n \t\tfor _, loader := range options.ExtensionToLoader {\n \t\t\tif loader == config.LoaderFile {\n \t\t\t\tlog.AddError(nil, logger.Loc{}, \"Cannot use the \\\"file\\\" loader without an output path\")\n@@ -758,6 +834,7 @@ func rebuildImpl(\n \t}\n \n \tvar outputFiles []OutputFile\n+\tvar metafileJSON string\n \tvar watchData fs.WatchData\n \n \t// Stop now if there were errors\n@@ -770,7 +847,8 @@ func rebuildImpl(\n \t\t// Stop now if there were errors\n \t\tif !log.HasErrors() {\n \t\t\t// Compile the bundle\n-\t\t\tresults := bundle.Compile(log, options)\n+\t\t\tresults, metafile := bundle.Compile(log, options)\n+\t\t\tmetafileJSON = metafile\n \n \t\t\t// Stop now if there were errors\n \t\t\tif !log.HasErrors() {\n@@ -871,6 +949,7 @@ func rebuildImpl(\n \t\tErrors:      convertMessagesToPublic(logger.Error, msgs),\n \t\tWarnings:    convertMessagesToPublic(logger.Warning, msgs),\n \t\tOutputFiles: outputFiles,\n+\t\tMetafile:    metafileJSON,\n \t\tRebuild:     rebuild,\n \t\tStop:        stop,\n \t}\n@@ -1030,7 +1109,7 @@ func (w *watcher) tryToFindDirtyPath() string {\n func transformImpl(input string, transformOpts TransformOptions) TransformResult {\n \tlog := logger.NewStderrLog(logger.OutputOptions{\n \t\tIncludeSource: true,\n-\t\tMessageLimit:  transformOpts.ErrorLimit,\n+\t\tMessageLimit:  transformOpts.LogLimit,\n \t\tColor:         validateColor(transformOpts.Color),\n \t\tLogLevel:      validateLogLevel(transformOpts.LogLevel),\n \t})\n@@ -1102,8 +1181,13 @@ func transformImpl(input string, transformOpts TransformOptions) TransformResult\n \t\t\tContents:   input,\n \t\t\tSourceFile: transformOpts.Sourcefile,\n \t\t},\n-\t\tBanner: transformOpts.Banner,\n-\t\tFooter: transformOpts.Footer,\n+\t}\n+\tif options.Stdin.Loader == config.LoaderCSS {\n+\t\toptions.CSSBanner = transformOpts.Banner\n+\t\toptions.CSSFooter = transformOpts.Footer\n+\t} else {\n+\t\toptions.JSBanner = transformOpts.Banner\n+\t\toptions.JSFooter = transformOpts.Footer\n \t}\n \tif options.SourceMap == config.SourceMapLinkedWithComment {\n \t\t// Linked source maps don't make sense because there's no output file name\n@@ -1131,7 +1215,7 @@ func transformImpl(input string, transformOpts TransformOptions) TransformResult\n \t\t// Stop now if there were errors\n \t\tif !log.HasErrors() {\n \t\t\t// Compile the bundle\n-\t\t\tresults = bundle.Compile(log, options)\n+\t\t\tresults, _ = bundle.Compile(log, options)\n \t\t}\n \t}\n "},{"sha":"9ca04d8cfd0a25fd173a110fde07c8b25fc7f374","filename":"pkg/cli/cli.go","status":"modified","additions":2,"deletions":2,"changes":4,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/pkg%2Fcli%2Fcli.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/pkg%2Fcli%2Fcli.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fcli%2Fcli.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -46,7 +46,7 @@ func Run(osArgs []string) int {\n //\n func ParseBuildOptions(osArgs []string) (options api.BuildOptions, err error) {\n \toptions = newBuildOptions()\n-\terr = parseOptionsImpl(osArgs, &options, nil)\n+\terr, _ = parseOptionsImpl(osArgs, &options, nil, kindExternal)\n \treturn\n }\n \n@@ -66,7 +66,7 @@ func ParseBuildOptions(osArgs []string) (options api.BuildOptions, err error) {\n //\n func ParseTransformOptions(osArgs []string) (options api.TransformOptions, err error) {\n \toptions = newTransformOptions()\n-\terr = parseOptionsImpl(osArgs, nil, &options)\n+\terr, _ = parseOptionsImpl(osArgs, nil, &options, kindExternal)\n \treturn\n }\n "},{"sha":"9d62a9c0b707fad4215da329742ad89489a9eb78","filename":"pkg/cli/cli_impl.go","status":"modified","additions":121,"deletions":114,"changes":235,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/pkg%2Fcli%2Fcli_impl.go","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/pkg%2Fcli%2Fcli_impl.go","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/pkg%2Fcli%2Fcli_impl.go?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -8,7 +8,6 @@ import (\n \t\"sort\"\n \t\"strconv\"\n \t\"strings\"\n-\t\"time\"\n \n \t\"github.com/evanw/esbuild/internal/cli_helpers\"\n \t\"github.com/evanw/esbuild/internal/fs\"\n@@ -20,6 +19,8 @@ func newBuildOptions() api.BuildOptions {\n \treturn api.BuildOptions{\n \t\tLoader: make(map[string]api.Loader),\n \t\tDefine: make(map[string]string),\n+\t\tBanner: make(map[string]string),\n+\t\tFooter: make(map[string]string),\n \t}\n }\n \n@@ -29,7 +30,19 @@ func newTransformOptions() api.TransformOptions {\n \t}\n }\n \n-func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpts *api.TransformOptions) error {\n+type parseOptionsKind uint8\n+\n+const (\n+\tkindInternal parseOptionsKind = iota\n+\tkindExternal\n+)\n+\n+func parseOptionsImpl(\n+\tosArgs []string,\n+\tbuildOpts *api.BuildOptions,\n+\ttransformOpts *api.TransformOptions,\n+\tkind parseOptionsKind,\n+) (err error, metafile *string) {\n \thasBareSourceMapFlag := false\n \n \t// Parse the arguments now that we know what we're parsing\n@@ -93,7 +106,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tcase \"utf8\":\n \t\t\t\t*value = api.CharsetUTF8\n \t\t\tdefault:\n-\t\t\t\treturn fmt.Errorf(\"Invalid charset value: %q (valid: ascii, utf8)\", name)\n+\t\t\t\treturn fmt.Errorf(\"Invalid charset value: %q (valid: ascii, utf8)\", name), nil\n \t\t\t}\n \n \t\tcase strings.HasPrefix(arg, \"--tree-shaking=\"):\n@@ -108,14 +121,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tcase \"ignore-annotations\":\n \t\t\t\t*value = api.TreeShakingIgnoreAnnotations\n \t\t\tdefault:\n-\t\t\t\treturn fmt.Errorf(\"Invalid tree shaking value: %q (valid: ignore-annotations)\", name)\n-\t\t\t}\n-\n-\t\tcase arg == \"--avoid-tdz\":\n-\t\t\tif buildOpts != nil {\n-\t\t\t\tbuildOpts.AvoidTDZ = true\n-\t\t\t} else {\n-\t\t\t\ttransformOpts.AvoidTDZ = true\n+\t\t\t\treturn fmt.Errorf(\"Invalid tree shaking value: %q (valid: ignore-annotations)\", name), nil\n \t\t\t}\n \n \t\tcase arg == \"--keep-names\":\n@@ -144,7 +150,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tcase \"both\":\n \t\t\t\tsourcemap = api.SourceMapInlineAndExternal\n \t\t\tdefault:\n-\t\t\t\treturn fmt.Errorf(\"Invalid sourcemap: %q (valid: inline, external, both)\", value)\n+\t\t\t\treturn fmt.Errorf(\"Invalid sourcemap: %q (valid: inline, external, both)\", value), nil\n \t\t\t}\n \t\t\tif buildOpts != nil {\n \t\t\t\tbuildOpts.Sourcemap = sourcemap\n@@ -162,7 +168,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tcase \"true\":\n \t\t\t\tsourcesContent = api.SourcesContentInclude\n \t\t\tdefault:\n-\t\t\t\treturn fmt.Errorf(\"Invalid sources content: %q (valid: false, true)\", value)\n+\t\t\t\treturn fmt.Errorf(\"Invalid sources content: %q (valid: false, true)\", value), nil\n \t\t\t}\n \t\t\tif buildOpts != nil {\n \t\t\t\tbuildOpts.SourcesContent = sourcesContent\n@@ -186,6 +192,9 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\tcase strings.HasPrefix(arg, \"--main-fields=\") && buildOpts != nil:\n \t\t\tbuildOpts.MainFields = strings.Split(arg[len(\"--main-fields=\"):], \",\")\n \n+\t\tcase strings.HasPrefix(arg, \"--conditions=\") && buildOpts != nil:\n+\t\t\tbuildOpts.Conditions = strings.Split(arg[len(\"--conditions=\"):], \",\")\n+\n \t\tcase strings.HasPrefix(arg, \"--public-path=\") && buildOpts != nil:\n \t\t\tbuildOpts.PublicPath = arg[len(\"--public-path=\"):]\n \n@@ -196,8 +205,13 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\t\ttransformOpts.GlobalName = arg[len(\"--global-name=\"):]\n \t\t\t}\n \n-\t\tcase strings.HasPrefix(arg, \"--metafile=\") && buildOpts != nil:\n-\t\t\tbuildOpts.Metafile = arg[len(\"--metafile=\"):]\n+\t\tcase strings.HasPrefix(arg, \"--metafile\") && buildOpts != nil && kind == kindExternal:\n+\t\t\tbuildOpts.Metafile = true\n+\n+\t\tcase strings.HasPrefix(arg, \"--metafile=\") && buildOpts != nil && kind == kindInternal:\n+\t\t\tmetafilePath := arg[len(\"--metafile=\"):]\n+\t\t\tbuildOpts.Metafile = true\n+\t\t\tmetafile = &metafilePath\n \n \t\tcase strings.HasPrefix(arg, \"--outfile=\") && buildOpts != nil:\n \t\t\tbuildOpts.Outfile = arg[len(\"--outfile=\"):]\n@@ -224,7 +238,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tvalue := arg[len(\"--define:\"):]\n \t\t\tequals := strings.IndexByte(value, '=')\n \t\t\tif equals == -1 {\n-\t\t\t\treturn fmt.Errorf(\"Missing \\\"=\\\": %q\", value)\n+\t\t\t\treturn fmt.Errorf(\"Missing \\\"=\\\": %q\", value), nil\n \t\t\t}\n \t\t\tif buildOpts != nil {\n \t\t\t\tbuildOpts.Define[value[:equals]] = value[equals+1:]\n@@ -244,23 +258,23 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tvalue := arg[len(\"--loader:\"):]\n \t\t\tequals := strings.IndexByte(value, '=')\n \t\t\tif equals == -1 {\n-\t\t\t\treturn fmt.Errorf(\"Missing \\\"=\\\": %q\", value)\n+\t\t\t\treturn fmt.Errorf(\"Missing \\\"=\\\": %q\", value), nil\n \t\t\t}\n \t\t\text, text := value[:equals], value[equals+1:]\n \t\t\tloader, err := cli_helpers.ParseLoader(text)\n \t\t\tif err != nil {\n-\t\t\t\treturn err\n+\t\t\t\treturn err, nil\n \t\t\t}\n \t\t\tbuildOpts.Loader[ext] = loader\n \n \t\tcase strings.HasPrefix(arg, \"--loader=\"):\n \t\t\tvalue := arg[len(\"--loader=\"):]\n \t\t\tloader, err := cli_helpers.ParseLoader(value)\n \t\t\tif err != nil {\n-\t\t\t\treturn err\n+\t\t\t\treturn err, nil\n \t\t\t}\n \t\t\tif loader == api.LoaderFile {\n-\t\t\t\treturn fmt.Errorf(\"Cannot transform using the \\\"file\\\" loader\")\n+\t\t\t\treturn fmt.Errorf(\"Cannot transform using the \\\"file\\\" loader\"), nil\n \t\t\t}\n \t\t\tif buildOpts != nil {\n \t\t\t\tif buildOpts.Stdin == nil {\n@@ -274,7 +288,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\tcase strings.HasPrefix(arg, \"--target=\"):\n \t\t\ttarget, engines, err := parseTargets(strings.Split(arg[len(\"--target=\"):], \",\"))\n \t\t\tif err != nil {\n-\t\t\t\treturn err\n+\t\t\t\treturn err, nil\n \t\t\t}\n \t\t\tif buildOpts != nil {\n \t\t\t\tbuildOpts.Target = target\n@@ -288,7 +302,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tvalue := arg[len(\"--out-extension:\"):]\n \t\t\tequals := strings.IndexByte(value, '=')\n \t\t\tif equals == -1 {\n-\t\t\t\treturn fmt.Errorf(\"Missing \\\"=\\\": %q\", value)\n+\t\t\t\treturn fmt.Errorf(\"Missing \\\"=\\\": %q\", value), nil\n \t\t\t}\n \t\t\tif buildOpts.OutExtensions == nil {\n \t\t\t\tbuildOpts.OutExtensions = make(map[string]string)\n@@ -305,7 +319,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tcase \"neutral\":\n \t\t\t\tbuildOpts.Platform = api.PlatformNeutral\n \t\t\tdefault:\n-\t\t\t\treturn fmt.Errorf(\"Invalid platform: %q (valid: browser, node, neutral)\", value)\n+\t\t\t\treturn fmt.Errorf(\"Invalid platform: %q (valid: browser, node, neutral)\", value), nil\n \t\t\t}\n \n \t\tcase strings.HasPrefix(arg, \"--format=\"):\n@@ -330,7 +344,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\t\t\ttransformOpts.Format = api.FormatESModule\n \t\t\t\t}\n \t\t\tdefault:\n-\t\t\t\treturn fmt.Errorf(\"Invalid format: %q (valid: iife, cjs, esm)\", value)\n+\t\t\t\treturn fmt.Errorf(\"Invalid format: %q (valid: iife, cjs, esm)\", value), nil\n \t\t\t}\n \n \t\tcase strings.HasPrefix(arg, \"--external:\") && buildOpts != nil:\n@@ -355,32 +369,38 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\t\ttransformOpts.JSXFragment = value\n \t\t\t}\n \n-\t\tcase strings.HasPrefix(arg, \"--banner=\"):\n-\t\t\tvalue := arg[len(\"--banner=\"):]\n-\t\t\tif buildOpts != nil {\n-\t\t\t\tbuildOpts.Banner = value\n-\t\t\t} else {\n-\t\t\t\ttransformOpts.Banner = value\n+\t\tcase strings.HasPrefix(arg, \"--banner=\") && transformOpts != nil:\n+\t\t\ttransformOpts.Banner = arg[len(\"--banner=\"):]\n+\n+\t\tcase strings.HasPrefix(arg, \"--footer=\") && transformOpts != nil:\n+\t\t\ttransformOpts.Footer = arg[len(\"--footer=\"):]\n+\n+\t\tcase strings.HasPrefix(arg, \"--banner:\") && buildOpts != nil:\n+\t\t\tvalue := arg[len(\"--banner:\"):]\n+\t\t\tequals := strings.IndexByte(value, '=')\n+\t\t\tif equals == -1 {\n+\t\t\t\treturn fmt.Errorf(\"Missing \\\"=\\\": %q\", value), nil\n \t\t\t}\n+\t\t\tbuildOpts.Banner[value[:equals]] = value[equals+1:]\n \n-\t\tcase strings.HasPrefix(arg, \"--footer=\"):\n-\t\t\tvalue := arg[len(\"--footer=\"):]\n-\t\t\tif buildOpts != nil {\n-\t\t\t\tbuildOpts.Footer = value\n-\t\t\t} else {\n-\t\t\t\ttransformOpts.Footer = value\n+\t\tcase strings.HasPrefix(arg, \"--footer:\") && buildOpts != nil:\n+\t\t\tvalue := arg[len(\"--footer:\"):]\n+\t\t\tequals := strings.IndexByte(value, '=')\n+\t\t\tif equals == -1 {\n+\t\t\t\treturn fmt.Errorf(\"Missing \\\"=\\\": %q\", value), nil\n \t\t\t}\n+\t\t\tbuildOpts.Footer[value[:equals]] = value[equals+1:]\n \n-\t\tcase strings.HasPrefix(arg, \"--error-limit=\"):\n-\t\t\tvalue := arg[len(\"--error-limit=\"):]\n+\t\tcase strings.HasPrefix(arg, \"--log-limit=\"):\n+\t\t\tvalue := arg[len(\"--log-limit=\"):]\n \t\t\tlimit, err := strconv.Atoi(value)\n \t\t\tif err != nil || limit < 0 {\n-\t\t\t\treturn fmt.Errorf(\"Invalid error limit: %q\", value)\n+\t\t\t\treturn fmt.Errorf(\"Invalid log limit: %q\", value), nil\n \t\t\t}\n \t\t\tif buildOpts != nil {\n-\t\t\t\tbuildOpts.ErrorLimit = limit\n+\t\t\t\tbuildOpts.LogLimit = limit\n \t\t\t} else {\n-\t\t\t\ttransformOpts.ErrorLimit = limit\n+\t\t\t\ttransformOpts.LogLimit = limit\n \t\t\t}\n \n \t\t\t// Make sure this stays in sync with \"PrintErrorToStderr\"\n@@ -393,7 +413,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tcase \"true\":\n \t\t\t\tcolor = api.ColorAlways\n \t\t\tdefault:\n-\t\t\t\treturn fmt.Errorf(\"Invalid color: %q (valid: false, true)\", value)\n+\t\t\t\treturn fmt.Errorf(\"Invalid color: %q (valid: false, true)\", value), nil\n \t\t\t}\n \t\t\tif buildOpts != nil {\n \t\t\t\tbuildOpts.Color = color\n@@ -415,7 +435,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\tcase \"silent\":\n \t\t\t\tlogLevel = api.LogLevelSilent\n \t\t\tdefault:\n-\t\t\t\treturn fmt.Errorf(\"Invalid log level: %q (valid: info, warning, error, silent)\", arg)\n+\t\t\t\treturn fmt.Errorf(\"Invalid log level: %q (valid: info, warning, error, silent)\", arg), nil\n \t\t\t}\n \t\t\tif buildOpts != nil {\n \t\t\t\tbuildOpts.LogLevel = logLevel\n@@ -424,16 +444,16 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\t\t}\n \n \t\tcase strings.HasPrefix(arg, \"'--\"):\n-\t\t\treturn fmt.Errorf(\"Unexpected single quote character before flag (use \\\\\\\" to escape double quotes): %s\", arg)\n+\t\t\treturn fmt.Errorf(\"Unexpected single quote character before flag (use \\\\\\\" to escape double quotes): %s\", arg), nil\n \n \t\tcase !strings.HasPrefix(arg, \"-\") && buildOpts != nil:\n \t\t\tbuildOpts.EntryPoints = append(buildOpts.EntryPoints, arg)\n \n \t\tdefault:\n \t\t\tif buildOpts != nil {\n-\t\t\t\treturn fmt.Errorf(\"Invalid build flag: %q\", arg)\n+\t\t\t\treturn fmt.Errorf(\"Invalid build flag: %q\", arg), nil\n \t\t\t} else {\n-\t\t\t\treturn fmt.Errorf(\"Invalid transform flag: %q\", arg)\n+\t\t\t\treturn fmt.Errorf(\"Invalid transform flag: %q\", arg), nil\n \t\t\t}\n \t\t}\n \t}\n@@ -445,7 +465,7 @@ func parseOptionsImpl(osArgs []string, buildOpts *api.BuildOptions, transformOpt\n \t\tbuildOpts.Sourcemap = api.SourceMapInline\n \t}\n \n-\treturn nil\n+\treturn\n }\n \n func parseTargets(targets []string) (target api.Target, engines []api.Engine, err error) {\n@@ -500,45 +520,43 @@ outer:\n }\n \n // This returns either BuildOptions, TransformOptions, or an error\n-func parseOptionsForRun(osArgs []string) (*api.BuildOptions, *api.TransformOptions, error) {\n+func parseOptionsForRun(osArgs []string) (*api.BuildOptions, *string, *api.TransformOptions, error) {\n \t// If there's an entry point or we're bundling, then we're building\n \tfor _, arg := range osArgs {\n \t\tif !strings.HasPrefix(arg, \"-\") || arg == \"--bundle\" {\n \t\t\toptions := newBuildOptions()\n \n \t\t\t// Apply defaults appropriate for the CLI\n-\t\t\toptions.ErrorLimit = 10\n+\t\t\toptions.LogLimit = 10\n \t\t\toptions.LogLevel = api.LogLevelInfo\n \t\t\toptions.Write = true\n \n-\t\t\terr := parseOptionsImpl(osArgs, &options, nil)\n+\t\t\terr, metafile := parseOptionsImpl(osArgs, &options, nil, kindInternal)\n \t\t\tif err != nil {\n-\t\t\t\treturn nil, nil, err\n+\t\t\t\treturn nil, nil, nil, err\n \t\t\t}\n-\t\t\treturn &options, nil, nil\n+\t\t\treturn &options, metafile, nil, nil\n \t\t}\n \t}\n \n \t// Otherwise, we're transforming\n \toptions := newTransformOptions()\n \n \t// Apply defaults appropriate for the CLI\n-\toptions.ErrorLimit = 10\n+\toptions.LogLimit = 10\n \toptions.LogLevel = api.LogLevelInfo\n \n-\terr := parseOptionsImpl(osArgs, nil, &options)\n+\terr, _ := parseOptionsImpl(osArgs, nil, &options, kindInternal)\n \tif err != nil {\n-\t\treturn nil, nil, err\n+\t\treturn nil, nil, nil, err\n \t}\n \tif options.Sourcemap != api.SourceMapNone && options.Sourcemap != api.SourceMapInline {\n-\t\treturn nil, nil, fmt.Errorf(\"Must use \\\"inline\\\" source map when transforming stdin\")\n+\t\treturn nil, nil, nil, fmt.Errorf(\"Must use \\\"inline\\\" source map when transforming stdin\")\n \t}\n-\treturn nil, &options, nil\n+\treturn nil, nil, &options, nil\n }\n \n func runImpl(osArgs []string) int {\n-\tshouldPrintSummary := false\n-\tstart := time.Now()\n \tend := 0\n \n \tfor _, arg := range osArgs {\n@@ -551,18 +569,12 @@ func runImpl(osArgs []string) int {\n \t\t\treturn 0\n \t\t}\n \n-\t\t// Filter out the \"--summary\" flag\n-\t\tif arg == \"--summary\" {\n-\t\t\tshouldPrintSummary = true\n-\t\t\tcontinue\n-\t\t}\n-\n \t\tosArgs[end] = arg\n \t\tend++\n \t}\n \tosArgs = osArgs[:end]\n \n-\tbuildOptions, transformOptions, err := parseOptionsForRun(osArgs)\n+\tbuildOptions, metafile, transformOptions, err := parseOptionsForRun(osArgs)\n \n \tswitch {\n \tcase buildOptions != nil:\n@@ -606,6 +618,30 @@ func runImpl(osArgs []string) int {\n \t\t\treturn 1\n \t\t}\n \n+\t\t// Validate the metafile absolute path and directory ahead of time so we\n+\t\t// don't write any output files if it's incorrect. That makes this API\n+\t\t// option consistent with how we handle all other API options.\n+\t\tvar metafileAbsPath string\n+\t\tvar metafileAbsDir string\n+\t\tif metafile != nil {\n+\t\t\tif buildOptions.Outfile == \"\" && buildOptions.Outdir == \"\" {\n+\t\t\t\t// Cannot use \"metafile\" when writing to stdout\n+\t\t\t\tlogger.PrintErrorToStderr(osArgs, \"Cannot use \\\"metafile\\\" without an output path\")\n+\t\t\t\treturn 1\n+\t\t\t}\n+\t\t\tif realFS, err := fs.RealFS(fs.RealFSOptions{AbsWorkingDir: buildOptions.AbsWorkingDir}); err == nil {\n+\t\t\t\tabsPath, ok := realFS.Abs(*metafile)\n+\t\t\t\tif !ok {\n+\t\t\t\t\tlogger.PrintErrorToStderr(osArgs, fmt.Sprintf(\"Invalid metafile path: %s\", *metafile))\n+\t\t\t\t\treturn 1\n+\t\t\t\t}\n+\t\t\t\tmetafileAbsPath = absPath\n+\t\t\t\tmetafileAbsDir = realFS.Dir(absPath)\n+\t\t\t} else {\n+\t\t\t\t// Don't fail in this case since the error will be reported by \"api.Build\"\n+\t\t\t}\n+\t\t}\n+\n \t\t// Run the build\n \t\tresult := api.Build(*buildOptions)\n \n@@ -619,9 +655,23 @@ func runImpl(osArgs []string) int {\n \t\t\treturn 1\n \t\t}\n \n-\t\t// Print a summary to stderr\n-\t\tif shouldPrintSummary {\n-\t\t\tprintSummary(osArgs, result.OutputFiles, start)\n+\t\t// Write the metafile to the file system\n+\t\tif metafile != nil {\n+\t\t\tif err != nil {\n+\t\t\t\t// This should already have been checked above\n+\t\t\t\tpanic(err.Error())\n+\t\t\t}\n+\t\t\tfs.BeforeFileOpen()\n+\t\t\tdefer fs.AfterFileClose()\n+\t\t\tif err := os.MkdirAll(metafileAbsDir, 0755); err != nil {\n+\t\t\t\tlogger.PrintErrorToStderr(osArgs, fmt.Sprintf(\n+\t\t\t\t\t\"Failed to create output directory: %s\", err.Error()))\n+\t\t\t} else {\n+\t\t\t\tif err := ioutil.WriteFile(metafileAbsPath, []byte(result.Metafile), 0644); err != nil {\n+\t\t\t\t\tlogger.PrintErrorToStderr(osArgs, fmt.Sprintf(\n+\t\t\t\t\t\t\"Failed to write to output file: %s\", err.Error()))\n+\t\t\t\t}\n+\t\t\t}\n \t\t}\n \n \tcase transformOptions != nil:\n@@ -642,11 +692,6 @@ func runImpl(osArgs []string) int {\n \t\t// Write the output to stdout\n \t\tos.Stdout.Write(result.Code)\n \n-\t\t// Print a summary to stderr\n-\t\tif shouldPrintSummary {\n-\t\t\tprintSummary(osArgs, nil, start)\n-\t\t}\n-\n \tcase err != nil:\n \t\tlogger.PrintErrorToStderr(osArgs, err.Error())\n \t\treturn 1\n@@ -655,44 +700,6 @@ func runImpl(osArgs []string) int {\n \treturn 0\n }\n \n-func printSummary(osArgs []string, outputFiles []api.OutputFile, start time.Time) {\n-\tvar table logger.SummaryTable = make([]logger.SummaryTableEntry, len(outputFiles))\n-\n-\tif len(outputFiles) > 0 {\n-\t\tif cwd, err := os.Getwd(); err == nil {\n-\t\t\tif realFS, err := fs.RealFS(fs.RealFSOptions{AbsWorkingDir: cwd}); err == nil {\n-\t\t\t\tfor i, file := range outputFiles {\n-\t\t\t\t\tpath, ok := realFS.Rel(realFS.Cwd(), file.Path)\n-\t\t\t\t\tif !ok {\n-\t\t\t\t\t\tpath = file.Path\n-\t\t\t\t\t}\n-\t\t\t\t\tbase := realFS.Base(path)\n-\t\t\t\t\tn := len(file.Contents)\n-\t\t\t\t\tvar size string\n-\t\t\t\t\tif n < 1024 {\n-\t\t\t\t\t\tsize = fmt.Sprintf(\"%db \", n)\n-\t\t\t\t\t} else if n < 1024*1024 {\n-\t\t\t\t\t\tsize = fmt.Sprintf(\"%.1fkb\", float64(n)/(1024))\n-\t\t\t\t\t} else if n < 1024*1024*1024 {\n-\t\t\t\t\t\tsize = fmt.Sprintf(\"%.1fmb\", float64(n)/(1024*1024))\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tsize = fmt.Sprintf(\"%.1fgb\", float64(n)/(1024*1024*1024))\n-\t\t\t\t\t}\n-\t\t\t\t\ttable[i] = logger.SummaryTableEntry{\n-\t\t\t\t\t\tDir:         path[:len(path)-len(base)],\n-\t\t\t\t\t\tBase:        base,\n-\t\t\t\t\t\tSize:        size,\n-\t\t\t\t\t\tBytes:       n,\n-\t\t\t\t\t\tIsSourceMap: strings.HasSuffix(base, \".map\"),\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\tlogger.PrintSummary(osArgs, table, start)\n-}\n-\n func parseServeOptionsImpl(osArgs []string) (api.ServeOptions, []string, error) {\n \thost := \"\"\n \tportText := \"0\"\n@@ -746,10 +753,10 @@ func serveImpl(osArgs []string) error {\n \toptions := newBuildOptions()\n \n \t// Apply defaults appropriate for the CLI\n-\toptions.ErrorLimit = 5\n+\toptions.LogLimit = 5\n \toptions.LogLevel = api.LogLevelInfo\n \n-\tif err := parseOptionsImpl(filteredArgs, &options, nil); err != nil {\n+\tif err, _ := parseOptionsImpl(filteredArgs, &options, nil, kindInternal); err != nil {\n \t\tlogger.PrintErrorToStderr(filteredArgs, err.Error())\n \t\treturn err\n \t}"},{"sha":"b159885d41f506f74aeb6679b57d2629e81dd586","filename":"scripts/browser/browser-tests.js","status":"modified","additions":12,"deletions":20,"changes":32,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fbrowser%2Fbrowser-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fbrowser%2Fbrowser-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fbrowser%2Fbrowser-tests.js?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -11,7 +11,7 @@ const esmMin = fs.readFileSync(path.join(__dirname, '..', '..', 'npm', 'esbuild-\n const wasm = fs.readFileSync(path.join(__dirname, '..', '..', 'npm', 'esbuild-wasm', 'esbuild.wasm'))\n \n // This is converted to a string and run inside the browser\n-async function runAllTests({ esbuild, service }) {\n+async function runAllTests({ esbuild }) {\n   function setupForProblemCSS(prefix) {\n     // https://github.com/tailwindlabs/tailwindcss/issues/2889\n     const original = `\n@@ -50,17 +50,17 @@ async function runAllTests({ esbuild, service }) {\n \n   const tests = {\n     async transformJS() {\n-      const { code } = await service.transform('1+2')\n+      const { code } = await esbuild.transform('1+2')\n       assertStrictEqual(code, '1 + 2;\\n')\n     },\n \n     async transformTS() {\n-      const { code } = await service.transform('1 as any + <any>2', { loader: 'ts' })\n+      const { code } = await esbuild.transform('1 as any + <any>2', { loader: 'ts' })\n       assertStrictEqual(code, '1 + 2;\\n')\n     },\n \n     async transformCSS() {\n-      const { code } = await service.transform('div { color: red }', { loader: 'css' })\n+      const { code } = await esbuild.transform('div { color: red }', { loader: 'css' })\n       assertStrictEqual(code, 'div {\\n  color: red;\\n}\\n')\n     },\n \n@@ -71,13 +71,13 @@ async function runAllTests({ esbuild, service }) {\n \n     async problemCSSPrettyPrinted() {\n       const [original, runAsserts] = setupForProblemCSS('pretty-print')\n-      const { code: prettyPrinted } = await service.transform(original, { loader: 'css' })\n+      const { code: prettyPrinted } = await esbuild.transform(original, { loader: 'css' })\n       runAsserts(prettyPrinted)\n     },\n \n     async problemCSSMinified() {\n       const [original, runAsserts] = setupForProblemCSS('pretty-print')\n-      const { code: minified } = await service.transform(original, { loader: 'css', minify: true })\n+      const { code: minified } = await esbuild.transform(original, { loader: 'css', minify: true })\n       runAsserts(minified)\n     },\n \n@@ -98,7 +98,7 @@ async function runAllTests({ esbuild, service }) {\n           })\n         },\n       }\n-      const result = await service.build({\n+      const result = await esbuild.build({\n         stdin: {\n           contents: `\n             import x from 'fib(10)'\n@@ -117,7 +117,7 @@ async function runAllTests({ esbuild, service }) {\n     },\n \n     async buildRelativeIssue693() {\n-      const result = await service.build({\n+      const result = await esbuild.build({\n         stdin: {\n           contents: `const x=1`,\n         },\n@@ -130,15 +130,7 @@ async function runAllTests({ esbuild, service }) {\n     },\n \n     async serve() {\n-      expectThrownError(service.serve, 'The \"serve\" API only works in node')\n-    },\n-\n-    async esbuildBuild() {\n-      expectThrownError(esbuild.build, 'The \"build\" API only works in node')\n-    },\n-\n-    async esbuildTransform() {\n-      expectThrownError(esbuild.transform, 'The \"transform\" API only works in node')\n+      expectThrownError(esbuild.serve, 'The \"serve\" API only works in node')\n     },\n \n     async esbuildBuildSync() {\n@@ -189,11 +181,11 @@ for (let format of ['iife', 'esm']) {\n     for (let async of [false, true]) {\n       let code = `\n         window.testStart = function() {\n-          esbuild.startService({\n+          esbuild.initialize({\n             wasmURL: '/esbuild.wasm',\n             worker: ${async},\n-          }).then(service => {\n-            return (${runAllTests})({ esbuild, service })\n+          }).then(() => {\n+            return (${runAllTests})({ esbuild })\n           }).then(() => {\n             testDone()\n           }).catch(e => {"},{"sha":"91c40aee0f11bbf18b5a6fe99c19914fce0b1483","filename":"scripts/end-to-end-tests.js","status":"modified","additions":137,"deletions":19,"changes":156,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fend-to-end-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fend-to-end-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fend-to-end-tests.js?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -65,7 +65,6 @@\n     1 │ import \"./file.js/what/is/this\"\n       ╵        ~~~~~~~~~~~~~~~~~~~~~~~~\n \n-1 error\n `,\n     }),\n   )\n@@ -153,7 +152,7 @@\n       }, { cwd: 'c' }),\n \n       // This is a test for https://github.com/evanw/esbuild/issues/766\n-      test(['--bundle', 'impl/index.mjs', '--outfile=node.js', '--format=cjs'], {\n+      test(['--bundle', 'impl/index.mjs', '--outfile=node.js', '--format=cjs', '--resolve-extensions=.mjs'], {\n         'config/yarn/link/@monorepo-source/a': { symlink: `../../../../monorepo-source/packages/a` },\n         'config/yarn/link/@monorepo-source/b': { symlink: `../../../../monorepo-source/packages/b` },\n         'impl/node_modules/@monorepo-source/b': { symlink: `../../../config/yarn/link/@monorepo-source/b` },\n@@ -1045,7 +1044,6 @@\n     2 │         const {exists} = require('fs')\n       ╵                          ~~~~~~~\n \n-1 warning\n `,\n     }),\n     test(['in.js', '--outfile=out.js', '--format=esm'], {\n@@ -1067,7 +1065,6 @@\n     2 │         const fs = require('fs')\n       ╵                    ~~~~~~~\n \n-1 warning\n `,\n     }),\n     test(['in.js', '--outfile=out.js', '--format=esm'], {\n@@ -1809,7 +1806,6 @@\n     24 │             expect(() => this.#getter = 1, 'member.set is not a func...\n        ╵                               ~~~~~~~\n \n-2 warnings\n `,\n     }),\n     test(['in.js', '--outfile=node.js', '--target=es6'], {\n@@ -1978,7 +1974,6 @@\n     3 │           class Foo {\n       ╵                 ~~~\n \n-1 warning\n `,\n     }),\n     test(['in.js', '--outfile=node.js', '--target=es6'], {\n@@ -2003,7 +1998,6 @@\n     2 │         class Foo {\n       ╵               ~~~\n \n-1 warning\n `,\n     }),\n \n@@ -2719,7 +2713,6 @@\n     2 │         //# sourceMappingURL=entry.js.map\n       ╵                              ~~~~~~~~~~~~\n \n-1 error\n `,\n       }),\n       test(['src/entry.js', '--bundle', '--outfile=node.js'], {\n@@ -2731,7 +2724,6 @@\n     1 │ {\"extends\": \"./base.json\"}\n       ╵             ~~~~~~~~~~~~~\n \n-1 error\n `,\n       }),\n       test(['src/entry.js', '--bundle', '--outfile=node.js'], {\n@@ -2743,7 +2735,6 @@\n     1 │ {\"extends\": \"foo\"}\n       ╵             ~~~~~\n \n-1 error\n `,\n       }),\n       test(['src/entry.js', '--bundle', '--outfile=node.js'], {\n@@ -2766,20 +2757,19 @@\n       expectedStderr: ` > error: Unexpected single quote character before flag (use \\\\\" to ` +\n         `escape double quotes): '--define:process.env.NODE_ENV=\"production\"'\n \n-1 error\n `,\n     }),\n   )\n \n   // Test injecting banner and footer\n   tests.push(\n-    test(['in.js', '--outfile=node.js', '--banner=const bannerDefined = true;'], {\n+    test(['in.js', '--outfile=node.js', '--banner:js=const bannerDefined = true;'], {\n       'in.js': `if (!bannerDefined) throw 'fail'`\n     }),\n-    test(['in.js', '--outfile=node.js', '--footer=function footer() { }'], {\n+    test(['in.js', '--outfile=node.js', '--footer:js=function footer() { }'], {\n       'in.js': `footer()`\n     }),\n-    test(['a.js', 'b.js', '--outdir=out', '--bundle', '--format=cjs', '--banner=const bannerDefined = true;', '--footer=function footer() { }'], {\n+    test(['a.js', 'b.js', '--outdir=out', '--bundle', '--format=cjs', '--banner:js=const bannerDefined = true;', '--footer:js=function footer() { }'], {\n       'a.js': `\n         module.exports = { banner: bannerDefined, footer };\n       `,\n@@ -2797,6 +2787,137 @@\n     }),\n   )\n \n+  // Test \"exports\" in package.json\n+  for (const flags of [[], ['--bundle']]) {\n+    tests.push(\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/subdir/foo.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \".\": \"./subdir/foo.js\"\n+          }\n+        }`,\n+      }),\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/subdir/foo.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \".\": {\n+              \"default\": \"./subdir/foo.js\"\n+            }\n+          }\n+        }`,\n+      }),\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/subdir/foo.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \"default\": \"./subdir/foo.js\"\n+          }\n+        }`,\n+      }),\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg/foo.js'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/subdir/foo.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \"./\": \"./subdir/\"\n+          }\n+        }`,\n+      }),\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg/foo.js'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/subdir/foo.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \"./\": {\n+              \"default\": \"./subdir/\"\n+            }\n+          }\n+        }`,\n+      }),\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg/dir/foo.js'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/subdir/foo.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \"./dir/\": \"./subdir/\"\n+          }\n+        }`,\n+      }),\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg/dir/foo.js'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/subdir/foo.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \"./dir/\": {\n+              \"default\": \"./subdir/\"\n+            }\n+          }\n+        }`,\n+      }),\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg/dirwhat'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/sub/what/dirwhat/foo.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \"./di*\": \"./nope.js\",\n+            \"./dir*\": \"./sub/*/dir*/foo.js\",\n+            \"./long*\": \"./nope.js\",\n+            \"./d*\": \"./nope.js\"\n+          }\n+        }`,\n+      }),\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg/foo'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/yes.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \"./foo\": [\n+              { \"unused\": \"./no.js\" },\n+              \"./yes.js\"\n+            ]\n+          }\n+        }`,\n+      }),\n+      test(['in.js', '--outfile=node.js', '--format=esm'].concat(flags), {\n+        'in.js': `import abc from 'pkg/foo'; if (abc !== 123) throw 'fail'`,\n+        'package.json': `{ \"type\": \"module\" }`,\n+        'node_modules/pkg/yes.js': `export default 123`,\n+        'node_modules/pkg/package.json': `{\n+          \"type\": \"module\",\n+          \"exports\": {\n+            \"./foo\": [\n+              { \"default\": \"./yes.js\" },\n+              \"./no.js\"\n+            ]\n+          }\n+        }`,\n+      }),\n+    )\n+  }\n+\n   // Test writing to stdout\n   tests.push(\n     // These should succeed\n@@ -2858,7 +2979,6 @@\n     2 │         import \"/file.js\"\n       ╵                ~~~~~~~~~~\n \n-1 error\n `,\n     }),\n   )\n@@ -2884,7 +3004,6 @@\n     3 │           import y from \"./file2.js\"\n       ╵                         ~~~~~~~~~~~~\n \n-2 warnings\n `,\n       }),\n       test(['in.js', '--bundle', '--outfile=node.js'], {\n@@ -2915,7 +3034,6 @@\n     3 │           import y from \"pkg/file2.js\"\n       ╵                         ~~~~~~~~~~~~~~\n \n-2 warnings\n `,\n       }),\n \n@@ -2947,7 +3065,7 @@\n       // If the test doesn't specify a format, test both formats\n       for (const format of formats) {\n         const formatArg = `--format=${format}`\n-        const modifiedArgs = !hasBundle || args.includes(formatArg) ? args : args.concat(formatArg)\n+        const modifiedArgs = (!hasBundle || args.includes(formatArg) ? args : args.concat(formatArg)).concat('--log-level=warning')\n         const thisTestDir = path.join(testDir, '' + testCount++)\n \n         try {\n@@ -3047,7 +3165,7 @@\n         // Run whatever check the caller is doing\n         await callback(async () => {\n           const { stdout } = await execFileAsync(\n-            esbuildPath, [inputFile].concat(args), { cwd: thisTestDir, stdio: 'pipe' })\n+            esbuildPath, [inputFile, '--log-level=warning'].concat(args), { cwd: thisTestDir, stdio: 'pipe' })\n           return stdout\n         })\n "},{"sha":"4782449eb4db0b316d860642d045cbd7bc2288d7","filename":"scripts/esbuild.js","status":"modified","additions":8,"deletions":2,"changes":10,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fesbuild.js","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fesbuild.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fesbuild.js?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -23,6 +23,7 @@ exports.buildNativeLib = (esbuildPath) => {\n     '--target=' + nodeTarget,\n     '--define:ESBUILD_VERSION=' + JSON.stringify(version),\n     '--platform=node',\n+    '--log-level=warning',\n   ], { cwd: repoDir })\n \n   // Generate \"npm/esbuild/lib/main.js\"\n@@ -35,6 +36,7 @@ exports.buildNativeLib = (esbuildPath) => {\n     '--define:WASM=false',\n     '--define:ESBUILD_VERSION=' + JSON.stringify(version),\n     '--platform=node',\n+    '--log-level=warning',\n   ], { cwd: repoDir })\n \n   // Generate \"npm/esbuild/lib/main.d.ts\"\n@@ -104,6 +106,7 @@ exports.buildWasmLib = async (esbuildPath) => {\n     '--define:WASM=true',\n     '--define:ESBUILD_VERSION=' + JSON.stringify(version),\n     '--platform=node',\n+    '--log-level=warning',\n   ], { cwd: repoDir })\n \n   // Generate \"npm/esbuild-wasm/lib/main.d.ts\" and \"npm/esbuild-wasm/lib/browser.d.ts\"\n@@ -133,6 +136,7 @@ exports.buildWasmLib = async (esbuildPath) => {\n         path.join(repoDir, 'lib', 'worker.ts'),\n         '--target=' + target,\n         '--define:ESBUILD_VERSION=' + JSON.stringify(version),\n+        '--log-level=warning',\n       ].concat(minifyFlags), { cwd: repoDir }).toString().trim()\n \n       wasmWorkerCode[format] = wasmExecCode + workerCode\n@@ -148,8 +152,9 @@ exports.buildWasmLib = async (esbuildPath) => {\n       '--format=cjs',\n       '--define:ESBUILD_VERSION=' + JSON.stringify(version),\n       '--define:WEB_WORKER_SOURCE_CODE=' + JSON.stringify(wasmWorkerCode.umd),\n-      '--banner=' + umdPrefix,\n-      '--footer=' + umdSuffix,\n+      '--banner:js=' + umdPrefix,\n+      '--footer:js=' + umdSuffix,\n+      '--log-level=warning',\n     ].concat(minifyFlags), { cwd: repoDir }).toString()\n     fs.writeFileSync(path.join(libDir, minify ? 'browser.min.js' : 'browser.js'), browserCJS)\n \n@@ -161,6 +166,7 @@ exports.buildWasmLib = async (esbuildPath) => {\n       '--format=esm',\n       '--define:ESBUILD_VERSION=' + JSON.stringify(version),\n       '--define:WEB_WORKER_SOURCE_CODE=' + JSON.stringify(wasmWorkerCode.esm),\n+      '--log-level=warning',\n     ].concat(minifyFlags), { cwd: repoDir }).toString()\n     fs.writeFileSync(path.join(esmDir, minify ? 'browser.min.js' : 'browser.js'), browserESM)\n   }"},{"sha":"ecf3a1f37f5e89d85ed7f1f454919334b6f8eb05","filename":"scripts/js-api-tests.js","status":"modified","additions":1019,"deletions":1007,"changes":2026,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fjs-api-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fjs-api-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fjs-api-tests.js?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5"},{"sha":"abd060238a53e3dd29a3f1b7e6a8575e3d786a07","filename":"scripts/node-unref-tests.js","status":"modified","additions":4,"deletions":10,"changes":14,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fnode-unref-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fnode-unref-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fnode-unref-tests.js?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -74,16 +74,10 @@ async function tests() {\n     result.rebuild.dispose()\n   }\n \n-  const service = await esbuild.startService();\n-  try {\n-    await testTransform()\n-    await testServe()\n-    await testBuild()\n-    await testWatch()\n-  } catch (error) {\n-    service.stop();\n-    throw error;\n-  }\n+  await testTransform()\n+  await testServe()\n+  await testBuild()\n+  await testWatch()\n }\n \n // Called when this is the child process to run the tests."},{"sha":"298fd3a0e54f2237715143c817b10d546b8293e2","filename":"scripts/plugin-tests.js","status":"modified","additions":224,"deletions":99,"changes":323,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fplugin-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fplugin-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fplugin-tests.js?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -36,7 +36,11 @@ let pluginTests = {\n     const output = path.join(testDir, 'out.js')\n     await writeFileAsync(input, `export default 123`)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [],\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [],\n     })\n     const result = require(output)\n     assert.strictEqual(result.default, 123)\n@@ -47,7 +51,11 @@ let pluginTests = {\n     const output = path.join(testDir, 'out.js')\n     await writeFileAsync(input, `export default 123`)\n     esbuild.buildSync({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [],\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [],\n     })\n     const result = require(output)\n     assert.strictEqual(result.default, 123)\n@@ -58,7 +66,9 @@ let pluginTests = {\n       // onResolve\n       try {\n         await esbuild.build({\n-          entryPoints: ['invalid.js'], write: false, plugins: [{\n+          entryPoints: ['invalid.js'],\n+          write: false,\n+          plugins: [{\n             name: 'name',\n             setup(build) {\n               build.onResolve({ filter }, () => { })\n@@ -73,7 +83,9 @@ let pluginTests = {\n       // onLoad\n       try {\n         await esbuild.build({\n-          entryPoints: ['invalid.js'], write: false, plugins: [{\n+          entryPoints: ['invalid.js'],\n+          write: false,\n+          plugins: [{\n             name: 'name',\n             setup(build) {\n               build.onLoad({ filter }, () => { })\n@@ -277,7 +289,11 @@ let pluginTests = {\n     `)\n     await writeFileAsync(custom, ``)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onLoad({ filter: /\\.custom$/ }, args => {\n@@ -301,7 +317,11 @@ let pluginTests = {\n     `)\n     await writeFileAsync(custom, `example text`)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^test$/ }, args => {\n@@ -323,7 +343,11 @@ let pluginTests = {\n       export default x\n     `)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^fib\\((\\d+)\\)$/ }, args => {\n@@ -352,7 +376,11 @@ let pluginTests = {\n       export default x\n     `)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^fib\\((\\d+)\\)/ }, args => {\n@@ -386,7 +414,11 @@ let pluginTests = {\n     `)\n     let trace = []\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [\n         {\n           name: 'plugin1',\n           setup(build) {\n@@ -437,7 +469,11 @@ let pluginTests = {\n     `)\n     let trace = []\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [\n         {\n           name: 'plugin1',\n           setup(build) {\n@@ -483,7 +519,11 @@ let pluginTests = {\n       export default x\n     `)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^http:\\/\\// }, args => {\n@@ -515,7 +555,11 @@ let pluginTests = {\n       export default exists\n     `)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^extern$/ }, () => {\n@@ -536,7 +580,11 @@ let pluginTests = {\n       export default exists\n     `)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^extern$/ }, () => {\n@@ -563,7 +611,11 @@ let pluginTests = {\n       module.exports = require('fs')\n     `)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outdir, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outdir,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^extern$/ }, () => {\n@@ -598,7 +650,11 @@ let pluginTests = {\n       export default 123\n     `)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onLoad({ filter: /\\.custom$/ }, async (args) => {\n@@ -629,7 +685,11 @@ let pluginTests = {\n       export default 123\n     `)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onLoad({ filter: /\\.custom$/ }, async (args) => {\n@@ -656,7 +716,11 @@ let pluginTests = {\n       export default 123\n     `)\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           let contents = `export {default} from './loadme'`\n@@ -685,7 +749,11 @@ let pluginTests = {\n     let error\n     try {\n       await esbuild.build({\n-        entryPoints: [input], bundle: true, outfile: output, format: 'cjs', logLevel: 'silent', plugins: [{\n+        entryPoints: [input],\n+        bundle: true,\n+        outfile: output,\n+        format: 'cjs',\n+        logLevel: 'silent', plugins: [{\n           name: 'name',\n           setup(build) {\n             let contents = `export {default} from './loadme'`\n@@ -721,7 +789,11 @@ let pluginTests = {\n       0x00, 0x20, 0x00, 0x20, 0x01, 0x6A, 0x0B,\n     ))\n     await esbuild.build({\n-      entryPoints: [input], bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      entryPoints: [input],\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /\\.wasm$/ }, args => ({\n@@ -744,7 +816,11 @@ let pluginTests = {\n   async virtualEntryPoints({ esbuild, testDir }) {\n     const result = await esbuild.build({\n       entryPoints: ['1', '2', 'a<>:\"|?*b', 'a/b/c.d.e'],\n-      bundle: true, write: false, outdir: testDir, format: 'esm', plugins: [{\n+      bundle: true,\n+      write: false,\n+      outdir: testDir,\n+      format: 'esm',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /.*/ }, args => {\n@@ -774,7 +850,10 @@ let pluginTests = {\n         contents: `import x from \"plugin\"; export default x`,\n         sourcefile: 'stdin-sourcefile',\n       },\n-      bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^plugin$/ }, args => {\n@@ -802,7 +881,10 @@ let pluginTests = {\n         sourcefile: 'stdin-sourcefile',\n         resolveDir: testDir,\n       },\n-      bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^plugin$/ }, args => {\n@@ -830,7 +912,10 @@ let pluginTests = {\n         sourcefile: path.join(testDir, 'stdin-sourcefile'),\n         resolveDir: testDir,\n       },\n-      bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /^plugin$/ }, args => {\n@@ -856,7 +941,10 @@ let pluginTests = {\n       stdin: {\n         contents: `import x from \"./stdinRelative.js\"; export default x`,\n       },\n-      bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /.*/ }, args => {\n@@ -883,7 +971,10 @@ let pluginTests = {\n         contents: `import x from \"./stdinRelative.js\"; export default x`,\n         resolveDir: testDir,\n       },\n-      bundle: true, outfile: output, format: 'cjs', plugins: [{\n+      bundle: true,\n+      outfile: output,\n+      format: 'cjs',\n+      plugins: [{\n         name: 'name',\n         setup(build) {\n           build.onResolve({ filter: /.*/ }, args => {\n@@ -929,7 +1020,10 @@ let pluginTests = {\n           export default fs.readdirSync(path.dirname(url.fileURLToPath(import.meta.url)))\n         `,\n       },\n-      bundle: true, outfile, format: 'esm', plugins: [\n+      bundle: true,\n+      outfile,\n+      format: 'esm',\n+      plugins: [\n         externalPlugin(['fs', 'url', 'path'])\n       ],\n     })\n@@ -954,7 +1048,10 @@ let pluginTests = {\n       }\n       let result = await esbuild.build({\n         entryPoints: [problem],\n-        bundle: true, write: false, format: 'cjs', plugins: [plugin],\n+        bundle: true,\n+        write: false,\n+        format: 'cjs',\n+        plugins: [plugin],\n       })\n       let value = new Function(result.outputFiles[0].text)()\n       assert.deepStrictEqual(value, problem)\n@@ -978,7 +1075,10 @@ let pluginTests = {\n       }\n       let result = await esbuild.build({\n         entryPoints: ['entry'],\n-        bundle: true, write: false, format: 'cjs', plugins: [plugin],\n+        bundle: true,\n+        write: false,\n+        format: 'cjs',\n+        plugins: [plugin],\n       })\n       let value = new Function(result.outputFiles[0].text)()\n       assert.deepStrictEqual(value, problem)\n@@ -1473,75 +1573,73 @@ let pluginTests = {\n     assert.strictEqual(result.outputFiles[0].text, 'import(\"import\");\\n')\n   },\n \n-  async pluginWithWatchMode({ esbuild, service, testDir }) {\n-    for (const toTest of [esbuild, service]) {\n-      const srcDir = path.join(testDir, 'src')\n-      const outfile = path.join(testDir, 'out.js')\n-      const input = path.join(srcDir, 'in.js')\n-      const example = path.join(srcDir, 'example.js')\n-      await mkdirAsync(srcDir, { recursive: true })\n-      await writeFileAsync(input, `import {x} from \"./example.js\"; exports.x = x`)\n-      await writeFileAsync(example, `export let x = 1`)\n-\n-      let onRebuild = () => { }\n-      const result = await toTest.build({\n-        entryPoints: [input],\n-        outfile,\n-        format: 'cjs',\n-        logLevel: 'silent',\n-        watch: {\n-          onRebuild: (...args) => onRebuild(args),\n-        },\n-        bundle: true,\n-        plugins: [\n-          {\n-            name: 'some-plugin',\n-            setup(build) {\n-              build.onLoad({ filter: /example\\.js$/ }, async (args) => {\n-                const contents = await fs.promises.readFile(args.path, 'utf8')\n-                return { contents }\n-              })\n-            },\n+  async pluginWithWatchMode({ esbuild, testDir }) {\n+    const srcDir = path.join(testDir, 'src')\n+    const outfile = path.join(testDir, 'out.js')\n+    const input = path.join(srcDir, 'in.js')\n+    const example = path.join(srcDir, 'example.js')\n+    await mkdirAsync(srcDir, { recursive: true })\n+    await writeFileAsync(input, `import {x} from \"./example.js\"; exports.x = x`)\n+    await writeFileAsync(example, `export let x = 1`)\n+\n+    let onRebuild = () => { }\n+    const result = await esbuild.build({\n+      entryPoints: [input],\n+      outfile,\n+      format: 'cjs',\n+      logLevel: 'silent',\n+      watch: {\n+        onRebuild: (...args) => onRebuild(args),\n+      },\n+      bundle: true,\n+      plugins: [\n+        {\n+          name: 'some-plugin',\n+          setup(build) {\n+            build.onLoad({ filter: /example\\.js$/ }, async (args) => {\n+              const contents = await fs.promises.readFile(args.path, 'utf8')\n+              return { contents }\n+            })\n           },\n-        ],\n+        },\n+      ],\n+    })\n+    const rebuildUntil = (mutator, condition) => {\n+      let timeout\n+      return new Promise((resolve, reject) => {\n+        timeout = setTimeout(() => reject(new Error('Timeout after 30 seconds')), 30 * 1000)\n+        onRebuild = args => {\n+          try { if (condition(...args)) clearTimeout(timeout), resolve(args) }\n+          catch (e) { clearTimeout(timeout), reject(e) }\n+        }\n+        mutator()\n       })\n-      const rebuildUntil = (mutator, condition) => {\n-        let timeout\n-        return new Promise((resolve, reject) => {\n-          timeout = setTimeout(() => reject(new Error('Timeout after 30 seconds')), 30 * 1000)\n-          onRebuild = args => {\n-            try { if (condition(...args)) clearTimeout(timeout), resolve(args) }\n-            catch (e) { clearTimeout(timeout), reject(e) }\n-          }\n-          mutator()\n-        })\n-      }\n+    }\n \n-      try {\n-        let code = await readFileAsync(outfile, 'utf8')\n-        let exports = {}\n+    try {\n+      let code = await readFileAsync(outfile, 'utf8')\n+      let exports = {}\n+      new Function('exports', code)(exports)\n+      assert.strictEqual(result.outputFiles, void 0)\n+      assert.strictEqual(typeof result.stop, 'function')\n+      assert.strictEqual(exports.x, 1)\n+\n+      // First rebuild: edit\n+      {\n+        const [error2, result2] = await rebuildUntil(\n+          () => writeFileAtomic(example, `export let x = 2`),\n+          () => fs.readFileSync(outfile, 'utf8') !== code,\n+        )\n+        code = await readFileAsync(outfile, 'utf8')\n+        exports = {}\n         new Function('exports', code)(exports)\n-        assert.strictEqual(result.outputFiles, void 0)\n-        assert.strictEqual(typeof result.stop, 'function')\n-        assert.strictEqual(exports.x, 1)\n-\n-        // First rebuild: edit\n-        {\n-          const [error2, result2] = await rebuildUntil(\n-            () => writeFileAtomic(example, `export let x = 2`),\n-            () => fs.readFileSync(outfile, 'utf8') !== code,\n-          )\n-          code = await readFileAsync(outfile, 'utf8')\n-          exports = {}\n-          new Function('exports', code)(exports)\n-          assert.strictEqual(error2, null)\n-          assert.strictEqual(result2.outputFiles, void 0)\n-          assert.strictEqual(result2.stop, result.stop)\n-          assert.strictEqual(exports.x, 2)\n-        }\n-      } finally {\n-        result.stop()\n+        assert.strictEqual(error2, null)\n+        assert.strictEqual(result2.outputFiles, void 0)\n+        assert.strictEqual(result2.stop, result.stop)\n+        assert.strictEqual(exports.x, 2)\n       }\n+    } finally {\n+      result.stop()\n     }\n   },\n \n@@ -1722,6 +1820,39 @@ let pluginTests = {\n     }\n     assert.strictEqual(resolveKind, 'url-token')\n   },\n+\n+  async warnIfUnusedNoWarning({ esbuild }) {\n+    const build = await esbuild.build({\n+      entryPoints: ['entry'],\n+      bundle: true,\n+      write: false,\n+      logLevel: 'silent',\n+      plugins: [{\n+        name: 'plugin',\n+        setup(build) {\n+          build.onResolve({ filter: /.*/ }, args => {\n+            if (args.importer === '') return { path: args.path, namespace: 'entry' }\n+            else return { path: args.path, namespace: 'bare-import' }\n+          })\n+          build.onLoad({ filter: /.*/, namespace: 'entry' }, () => {\n+            return {\n+              contents: `\n+                import \"base64\"\n+                import \"binary\"\n+                import \"dataurl\"\n+                import \"json\"\n+                import \"text\"\n+              `,\n+            }\n+          })\n+          build.onLoad({ filter: /.*/, namespace: 'bare-import' }, args => {\n+            return { contents: `[1, 2, 3]`, loader: args.path }\n+          })\n+        },\n+      }],\n+    })\n+    assert.strictEqual(build.warnings.length, 0)\n+  },\n }\n \n async function main() {\n@@ -1738,15 +1869,12 @@ async function main() {\n     process.exit(1)\n   }, minutes * 60 * 1000)\n \n-  // Start the esbuild service\n-  const service = await esbuild.startService()\n-\n   // Run all tests concurrently\n   const runTest = async ([name, fn]) => {\n     let testDir = path.join(rootTestDir, name)\n     try {\n       await mkdirAsync(testDir)\n-      await fn({ esbuild, service, testDir })\n+      await fn({ esbuild, testDir })\n       removeRecursiveSync(testDir)\n       return true\n     } catch (e) {\n@@ -1757,9 +1885,6 @@ async function main() {\n   const tests = Object.entries(pluginTests)\n   const allTestsPassed = (await Promise.all(tests.map(runTest))).every(success => success)\n \n-  // Clean up test output\n-  service.stop()\n-\n   if (!allTestsPassed) {\n     console.error(`❌ plugin tests failed`)\n     process.exit(1)"},{"sha":"1ab6ec8f9b2c0046924bc9a7233852d07c022116","filename":"scripts/terser-tests.js","status":"modified","additions":5,"deletions":7,"changes":12,"blob_url":"https://github.com/evanw/esbuild/blob/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fterser-tests.js","raw_url":"https://github.com/evanw/esbuild/raw/ee1260f1348d99bd2c5d92f746d1badb6e0414f5/scripts%2Fterser-tests.js","contents_url":"https://api.github.com/repos/evanw/esbuild/contents/scripts%2Fterser-tests.js?ref=ee1260f1348d99bd2c5d92f746d1badb6e0414f5","patch":"@@ -27,7 +27,6 @@ async function main() {\n \n   // Start the esbuild service\n   const esbuild = installForTests();\n-  const service = await esbuild.startService();\n \n   // Find test files\n   const compressDir = path.join(terserDir, 'test', 'compress');\n@@ -36,15 +35,14 @@ async function main() {\n   // Run all tests concurrently\n   let passedTotal = 0;\n   let failedTotal = 0;\n-  const runTest = file => test_file(service, path.join(compressDir, file))\n+  const runTest = file => test_file(esbuild, path.join(compressDir, file))\n     .then(({ passed, failed }) => {\n       passedTotal += passed;\n       failedTotal += failed;\n     });\n   await Promise.all(files.map(runTest));\n \n   // Clean up test output\n-  service.stop();\n   childProcess.execSync(`rm -fr \"${testDir}\"`);\n \n   console.log(`${failedTotal} failed out of ${passedTotal + failedTotal}`);\n@@ -53,11 +51,11 @@ async function main() {\n   }\n }\n \n-async function test_file(service, file) {\n+async function test_file(esbuild, file) {\n   let passed = 0;\n   let failed = 0;\n   const tests = parse_test(file);\n-  const runTest = name => test_case(service, tests[name])\n+  const runTest = name => test_case(esbuild, tests[name])\n     .then(() => passed++)\n     .catch(e => {\n       failed++;\n@@ -69,7 +67,7 @@ async function test_file(service, file) {\n }\n \n // Modified from \"terser/demo/test/compress.js\"\n-async function test_case(service, test) {\n+async function test_case(esbuild, test) {\n   const sandbox = require(path.join(terserDir, 'test', 'sandbox'));\n   const log = (format, args) => { throw new Error(tmpl(format, args)); };\n \n@@ -119,7 +117,7 @@ async function test_case(service, test) {\n \n   // Run esbuild as a minifier\n   try {\n-    var { code: output } = await service.transform(ast_as_string, {\n+    var { code: output } = await esbuild.transform(ast_as_string, {\n       minify: true,\n       keepNames: test.options.keep_fnames,\n     });"}]}]